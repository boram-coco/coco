[
  {
    "objectID": "posts/Python/4. Class/python 11_0511.html",
    "href": "posts/Python/4. Class/python 11_0511.html",
    "title": "파이썬 (0511) 11주차",
    "section": "",
    "text": "!pip install pillow\n\nCollecting pillow\n  Downloading Pillow-9.4.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 57.2 MB/s eta 0:00:00a 0:00:01\nInstalling collected packages: pillow\nSuccessfully installed pillow-9.4.0\n- 예제1\n- 예제2"
  },
  {
    "objectID": "posts/Python/4. Class/python 11_0511.html#클래스-사용법",
    "href": "posts/Python/4. Class/python 11_0511.html#클래스-사용법",
    "title": "파이썬 (0511) 11주차",
    "section": "클래스 사용법",
    "text": "클래스 사용법\n- 클래스를 선언\n\nclass STOOOP:\n    title=\"학교폭력\"\n    url= url1\n    end=\"멈춰~~~~\"\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\n규칙1: 메소드(=class안에 정의된 함수)의 첫번째 인자는 무조건 self\n규칙2: 메소드에서 class 안에 정의된 변수들(title, url, end)를 사용하려면 “self.변수이름”과 같은 형식으로 쓴다.\n\n즉 “self.title”, “self.url”, “self.end”와 같은 방식으로 써야한다.\n\n참고: 규칙2에서 가끔 self의 자리에 “STOOOP.title”, “STOOOP.url”, “STOOOP.end”와 같이 클래스의 이름으로 쓰기도 한다.\n\n- 클래스 사용에서\n- (예시1) STOOOP 클래스 -> school instance를 만드는 과정\n\nschool=STOOOP()\n\n\nschool.stop()\n\n학교폭력\n\n\n\n\n\n멈춰~~~~\n\n\n- (예시2) STOOOP 클래스 -> kospi 인스턴스를 만듬\n\nkospi=STOOOP()\n\n\nkospi.title=\"KOSPI 하락\"\n\n\nkospi.stop()\n\nKOSPI 하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n클래스의 성능\n- 성능1: 클래스에서 인스터스를 생성\n\nschool = STOOOP()\nkospi = STOOOP()\n\n\n함수의 사용법과 비슷하다.\n클래스 이름을 쓰고 콘텐츠를 구체화 하는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. 이때는 STOOOP(입력1, 입력2)와 같이 생성\n위의 예시는 따로 입력이 없으므로 비워둔 상태임. 즉 STOOOP()와 같은 식으로 생성.\n\n- 성능2: 클래스에서 만들어진 인스턴스는 그 내부에 변수를 따로 가지고 있는데, 그것을 독립적으로 출력 혹은 변경할 수 있다.\n\nschool.title #출ㄺ\n\n'학교폭력'\n\n\n\nkospi.title #출력\n\n'학교폭력'\n\n\n\nkospi.title = '코스피하락' #변경\n\n\nkospi.title\n\n'코스피하락'\n\n\n- 성능3: 클래스에서 만들어진 인스턴스는 그 내부에 자체적인 함수를 가지는데, 이것을 사용할 수 있다.\n\nschool.stop()\n\n학교폭력\n\n\n\n\n\n멈춰~~~~\n\n\n\nkospi.stop()\n\n코스피하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n연습문제\n문제1 아래의 클래스를 구현하라.\n- 클래스내에는 변수 a가 있고, 변수 a의 초기값은 True이다.\n- 클래스에는 show()라는 메소드가 있는데, a의 값을 출력하는 기능을 한다.\n(풀이)\n\nclass Klass1:\n    a = True\n    def show(self):\n        print(self.a)\n\n\nex1=Klass1()\n\n\nex1.a\n\nTrue\n\n\n\nex1.show()\n\nTrue\n\n\n문제2 아래의 클래스를 구현하라.\n- 클래스내에는 변수 a가 있고, 변수 a의 초기값은 1이다.\n- 클래스에는 up()라는 메소드가 있는데, a의 값을 1증가시키는 기능을 한다.\n(풀이)\n\nclass Klass2:\n    a=1\n    def up(self):\n        self.a = self.a + 1\n\n\nex2=Klass2()\n\n\nex2.a\n\n1\n\n\n\nex2.up()\n\n\nex2.a\n\n2\n\n\n\nex2.up()\nex2.up()\nex2.up()\nex2.up()\nex2.a\n\n6\n\n\n문제3 아래의 클래스를 구현하라.\n- 클래스내에는 변수 a가 있고, 변수 a의 초기값은 0이다.\n- 클래스에는 up(),down(), show()라는 메소드가 있는데, 각각은 a의 값을 1증가시키고, 1감소시키고, a의 값을 출력하는 기능을 한다.\n(풀이)\n\nclass Klass3:\n    a=0\n    def up(self):\n        self.a=self.a+1\n        \n    def down(self):\n        self.a=self.a-1\n        \n    def show(self):\n        print(self.a)\n\n\nex3=Klass3()\n\n\nex3.show()\n\n0\n\n\n\nex3.up()\nex3.show()\n\n1\n\n\n\nex3.down()\nex3.show()\n\n0\n\n\n문제4 아래의 클래스를 구현하라.\n- 클래스내에는 변수 url이 있고, 초기값은 url1이다.\nurl1:’https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true’\n- 클래스에는 show()라는 메소드를 가지는데, 아래와 같은 기능을 한다. - 기능1: url의 그림을 출력 - 기능2: ‘당신은 이 그림을 \\(n\\)번 보았습니다.’ 출력.\\(n\\)은 그림을 본 횟수\n\nurl1\n\n'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n\n\n(풀이)\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n        self.n = self.n+1 \n\n\na=Klass4()\n\n\na.show()\n\n\n\n\n당신은 이 이미지를 3번 보았습니다\n\n\n\nb=Klass4()\nb.url=url2\n\n\nb.show() # a와 독립적으로..\n\n\n\n\n당신은 이 이미지를 2번 보았습니다\n\n\n\n\n숙제\n\nimport numpy as np\n\n\nnp.random.choice([\"가위\",\"바위\",\"보\"])\n\n'보'\n\n\n\nclass homework:\n    def show(self):\n        self.work=np.random.choice([\"가위\",\"바위\",\"보\"])\n        print(self.work)\n\n\nwork = homework()\n\n\nwork.show()\n\n가위"
  },
  {
    "objectID": "posts/Python/4. Class/python 13_0530.html",
    "href": "posts/Python/4. Class/python 13_0530.html",
    "title": "파이썬 (0530) 13주차",
    "section": "",
    "text": "- 상속\n\n\n- 아래와 같은 클래스를 만들자. - 이름, 직급, 연봉에 대한 정보가 있다. - 연봉을 올려주는 메소드가 존재\n\nclass Employee:\n    def __init__(self, name, position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct)\n        \n\n- 확인\n\niu = Employee('iu', position='staff', pay=5000)\nhynn = Employee('hynn', position='staff', pay=4000)\nhd = Employee('hodonh', position='mgr', pay=8000)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5000 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4000 \n        \n\n\n\nhd\n\n\n        이름: hodonh \n        직급: mgr \n        연봉: 8000 \n        \n\n\n\niu.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn.giveraise(0.2)\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4800.0 \n        \n\n\n- 회사의 모든 직원의 연봉을 10%씩 올려보자.\n\niu = Employee('iu', position='staff', pay=5000)\nhynn = Employee('hynn', position='staff', pay=4000)\nhd = Employee('hodonh', position='mgr', pay=8000)\n\n\nfor i in [iu, hynn, hd]:\n    print(i.name)\n\niu\nhynn\nhodonh\n\n\n\nfor i in [iu, hynn, hd]:\n    i.giveraise(0.1) # 일괄적으로 상승\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodonh \n        직급: mgr \n        연봉: 8800.0 \n        \n\n\n- 매니저 직급은 일반직원들의 상승분에서 5%의 보너스가 추가되어 상승한다고 가정\n- 모든회사 직원들의 연봉을 10% 상승\n(구현1) if문을 통한\n\niu = Employee('iu', position='staff', pay=5000)\nhynn = Employee('hynn', position='staff', pay=4000)\nhd = Employee('hodonh', position='mgr', pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    if i.position == 'mgr':\n        i.giveraise(0.1 + 0.05)\n    else:\n        i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodonh \n        직급: mgr \n        연봉: 9200.0 \n        \n\n\n(구현2) 새로운 클래스를 만들자\n\nclass Manager:\n    def __init__(self, name, position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n        \n\n\niu = Employee('iu', position='staff', pay=5000)\nhynn = Employee('hynn', position='staff', pay=4000)\nhd = Manager('hodonh', position='mgr', pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodonh \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n- 구현3: 이미 만들어진 클래스에서\n\nclass Manager(Employee):\n    # 나머지 기타 함수내용은 Emplyee 클래스와 같음걸 표현하려면 위 가로에 Employee를 작성한다.\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n        \n\n\nhd=Manager('hodong',pay=8000)\nhd  # 명시하지 않았는데 상속됨\n\n\n        이름: hodong \n        직급: None \n        연봉: 8000 \n        \n\n\n\niu = Employee('iu', position='staff', pay=5000)\nhynn = Employee('hynn', position='staff', pay=4000)\nhd = Manager('hodonh', position='mgr', pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodonh \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n- 요약: 이미 만들어진 클래스에서 대부분의 기능은 그대로 쓰지만 일부기능만 변경 혹은 추가하고 싶다면 클래스를 상속하면 된다!\n\n\n\n\n내가 만든 클래스를 계속 상속하는 경우\n\n- list 와 비슷한데 멤버들의 빈도가 계산되는 메소드를 포함하는 새로운 나만의 list를 만들자\n\nlst = ['a','b','a','c','b','a','d']\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n- 아래와 같은 딕셔너리를 만들고 싶다.\n\nfreq = {'a':3, 'b':2, 'c':1, 'd':1}  # 갯수\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n\nlst.frequency()를 입력하면 위의 기능이 수행되도록 변형된 list를 쓰고 싶다.\n\n- 구현\n(시도1) 절반 성공\n\nfreq = {'a':0, 'b':0, 'c':0, 'd':0}   # 일단 다 0이라 생각하고 코드 짜기 \nfreq\n\n{'a': 0, 'b': 0, 'c': 0, 'd': 0}\n\n\n\nfor item in lst:\n    print(item)\n\na\nb\na\nc\nb\na\nd\n\n\n\nfor item in lst:\n    print(freq[item])\n\n0\n0\n0\n0\n0\n0\n0\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n반쯤 성공.. 리스트가 a,b,c,d 라는걸 알고 있어야 함\n(시도2) 실패\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\nKeyError: 'a'\n\n\n\nfreq['a']  # 매칭되는게 없다!\n\nKeyError: 'a'\n\n\n에러이유? freq['a'] 를 호출할 수 없다 -> freq.get('a',0)을 이용\n\nfreq.get('a')   # 4주차 3월 23일 복습  get메소드를 사용하면 없어도 에러를 표시하지 않음\n\n\nfreq.get?\n\n\nSignature: freq.get(key, default=None, /)\nDocstring: Return the value for key if key is in the dictionary, else default.\nType:      builtin_function_or_method\n\n\n\n\n\nkey에 대응하는 값이 있으면 그 값을 리턴하고 없으면 default를 리턴\n\n\nfreq.get('a',0)  # a값 없으면 0으로 리턴\n\n0\n\n\n(시도3)\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq.get(item,0) + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n- 이것을 내가 정의하는 새로운 list의 메소드로 넣고 싶다.\n\nclass L(list):   # L 이라는 클래스에 list에 있는 모든걸 상속받겠다.\n    pass\n\n\na=[1,2,3]\na\n\n[1, 2, 3]\n\n\n\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n\nclass L(list):\n    def frequency(self):\n        freq = dict()\n        for item in self:\n            freq[item] = freq.get(item,0) + 1\n        return freq\n\n\nlst = L([1,1,1,2,2,3])\n\n\nlst?  \n\nSyntaxError: invalid syntax (<ipython-input-96-8d8983ef4faf>, line 1)\n\n\n\n # 리스트 같아 보이지만 타입이 L! 내가 설정한 클래스\n\n\nlst  #원래 list에 있는 repr 기능을 상속받아서 이루어지는 결과\n\n[1, 1, 1, 2, 2, 3]\n\n\n\n_lst = L([4,5,6])\n_lst + _lst   # L자로형끼리 덧셈\n\n[4, 5, 6, 4, 5, 6]\n\n\n\nlst + [4,5,6]   # l자료형과  list 자료형의 덧셈도 가능\n\n[1, 1, 1, 2, 2, 3, 10, 10, 4, 5, 6]\n\n\n\nL자료형의 덧셈은 list의 덧셈과 완전히 같음\n\n\nlst.append(10)\nlst   # 요론 기본적인 리스트 기능도 가능\n\n[1, 1, 1, 2, 2, 3, 10, 10]\n\n\n\nlst.frequency()  # 리스트에서 이것 기능만 추가된거랑 똑같고 나머지는 다 리스트랑 똑같다\n\n{1: 3, 2: 2, 3: 1}"
  },
  {
    "objectID": "posts/Python/4. Class/python 13_0530.html#appendix-사용자-정의-자료형의-유용함",
    "href": "posts/Python/4. Class/python 13_0530.html#appendix-사용자-정의-자료형의-유용함",
    "title": "파이썬 (0530) 13주차",
    "section": "Appendix: 사용자 정의 자료형의 유용함",
    "text": "Appendix: 사용자 정의 자료형의 유용함\n- 사용자정의 자료형이 어떤 경우에는 유용할 수 있다.\n\n!pip install matplotlib\n\nCollecting matplotlib\n  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 97.5 MB/s eta 0:00:00a 0:00:01\nCollecting fonttools>=4.22.0\n  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 965.4/965.4 kB 81.8 MB/s eta 0:00:00\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib) (23.0)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib) (2.8.2)\nCollecting pyparsing>=2.2.1\n  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 18.6 MB/s eta 0:00:00\nCollecting kiwisolver>=1.0.1\n  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 82.9 MB/s eta 0:00:00\nRequirement already satisfied: numpy>=1.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib) (1.21.6)\nCollecting cycler>=0.10\n  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\nRequirement already satisfied: pillow>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: typing-extensions in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.4.0)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, matplotlib\nSuccessfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.5.3 pyparsing-3.0.9\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n- 예제1\n\nyear = ['2016', '2017', '2017', '2017', 2017, 2018, 2018, 2019, 2019]\nvalue = np.random.randn(9)\n\n\ndf = pd.DataFrame({'year':year, 'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      0.729447\n    \n    \n      1\n      2017\n      0.110630\n    \n    \n      2\n      2017\n      0.108119\n    \n    \n      3\n      2017\n      -0.095107\n    \n    \n      4\n      2017\n      -0.337716\n    \n    \n      5\n      2018\n      -0.134635\n    \n    \n      6\n      2018\n      -2.182677\n    \n    \n      7\n      2019\n      -0.150227\n    \n    \n      8\n      2019\n      0.849774\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value)\n\nTypeError: 'value' must be an instance of str or bytes, not a int\n\n\n\n\n\n\ndf.year\n\n0    2016\n1    2017\n2    2017\n3    2017\n4    2017\n5    2018\n6    2018\n7    2019\n8    2019\nName: year, dtype: object\n\n\n\ndtype이 object 로 되어있어서 그림이 그려지지 않는다.. float로 되어야 할텐데?\n에러의 이유: df.year에 str, int가 동시에 있음\n\n\nnp.array(df.year)\n\narray(['2016', '2017', '2017', '2017', 2017, 2018, 2018, 2019, 2019],\n      dtype=object)\n\n\n\n자료형의 형태를 바꿔주면 해결할 수 있다.\n\n\nnp.array(df.year, dtype=np.float64)\n\narray([2016., 2017., 2017., 2017., 2017., 2018., 2018., 2019., 2019.])\n\n\n\nnp.array(df.year).astype(np.float64) # 위와 같은 효과\n\narray([2016., 2017., 2017., 2017., 2017., 2018., 2018., 2019., 2019.])\n\n\n\ndf.year.astype(np.float64)  # 위와 같은 효과\n\n0    2016.0\n1    2017.0\n2    2017.0\n3    2017.0\n4    2017.0\n5    2018.0\n6    2018.0\n7    2019.0\n8    2019.0\nName: year, dtype: float64\n\n\n\nplt.plot(df.year.astype(np.float64), df.value,'.')\n\n\n\n\n- 예제2\n\nyear = ['2016', '2017', '2017', '2017년', 2017, 2018, 2018, 2019, 2019]\nvalue = np.random.randn(9)\n\n\ndf = pd.DataFrame({'year':year, 'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      -0.254312\n    \n    \n      1\n      2017\n      0.839603\n    \n    \n      2\n      2017\n      -1.386845\n    \n    \n      3\n      2017년\n      0.010756\n    \n    \n      4\n      2017\n      0.949379\n    \n    \n      5\n      2018\n      0.280954\n    \n    \n      6\n      2018\n      -0.227516\n    \n    \n      7\n      2019\n      -1.100002\n    \n    \n      8\n      2019\n      0.152285\n    \n  \n\n\n\n\n\nnp.array(df.year, dtype=np.float64) # \"년\"이 써있어서 타입을 일괄적으로 바꾸기 어렵다.\n\nValueError: could not convert string to float: '2017년'\n\n\n\ndf.year   # 어떤 값이 있는지 확인\n\n0     2016\n1     2017\n2     2017\n3    2017년\n4     2017\n5     2018\n6     2018\n7     2019\n8     2019\nName: year, dtype: object\n\n\n\nnp.unique(df.year)   # 섞여있는 타입에서는 unique는 동작하지 않는다.\n\nTypeError: '<' not supported between instances of 'int' and 'str'\n\n\n\nL(df.year).frequency()\n\n{'2016': 1, '2017': 2, '2017년': 1, 2017: 1, 2018: 2, 2019: 2}\n\n\n\n’2016’과 같은 형태, ’2017년’과 같은 형태, 숫자형이 혼합 .. 이라는 파악 가능 -> 맞춤형 변환이 필요함\n\n\n'2017년'.replace(\"년\",\"\")\n\n'2017'\n\n\n\ndef f(a):    # 데이터의 구조를 모르면 이런 함수를 짤 수가 없다. -> 자료의 구조를 확인해준다는 의미에서 freq가 있다면 편리하다.\n    if type(a) is str:\n        if \"년\" in a:\n            return int(a.replace(\"년\",\"\"))\n        else:\n            return int(a)\n    else:\n        return a\n\n\n[f(a) for a in df.year]\n\n[2016, 2017, 2017, 2017, 2017, 2018, 2018, 2019, 2019]\n\n\n\ndf.year = [f(a) for a in df.year]\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      -0.254312\n    \n    \n      1\n      2017\n      0.839603\n    \n    \n      2\n      2017\n      -1.386845\n    \n    \n      3\n      2017\n      0.010756\n    \n    \n      4\n      2017\n      0.949379\n    \n    \n      5\n      2018\n      0.280954\n    \n    \n      6\n      2018\n      -0.227516\n    \n    \n      7\n      2019\n      -1.100002\n    \n    \n      8\n      2019\n      0.152285\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value, '.')"
  },
  {
    "objectID": "posts/Python/4. Class/python 10_0509.html",
    "href": "posts/Python/4. Class/python 10_0509.html",
    "title": "파이썬 (0509) 10주차",
    "section": "",
    "text": "# jupyter notebook을 통한 ppt발표(슬라이드)가 가능. 관련 프로그램을 깔아야한다."
  },
  {
    "objectID": "posts/Python/4. Class/python 10_0509.html#밈meme과-클래스",
    "href": "posts/Python/4. Class/python 10_0509.html#밈meme과-클래스",
    "title": "파이썬 (0509) 10주차",
    "section": "밈(Meme)과 클래스",
    "text": "밈(Meme)과 클래스\n\n신혜선의 어쩔티비\n- 밈이란? 유전자처럼 복제가능한 something"
  },
  {
    "objectID": "posts/Python/4. Class/python 10_0509.html#클래스",
    "href": "posts/Python/4. Class/python 10_0509.html#클래스",
    "title": "파이썬 (0509) 10주차",
    "section": "클래스",
    "text": "클래스\n- 클래스에 대한 비유적 설명 (implicit definition)\n\n클래스는 과자틀과 비슷하다. 클래스란 똑같은 무엇인가를 계속 만들어 낼 수도 있는 설계도면이고 객체란 클래스로 만든 피조물을 뜻한다. (점프투파이썬)\nIn object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). // 객체 지향 프로그래밍에서 클래스는 상태(멤버 변수) 및 동작 구현(멤버 함수 또는 메서드)에 대한 초기 값을 제공하는 객체 생성을 위한 확장 가능한 프로그램 코드 템플릿입니다.\nhttp://www.tcpschool.com/java/java_class_intro\nhttps://javacpro.tistory.com/29\nhttps://ko.wikipedia.org/wiki/%ED%81%B4%EB%9E%98%EC%8A%A4_(%EC%BB%B4%ED%93%A8%ED%84%B0_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D)\n\n- 클래스에 대한 명시적 정의 (교수님 생각)\n\n클래스는 복제, 변형, 재생산을 용이하게 하기 위해 만들어진 확장가능한 프로그램의 코드의 단위(extensible program-code-template)이다. 즉 밈이다.\n\n- 클래스도 결국 밈이다. 생각해보면 클래스를 만들고 사용하는 과정이 인터넷에서 밈을 만들고 노는것과 닮아 있다.\n\n1단계: 개념의 인지 (이거 재미있겠다 밈으로 만들자 // 이 코드 쓸모있다, 이 코드를 쉽게 찍어내는 클래스로 만들어두자)\n2단계: 복사하고 싶은 속성을 추려 복사가능한 틀을 만듬 (밈 초기 컨텐츠 // 클래스의 선언)\n3단계: 밈에서 다양한 컨텐츠를 재생산, 때로는 변형하여 재생산, 때로는 그것을 응용한 다른밈을 만듬 (밈화 // 클래스의 인스턴스화, 상속, 메소드오버라이딩)"
  },
  {
    "objectID": "posts/Python/4. Class/python 10_0509.html#멈춰-밈을-컨텐츠화",
    "href": "posts/Python/4. Class/python 10_0509.html#멈춰-밈을-컨텐츠화",
    "title": "파이썬 (0509) 10주차",
    "section": "“멈춰” 밈을 컨텐츠화",
    "text": "“멈춰” 밈을 컨텐츠화\n- 멈춰 밈을 이용하여 코스피하락, 수강신청 매크로 등 다양한 예제를 만들자\n\nfrom IPython.core.display import HTML\n\n\n예비학습\n\n문자열포맷팅 (문자열끼워넣기)\n- 예제1\n\n'제 이름은 {}입니다.'.format('보람')\n\n'제 이름은 보람입니다.'\n\n\n-예제2\n\n'제 이름은 {}이고 사는 곳은 {}입니다.'.format('보람','전주')\n\n'제 이름은 보람이고 사는 곳은 전주입니다.'\n\n\n\n'제 이름은 {}이고 사는 곳은 {}입니다.'.format('전주','보람')\n\n'제 이름은 전주이고 사는 곳은 보람입니다.'\n\n\n-예제3\n\n'제 이름은 {name}이고 사는 곳은 {add}입니다.'.format(name='보람',add='전주')\n\n'제 이름은 보람이고 사는 곳은 전주입니다.'\n\n\n\n'제 이름은 {name}이고 사는 곳은 {add}입니다.'.format(add='전주',name='보람')\n\n'제 이름은 보람이고 사는 곳은 전주입니다.'\n\n\n\n\nHTML\n-예제1\n\nHTML(\"<p> 이름 </p>\")\n\n 이름 \n\n\n-예제2\n\nHTML(\"<img src='https://stat.jbnu.ac.kr/sites/stat/atchmnfl_mngr/imageSlide/469/temp_1573001043314100.jpg'>\")\n\n\n\n\n- 예제3\n\nHTML(\"<p> 전북대학교 </p><img src='https://stat.jbnu.ac.kr/sites/stat/atchmnfl_mngr/imageSlide/469/temp_1573001043314100.jpg'>\")\n\n 전북대학교 \n\n\n\n\nHTML을 이용한 밈생성\n- 밈을 위한 이미지 주소\n\nurl1='https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2='https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true'\n\n- 예제1: 원본\n\nhtmlstr.format(title='학교폭력',url=url1,end='멈춰~~~~')\n\n\"<p> 학교폭력 </p> <img src='https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'> <p> 멈춰~~~~ </p>\"\n\n\n\nhtmlstr = \"<p> {title} </p> <img src='{url}'> <p> {end} </p>\"\nHTML(htmlstr.format(title='학교폭력',url=url1,end='멈춰~~~~'))\n\n 학교폭력    멈춰~~~~ \n\n\n- 예제2: 코스피하락 멈춰어\n\nHTML(htmlstr.format(title='코스피하락',url=url1,end='멈춰~~~~'))\n\n 코스피하락    멈춰~~~~ \n\n\n- 예제3: 매크로 멈춰어\n\nHTML(htmlstr.format(title='수강신청매크로',url=url1,end='멈춰~~~~'))\n\n 수강신청매크로    멈춰~~~~ \n\n\n\n\n\n함수를 만들어서 코드를 관리\n- 함수의 선언\n\ndef stop():\n    htmlstr = \"<p> {title} </p> <img src='{url}'> <p> {end} </p>\"\n    display(HTML(htmlstr.format(title=ttl,url=url,end=end)))   #display로 받아주는게 좋다\n    \n\n- 사용\n\nttl = '돈쓰는거'\nurl = url1\nend = '멈춰 ㅠ'\nstop()\n\n 돈쓰는거    멈춰 ㅠ \n\n\n\nttl = '술담배'\nurl = url1\nend = '멈춰!'\nstop()\n\n 술담배    멈춰! \n\n\n\nttl = '코코 주워먹는거'\nurl = url2\nend = '멈춰!!!!!'\nstop()\n\n 코코 주워먹는거    멈춰!!!!! \n\n\n\n\n클래스를 만들어서 관리\n\nclass STOOOP: #STOOOP은 양식문서의 이름이라 생각하자.\n    title = \"학교폭력\"\n    url = url1\n    end = \"멈춰~~~~\"\n    def stop(self):  # 규칙1: class안에서 정의된 함수는 첫번째 입력으로 무조건 self를 받는다.\n        htmlstr = \"<p> {title} </p> <img src='{url}'> <p> {end} </p>\"\n        display(HTML(htmlstr.format(title=self.title,url=self.url,end=self.end))) \n        # 규칙2: class안에서 정의된 변수 (title, url, end)를 쓰려면 \"self.변수이름\"의 형태로 써야함\n\n\nt=1 학교폭력멈춰\n\nschool = STOOOP()   \n\n# STOOOP이라는 이름의 양식문서를 복사해 하나의 hwp 파일을 만들어 밈을 생성하고 그 파일이름을 school이라고 하자.\n# 그러니가 STOOP.hwp 와 school.hwp가 잇다..\n\n\nschool.title\n\n'학교폭력'\n\n\n\nschool.url\n\n'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n\n\n\nschool.end\n\n'멈춰~~~~'\n\n\n\nschool.stop()\n\n 학교폭력    멈춰~~~~ \n\n\n\n\nt=2 코스피하락멈춰\n\nkospi = STOOOP() # 코스피하락 멈춰를 위해 STOOP.hwp양식문서에서 하나의 밈을 찍어낸다. (kospi.hwp)\nkospi.title = '코스피하락' #제목변경\n\n\nkospi.stop()\n\n 코스피하락    멈춰~~~~ \n\n\n\n\nt=3 수강신청매크로 멈춰\n\nmacro = STOOOP()\n\n\nmacro.title, macro.url, macro.end\n\n('학교폭력',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~~')\n\n\n\nmacro.title = \"수강신청매크로\"\n\n\nmacro.stop()\n\n 수강신청매크로    멈춰~~~~ \n\n\n\n\nt=4 수강신청 매크로 멈춰 끝 물결대신 느낌표\n\nmacro.end = \"멈춰!!!!!!!!\"\n\n\nmacro.title, macro.url, macro.end\n\n('수강신청매크로',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰!!!!!!!!')\n\n\n\nmacro.stop()\n\n 수강신청매크로    멈춰!!!!!!!! \n\n\n\n\nt=5 코스피하락 다시 출력 (함수와 비교했을때 실수 발생x)\n\nkospi.stop()\n\n 코스피하락    멈춰~~~~ \n\n\n\n\nt=6 학교폭력 멈춰와 코스피하락 멈춰 동시에 출력\n\nschool.stop()\n\n 학교폭력    멈춰~~~~ \n\n\n\nkospi.stop()\n\n 코스피하락    멈춰~~~~ \n\n\n\n\nt=7 “학교폭력 멈춰”의 이미지를 신혜선으로 변경, “코스피하락 멈춰”의 title을 ’KOSPI하락’으로 변경\n\nschool.url = url2\nkospi.title = \"KOSPI하락\"\n\n\nschool.stop()\n\n 학교폭력    멈춰~~~~ \n\n\n\nkospi.stop()\n\n KOSPI하락    멈춰~~~~ \n\n\n\n\n\n숙제\n“수강신청 멈춰”의 이미지를 신혜선으로 변경하고 출력해볼 것\nmacro.url 변경 macro.stop() 을 사용\n\nmacro.url=url2\n\n\nmacro.stop()\n\n 수강신청매크로    멈춰!!!!!!!!"
  },
  {
    "objectID": "posts/Python/4. Class/python 12_0523.html",
    "href": "posts/Python/4. Class/python 12_0523.html",
    "title": "파이썬 (0523) 12주차",
    "section": "",
    "text": "import numpy as np"
  },
  {
    "objectID": "posts/Python/4. Class/python 12_0523.html#클래스공부-4단계",
    "href": "posts/Python/4. Class/python 12_0523.html#클래스공부-4단계",
    "title": "파이썬 (0523) 12주차",
    "section": "클래스공부 4단계",
    "text": "클래스공부 4단계\n\nMotivating Example\n- 가위바위보\n\n방법1\n\n\nclass RPC2:\n    def throw2(self):\n        print(np.random.choice(['가위', '바위','보']))\n\n\na=RPC2()\n\n\na.throw2()\n\n바위\n\n\n\n방법2\n\n\nclass RPC:\n    def thorw(self, candidate):\n        print(np.random.choice(candidate))\n\n\na=RPC()\n\n\na.thorw(['가위','바위','보'])\n\n바위\n\n\n\n방법3\n\n\nclass RPC3:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n    def throw3(self):\n        print(np.random.choice(self.candidate))\n\n\na=RPC3()   # __init__ 는 암묵적으로 실행\n\n\na.throw3()\n\n바위\n\n\n\n방법4\n\n\nclass RPC4:\n    pass\n\n\nb=RPC4()\n\n\ndef initt(b, candidate=['가위','바위','보']):\n    b.candidate = candidate\n\n\ninitt(b)\n\n\nb.candidate\n\n['가위', '바위', '보']\n\n\n\ndef throww(b):\n        print(np.random.choice(b.candidate))\n\n\nthroww(b)\n\n가위\n\n\n\n방법5\n\n\n# 위의 코드를 하나로 합치면..\n\n\nclass RPC4:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n    def throww(self):\n        print(np.random.choice(self.candidate))\n\n\na=RPC4()\n\n\na.throww()\n\n가위\n\n\n- 생각해보니까 throw는 choose + show 의 결합인 것 같다.\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n    def choose(self):\n        self.actions = np.random.choice(self.candidate)\n    def show(self):\n        print(self.actions)\n\n\na=RPC()\n\n\na.actions()   # 지금은 정의되지 않음\n\nAttributeError: 'RPC' object has no attribute 'actions'\n\n\n\na.choose()\n\n\na.actions  # 가위, 바위, 보 중 고른 결과가 나옴\n\n'가위'\n\n\n\na.show()\n\n가위\n\n\n보충학습 : 위와 같은 코드\n\nclass _RPS: ## 시점1\n    pass # <- 이렇게하면 아무기능이 없는 비어있는 클래스가 정의된다\n\n\n_a = _RPS() ## 시점2\ndef _init(_a,candidate=['가위','바위','보']):\n    _a.candidate = candidate \n_init(_a)\n\n\n_a.actions ## 시점3\n\nAttributeError: '_RPS' object has no attribute 'actions'\n\n\n\ndef _choose(_a): ## 시점4\n    _a.actions = np.random.choice(_a.candidate)\n_choose(_a)\n\n\n_a.actions ## 시점5\n\n'보'\n\n\n\ndef _show(_a): ## 시점6\n    print(_a.actions)\n_show(_a)\n\n보\n\n\n- 또 다른 인스턴스 b를 만들자. b는 가위만 낼 수 있다.\n\nRPC?\n\n\nInit signature: RPC(candidate=['가위', '바위', '보'])\nDocstring:      <no docstring>\nType:           type\nSubclasses:     \n\n\n\n\n\nb=RPC(['가위'])\n\n\nb.candidate\n\n['가위']\n\n\n\nb.choose()\nb.show()\n\n가위\n\n\n- a,b의 선택들을 모아서 기록을 하고 싶다.\n\nclass RPS:\n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])   # 지금 현재 내가 선택한 마지막만 보여줘!\n\n\na=RPS()\nb=RPS(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n바위\n가위\n바위\n바위\n보\n\n\n\na.actions   # 지금까지 뽑힌 히스토리들\n\n['바위', '가위', '바위', '바위', '보']\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\nb.actions\n\n['가위', '가위', '가위', '가위', '가위']\n\n\n\na.candidate, a.actions\n\n(['가위', '바위', '보'], ['바위', '가위', '바위', '바위', '보'])\n\n\n\nb.candidate, b.actions\n\n(['가위'], ['가위', '가위', '가위', '가위', '가위'])\n\n\n- info라는 함수를 만들어서 a의 오브젝트가 가지고 있는 정보를 모두 보도록 하자.\n(예비학습) 문자열 \\n이 포함된다면?\n\n'asdf\\n1234'\n\n'asdf\\n1234'\n\n\n\nprint('asdf\\n1234')\n\nasdf\n1234\n\n\n예비학습 끝\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def info(self):\n        print(\"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions))\n\n\na=RPS()\nb=RPS(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()    \n\n가위\n바위\n가위\n보\n보\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\na.info()\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['가위', '바위', '가위', '보', '보']\n\n\n\nb.info()\n\n낼 수 있는 패: ['가위']\n기록: ['가위', '가위', '가위', '가위', '가위']\n\n\n- 만들고 보니까 info와 print의 기능이 거의 비슷함 \\(\\to\\) print(a)를 하면 a.info()와 동일한 효과를 내도록 만들 수 있을까?\n- 안될 거 같다. 왜?\n\n안될 것 같은 이유 1: print 는 파이썬 내장기능, 내장기능을 우리가 맘대로 커스터마이징해서 쓰기는 어려울 것 같다.\n안될 것 같은 이유 2: 이유1이 해결된다고 해도 문제다. 다 꼬아져버려… 그럼 지금까지 사용했던 print()의 결과는 어떻게 되는가?\n\n(예)\n\ntype(a)\n\n__main__.RPS\n\n\n\na?\n\n\nType:        RPS\nString form: <__main__.RPS object at 0x7f6565f29e10>\nDocstring:   <no docstring>\n\n\n\n\n- 그런데 a의 자료형(RPS자료형)에 해당하는 오브젝트들에 한정하여 print를 수정하는 방법이 가능하다면? (그럼 다른 오브젝트들은 수정된 print에 영향을 받지 않음)\n\n\n__str___\n- 관찰1: 현재 print(a)의 결과는 아래와 같다.\n\nprint(a)\n\n<__main__.RPS object at 0x7f6565f29e10>\n\n\n\nprint([1,2,3])\n\n[1, 2, 3]\n\n\n\na는 RPS클래스에서 만든 오브젝트이며 a가 저장된 메모리 주소는 0x7f6565f29e10라는 의미\n\n- 관찰2: a에는 __str__ 이 있다.\n\ndir(a)   # a + _ + tab을 누르면 숨겨진 메소드들이 나온다.\n\n['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n 'actions',\n 'candidate',\n 'choose',\n 'info',\n 'show']\n\n\n\nset(dir(a)) & {'__str__'}\n\n{'__str__'}\n\n\n\na.__str__\n\n<method-wrapper '__str__' of RPS object at 0x7f6565f29e10>\n\n\n이것을 함수처럼 사용하니까 아래와 같이 된다.\n\na.__str__()\n\n'<__main__.RPS object at 0x7f6565f29e10>'\n\n\n?? print(a)를 해서 나오는 문자열이 리턴된다..\n\nprint(a.__str__()) # 이거 print(a)를 실행한 결과와 같다?\n\n<__main__.RPS object at 0x7f6565f29e10>\n\n\n- 생각: 만약 내가 a.__str__() 라는 함수를 재정의하여 리턴값을 boram hahaha로 바꾸게 되면 print(a)해서 나오는 결과는 어떻게 될까? (해커???)\n(예비학습)\n\ndef f():\n    print('adsf')\n\n\nf()\n\nadsf\n\n\n\ndef f():\n    print('boram hahaha')\n\n\nf()\n\nboram hahaha\n\n\n이런식으로 함수가 이미 정의되어 있더라도, 내가 나중에 덮어씌우면 그 함수의 기능을 다시 정의한다.\n(해킹시작)\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return 'boram hahaha'\n    def info(self):\n        print(\"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions))\n\n\na=RPS()\n\n\nprint(a)\n\nboram hahaha\n\n\n\nprint(a.__str__())\n\nboram hahaha\n\n\n\n# 다른건 다 변함이 없음\n\n\na.choose()\na.show()\n\n가위\n\n\n\na.actions\n\n['가위']\n\n\n\na.info()\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['가위']\n\n\n- __str__의 리턴값을 info에서 타이핑했던 문자열로 재정의 한다면?\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\n\n\na=RPS()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.choose()\na.show()\n\n바위\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['보', '바위']\n\n\n\n\n파이썬의 비밀2\n- print(a)와 print(a.__str__()) 는 같은 문법이다.\n- 참고로 a.__Str__() 와 str(a) 도 같은 문법\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['보', '바위']\"\n\n\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['보', '바위']\"\n\n\n- 지금까지 썼던 기능들 확인!\n(예제1)\n\na=[1,2,3]\nprint(a)\n\n[1, 2, 3]\n\n\n\na.__str__()\n\n'[1, 2, 3]'\n\n\n\nstr(a)\n\n'[1, 2, 3]'\n\n\n(예제2)\n\na={1,2,3}\nprint(a)\n\n{1, 2, 3}\n\n\n\na.__str__()\n\n'{1, 2, 3}'\n\n\n\nstr(a)\n\n'{1, 2, 3}'\n\n\n(예제3)\n\na=np.array(1)\na.shape\n\n()\n\n\n\ntype(a.shape)\n\ntuple\n\n\n\nprint(a.shape)\n\n()\n\n\n\na.shape.__str__()\n\n'()'\n\n\n\nstr(a.shape)\n\n'()'\n\n\n(예제4)\n\na = range(10)\nprint(a)\n\nrange(0, 10)\n\n\n\na.__str__()\n\n'range(0, 10)'\n\n\n(예제5)\n\na = np.arange(100).reshape(10,10)\nprint(a)\n\n[[ 0  1  2  3  4  5  6  7  8  9]\n [10 11 12 13 14 15 16 17 18 19]\n [20 21 22 23 24 25 26 27 28 29]\n [30 31 32 33 34 35 36 37 38 39]\n [40 41 42 43 44 45 46 47 48 49]\n [50 51 52 53 54 55 56 57 58 59]\n [60 61 62 63 64 65 66 67 68 69]\n [70 71 72 73 74 75 76 77 78 79]\n [80 81 82 83 84 85 86 87 88 89]\n [90 91 92 93 94 95 96 97 98 99]]\n\n\n\na.__str__()\n\n'[[ 0  1  2  3  4  5  6  7  8  9]\\n [10 11 12 13 14 15 16 17 18 19]\\n [20 21 22 23 24 25 26 27 28 29]\\n [30 31 32 33 34 35 36 37 38 39]\\n [40 41 42 43 44 45 46 47 48 49]\\n [50 51 52 53 54 55 56 57 58 59]\\n [60 61 62 63 64 65 66 67 68 69]\\n [70 71 72 73 74 75 76 77 78 79]\\n [80 81 82 83 84 85 86 87 88 89]\\n [90 91 92 93 94 95 96 97 98 99]]'\n\n\n\nstr(a)\n\n'[[ 0  1  2  3  4  5  6  7  8  9]\\n [10 11 12 13 14 15 16 17 18 19]\\n [20 21 22 23 24 25 26 27 28 29]\\n [30 31 32 33 34 35 36 37 38 39]\\n [40 41 42 43 44 45 46 47 48 49]\\n [50 51 52 53 54 55 56 57 58 59]\\n [60 61 62 63 64 65 66 67 68 69]\\n [70 71 72 73 74 75 76 77 78 79]\\n [80 81 82 83 84 85 86 87 88 89]\\n [90 91 92 93 94 95 96 97 98 99]]'\n\n\n\n\n__repr__\n- 생각해보니까 print를 해서 원하는 정보를 확인하는 건 아니었음\n\na=[1,2,3]\n\n\na\n\n[1, 2, 3]\n\n\n\nprint(a)   # print(a.__str__()) + enter => a + enter 와 같은 효과?\n\n[1, 2, 3]\n\n\n- a + 엔터를 하면 print(a) + 엔터를 하는 것과 같은 효과인가?\n(반례)\n\na=np.array([1,2,3,4]).reshape(2,2)\n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nprint(a)\n\n[[1 2]\n [3 4]]\n\n\n- a + 엔터를 하면 print(a) + 엔터가 다른 경우도 있다. \\(\\to\\) 서로 다른 숨겨진 기능이 잇다! \\(\\to\\) 결론 : 그 기능은 __repr__에 저장되어 있다.\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\n\n\na=RPS()\n\n\na  # print(a.__repr__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- 그럼 지금까지 한것은?\n\na = np.array([1,2,3])\n\n\na\n\narray([1, 2, 3])\n\n\n\nprint(a)\n\n[1 2 3]\n\n\n\na.__repr__()\n\n'array([1, 2, 3])'\n\n\n\na.__str__()\n\n'[1 2 3]'\n\n\n\n\n파이썬의 비밀3\n- 대화형 콘솔에서 오브젝트 이름 + 엔터 를 쳐서 나오는 출력은 __repr__ 의 결과와 연관 있다.\n\na = np.array(range(10000)).reshape(100,100)\n\n\na\n\narray([[   0,    1,    2, ...,   97,   98,   99],\n       [ 100,  101,  102, ...,  197,  198,  199],\n       [ 200,  201,  202, ...,  297,  298,  299],\n       ...,\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])\n\n\n\na.__repr__()\n\n'array([[   0,    1,    2, ...,   97,   98,   99],\\n       [ 100,  101,  102, ...,  197,  198,  199],\\n       [ 200,  201,  202, ...,  297,  298,  299],\\n       ...,\\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])'\n\n\n- 참고로 a.__repr__() 은 representation의 약자인데, repr(a)와 같다.\n\n\n주피터 노브북의 비밀 (__repr__html__)\n- 요즘에는 IDE의 발전에 따라서 오브젝트이름+엔터 칠때 나오는 출력의 형태도 다양해지고 있다.\n\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n예쁘게 나온다.\n\n- 그런데? print(df.__repr__())의 결과가 조금 다르게 나온당\n\nprint(df.__repr__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n- print(df.__repr__()) 는 예전 검은화면에서 코딩할 때가 나오는 출력임\nPython 3.10.2 | packaged by conda-forge | (main, Feb  1 2022, 19:28:35) [GCC 9.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n> >> import pandas as pd \n>>> df = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})>>> df\n   a  b\n0  1  2\n1  2  3\n2  3  4\n>>>\n- 주피터에서는? “오브젝트이름+엔터”치면 HTML(df._repr_html_())이 실행되고, _repr_html_()이 정의되어 있지 않으면 print(df.__repr__())이 실행된다.\n\ndf._repr_html_()\n\n'<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>a</th>\\n      <th>b</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>1</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>2</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>3</td>\\n      <td>4</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>'\n\n\n\nhtml코드\n\n\nfrom IPython.core.display import HTML\n\n\nHTML('<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>a</th>\\n      <th>b</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>1</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>2</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>3</td>\\n      <td>4</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\nHTML(df._repr_html_())\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n- 물론 df._repr_html_() 함수가 내부적으로 있어도 html이 지원되지 않는 환경이라면 print(__repr__())이 내부적으로 수행된다.\n\n\n__repr__와 __str__의 우선적용 순위\n(예제1)\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\n\n\na=RPS()\na\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__repr__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nrepr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n- 여기까지는 상식수준의 결과. 아래 관찰하자\n\nprint(a) # print(a.__str__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n- __str__()은 건드린적이 없다…?\n\na.__repr__??\n\n\nSignature: a.__repr__()\nDocstring: Return repr(self).\nSource:   \n    def __repr__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\nFile:      ~/Dropbox/coco/posts/python/<ipython-input-201-29baf6ff56bf>\nType:      method\n\n\n\n\n얘는 건드림\n\na.__str__??\n\n\nSignature:      a.__str__()\nCall signature: a.__str__(*args, **kwargs)\nType:           method-wrapper\nString form:    <method-wrapper '__str__' of RPS object at 0x7f6561614c10>\nDocstring:      Return str(self).\n\n\n\n\n얘는 안건드렸는디..\n(예제2)\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\n\n\na=RPS()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na\n\n<__main__.RPS at 0x7f6561429950>\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\na.__repr__()\n\n'<__main__.RPS object at 0x7f6561429950>'\n\n\n\na.__str__??\n\n\nSignature: a.__str__()\nDocstring: Return str(self).\nSource:   \n    def __str__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\nFile:      ~/Dropbox/coco/posts/python/<ipython-input-214-cd2a21868510>\nType:      method\n\n\n\n\n\na.__repr_??\n\nObject `a.__repr_` not found.\n\n\n(예제3)\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return \"haha\"\n    def __str__(self):\n        return \"낼 수 있는 패: {}\\n기록: {}\".format(self.candidate,self.actions)\n\n\na=RPS()\n\n\na\n\nhaha\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- __str__ 와 __repr__ 을 건드리지 않고 출력결과를 바꾸고 싶다면?\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions)\n\n\na=RPS()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: []\n        \n\n\n\nprint(a)\n\n<__main__.RPS object at 0x7f6561534410>\n\n\n\nstr(a)\n\n'<__main__.RPS object at 0x7f6561534410>'\n\n\n\nrepr(a)\n\n'<__main__.RPS object at 0x7f6561534410>'\n\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n바위\n바위\n바위\n가위\n보\n\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: ['바위', '바위', '바위', '가위', '보']"
  },
  {
    "objectID": "posts/Python/4. Class/python 13_0525.html",
    "href": "posts/Python/4. Class/python 13_0525.html",
    "title": "파이썬 (0525) 13주차",
    "section": "",
    "text": "import numpy as np"
  },
  {
    "objectID": "posts/Python/4. Class/python 13_0525.html#클래스-공부-5단계",
    "href": "posts/Python/4. Class/python 13_0525.html#클래스-공부-5단계",
    "title": "파이썬 (0525) 13주차",
    "section": "클래스 공부 5단계",
    "text": "클래스 공부 5단계\n- 지난시간까지 배운것: RPC자료형에 한정해서 print() 등의 기능을 조작할 수 있었다. (재정의 할 수 있었다.)\n- 이번시간에 배울것: 특정자료형에 한정하여 print 이외의 파이썬 내부기능을 조작하여 보자. (재정의하여 보자)\n\nmotive\n\na=1\nb=2\n\n\ntype(a)\n\nint\n\n\n\na+b\n\n3\n\n\n\na라는 인스턴스와 b라는 인스턴스를 + 라는 기호가 연결하고 있다.\n\n\na=[1,2]\nb=[3,4]\na+b\n\n[1, 2, 3, 4]\n\n\n\na라는 인스턴스와 b라는 인스턴스를 + 라는 기호가 연결하고 있다.\n\n- 동작이 다른 이유?\n\n클래스를 배우기 이전: int자료형의 + 는 “정수의 덧셈”을 의미하고 list 자료형의 +는 “자료의 추가”를 의미한다.\n클래스를 배운 이후: 아마 클래스는 + 라는 연산을 정의하는 숨겨진 메소드가 있을 것이다. (print가 그랬듯이) 그런데 int 클래스에서는 그 메소드를 “정수의 덧셈”이 되도록 정의하였고 list클래스에서는 그 메소드를 “자료의 추가”를 의미하도록 정의하였다.\n\n\na=1\nb=2\n\n\na.__add__\n\n<method-wrapper '__add__' of int object at 0x70c560>\n\n\n\ndir(a)\n\n['__abs__',\n '__add__',\n '__and__',\n '__bool__',\n '__ceil__',\n '__class__',\n '__delattr__',\n '__dir__',\n '__divmod__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floor__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getnewargs__',\n '__gt__',\n '__hash__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__le__',\n '__lshift__',\n '__lt__',\n '__mod__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdivmod__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__round__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__truediv__',\n '__trunc__',\n '__xor__',\n 'bit_length',\n 'conjugate',\n 'denominator',\n 'from_bytes',\n 'imag',\n 'numerator',\n 'real',\n 'to_bytes']\n\n\n\na.__add__(b)\n\n3\n\n\n\nb.__add__(a)\n\n3\n\n\n\na=[1,2]\nb=[3,4]\n\n\na.__add__(b)\n\n[1, 2, 3, 4]\n\n\n\nb.__add__(a)\n\n[3, 4, 1, 2]\n\n\n- a+b는 사실 내부적으로 a.__add__(b)의 축약구문이다. 따라서 먄악 a.__add__(b)의 기능을 바꾸면 (재정의하면) a+b의 기능도 바뀔 것이다.\n\n\n__add__\n- 예제\n\nclass Student:\n    def __init__(self, age=20.0, semester=1):\n        self.age = age\n        self.semester = semester\n        print(\"입학을 축하합니다. 나이는 {}이고 현재 {}학기 입니다.\".format(self.age, self.semester))\n    def __add__(self,val): \n        # val == 0: 휴학 \n        # val == 1: 등록 \n        if val==0: \n            self.age=self.age+0.5\n        elif val==1:\n            self.age=self.age+0.5 \n            self.semester= self.semester+1 \n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {}<br/>\n        학기: {}<br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 나이는 20.0이고 현재 1학기 입니다.\n\n\n\niu.semester\n\n1\n\n\n\niu  # 클래스가 저장되어있는 주소를 _repr_html_ 통해서 바꿔즘\n\n\n        나이: 20.0\n        학기: 1\n        \n\n\n\niu + 1 #1학년 2학기 등록\niu\n\n\n        나이: 20.5\n        학기: 2\n        \n\n\n\niu + 0 # 휴학\niu\n\n\n        나이: 21.0\n        학기: 2\n        \n\n\n- 연산을 연속으로 하고 싶다.\n\niu + 1 + 0 + 0 + 0 + 0\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러의 이유?\n\n1+1+1 #이거는 되는데?\n\n3\n\n\n\n(1+1)+1\n\n3\n\n\n\n_a = (1+1)\ntype(_a)\n\nint\n\n\n\n_a + 1    # 이 연산은 int인스턴스 + int인스턴스 \n\n3\n\n\n(안되는거)\n\niu+1+1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n\n_a=iu+1\n\n\ntype(_a)\n\nNoneType\n\n\n\n_a+1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러를 해결하는 방법: iu+1의 결과로 Student 클래스의 인스턴스가 리턴되면 된다.\n\nclass Student:\n    def __init__(self, age=20.0, semester=1):\n        self.age = age\n        self.semester = semester\n        print(\"입학을 축하합니다. 나이는 {}이고 현재 {}학기 입니다.\".format(self.age, self.semester))\n    def __add__(self,val): \n        # val == 0: 휴학 \n        # val == 1: 등록 \n        if val==0: \n            self.age=self.age+0.5\n        elif val==1:\n            self.age=self.age+0.5 \n            self.semester= self.semester+1 \n        return self\n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {}<br/>\n        학기: {}<br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 나이는 20.0이고 현재 1학기 입니다.\n\n\n\niu + 1   # __add__의 return에 Student클래스의 인스턴스가 리턴되면서 자동으로 __repr_html_()실행\n\n\n        나이: 23.0\n        학기: 4\n        \n\n\n\niu + 1 + 0 + 0 + 0 \n\n\n        나이: 25.0\n        학기: 5\n        \n\n\n\n\n__mul__\n\na=1\nb=1\na*b\n\n1\n\n\n\na.__mul__\n\n<method-wrapper '__mul__' of int object at 0x70c560>\n\n\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions)\n\n\na=RPS()\nb=RPS()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: []\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: []\n        \n\n\n\na*b 해서 승패를 확인하기 위한 클래스를 만들자\n\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n        self.results = list()\n    def __mul__(self,other):\n        self.choose()\n        other.choose()\n        if self.actions[-1]=='가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1]=='가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1]=='가위' and other.actions[-1]=='보':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1]=='바위' and other.actions[-1]=='가위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1]=='바위' and other.actions[-1]=='바위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1]=='바위' and other.actions[-1]=='보':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1]=='보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1]=='보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1]=='보' and other.actions[-1]=='보':\n            self.results.append(0)\n            other.results.append(0)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions,self.results)\n\n\na=RPS()\nb=RPS()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        액션: [] \n        승패: []\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        액션: [] \n        승패: []\n        \n\n\n\nfor i in range(5):\n    a*b\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        액션: ['보', '바위', '가위', '가위', '바위'] \n        승패: [1, 0, -1, 0, 1]\n        \n\n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보']  \n        액션: ['바위', '바위', '바위', '가위', '가위'] \n        승패: [-1, 0, 1, 0, -1]"
  },
  {
    "objectID": "posts/Python/4. Class/python 13_0525.html#숙제",
    "href": "posts/Python/4. Class/python 13_0525.html#숙제",
    "title": "파이썬 (0525) 13주차",
    "section": "숙제",
    "text": "숙제\nRPS클래스에서 player a와 player b를 만들어라. Player a는 [‘가위’,‘보’] 중에 하나를 낼 수 있다. 그리고 Player b는 [‘가위’,‘바위’] 중에 하나를 낼 수 있다. 두 player는 가지고 있는 패를 (같은확률로) 랜덤으로 낸다. (즉 player a가 가위만 내거나 보만 내는 경우는 없다.)\n\n누가 더 유리한가? 이유를 스스로 생각해보라. (이유를 정리하여 숙제로 제출할 필요 없음)\n50000번의 시뮬레이션을 해보고 결과를 분석해보라.\n\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n        self.results = list()\n    def __mul__(self,other):\n        self.choose()\n        other.choose()\n        if self.actions[-1]=='가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1]=='가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1]=='보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1]=='보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions,self.results)\n\n\na=RPS(['가위','보'])\nb=RPS(['가위','바위'])\n\n\nfor i in range(50000):\n    a*b\n\n\nsum(a.results)\n\n-12358\n\n\n\nsum(b.results)\n\n12358"
  },
  {
    "objectID": "posts/Python/4. Class/python 12_0518.html",
    "href": "posts/Python/4. Class/python 12_0518.html",
    "title": "파이썬 (0518) 12주차",
    "section": "",
    "text": "- 클래스 오브젝트에 소속된 변수와 인스턴스오브젝트에 소속된 변수를 설명한다.\n\n\n- 파이썬은 모든 것이 오브젝트로 이루어져 있다. <- 우선은 그냥 명언처럼 외우자\n- 오브젝트는 메모리 주소에 저장되는 모든 것을 의미한다.\n\na=1\nid(a)  # 메모리주소를 보는 명령어\n\n7390560\n\n\n\na='asdf'\nid(a)\n\n139914601692912\n\n\n\na=[1,2,3]\nid(a)\n\n139914601744176\n\n\n- 클래스와 인스턴스도 오브젝트이다.\n\nclass A:\n    x=0\n    def f(self):\n        print(self.x)\n\n\nA는 오브젝트\n\n\nid(A)\n\n37700928\n\n\n\na는 오브젝트\n\n\na=A()\nid(a)\n\n139914601844368\n\n\n\nb는 오브젝트\n\n\nb=A()\nid(b)\n\n139914601854160\n\n\n- 앞으로는 A를 클래스오브젝트, a,b를 인스턴스 오브젝트라고 부르자.\n\n\n\n- 시점0\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행\".format(self.y))\n\n\nid(A)\n\n38051088\n\n\n\nA.x, A.y\n\n(0, 0)\n\n\n- 시점1\n\na= A()\nb= A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 0], [0, 0], [0, 0])\n\n\n- 시점2\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 1], [1, 1], [0, 1])\n\n\n- 시점3\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 2], [1, 2], [1, 2])\n\n\n- 시점4\n\nb.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 3], [1, 3], [2, 3])\n\n\n- 시점5\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 4], [2, 4], [2, 4])\n\n\n- 시점6\n\nc=A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 4], [2, 4], [2, 4], [0, 4])\n\n\n- 시점7\n\nc.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 5번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 5], [2, 5], [2, 5], [1, 5])\n\n\n- 신기한점: 각 인스턴스에서 인스턴스이름.f()를 실행한 횟수를 서로 공유하는 듯 하다. (A가 관리하는 것처럼 느껴진다.)\n- x와 y는 약간 느낌이 다르다. x는 지점소속, y는 본사소속의 느낌?\n\n이 예제에서 x는 인스턴스오브젝트에 소속된 변수, y는 클래스 오브젝트에 소속된 변수처럼 느껴짐\n\n(약속) 앞으로는 인스턴스 오브젝트에 소속된 변수를 인스턴스 변수라고 하고, 클래스 오브젝트에 소속된 변수를 클래스 변수라고 하자.\n- 인스턴스 변수와 클래스 변수를 구분하는 방법? 인스턴스이름.__dict__를 쓰면 인스턴스 변수만 출력된다.\n\n따라서 a. + tab을 눌러서 나오는 변수중 a.__dict__에 출력되지 않으면 클래스 변수이다.\n\n\na.__dict__\n\n{'x': 2}\n\n\n\nb.__dict__\n\n{'x': 2}\n\n\n\nc.__dict__\n\n{'x': 1}\n\n\n- 이 예제에서 아래는 모두 클래스 변수이다.\n\na.y, b.y, c.y\n\n(5, 5, 5)\n\n\n\n\n\n- 시점0\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행\".format(self.y))\n\n\na=A()\n\n\n[A.x, A.y], [a.x, a.y]\n\n([0, 0], [0, 0])\n\n\n- 시점1\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 3번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행\n\n\n\n[A.x,A.y], [a.x, a.y]\n\n([0, 3], [3, 3])\n\n\n- 시점2\n\na.x = 0 # f의 실행기록을 초기화 하고 싶다.\n\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행\n\n\n\n[A.x,A.y], [a.x, a.y]\n\n([0, 4], [1, 4])\n\n\n\n\n\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행\".format(self.y))\n\n\na=A()\n\n\nb=A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 0], [0, 0], [0, 0])\n\n\n- 시점1\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 1], [1, 1], [0, 1])\n\n\n- 시점2\n\nA.y = 100\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 100], [1, 100], [0, 100])\n\n\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 101번 실행\n\n\n\n\n\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행\".format(self.y))\n\n\na=A()\n\n\n[A.x, A.y], [a.x, a.y]\n\n([0, 0], [0, 0])\n\n\n- 시점1\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행\n\n\n\n[A.x, A.y], [a.x, a.y]\n\n([0, 1], [1, 1])\n\n\n- 시점2\n\nA.x = 100   # 이렇게 되면 앞으로 만들어진 인스턴스튼 기본적으로 현재 인스턴스에서| 100번 f를 실행하였다는 정보를 가지고 태어나게 된다.\n\n\n[A.x, A.y], [a.x, a.y]\n\n([100, 1], [1, 1])\n\n\n- 시점3\n\nb=A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([100, 1], [1, 1], [100, 1])\n\n\n- 시점4\n\nb.f()\n\n현재 인스턴스에서 f가 101번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행\n\n\n- 시점5\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 3번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 102번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 5번 실행\n\n\n\n\n\n\nclass B:\n    x=100   # 초기자본금\n    y=0\n    def f(self):   # f를 실행할때마다 돈을 쓴다.\n        self.x=self.x - 1\n        B.y = B.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 {}원 잔액남음\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 총 {}원 사용\".format(self.y))\n\n\na=B()\n\n\nb=B()\n\n\n[B.x, B.y], [a.x, a.y], [b.x, b.y]\n\n([100, 0], [100, 0], [100, 0])\n\n\n- 시점1\n\na.f() # 돈을 쓴다\n\n현재 인스턴스에서 99원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 1원 사용\n\n\n\na.f()\n\n현재 인스턴스에서 98원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 2원 사용\n\n\n\nb.f()\n\n현재 인스턴스에서 99원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 3원 사용\n\n\n- 시점2\n\n[B.x, B.y], [a.x, a.y], [b.x, b.y]\n\n([100, 3], [98, 3], [99, 3])\n\n\n\nB.x=999\n\n\n[B.x, B.y], [a.x, a.y], [b.x, b.y]\n\n([999, 3], [98, 3], [99, 3])\n\n\n- 시점3\n\nc=B()\n\n\nc.f()\n\n현재 인스턴스에서 998원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 4원 사용\n\n\n- 시점4\n\na.f()\n\n현재 인스턴스에서 97원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 5원 사용\n\n\n\nb.f()\n\n현재 인스턴스에서 98원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 6원 사용\n\n\n\nc.f()\n\n현재 인스턴스에서 997원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 7원 사용\n\n\n\nc.f()\n\n현재 인스턴스에서 996원 잔액남음\nA클래스에서 만들어진 모든 인스턴스들에서 총 8원 사용\n\n\n\n\n\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행\".format(self.y))\n\n\n[A.x, A.y]\n\n[0, 0]\n\n\n\na=A()\nb=A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x,b.y]\n\n([0, 0], [0, 0], [0, 0])\n\n\n- 시점1\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행\n\n\n- 시점2\n\na.__dict__\n\n{'x': 2}\n\n\n\na.y  # 인스턴스 a에 소속되어 있지만 클래스 변수 \n\n3\n\n\n\na.y = 999 # A.y 였으면 다 바꼈을 테지만 a.y 였다면??\n# 내가 하드코딩으로 a.y에 999 입력 -> 이것이 A.y나 b.y에도 반영될까? (x)\n\n\n[A.x, A.y], [a.x, a.y], [b.x,b.y]\n\n([0, 3], [2, 999], [1, 3])\n\n\n\na.__dict__\n\n{'x': 4, 'y': 999}\n\n\n- 시점3\n\nb.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 3번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 999번 실행\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 3번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 6번 실행\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 4번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 7번 실행\n\n\n\na.f()\n\n현재 인스턴스에서 f가 4번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 999번 실행\n\n\n- 요약 - 인스턴스에서 클래스 변수의 값을 변경하면? -> 클래스변수의 값이 변경되는 것이 아니라 인스턴스 변수가 새롭게 만들어져서 할당 된다. - 이 예제에서 a.y는 이제 클래스변수에서 인스턴스 변수로 재탄생 되었다. 즉, 999오브젝트가 새롭게 만들어져서 a.x라는 이름을 얻은것이다. - 기존의 A.y나 b.y에는 아무런 변화가 없다.\n\nid(999) #999도 오브젝트임\n\n139914476320048\n\n\n\na.y = 999 는 새로운 인스턴스 변수 y를 할당하는 역할을 한다. 클래스변수의 값을 변경하는 것이 아니다. (왜냐하면 애초에 a.y는 없는 값이었고, A.y를 빌리고 있었던 것임)\n\n\na.__dict__\n\n{'x': 4, 'y': 999}\n\n\n\nb.__dict__\n\n{'x': 4}\n\n\n\n\n\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행 (인스턴스레벨)\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (클레스레벨)\".format(A.y))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (인스턴스레벨)\".format(self.y))\n\n\na=A()\n\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (인스턴스레벨)\n\n\n\nb=A()\n\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행 (인스턴스레벨)\n\n\n- 시점1\n\na.y = 999\n\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 999번 실행 (인스턴스레벨)\n\n\n\na.f()\n\n현재 인스턴스에서 f가 3번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 999번 실행 (인스턴스레벨)\n\n\n\n\n\n- 의문: 아래의 코드에서 x는 클래스 변수라고 봐야할까? 인스턴스 변수라고 봐야할까? —> 클래스 변수!\nclass SoWhaTV: \n    x=0   # 이 시점에서 x는 클래스변수인가? 아니면 인스턴스 변수인가?\n    def f(self):\n        print(self.x)\n- 시점0\n\nclass A:\n    x=0\n    y=0\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행 (인스턴스레벨)\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (클레스레벨)\".format(A.y))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (인스턴스레벨)\".format(self.y))\n\n\na=A()\nb=A()\n\n\na.x, a.y, b.x, b.y\n\n(0, 0, 0, 0)\n\n\n\na.__dict__, b.__dict__\n\n({}, {})\n\n\n\n지금 시점에서 a.x, a.y, b.x, b.y는 모두 클래스 변수임\n\n- 시점1\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (인스턴스레벨)\n\n\n\na.__dict__, b.__dict__\n\n({'x': 1}, {})\n\n\n\n이 순간 a.x가 클래스변수에서 인스턴스 변수로 변경되었다. (예제5와 같이..) 왜? f가 실행되면서 self.x = self.x + 1이 실행되었으므로!\n\n- 시점2\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행 (클레스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행 (인스턴스레벨)\n\n\n\na.__dict__, b.__dict__\n\n({'x': 1}, {'x': 1})\n\n\n\n\n\n- 아래처럼 코드를 바꾸면 어떻게 되는가?\n\nclass A:\n    def __init__(self):\n        self.x=0 # 인스턴스 변수로 나중에 쓸꺼니까 명시함\n        A.y=0  # 클래스변수로 나중에 쓸꺼니까 명시함\n    def f(self):\n        self.x=self.x + 1\n        A.y = A.y + 1\n        # self.y = self.y + 1 이렇게 안쓰고 위에처럼 써보자!\n        print(\"현재 인스턴스에서 f가 {}번 실행 (인스턴스레벨)\".format(self.x))\n        print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (클레스레벨)\".format(A.y))\n        #print(\"A클래스에서 만들어진 모든 인스턴스들에서 f가 총 {}번 실행 (인스턴스레벨)\".format(self.y))\n\n- 사용\n\na=A()\nb=A()\n\n\na.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (클레스레벨)\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 2번 실행 (클레스레벨)\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 2번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 3번 실행 (클레스레벨)\n\n\n\nb.f()\n\n현재 인스턴스에서 f가 3번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 4번 실행 (클레스레벨)\n\n\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 5번 실행 (클레스레벨)\n\n\n- 잘 되는 것 같다?\n- 조금만 생각해보면 엉터리라는 것을 알 수 있다. 아래를 관찰하자.\n\nc=A()   # 이 시점에서 __init__()이 실행된다\n\n\na.f()\n\n현재 인스턴스에서 f가 3번 실행 (인스턴스레벨)\nA클래스에서 만들어진 모든 인스턴스들에서 f가 총 1번 실행 (클레스레벨)\n\n\n\n클래스 레벨의 변수가 왜 초기화가 되었지?\n\n- 오류의 이유? c=A()가 실행되는 시점에 __init__()이 실행되면서 A.y=0이 실행된다. 따라서 강제 초기화가 진행되었다.\n\nㅇ"
  },
  {
    "objectID": "posts/Python/4. Class/python 11_0516.html",
    "href": "posts/Python/4. Class/python 11_0516.html",
    "title": "파이썬 (0516) 11주차",
    "section": "",
    "text": "from PIL import Image\nimport requests"
  },
  {
    "objectID": "posts/Python/4. Class/python 11_0516.html#클래스-공부-2단계",
    "href": "posts/Python/4. Class/python 11_0516.html#클래스-공부-2단계",
    "title": "파이썬 (0516) 11주차",
    "section": "클래스 공부 2단계",
    "text": "클래스 공부 2단계\n\ninit()\n- STOOOP를 다시 복습\n\nurl1 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true'\n\n\nclass STOOOP: \n    title = '학교폭력!' \n    url = url1\n    end = '멈춰~~~~'\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end) \n\n\ns1=STOOOP() # STOOOP라는 클래스에서 s1이라는 인스턴스를 만드는 과정\n\n\ns1.title, s1.url, s1.end\n\n('학교폭력!',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~~')\n\n\n\ns1.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~~\n\n\n- 왜 s1의 default title이 항상 “학교폭력”이어야 하는가? => __init__의 개발\n- 성능4: __init__() 함수를 이용하여 “클래스->인스턴스”의 시점에서 수행하는 일련의 동작들을 묶어서 수행할 수 있음\n\nclass STOOOP: \n    #title = '학교폭력!' \n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self,title):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end) \n\n- 잘못된사용\n\ns1=STOOOP()  # 이 시점에서 _init_ 이 수행된다!\n\nTypeError: __init__() missing 1 required positional argument: 'title'\n\n\n- 올바른사용\n\ns1=STOOOP(\"수강신청\")  # 이 시점에서 _init_ 이 수행된다!\n\n\ns1.title, s1.url, s1.end\n\n('수강신청',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~~')\n\n\n\ns1.stop()\n\n수강신청\n\n\n\n\n\n멈춰~~~~\n\n\n- 잘못된 사용에서 에러가 발생한 이유?\nTypeError: __init__() missing 1 required positional argument: 'title'\n\ns1 = STOOOP() 가 실행되는 순간 __init__() 이 내부적으로 실행된다.\n그런데 __init__()의 첫번째 입력은 self 는 입력안해도 무방했음. (현재는 메소드와 함수를 구분하는 문법으로 self를 이해하면 된다.) 그런데 두번째 입력은 title은 입력을 해야했음.\n그런데 title을 입력하지 않아서 발생하는 에러\n\n- __init__(self, arg1, arg2, ...) 함수에 대하여 - 엄청나게 특별해 보이지만 사실 몇가지 특별한 점을 제외하고는 어떠한 마법도 없는 함수이다. - 특별한점1: 첫번째 입력으로 반드시 self를 넣어야함. (이거 ㄴ사실 클래스 내의 메소드 거의 다 그러하다.) - 특별한점2: 클래스에서 인스턴스를 만드는 시점에 자동으로 생성됨 - 특별한점3: __init__(self, arg1, arg2, ...) 의 입력중 self 이외의 입력들은 “클래스->인스턴스”의 시점에서 “인스턴스이름 = 클래스이름(arg1,arg2,…)”와 같이 사용한다. (이 예제의 경우 STOOOP(title)와 같이 사용해야함)\n- title 이 디폴트로 들어가는 상황도 불편했지만, title을 명시적으로 넣지 않으면 에러가 발생하는 것도 불편하다?\n\nclass STOOOP: \n    #title = '학교폭력!' \n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self,title=None):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end) \n\n\ns2=STOOOP()\ns3=STOOOP('KOSPI하락')\n\n\ns2.stop()\n\nNone\n\n\n\n\n\n멈춰~~~~\n\n\n\n제목이 없으면 없는데로\n\n\ns3.stop()\n\nKOSPI하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\nself의 의미\n- 이전 예제를 다시 복습\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n        self.n = self.n+1 \n\n\nk4=Klass4()\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 5번 보았습니다\n\n\n- 위의 예제는 아래와 같이 구현할 수도 있다.\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n       # self.n = self.n+1 \n\n\nk4=Klass4()\n\n\nk4.n\n\n1\n\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 1번 보았습니다\n\n\n\nk4.n = k4.n +1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 2번 보았습니다\n\n\n\nk4.n = k4.n + 1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 3번 보았습니다\n\n\n- 결국에는 k4.n = k4.n +1 의 기능을 구현하여 넣은 것이 self.n = slef.n + 1 이다.\n- 따라서 self는 k4에 대응한다. 즉 self는 인스턴스의 이름에 대응한다. 우리가 하고 싶은 것은 클래스를 선언하는 시점에 인스턴스가 생성된 이후의 시점에 대한 어떠한 동작들을 정의하고 싶음. 그런데 클래스를 설계하는 시점에서는 인스턴스의 이름이 정해지지 않았으므로 (아직 인스턴스가 태어나지도 않음) 이러한 동작들을 정의하기 불편하다. 그래서 클래스를 설계하는 시점에서 그 클래스로부터 만들어지는 인스턴스는 그냥 self라는 가칭으로 부른다. (굳이 비유하면 self는 인스턴스의 태명같은것..)\n\n# 여기서 말하는 인스턴스는 정확하게 무엇인가? 그냥.. self, k4 와 같이 이름을 말하는건가?\n\n- self의 의미는 (이후에 만들어질) 인스턴스의 이름이다. (즉 self는 인스턴스의 태명같은 것임)\n\n\n파이썬의 비밀1\n탐구 : 인스턴스의 자료형이 뭔지 탐구하자!\n- 아래의 두 클래스를 비교해보자\n\nclass STOOOP: \n    #title = '학교폭력!' \n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self,title=None): \n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end) \n\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n        #self.n = self.n+1     \n\n- 인스턴스를 생성해보자.\n\nk4=Klass4()\ns1=STOOOP()\n\n- 타입을 알아보자.\n\nk4?\n\n\nType:        Klass4\nString form: <__main__.Klass4 object at 0x7fc527259890>\nDocstring:   <no docstring>\n\n\n\n\n\ns1?\n\n\nType:        STOOOP\nString form: <__main__.STOOOP object at 0x7fc527259bd0>\nDocstring:   <no docstring>\n\n\n\n\n-??? 타입은 자료형, 즉 int, float, list 이런 것 아니었나?\n\na=[1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n\na=3.14\na?\n\n\nType:        float\nString form: 3.14\nDocstring:   Convert a string or number to a floating point number, if possible.\n\n\n\n\n- 그런데 지금 k4, s1의 타입은 Klass4, STOOOP이다.\n\n가설1: 사실 파이썬 내부에 Klass4, STOOOP 이라는 자료형이 있었다. 그런데 내가 만든 k4, s1이 우연히 그 자료형을 따르는 것 (억지스러움)\n\n\nclass SoWhatTV:\n    title='어쩔티비'\n\n\na=SoWhatTV()\na?\n\n\nType:        SoWhatTV\nString form: <__main__.SoWhatTV object at 0x7fc5259e6810>\nDocstring:   <no docstring>\n\n\n\n\n\n# 잉.. 우연히 자료형이 sowhattv가 잇을거 같진 않은데. .가설1이 맞진 않는거 같다\n\n\n가설2: type이 list인것은 사실 list라는 클래스에서 생긴 인스턴스이다. -> 리스트자료형을 찍어낼 수 있는 어떠한 클래스가 내부적으로 존재할 것이다.\n\n깨달음1\n- 가설2가 맞다면 아래는 모두 어딘가에서 찍혀진 인스턴스이다.\n\na=[1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n\na='1'\na?\n\n\nType:        str\nString form: 1\nLength:      1\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n\n- 그리고 위의 a=[1,2,3]과 같은 것들은 모두 “클래스->인스턴스”에 해당하는 과정이었음\n깨달음2\n- 생각해보니까 아래와 같이 list를 선언하는 방식도 있었음\n\na=list()\na\n\n[]\n\n\n\nlist라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법이다.\n\n- 아래도 가능\n\na=list((1,2,3))\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n- list라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법. 여기에서 (1,2,3)은 __init__()의 입력이다.\n깨달음3\n- 각 자료형마다 특수한 기능들이 있다.\n\na=[1,2,3]\na\n\n[1, 2, 3]\n\n\n- a. + tab 을 하면 append, clear 등등이 나온다.\n- 이러한 기능은 지금까지 우리가 “list자료형 특수기능들” 이라고 부르면서 사용했다. 그런데 a가 list클래스에서 생성된 인스턴스라는 관점에서 보면 이러한 기능들은 list클래스에서 정의된 메소드라고 볼 수 있다.\n깨달음4\n- a.f()는 f(a)로 해석가능하다고 했다. 이 해석에 따르면 메소드의 첫번째 입력은 메소드가 소속된 인스턴스라고 해석할 수 있다.\n- 동일한 논리로 아래의 코드는 stop()의 입력에서 s1을 넣는다는 의미이다.\n\ns1.stop()   #s1자체가 입력이 되는것\n\nNone\n\n\n\n\n\n멈춰~~~~"
  },
  {
    "objectID": "posts/Python/4. Class/python 11_0516.html#숙제",
    "href": "posts/Python/4. Class/python 11_0516.html#숙제",
    "title": "파이썬 (0516) 11주차",
    "section": "숙제",
    "text": "숙제\n아래의 조건에 맞는 클래스를 생성하라.\n\n[‘가위’,‘바위’]와 같은 리스트를 입력으로 받아 인스턴스를 생성한다.\n위의 리스트에서 하나의 값을 뽑는 메소드 f를 가지고 있다.\n\n\n# # 너무 헷 갈ㄹ  ㅕ .. \n\n# # 사용예시\n\n\n# a = Klass(['가위','바위'])\n# a.f() # 가위가 1/2 바위가 1/2의 확률로 출력 \n# b = Klass(['가위','바위','보'])\n# b.f() # 가위, 바위, 보가 1/3의 확률로 출력"
  },
  {
    "objectID": "posts/Python/4. Class/python 14_0606.html",
    "href": "posts/Python/4. Class/python 14_0606.html",
    "title": "파이썬 (0606) 14주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "posts/Python/4. Class/python 14_0606.html#클래스공부-7단계",
    "href": "posts/Python/4. Class/python 14_0606.html#클래스공부-7단계",
    "title": "파이썬 (0606) 14주차",
    "section": "클래스공부 7단계",
    "text": "클래스공부 7단계\n\n함수공부\n- 다시 함수를 공부해보자\n\ndef f(x):\n    return x+1\n\n\nf(3)\n\n4\n\n\n- 함수의 사용방법? - 입력으로 변수 x를 받음 = 입력으로 인스턴스 x를 받음 - 출력으로 변수 x+1을 리턴 = 출력으로 인스턴스 x+1을 리턴\n- 사실1: 파이썬에서 함수는 인스턴스를 입력으로 받고 인스턴스를 출력한다.\n- 함수의 자료형?\n\nf\n\n<function __main__.f(x)>\n\n\n\n?f\n\n\nSignature: f(x)\nDocstring: <no docstring>\nFile:      ~/Dropbox/coco/posts/python/<ipython-input-2-9897bae5f29b>\nType:      function\n\n\n\n\n\ntype이 function 이다.\nf는 function 의 class의 instance이다.\n결국 f도 하나의 오브젝트에 불과하다.\n\n- 사실2: 함수도 결국 인스턴스이다. -> 함수의 입력으로 함수를 쓸 수도 있고 함수의 출력으로 함수가 나올 수도 있다.\n\n\n함수형 프로그래밍\n(예제1) 숫자입력, 함수출력\n\ndef f(a):\n    def _f(x):\n        return (x-a)**2\n    return _f\n\n\ng=f(10)    # g(x) = (x-10)**2\n\n\ng(2)    # (8)**2\n\n64\n\n\n\n해석: f(a)는 a를 입력으로 받고 g(x) = (x-a)^2 함수를 리턴해주는 함수\n\n(예제1)의 다른표현: 익명함수 lambda\n표현1\n\ndef f(a):\n    _f = lambda x: (x-a)**2   # lambda x : (x-a)**2 가 실행되는 순간 함수오브젝트가 만들어지고 그것이 _f로 저장됨\n    return _f\n\n\ng=f(10)    # g(x) = (x-10)**2\n\n\ng(2)\n\n64\n\n\n표현2\n\ndef f(a):\n    return lambda x: (x-a)**2\n\n\ng=f(10)    # g(x) = (x-10)**2\n\n\ng(2)\n\n64\n\n\n\nlambda x: (x-a)**2 는 \\(\\text{lambda}(x) = (x-a)^2\\) 의 느낌으로 기억하면 쉽다.\nlambda x: (x-a)**2 는 “아직 이름이 없는 함수 오브젝트를 (가칭 lmabda라고 하자) 만들고 기능은 x를 입력으로 하고 (x-a)**2를 출력하도록 하자” 라는 뜻이로 해석\n\n\n(lambda x,y : x<y)(2,3)\n\nTrue\n\n\n\nf=lambda x,y : x<y   # 위와 같은 코드\nf(2,3)\n\nTrue\n\n\n(예제2) 함수입력, 숫자출력\n\ndef f(x):\n    return x**2\n\n\nf(3)\n\n9\n\n\n\ndef d(f,x):    # 함수를 입력을 받는 함수를 정의\n    h=0.0000000000001\n    return (f(x+h)-f(x)) / h\n\n\\[f'(x)\\approx \\frac{f(x+h)-f(x)}{h}\\]\n\n\\(h\\) 의 값이 점점 0에 가까울수록 등호에 가까워짐\n\n\nd(f,4)   # f'(4) = 2*4 = 8\n\n8.029132914089132\n\n\n(예제3) 함수입력, 함수출력\n\ndef f(x):\n    return x**2\n\n\ndef derivate(f):\n    def df(x):\n        h=0.0000000000001\n        return (f(x+h)-f(x)) / h\n    return df\n\n\nff = derivate(f)  # f미분\n\n\nff(10)  #f의 도함수\n\n19.895196601282805\n\n\n원래함수 시각화\n\nx=np.linspace(-1,1,100)\nplt.plot(x,f(x))\n\n\n\n\n도함수 시각화\n\nx=np.linspace(-1,1,100)\nplt.plot(x,ff(x))\n\n\n\n\n(예제3)의 다른표현\n\ndef f(x):\n    return x**2\n\n\ndef derivate(f):\n    h=0.0000000000001\n    return lambda x:(f(x+h)-f(x)) / h\n\n\nff=derivate(f)\n\n\nff(10)\n\n19.895196601282805\n\n\n(예제4) 함수들의 리스트\n\n# # 리스트의 컴마 컴마 안에 들어갈 수 있는것은 \n# [인스턴스, 인스턴스, 인스턴스]\n# [오브젝트, 오브젝트, 오브젝트]\n# [함수오브젝트, 함수오브젝트, 함수오브젝트]\n# # ....\n\n\nflst = [lambda x:x, lambda x:x**2, lambda x:x**3]\nflst\n\n[<function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>]\n\n\n\nfor f in flst:\n    print(f(2))\n\n2\n4\n8\n\n\n\nfor f in flst:\n    plt.plot(x,f(x),'--')\n\n\n\n\n위 아래 동일\n\nplt.plot(x, (lambda x:x)(x),'--')\nplt.plot(x, (lambda x:x**2)(x),'--')\nplt.plot(x, (lambda x:x**3)(x),'--')\n\n\n\n\n\n\n정리\n- 지금까지 개념 - 함수: 변수를 입력으로 받아서 변수를 출력하는 개념 - 변수: 어떠한 값을 저장하는 용도로 쓰이거나 함수의 입력 혹은 출력으로 사용함\n- 파이썬의 함수형프로그래밍을 잘하려면? - 변수든 함수든 둘다 인스턴스임 - 변수를 함수처럼: 메소드 - 함수를 변수처럼(\\(\\star\\)) : 함수자체를 함수의 입력으로 혹은 출력으로 쓸 수도 있음. 함수를 특정 값처럼 생각해서 함수들의 list를 만들 수도 있다.\n\n\ncollable object\n- 함수 오브젝트의 비밀?\n\nf = lambda x: x+1\n\n\nf(4)\n\n5\n\n\n\n?f\n\n\nSignature: f(x)\nDocstring: <no docstring>\nFile:      ~/Dropbox/coco/posts/python/<ipython-input-66-1a55436594c9>\nType:      function\n\n\n\n\n\ndir(f)\n\n['__annotations__',\n '__call__',\n '__class__',\n '__closure__',\n '__code__',\n '__defaults__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__get__',\n '__getattribute__',\n '__globals__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__kwdefaults__',\n '__le__',\n '__lt__',\n '__module__',\n '__name__',\n '__ne__',\n '__new__',\n '__qualname__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__']\n\n\n\nset(dir(f)) & {'__call__'}\n\n{'__call__'}\n\n\n\n함수 오브젝트에는 숨겨징 기능 __call__이 있다.\n\n\nf.__call__(3)    # f(3)\n\n4\n\n\n\nf.__call__(4)   # f(4)\n\n5\n\n\n\n여기에 우리가 정의한 내용이 있따.\n\ncall 만 정의를 해주면 함수처럼 쓸 수 있다 ?! -> list의 dir 확인해보면 call 없음\n- 함수처럼 쓸 수 없는 인스턴스는 단지 call이 없는 것일 뿐이다.\n\nclass Klass:\n    def __init__(self):\n        self.name = 'boram'\n\n\na=Klass()\n\n\na()\n\nTypeError: 'Klass' object is not callable\n\n\n\nTypeError: ‘Klass’ object is not callable\n\n\nclass Klass2(Klass):  # 상속\n    def __call__(self):\n        print(self.name)\n\n\nb=Klass2()\n\n\nb()\n\nboram\n\n\n\nb는 collable obeject 라는 의미. 즉 숨겨진 메서드로 __call__를 가진 오브젝트!\nKlass는 collable object를 만들지 못하지만 Klass2는 collable object를 만든다.\n\n- 클래스로 함수를 만들기\n\nclass AddConstant:\n    def __init__(self,c):\n        self.c = c\n    def __call__(self,a):\n        return a + self.c\n\n\nf = AddConstant(3)   # collabe object 생성, f.c에는 3이 저장되어 있음.\n\n\nf(7)   # f.c와 7을 더하는 기능을 수행, # f(x) = x+3 을 수행함\n\n10\n\n\n\nf(10)\n\n13\n\n\n- 클래스도 일종의 오브젝트이고 함수처럼 Klass()와 같이 사용하여 인스턴스를 만들었음. -> Klass.__call__()는 Klass()와 같은 역할을 할 것이다.\n\nclass Klass:\n    def __init__(self):\n        self.name='coco'\n    \n\n\na=Klass.__call__()   # 이것이 a=Klass()와 같은 효과\n\n\na.name\n\n'coco'\n\n\n\n\n파이썬의 비밀 1~4\n\n파이썬의 비밀1: 자료형은 클래스의 비밀이다.(11주차)\n파이썬의 비밀2: 클래스에는 __str__처럼 숨겨진 메서드가 존재한다. 이를 이용하여 파이썬 내부의 기능을 가로챌 수 있다.(12주차0523)\n파이썬의 비밀3: 주피터노트북에서는 “오브젝트이름+엔터” 를 쳐서 나오는 출력은 __repr__로 가로챌 수 잇다.(주피터의 비밀)\n파이썬의 비밀4: 함수와 클래스는 숨겨진 메서드에 __call__을 가진 오브젝트일 뿐이다."
  },
  {
    "objectID": "posts/Python/4. Class/python 14_0606.html#클래스공부-8단계",
    "href": "posts/Python/4. Class/python 14_0606.html#클래스공부-8단계",
    "title": "파이썬 (0606) 14주차",
    "section": "클래스공부 8단계",
    "text": "클래스공부 8단계\n\nfor문의 복습\n- 아래와 같은 예제들을 관찰하여 for문을 복습하자.\n(예제1)\n\nfor i in [1,2,3,4]:\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제2)\n\nfor i in (1,2,3,4):\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제3)\n\nfor i in'1234':\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제4)\n\na=5\nfor i in a:\n    print(i)\n\nTypeError: 'int' object is not iterable\n\n\n\n5라고 출력되어야 하지 않나?\n\n- 의문1:\nfor i in ???:\n    print(i)\n에서 ??? 자리에 올수 있는 것이 무엇일까?\n(예제5)\n상황1\n\nlst = [[1,2,3,4],[3,4,5,6]]\nfor l in lst:\n    print(l)\n\n[1, 2, 3, 4]\n[3, 4, 5, 6]\n\n\n상황2\n\ndf=pd.DataFrame(lst)\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\n0\n1\n2\n3\n\n\n칼럼이름들이 나오는 것 같음 -> 확인해보자\n\ndf.columns = pd.Index(['X'+str(i) for i in range(1,5)])\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n      X4\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n- 의문2: for의 출력결과는 어떻게 예측할 수 있을까?\n\n\nfor문의 동작원리\n- 의문1의 해결: 아래의 ???자리에 올 수 있는 것은 dir()하여 __iter__가 있는 object이다.\nfor i in ???:\n    print(i)\n이러한 오브젝트를 iterable object라고 한다.\n- 확인\n\na=[1,2,3]\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na='123'\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na=3\nset(dir(a)) & {'__iter__'}\n\nset()\n\n\n\n예상대로 예제 1~4에서는 int클래스의 instance만 __iter__ 가 없다.\n\n- __iter__ 의 역할: iterable object를 iterator로 만들 수 있다!\n\nlst = [1,2,3]\nlst\n\n[1, 2, 3]\n\n\n\nlst[1] # 충실한 리스트\n\n2\n\n\n\nltor = iter(lst)\n#ltor = lst.__iter__()\nltor\n\n<list_iterator at 0x7f4b7b39efd0>\n\n\n\nltor[1]   # 더이상 리스트가 아니다.\n\nTypeError: 'list_iterator' object is not subscriptable\n\n\n\nltor?\n\n\nType:        list_iterator\nString form: <list_iterator object at 0x7f4b7b39efd0>\nDocstring:   <no docstring>\n\n\n\n\n- iterator가 되면 무엇이 좋은가? -> 숨겨진 기능 __next__ 가 열린다.\n\nset(dir(lst)) & {'__next__'}\n\nset()\n\n\n\nset(dir(ltor)) & {'__next__'}\n\n{'__next__'}\n\n\n\nlst에는 __next__가 없지만 ltor에는 있다!\n\n- 그래서 __next__의 기능은? -> 원소를 차례대로 꺼내준다. + 더 이상 꺼낼 원소가 없으면 StopIteration Error를 발생시킨다.\n\nlst\n\n[1, 2, 3]\n\n\n\nltor.__next__()\n\n1\n\n\n\nltor.__next__()\n\n2\n\n\n\nltor.__next__()\n\n3\n\n\n\nltor.__next__()\n\nStopIteration: \n\n\n- for 문의 동작원리\nfor i in lst\n    print(i)\n\nlst.__iter__() 혹은 iter(lst) 를 이용하여 lst를 iterator로 만든다. (iterable object를 iterator object로 만든다.)\niterator에서 .__next__() 함수를 호출하고 결과를 i에 저장한 뒤에 for문 블락안에 있는 내용 (들여쓰기 된 내용)을 실행한다. -> 반복\nStopIteration 에러가 발생하면 for무늘 멈춘다.\n\n- 아래의 ??? 자리에 올 수 있는 것이 iterable object가 아니라 iterator 자체여도 for 문이 돌아갈까? -> (당연히 돌아가야 할 것 같음)\nfor i in ???\n    print(i)\n\nfor i in iter([1,2,3]):\n    print(i)\n\n1\n2\n3\n\n\n\n당연히 가능!\n\n- a가 iterator일때 iter(a) 의 출력결과가 a와 같도록 조정한다면 for문의 동작원리 (1) ~ (3) 을 수정하지 않아도 좋다. -> 실제로 이렇게 동작한다.\n\nltor?\n\n\nType:        list_iterator\nString form: <list_iterator object at 0x7f4b7b39efd0>\nDocstring:   <no docstring>\n\n\n\n\n\ndir(ltor)\n\n['__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__length_hint__',\n '__lt__',\n '__ne__',\n '__new__',\n '__next__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__']\n\n\n- 요약 - iterable object는 숨겨진 기능으로 __iter__를 가진다. - iterator object는 숨겨진 기능으로 __iter__와 __next__를 가진다. (즉 iterator는 그 자체로 iterable object가 된다!)\n\nlst = [1,2,3]\nltor = iter(lst)\n\n\nset(dir(lst)) & {'__iter__', '__next__'}\n\n{'__iter__'}\n\n\n\nset(dir(ltor)) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n- 의문2의 해결: for문의 출력결과는 어떻게 예측할 수 있을까? iterator를 만들어서 __next__()의 출력값을 확인하면 알 수 있다.\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n\ndftor = iter(df)\ndftor?\n\n\nType:        map\nString form: <map object at 0x7f4b7c0d1350>\nDocstring:  \nmap(func, *iterables) --> map object\nMake an iterator that computes the function using arguments from\neach of the iterables.  Stops when the shortest iterable is exhausted.\n\n\n\n\n\ndftor.__next__()\n\n'X1'\n\n\n\ndftor.__next__()\n\n'X2'\n\n\n\ndftor.__next__()\n\n'X3'\n\n\n\ndftor.__next__()\n\n'X4'\n\n\n\ndftor.__next__()\n\nStopIteration: \n\n\n\n\nrange()\n- 파이썬에서 for문을 처음 배울 때: range(5)를 써라!\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\nrange(5) 가 도대체 무엇인가?\n\n\nset(dir(range(5))) & {'__iter__', '__next__'}\n\n{'__iter__'}\n\n\n- range(5)의 정체는 그냥 iterable object이다.\n- 그래서 언제든지 iterator로 바꿀 수 있다.\n\nrtor = iter(range(5))\nrtor\n\n<range_iterator at 0x7f4b7af5d8a0>\n\n\n\nset(dir(rtor)) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n- for문에서 range(5)가 행동하는 방법?\n\nrtor = iter(range(5))\n\n\nrtor.__next__()\n\n0\n\n\n\nrtor.__next__()\n\n1\n\n\n\nrtor.__next__()\n\n2\n\n\n\nrtor.__next__()\n\n3\n\n\n\nrtor.__next__()\n\n4\n\n\n\nrtor.__next__()\n\nStopIteration: \n\n\n\n\nzip\n- 이터레이터의 개념을 알면 for문에 대한 이해도가 대폭 상승한다.\n\nfor i in zip([1,2,3],'abc'):\n    print(i)\n\n(1, 'a')\n(2, 'b')\n(3, 'c')\n\n\n\nzip은 뭐지?\n\n\nzip([1,2,3],'abc')\n\n<zip at 0x7f4b7c63a690>\n\n\n- 어차피 for i in ????: 의 ???? 자리는 iterable object의 자리이다.\n\nset(dir(zip([1,2,3],'abc'))) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n\n__next__() 함수가 있음 \\(\\to\\) zip([1,2,3],'abc')은 그 자체로 iterator 이다!\n\n\nz = zip([1,2,3],'abc')\n\n\nz.__next__()\n\n(1, 'a')\n\n\n\nz.__next__()\n\n(2, 'b')\n\n\n\nz.__next__()\n\n(3, 'c')\n\n\n\nz.__next__()\n\nStopIteration: \n\n\n\n\n사용자정의 이터레이터\n- 내가 이터레이터를 만들어보자.\n\nclass Klass: # 찌를 내는 순간 for문이 멈추도록 하는 이터레이터를 만들자.\n    def __init__(self):\n        self.candidate = [\"묵\", \"찌\", \"빠\"]\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        if action == \"찌\":\n            print(\"찌가 나와서 for문을 멈춥니다.\")\n            raise StopIteration\n        else:\n            return action\n\n\na=Klass()\n\n\na?\n\n\nType:        Klass\nString form: <__main__.Klass object at 0x7f4b7aabf0d0>\nDocstring:   <no docstring>\n\n\n\n\n\nset(dir(a)) & {'__iter__', '__next__'}  # a는 이터레이터\n\n{'__iter__', '__next__'}\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n'빠'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n'빠'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n찌가 나와서 for문을 멈춥니다.\n\n\nStopIteration: \n\n\n\nfor i in a:\n    print(i)\n\n묵\n묵\n묵\n찌가 나와서 for문을 멈춥니다.\n\n\n\n\n파이썬의 비밀 1~5\n\n파이썬의 비밀1: 자료형은 클래스의 비밀이다.(11주차)\n파이썬의 비밀2: 클래스에는 __str__처럼 숨겨진 메서드가 존재한다. 이를 이용하여 파이썬 내부의 기능을 가로챌 수 있다.(12주차0523)\n파이썬의 비밀3: 주피터노트북에서는 “오브젝트이름+엔터” 를 쳐서 나오는 출력은 __repr__로 가로챌 수 잇다.(주피터의 비밀)\n파이썬의 비밀4: 함수와 클래스는 숨겨진 메서드에 __call__을 가진 오브젝트일 뿐이다.\n파이썬의 비밀5: for문의 비밀 (iterable object, iterator, StopIteration Error)"
  },
  {
    "objectID": "posts/Python/4. Class/python 14_0606.html#클래스공부-9단계",
    "href": "posts/Python/4. Class/python 14_0606.html#클래스공부-9단계",
    "title": "파이썬 (0606) 14주차",
    "section": "클래스공부 9단계",
    "text": "클래스공부 9단계\n\n예비학습 (변수의 범위)\n커널을 재시작하고 아래를 관찰하자\n예제1\n- 관찰1: 함수내의 변수 출력\n\ndef f():\n    x=10\n    print(x)\n\n\nf()\n\n10\n\n\n- 관찰2: 함수내의 변수가 없을 경우 출력이 되지 않음\n\ndef g():\n    print(x)\n\n\ng()\n\nNameError: name 'x' is not defined\n\n\n- 관찰3: 동일한 이름의 변수가 global에 있다면 함수내에 (local에) 그 이름의 변수가 선언되지 않아도 global의 변수를 빌려서 사용함\n\nx=20        # global\ndef g():    # local\n    print(x)\n\n\ng()\n\n20\n\n\n- 관찰4: f()가 실행되면서 x=10이 함수내에 (=local에) 실행되지만 이 결과가 외부의 x=20에 (=global에) 영향을 미치지는 못함\n\nf()\n\n10\n\n\n\nx\n\n20\n\n\n예제2\n(코드1)\n\nx= 38\ndef nextyear():\n    y=x+1\n    print(x,y)\nnextyear()\n\n38 39\n\n\n(코드2)\n\nx= 38\ndef nextyear():\n    y=x+1\n    print(x,y)\n    x=0\nnextyear()\n\nUnboundLocalError: local variable 'x' referenced before assignment\n\n\n- 해석: - 잘못된 해석: 코드1은 실행되었고 코드 2에서 에러가 남. 코드1과 2의 차이점은 x=0 이라는 코드가 코드2에 추가로 포함되어 있다는 것이다. 따라서 x=0이 잘못된 코드이고 이걸 실행하는 과정에서 에러가 발생했다. - 올바른 해석: 코드1에서는 x가 global variable 이고 코드2에서는 x가 local bariable이어서 생기는 문제\n- 코드2의 올바른 수정\n\nx= 38\ndef nextyear():\n    x=0\n    y=x+1\n    print(x,y)\nnextyear()\n\n0 1\n\n\n\n\n인스턴스 변수, 클래스 변수 (12주차) 0518\n- 예비학습이 주는 교훈\n(원칙1) global 에서 정의된 이름은 local에서 정의된 이름이 없을 경우 그를 대신할 수 있다. (local은 경우에 따라서 global에 있는 변수를 빌려 쓸 수 있다.)\n(원칙2) local과 global 에서 같은 이름이 ’x’가 각각 정의되어 있는 경우? global의 변수와 local의 변수는 각각 따로 행동하며 서로 영향을 주지 않는다. (독립적이다)\n\n만약에 local이 global의 변수를 같이 쓰고 있었다고 할지라도, 추후 새롭게 local에 이름이 새롭게 같은 이름의 변수가 정의된다면 그 순간 local과 global의 변수를 각자 따로 행동하며 서로 영향을 주지 않는다. \\(\\to\\) 아래 예제 확인\n\n\nx=10\ndef f():\n    print(x)\n\n\nf() # x를 빌려쓰는 신세\n\n10\n\n\n\ndef f():\n    x=20   # 이제 새롭게 x를 정의했으니까\n    print(x)\n\n\nf()    # 다른길을 간다\n\n20\n\n\n- 이전에 공부하였던 인스턴스변수와 클래스변수 역시 비슷한 행동을 보인다.\n\nclass Moo:\n    x=0  # 클래스변수\n    \n    \n    ## 인스턴스변수는 self.x 또는 __init__ 이렇게\n\n\nmoo=Moo()\n\n(관찰1)\n\nMoo.x, moo.x\n\n(0, 0)\n\n\n\nmoo.x는 사실 정의한적 없지만 Moo.x 를 빌려쓰고 있다 (원칙1)\n\n(관찰2)\n\nMoo.x=100\n\n\nMoo.x, moo.x\n\n(100, 100)\n\n\n\nMoo.x를 변화시키면 moo.x도 변화한다. (빌려쓰고 있는 것이므로, 원칙1 재확인)\n\n(관찰3)\n\nmoo.x = 200\n\n\nMoo.x, moo.x\n\n(100, 200)\n\n\n\nmoo.x=200 을 하는 순간 새롭게 인스턴스 변수를 선언한 셈이 된다. 따라서 원칙2가 적용되어 이제부터 Moo.x와 moo.x는 서로 독립적으로 행동한다.\n\n(관찰4)\n\nMoo.x= -99\n\n\nMoo.x, moo.x\n\n(-99, 200)\n\n\n\nmoo.x=99\n\n\nMoo.x, moo.x\n\n(-99, 99)\n\n\n\nMoo.x를 바꾼다고 해서 moo.x가 영향받지 않고 moo.x를 바꿔도 Moo.x가 영향 받지 않음 (완전히 독립, 원칙2의 재확인)\n\n- 포인트: (1) 클래스변수와 인스턴스 변수의 구분 (2) 인스턴스 변수가 정의되지 않으면 클래스변수를 빌려쓸 수 있음 (3) 인스턴스변수와 클래스변수가 같은 이름으로 저장되어 있으면 각각 독립적으로 행동\n\n\n인스턴스 메서드\n- self의 비밀: 사실 클래스에서 정의된 함수의 첫번째 인자의 이름이 꼭 self일 필요는 없다. (무엇으로 전달하든 클래스안에서 정의된 메소드의 첫번째 인자는 기본적으로 instance의 태명 역할을 한다.)\n\nclass Moo:\n    def __init__(abab):\n        abab.name = 'boram'\n    def f(self):\n        print(self.name)\n\n\nmoo=Moo()\n\n\nmoo.name\n\n'boram'\n\n\n\nmoo.f()\n\nboram\n\n\n\n# self대신에 ababab 이런거 써도 되긴 함\n\n- 인스턴스 메서드: 위의 __init__ 와 f 와 같이 첫번째 인자를 인스턴스의 태명으로 받는 함수를 인스턴스 메서드(간단히 메서드) 라고 한다. - 인스턴스 메소드는 self.f() 와 같이 사용한다. 의미는 f(self) 이다.\n\nmoo.name = 'hynn'\n\n\nmoo.__init__()   # 인스턴스메서드의 사용예시: self.__init__()의 꼴로 사용\n\n\nmoo.name\n\n'boram'\n\n\n\nmoo.f() # 인스턴스메서드의 사용예시: self.__init__()의 꼴로 사용\n\nboram\n\n\n\nMoo.__init__()  # 사용안됨\n\nTypeError: __init__() missing 1 required positional argument: 'abab'\n\n\n\nMoo.f()  # 사용안됨\n\nTypeError: f() missing 1 required positional argument: 'self'\n\n\n\n\n클래스 메서드\n- 클래스 메서드: 함수의 첫 인자로 클래스오브젝트를 받는 메서드를 클래스 메서드라고 한다.\n- 목표: Moo.f()와 같은 형태로 사용할 수 있는 함수를 만들어 보자 -> 클래스 메서드를 만들어보자!\n\nclass Moo:\n    def f(self):\n        print(\"인스턴스 메서드\")\n\n\nmoo=Moo()\n\n\nmoo.f()\n\n인스턴스 메서드\n\n\n\nMoo.f()\n\nTypeError: f() missing 1 required positional argument: 'self'\n\n\n\nclass Moo:\n    @classmethod\n    def f(cls):  # 함수의 첫 인자로 클래스오브젝트를 받는다. cls는 클래스 Moo의 가칭이라고 생각하면 된다.\n        print(\"클래스 메서드\")\n\n\nmoo=Moo()\n\n\nMoo.f()\n\n클래스 메서드\n\n\n\nmoo.f()  # 상위에서 정의한걸 빌려옴.. \n#인스턴스 메서드를 따로 정의한적은 없지만 같은 이름의 클래스 메서드가 있으므로 빌려서 씀\n\n클래스 메서드\n\n\n- 예제\n\nclass Moo:\n    @classmethod\n    def set_class_x(cls,value): # 클래스메서드\n        cls.x=value   # 클래스변수 선언, note: Moo.x = value와 같은 코드 \n    def set_instance_x(self, value): # 인스턴스메서드\n        self.x = value  # 인스턴스 변수선언\n\n\nmoo=Moo()\n\n\nMoo.set_class_x(10)   # 클래스 메서드로 클래스 변수에 10을 설정\n\n\nMoo.set_instance_x(10)   # 클래스에서 인스턴스 메서드를 사용 -> 사용 불가\n\nTypeError: set_instance_x() missing 1 required positional argument: 'value'\n\n\n\nMoo.x, moo.x   # 인스턴스 변수는 따로 설정하지 않았지만 클래스 변수값을 빌려쓰고 있음\n\n(10, 10)\n\n\n\nmoo.set_class_x(20) # 인스턴스에서는 원래 set_class_x 라는 메서드는 없지만 클래스에는 있어서 빌려씀\n\n\nMoo.x, moo.x  # 현재 moo.x는 클래스 변수를 빌려쓰고 있는 상황이므로 같이 바뀜\n\n(20, 20)\n\n\n\nmoo.set_instance_x(-20) # 인스턴스에서 인스턴스 메서드를 사용하여 인스턴스 변수값을 -20으로 설정\n#-> 이때부터 인스턴스변수와 클래스 변수는 서로 독립적인 노선을 간다.\n\n\nMoo.x, moo.x \n\n(20, -20)\n\n\n\nMoo.set_class_x(30)   # 독립적인 노선을 가기로 했으므로 클래스변수만 30으로 바뀜\n\n\nMoo.x, moo.x \n\n(30, -20)\n\n\n\nmoo.set_class_x(-40)   # 여전히 인스턴스에서 set_class_x라는 함수는 없으므로 클래스메서드를 빌려쓰고 있음\nMoo.x, moo.x\n\n(-40, -20)\n\n\n\n\n스태틱 메서드\n- 스태틱 메서드: 첫 인자로 인스턴스와 클래스 모두 받지 않음. (클래스 안에 정의되어 있지만 그냥 함수와 같음)\n\nclass Cals:\n    @staticmethod\n    def add(a,b):\n        return a+b\n    @staticmethod\n    def sub(a,b):\n        return a-b\n\n\nfs = Cals()\n\n\nfs.add(1,2)\n\n3\n\n\n\nfs.sub(1,2)\n\n-1\n\n\n\nfs는 그냥 함수들을 묶어놓은 느낌? 정리하기 편하게"
  },
  {
    "objectID": "posts/Python/4. Class/python 14_0606.html#클래스공부-10단계",
    "href": "posts/Python/4. Class/python 14_0606.html#클래스공부-10단계",
    "title": "파이썬 (0606) 14주차",
    "section": "클래스공부 10단계",
    "text": "클래스공부 10단계\n\n문자열 join\n- 예제\n\nlst = list('abcd')\n\n\nlist('abcd')\n\n['a', 'b', 'c', 'd']\n\n\n\n'abcd' #위의 리스트를 이렇게 모여서 쓰여지게 하고 싶다\n\n'abcd'\n\n\n\n''.join(lst)\n\n'abcd'\n\n\n- 해설: ’’는 string object이고 .join는 string object에 소속된 메서드이다.\n\na=''\n\n\na?\n\n\nType:        str\nString form: \nLength:      0\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n\n\na.join?\n\n\nSignature: a.join(iterable, /)\nDocstring:\nConcatenate any number of strings.\nThe string whose method is called is inserted in between each given string.\nThe result is returned as a new string.\nExample: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\nType:      builtin_function_or_method\n\n\n\n\n\na.join(lst)  # join(a,lst)와 같은효과\n\n'abcd'\n\n\n- join의 간단한 사용방법\n\n'-'.join(lst)  # '' 안에 - 넣어서 \n\n'a-b-c-d'\n\n\n\n\nmatplotlib\n- 파이썬의 모든 것은 객체이다: - matplotlib의 다른사용 (객체지향적 언어로 그림 그리기!)\n- 그림 오브젝트 생성\n\nfig = plt.figure() # 그림 오브젝트가 생성되고 fig라는 이름 \n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig\n\n<Figure size 432x288 with 0 Axes>\n\n\n- 그림 오브젝트의 액시즈를 확인 -> 아무것도 없음..\n\nfig.axes\n\n[]\n\n\n- (0,0) 자리에 (가로=1, 세로=1) 크기의 그림틀(액시즈)을 넣어보자.\n\nfig.add_axes([0,0,1,1])\n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig\n\n\n\n\n- 액시즈추가\n\nfig.add_axes([0,1.2, 1,1])  #   (0,1.2) 위치에  가로길이가 1, 세로길이가 1인 그림\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n- (0.5,0.5) 위치에 (가로=1, 세로=1 ) 크기의 그림 추가\n\nfig.add_axes([0.5,0.5,1,1])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n- fig 의 세번째 액시즈에 접근\n\na3=fig.axes[2]   # id 찍어보면 어딘가게 엊장되어 있음. 오브젝트임\na3\n\n<Axes:>\n\n\n- 액시즈의 메소드중에 plot가 있음 -> 이것을 그림으로 그려보자\n\na3.plot([1,2,3],[4,5,3],'--r')   # --r : 점선으로 빨간색으로 \n\n\nfig\n\n\n\n\n- 다시 세번째 축에 접근하여 다른그림을 그려보자.\n\nfig.axes[-1].plot([1,2,3],[5,4,3],':o')\nfig\n\n\n\n\n- 이제 첫번째 축에 접근하여 다른그림을 그려보자.\n\nfig.axes[0].plot([1,2,3],[4,1,4],'--b')\nfig\n\n\n\n\n- 클래스에 대한 이해가 없다면 위와 같은 그림을 그리기도 힘들고 코드를 해석하기도 힘듬\n\n\nshallow copy\n- 아래의 코드를 관찰하자.\n\na=[1,2,3]\nb=a\na=a+[4]\n\n현재 a,b의 출력 결과는?\n\na, b\n\n([1, 2, 3, 4], [1, 2, 3])\n\n\n- 이제 다시 아래의 코드를 관찰하자.\n\na=[1,2,3]\nb=a\na.append(4)\n\n현재 a,b의 출력 결과는?\n\na, b\n\n([1, 2, 3, 4], [1, 2, 3, 4])"
  },
  {
    "objectID": "posts/Python/1. Basic/python 3_0321.html",
    "href": "posts/Python/1. Basic/python 3_0321.html",
    "title": "파이썬 (0321) 3주차",
    "section": "",
    "text": "(리스트가 아니고) 튜플을 쓰는 이유\n- 책의 설명 (파이썬에 한정되는 것은 아니고 모든 언어에 존재하는 불변형 객체에 적용가능한 설명) - 실수방지 - 빠르다, 다중작업에 유리하다, 여러사람과 작업하기에 유리하다, 깊은복사/얕은복사시 원하지 않는 오류(side effect라고 함)를 방지할 수 있다, 메모리관리에도 유리함 등등 - 느낌: 불변형은 기능제한이 있는데 가볍고 빠른, 가변형은 기능은 풍부하지만 약간 느리고 무거운 느낌임 (불변형: 라면사리, 가변형:라면)\n- 교수님 설명 (파이썬 한정 불변객체, 즉 튜플에 대한 설명) - 튜플의 장점은 소괄호의 생략에 있음 (파이썬과 줄리아만 가능) - 이것이 언패킹구문과 결합하여 어마무시한 가독성을 제공한다.\n\ndef mycal(a,b):\n    return a+b, a-b, a*b, a/b # 여러개의 값을 리턴하는 듯 보인다. ->  사실은 길이가 4인 튜플 1개를 리턴\n\n\nmycal(2,3)\n\n(5, -1, 6, 0.6666666666666666)\n\n\n\n_, _, mulrslt, _ = mycal(2,3) # 병렬할당\n\n\nmulrslt\n\n6\n\n\n- 의문: 왜 튜플만 괄호를 생략할 수 있지?\n- 교수님 생각 - 튜플을 먼저 만들고, 괄호를 생략하는 문법을 추가한것은 아닐것임 - 원래 괄호없이 컴마만 대충찍어서 선언가능한 간단한 타입의 벡터형을 만들고 싶었을 것임 - 왜? 괄호없는 벡터를 만들고 + 연패킹을 사용하면 여러가지 구문들이 엄청나게 간단해짐 - 컴마컴마로 선언하는 벡터는 한 두번 쓰고 버리는 경우가 많으며 대부분 이름도 필요 없음 -> 원소에 접근해서 sorting하여 순서를 바꾸고 싶다던가 원소를 추가할 이유가 없음 -> 비싼 가변형으로 만들 이유가 없다. - 필요한것: 데이터가 벡터의 형태로 모여있기만 하면 된다.\n- 다른사람들 의견 (컴공과) - 튜플 + 언패킹에 충격 \\(\\to\\) 파이썬 편하다..\n\n\n인덱싱고급(스트라이딩)\n- 스트라이딩 [start:stop:step]\n\nlst = list('abcdefgh')\nlst\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n\nlst[0:8:2]\n\n['a', 'c', 'e', 'g']\n\n\n- 생략\n\nlst[:]\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n\nlst[::2]\n\n['a', 'c', 'e', 'g']\n\n\n\nlst[:8:2]\n\n['a', 'c', 'e', 'g']\n\n\n- 예제: 짝수/홀수 원소 추출\n\nlst\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n\nlst[::2]  # 1,3,5,7, ... 홀수 원소\n\n['a', 'c', 'e', 'g']\n\n\n\nlst[1::2] # 2,4,6,8,... 짝수 원소\n\n['b', 'd', 'f', 'h']\n\n\n- step = -1이면?\n\nlst[::-1]    # 뒤에서부터\n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n\nreverse와 같은 기능\n\n(reverse)와 비교\n관찰1: reverse 메소드는 리소드 자체를 변화시킴\n\nlst = list('abcdefgh')\nlst\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n\nlst.reverse()  # 리버스는 자체가 변화한다.\nlst  \n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n관찰2: [::-1] 는 리스트는 변화시키지 않음\n\nlst = list('abcdefgh')\nlst\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n\nlst[::-1]\n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n\nlst\n\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n\n\n- 사실 -step은 쓰는 것이 조금 까다롭다.\n(예제) 처음과 끝을 생략하지 않고 아래와 동일한 효과를 주는 코드를 만들어 보자.\n\nlst = list('abcdefgh')\nlst[::-1]\n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n결국 lst[?:?:-1]의 꼴에서 적당히 ?의 값을 채우면 된다.\n\nlst[-1::-1] # 일단 첫 시작ㄷ은 제일 마지막 원소\n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n\nlst[-1:0:-1] # 마지막 인덱스는 포함x\n\n['h', 'g', 'f', 'e', 'd', 'c', 'b']\n\n\n\nlst[-1:-1:-1] \n\n[]\n\n\n잠깐 인덱스를 생각해보자.\n\n\n\na\nb\nc\nd\ne\nf\ng\nh\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n\n\n-8\n-7\n-6\n-5\n-4\n-3\n-2\n-1\n\n\n\n\nlst[-1:-8:-1] \n\n['h', 'g', 'f', 'e', 'd', 'c', 'b']\n\n\n\nlst[-1:-9:-1] \n\n['h', 'g', 'f', 'e', 'd', 'c', 'b', 'a']\n\n\n(예제)\n\nlst[2::2]\n\n['c', 'e', 'g']\n\n\n\nlst[-2::-2]\n\n['g', 'e', 'c', 'a']\n\n\n\nlst[-2:2:2]\n\n[]\n\n\n\nlst[2:3:2]\n\n['c']\n\n\n\nlst[2:2:2]\n\n[]\n\n\n\nlst[2:2:-2]\n\n[]\n\n\n결론: -step을 자주 쓰진 말자\n\n\n컴프리헨션 고급 (if문이 포함된 컴프리헨션)\n- 예제: 제곱수준에서 12로 나누어 떨어지는 수만 원소로 가지는 리스트를 만들고 싶다. - 제곱수: 1,4, 9, 16, 25, 36, … - 12로 나누어 떨어지는 수: 36…\n(예비학습)\n\n12 % 5 # 나머지 리턴\n\n2\n\n\n(풀이)\n\nlst=[]\nfor i in range(1,101):\n    if (i**2 % 12 == 0 ):\n        lst.append(i**2)\n\n\nlst\n\n[36,\n 144,\n 324,\n 576,\n 900,\n 1296,\n 1764,\n 2304,\n 2916,\n 3600,\n 4356,\n 5184,\n 6084,\n 7056,\n 8100,\n 9216]\n\n\n(풀이2)\n\n[i**2 for i in range(1,101) if (i**2 % 12==0)]\n\n[36,\n 144,\n 324,\n 576,\n 900,\n 1296,\n 1764,\n 2304,\n 2916,\n 3600,\n 4356,\n 5184,\n 6084,\n 7056,\n 8100,\n 9216]\n\n\n\n\n함수고급 (조건부리턴)\n- 홀수 짝수를 판별하는 함수 만들기1\n\ndef test(a):\n    if a% 2 ==0:\n        return 'even'\n    else:\n        return 'odd'\n\n\ntest(0)\n\n'even'\n\n\n\ntest(3)\n\n'odd'\n\n\n\n[test(a) for a in range(1,11)]\n\n['odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even']\n\n\n- 홀수 짝수를 판별하는 함수 만들기2\n\ndef test(a):\n    return 'even' if a%2==0 else 'odd'\n\n\ntest(2)\n\n'even'\n\n\n\n[test(a) for a in range(1,11)]\n\n['odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even']\n\n\n\n\nlen함수\n- 0차원 자료형은 len함수가 동작하지 않음\n\na=1\nlen(a)\n\nTypeError: object of type 'int' has no len()\n\n\n\na=True\nlen(a)\n\nTypeError: object of type 'bool' has no len()\n\n\n\na=3.14\nlen(a)\n\nTypeError: object of type 'float' has no len()\n\n\n\nnote: 이것이 어떠한 수학적인 의미를 가지거나 0차원의 본질적인 진리를 뜻하는 것은 아니다. R에서는 1, 3.14, True의 길이가 1로 존재함\n\n- 1차원 자료형은 len함수가 동작\n\na='boram'\nlen(a)\n\n5\n\n\n\na=[1,2,3,4,5,6,7]\nlen(a)\n\n7\n\n\n\na=1,2,3,4\nlen(a)\n\n4\n\n\n\na=range(10)\nlen(a)\n\n10\n\n\n- 길이가 1인 1차원 자료형과 0차원 자료형은 다른것임\n\na='g'\nlen(a)\n\n1\n\n\n\na=[1]   \nlen(a)\n\n1\n\n\n\na=(1,)\nlen(a)\n\n1\n\n\n\na=range(1)\nlen(a)\n\n1\n\n\n- 길이가 0인 1차원 자료형도 존재함\n\na=''\nlen(a)\n\n0\n\n\n\na=[]\nlen(a)\n\n0\n\n\n\na=()\nlen(a)\n\n0\n\n\n\na=range(0)\nlen(a)\n\n0\n\n\n\n\nsummary : str, list, tuple\n- str,list, tuple은 모두 시퀀스형이라는 공통점이 있다. \\(\\to\\) 원소의 위치번호로 인덱싱이 가능\n\nlst=[1,2,3,4]\n\n\nlst[0]  #위치번호=0\n\n1\n\n\n\nlst[-1]  #위치번호=1\n\n4\n\n\n- str, list, tuple은 차이점도 존재함. 잠깐 정리해보자.\n*** 시퀀스형의 카테고리***\n\n컨테이너형: list, tuple\n균일형: str\n가변형: list\n불변형: tuple, str\n\n*****표로 정리하면*****\n\n\n\n\n컨테이너형\n균일형\n\n\n\n\n가변형\nlist\n-\n\n\n불변형\ntuple\nstr\n\n\n\n- 시퀀스형이 아닌 1차원 자료형도 있을까? 원소의 위치번호로 인덱싱이 불가능한 자료형\n- 왜 이런게 필요할까? - 벡터에서 원소를 뽑는것은 정보의 모임에서 정보를 검색하는 것과 같다. - 정보를 순서대로 나열한 뒤에 그 순서를 이용하여 검색하는 방법은 유용하다. - 하지만 경우에 따라서는 키워드 를 기억해서 그 키워드를 바탕으로 정보에 접근하는 방법이 유용할 수 있다.\n****카카오톡 대화내용 검색****\n(상황1) 오늘 아침에 와이프가 뭔가를 카톡으로 부탁함. 그런데 그 뭔가가 기억안남.\n(상황2) 개강전에 동료교수와 함께 저녁약속을 카톡으로 잡았었음. 그런데 그게 언제인지 기억안남.\n(상황3) 오늘아침 동료교수와 함께 점심약속을 카톡으로 잡았었음. 그런데 그 장소가 기억나지 않음\n- 순서대로 정리된 자료를 검색할때는 시퀀스형이 유리하다. 그런데 키워드로 검색하고 싶을 경우는 딕셔너리 타입이 유리하다.\n\n\ndict\n선언\n- 방법1\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n\ntype(score)\n\ndict\n\n\n- 방법2\n\nscore=dict(boram=49, iu=80)\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n\ntype(score)\n\ndict\n\n\n- 방법3\n\n_lst= [['boram',40],['iu',80]] \n_lst\n\n[['boram', 40], ['iu', 80]]\n\n\n\ndict(_lst)\n\n{'boram': 40, 'iu': 80}\n\n\n- 방법4\n\n_tpl = ('boram',49),('iu',80)\n_tpl\n\n(('boram', 49), ('iu', 80))\n\n\n\ndict(_tpl)\n\n{'boram': 49, 'iu': 80}\n\n\n원소추출\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\nboram의 점수를 추출하고 싶다면?\n\nscore[0]   # 이렇게 ㄴㄴ \n\nKeyError: 0\n\n\n\nscore['boram']   # 위치번호가 아닌 key를 넣어야 한다.\n\n49\n\n\n- 리스트로 저장했다면?\n\nscore=[['boram',49],['iu',80]]\nscore\n\n[['boram', 49], ['iu', 80]]\n\n\n(방법1)\n\nscore[0][1]  # boram의 점수를 출력하란 의미 , 가독성이 떨어짐,\n\n49\n\n\n(방법2)\n\n_keys = [score[i][0] for i in range(len(score))]   #리스트컴프리헨션\n_keys\n\n['boram', 'iu']\n\n\n\n_values = [score[i][1] for i in range(len(score)) if score[i][0]=='boram']  \n_values\n\n[49]\n\n\n원소추가, 변경, 삭제\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n- 추가\n\nscore['hynn']=99 # 추가\n\n\nscore\n\n{'boram': 49, 'iu': 80, 'hynn': 99}\n\n\n\nscore['boram']\n\n49\n\n\n- 변경\n\nscore['iu']=99   # 변경 ( 가변형)\nscore\n\n{'boram': 49, 'iu': 99, 'hynn': 99}\n\n\n\nscore\n\n{'boram': 49, 'iu': 99, 'hynn': 99}\n\n\n-삭제1\n\nscore={'boram':49, 'iu':80, 'hynn':99}\ndel score['boram']   # 삭제 방법 1\nscore\n\n{'iu': 80, 'hynn': 99}\n\n\n-삭제2\n\nscore={'boram':49, 'iu':80, 'hynn':99}\nscore.pop('boram')   # 삭제 방법 2\nscore\n\n{'iu': 80, 'hynn': 99}\n\n\n- 참고로 리스트였다면 이러한 삭제작업역시 비효율적이였을 것임\n\nscore = [['guebin',49],['iu',80],['hynn',99]] \nscore\n\n[['guebin', 49], ['iu', 80], ['hynn', 99]]\n\n\n\nscore = [[key,val] for key,val in score if key != 'guebin'] \nscore\n\n[['iu', 80], ['hynn', 99]]\n\n\n(숙제) 길이가 4인 dictionary를 생성 - len 함수를 이용하여 길이를 측정 - key를 이용하여 각 원소에 접근하여 보기\n\n_number = {'sung':2195, 'park':2836, 'choi':4236, 'kim':4738}\n_number\n\n{'sung': 2195, 'park': 2836, 'choi': 4236, 'kim': 4738}\n\n\n\nlen(_number)\n\n4\n\n\n\n_number['park']\n\n2836\n\n\n\n_number['choi']\n\n4236\n\n\n\n_number['jung']=4280\n\n\n_number\n\n{'sung': 2195, 'park': 2836, 'choi': 4236, 'kim': 4738, 'jung': 4280}\n\n\n\n_number.pop('kim')\n\n4738\n\n\n\n_number\n\n{'sung': 2195, 'park': 2836, 'choi': 4236, 'jung': 4280}"
  },
  {
    "objectID": "posts/Python/1. Basic/python 1_0307.html",
    "href": "posts/Python/1. Basic/python 1_0307.html",
    "title": "파이썬 (0307) 1주차",
    "section": "",
    "text": "- 파이썬의 기본자료형은 int, float, bool, str, list, tuple, dict, set 등이 있다.\n\n0차원 자료형: int, float, bool\n1차원 자료형: str, list, tuple, dict, set\n\n\n\n- int형\n\na=100\n\n\ntype(a)\n\nint\n\n\n- float형\n\na?\n\n\na=1.2*3\n\n\ntype(a)\n\nfloat\n\n\n- bool형\n\na=True   # 숫자1\nb=False  # 숫자0\n\n\ntype(a)\n\nbool\n\n\n\n# bool형의 연산\na+b\n\n1\n\n\n- complex형\n\na=1+2j\nb=2-2j\n\n\na\n\n(1+2j)\n\n\n\ntype(a)\n\ncomplex\n\n\n\na+b\n\n(3+0j)\n\n\n\ntype(a+b)\n\ncomplex\n\n\n- 형태변환: float -> int\n\na=3.0\ntype(a)\n\nfloat\n\n\n\na=int(a)\n\n\na?\n\n\na=3.14\nint(a)\n\n# 0.14날라가고 3만나옴. 정보의 손실이 있다.\n\n3\n\n\n- 형태변환: int $$ float\n\na=3\ntype(a)\n\nint\n\n\n\na=float(a)\ntype(a)\n\nfloat\n\n\n- 형태변환: bool $$ int/float\n(예시1)\n\na=True\ntype(a)\n\nbool\n\n\n\nint(a)\n\n1\n\n\n\nfloat(a)\n\n1.0\n\n\n(예시2)\n\na=1\nbool(a)\n\nTrue\n\n\n(예시3)\n\na=1.0\nbool(a)\n\nTrue\n\n\n\na=0.0\nbool(a)\n\nFalse\n\n\n- 이상한 형태변환도 가능하다\n\nbool(-3.14)\n\nTrue\n\n\n\nbool(3.14)\n\nTrue\n\n\n\nbool(0)\n\nFalse\n\n\n\nbool(3.24342)\n\nTrue\n\n\n\n# 위와 같은 코드를 의도적으로 사용하진 않는다. \n\n- 형태변환이 항상 가능한 것도 아님\n\nfloat(3+0j) # 사실상 3+0j= 3이므로 float으로 형변환하면 3.0이 되어야 할 것 같은데 오류가 남\n\nTypeError: can't convert complex to float\n\n\n- 암묵적형변환 (implicit)\n(예비학습) implicit의 의미 - 추운날씨 -> 보일러좀 틀자! 명시적(explicit) / 오늘 날씨가 좀 춥지 않아? (implicit) - 짜장면 먹을래? -> 싫어 (explicit) / 난 어제 짜장면 먹었는데… (implicit)\n\nint(True) #명시적\n\n1\n\n\n\nTrue * 1 # 암묵적형\n\n1\n\n\n\n1 * 1.0\n\n1.0\n\n\n\nTrue+True\n\n2\n\n\n\n\n\n- str\n\n# 선언\na='br'\n\n\na\n\n'br'\n\n\n\n# 연산\n# 더하기 연산\na='x'\nb='2'\n\n\na+b\n\n'x2'\n\n\n\n# 빼기 연산 없다. \na-b\n\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n\n\n\n# 곱하기 연산\na*2\n\n'xx'\n\n\n\n2*a\n\n'xx'\n\n\n\n# 의미상 맞지 않는 것은 수행되지 않는다.\na='x'\nb='y'\na+b\n\n'xy'\n\n\n\na*b\n\nTypeError: can't multiply sequence by non-int of type 'str'\n\n\n\n# 나눗셈연산은 없다. \na='xx'\na/2\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\n\n\n\n- str은 하나의 벡터 문자가 여러개 있는 형태라고 생각하기\n\na='boram'\na\n\n'boram'\n\n\n\n5개의 칸에 글씨가 하나씩 들어가 있음\n\n\na[0]  # 0이 첫번쨰 원소\n\n'b'\n\n\n\na[1] # 두번째 원소\n\n'o'\n\n\n\n# 마지막 원소를 호출하려면 -1로 호출할 수도 있다.\na[-1]\n\n'm'\n\n\n\na[4]\n\n'm'\n\n\n\na[-2]\n# 마지막에서 2번째 원소는 -2로 호출 가능\n\n'a'\n\n\n\n어려개의 원소는 :을 이용하여 호출할 수 있음\n\n\na[0:3] # a[0], a[1], a[2]까지만 뽑힌다. a[3]은 호출되지 않는다.\n\n'bor'\n\n\n\na[1:3]\n\n'or'\n\n\n\nindex=1부터 시작해서 마지막 원소까지 호출하려면?\n\n\na[5]\n\nIndexError: string index out of range\n\n\n\na[1:5]  # a[5]는 없는데,, 이렇게 쓰니까 헷갈릴 수 있다.\n\n'oram'\n\n\n\na[1:-1]   # 이것은 a[1:4] 와 같음\n\n'ora'\n\n\n\n# 해결책! 생략한다.\na[1:]\n\n'oram'\n\n\n- 생략의 응용1\n\na='k-pop'\na\n\n'k-pop'\n\n\n\na[2:]\n\n'pop'\n\n\n\na[2:5]\n\n'pop'\n\n\n- 생략의 응용2\n\na='k-pop'\na\n\n'k-pop'\n\n\n\na[0:2]\n\n'k-'\n\n\n\na[:2]   # 앞을 생략하면 첫 원소부터 나온다.\n\n'k-'\n\n\n- 생략의 응용3\n\na='k-pop'\na\n\n'k-pop'\n\n\n\na[:]\n\n'k-pop'\n\n\n\na[0:5]\n\n'k-pop'\n\n\n\n\n- 파이썬의 변수는 단순히 정보를 담는 그릇이 아니다. 유용한 기능을 제공하는 경우가 있다.\n\na='ABCD'  #a라는 변수는 'ABCD'라는 정보를 담는 그릇의 역할만 하지 않고, 특화된 어떠한 기능도 제공한다.\na\n\n'ABCD'\n\n\n\na.lower() #소문자변환\n\n'abcd'\n\n\n\n# lower()는 문자열에 특화된 기능이며 아래 내용은 안됨\na=3.14\na.lower()\n\nAttributeError: 'float' object has no attribute 'lower'\n\n\n- 자료형에 특화된 기능(=함수)을 확인하는 방법 a. + tab 으로 목록 확인 가능\n\na='boram'\n\n\na.lower?\n\n\na.upper()   # 대문자 변환\n# upper(a)\n\n'BORAM'\n\n\n\na.capitalize()\n\n'Boram'\n\n\n- 마음의눈: a.f() 형태를 읽는 팁 - a.f()는 f(a)로 생각하면 편리함 - a.f(2)는 f(a,2)로 생각하면 편리함 - 이런점에서 R %>% 연산자와 비슷하다고 생각할 수 있다. (약간 다름)\n- 사실 .은 좀 더 다양한 상황에서 쓰일 수 있다. 변수이름.함수이름() 의 형태가 아니라 - 패키지이름.함수이름() - 패키지이름.변수이름 - 패키지이름.패키지이름.함수이름()\n… 와 같이 다양한 형태가 가능하다. 근본적인 고통점은 .을 기준으로 상위개념.하위개념으로 이해하는 것이 좋다.\n\n\n\n\n- len 함수 : 원소의 갯수를 알려주는 함수\n(0차원) len함수가 동작하지 않는다.\n\na=3.14\nlen(a)\n\nTypeError: object of type 'float' has no len()\n\n\n\nb=True\nlen(b)\n\nTypeError: object of type 'bool' has no len()\n\n\n(1차원) len함수가 잘 동작함\n\na='3.14'\nlen(a)\n\n4\n\n\n\nb=[1,2,3]\nlen(b)\n\n3\n\n\n숙제\n\na='BoramKim'\na\n\n'BoramKim'\n\n\n\na[:5]\n\n'Boram'\n\n\n\na[5:]\n\n'Kim'"
  },
  {
    "objectID": "posts/Python/1. Basic/python 4_0323.html",
    "href": "posts/Python/1. Basic/python 4_0323.html",
    "title": "파이썬 (0323) 4주차",
    "section": "",
    "text": "연산\n- 하나있다.`\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n\n'boram' in score\n\nTrue\n\n\n\n\n'iu' in score\n\nTrue\n\n\n\n'hynn' in score\n\nFalse\n\n\n- in은 사실 다른 자료형도 가능하다`\n(관찰1)\n\n'a' in 'boram'\n\nTrue\n\n\n\n'c' in 'boram'\n\nFalse\n\n\n(관찰2)\n\ntpl = 1,2,3\ntpl\n\n(1, 2, 3)\n\n\n\n1 in tpl\n\nTrue\n\n\n\n4 in tpl\n\nFalse\n\n\n(관찰3)\n\nscore=[['boram',49], ['iu',80]]\nscore\n\n[['boram', 49], ['iu', 80]]\n\n\n\n['boram', 49] in score\n\nTrue\n\n\n- in 연산자가 dict형에 사용되면 key를 기준으로 True, False을 판단한다.\n\n\n메소드\n(get)\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n\nscore.get('boram')\n\n49\n\n\n아래와 같은 기능\n\nscore['boram']\n\n49\n\n\n미묘한 차이점이 존재함\n\nscore['hynn']  # hynn이 없어서 키에러 출력, 그런 key는 없다..\n\nKeyError: 'hynn'\n\n\n\nscore.get('hynn')  #hynn이 없으면 아무것도 출력안함\n\n(kyes, values, items)\n-.keys()는 딕셔너리의 키를 리턴한다.\n\nscore={'boram':49, 'iu':80}\nscore\n\n{'boram': 49, 'iu': 80}\n\n\n\n?score.keys\n\n\n_keys=score.keys()\n_keys\n\ndict_keys(['boram', 'iu'])\n\n\n\ntype(_keys)   # 모르는 자료형이지만, list나 tuple과 같이 자료형을 바꿀수 있다.\n\ndict_keys\n\n\n\nlist(_keys)  # 아무튼 그 이상한 자료형도 리스트화가 가능\n\n['boram', 'iu']\n\n\n-.values()는 딕셔너리의 키를 리턴한다.\n\n_values=score.values()\n_values\n\ndict_values([49, 80])\n\n\n\ntype(_values)\n\ndict_values\n\n\n\nlist(_values)\n\n[49, 80]\n\n\n-.items()는 딕셔너리의 키를 리턴한다.\n\n_items=score.items()\n_items\n\ndict_items([('boram', 49), ('iu', 80)])\n\n\n\ntype(_items)\n\ndict_items\n\n\n\nlist(_items)\n\n[('boram', 49), ('iu', 80)]\n\n\n- for문에서의 dict\n(예시1)\n\nfor i in score.keys():\n    print(i)\n\nboram\niu\n\n\n\nfor i in score:\n    print(i)\n\nboram\niu\n\n\n\n딕셔너리 그자체도 for문에 넣을 수 있다.\ni에는 value가 삭제되어 들어간다. (즉 key만)\n결과를 보면 score대신에 score.keys()와 list(score)를 넣었을때와 결과가 같다.\n\n\nNote: list(score)하면 key만 리턴된다.\n\n(예시2)\n\nfor i in score.values():\n    print(i)\n\n49\n80\n\n\n(예시3)\n\nfor k in score.items():\n    print(k)\n\n('boram', 49)\n('iu', 80)\n\n\n(예시4)\n\nfor i,j in score.items():\n    print(i,j)\n\nboram 49\niu 80\n\n\n(예시5)\n\nfor i,j in score.items():\n    print(i + '의 중간고사 점수는 %s점입니다' %j)\n\nboram의 중간고사 점수는 49점입니다\niu의 중간고사 점수는 80점입니다\n\n\n[보충학습] 문자열 새치기\n\n'제 이름은 %s입니다.'  % '김보람' \n\n'제 이름은 김보람입니다.'\n\n\n\n'제 이름은 %s입니다.'  % [1,2]\n\n'제 이름은 [1, 2]입니다.'\n\n\n\n1+1\n\n2\n\n\n\n[1,2]+[3,4]\n\n[1, 2, 3, 4]\n\n\n\n%는 새치기연산자임. %s는 새치기하는 자리라고 생각\n\n보충학습끝\n\n\n딕셔너리 고급\n키는 문자열만 가능한 것이 아니다.\n- 정수키\n\nscore = {0:49, 1:80, 1:99} # key를 0,1,2로\nscore\n\n{0: 49, 1: 99}\n\n\n- 인덱싱은?\n\nscore[0] # 키로 인덱싱을 하고 있는데 마치 원소의 위치로 인덱싱을 하는 기분\n\n49\n\n\n- 그럼 혹시 이것도?\n\nscore[:2]\n\nTypeError: unhashable type: 'slice'\n\n\n\nscore[-1]   # 될리가 없지..\n\nKeyError: -1\n\n\n- key로 가능한 것이 문자열만 가능한 것이 아니라 다른 것도 가능하다. (숫자,튜플,,)\n(예시)\n\nscore={(0,'boram'):49, (1, 'iu'):80, (2, 'hynn'):99}\nscore\n\n{(0, 'boram'): 49, (1, 'iu'): 80, (2, 'hynn'): 99}\n\n\n\nscore[(0,'boram')]\n\n49\n\n\n\nscore[0,'boram'] #tuple이니까 가로 생략 가능\n\n49\n\n\n(예시)\n\nscore={('boram',0):10, ('boram',1):20, ('boram',2):30} #0은 출석점수, 1은 레포트 점수, 2는 중간고사 점수\nscore\n\n{('boram', 0): 10, ('boram', 1): 20, ('boram', 2): 30}\n\n\n\nscore[('boram',0)]\n\n10\n\n\n\nscore['boram',0]\n\n10\n\n\n\nscore[('broam,3')] = 99  # 보람의 기말고사 점수를 추가\n\n\nscore\n\n{('boram', 0): 10, ('boram', 1): 20, ('boram', 2): 30, 'broam,3': 99}\n\n\n- 문자열, 숫자값, 튜플의 공통점? 불변객체\n\na=11\n\n\na=22  # 22로 수정된 것이 아니고 재할당된것임..\n\n\na\n\n22\n\n\n\na='boram'\n\n\na='Broam'\n\n\na  # 이것도 재할당..\n\n'Broam'\n\n\n\na[0]\n\n'B'\n\n\n\na[0]='b'  # 문자열 불변\n\nTypeError: 'str' object does not support item assignment\n\n\n\n# 수정이랑 재할당을 구분하는 방법 -> 메모리 주소 값을 찍어보면 된다.\n\n[참고로만]\n(인트형은 불변)\n\na=1\na, id(a)\n\n(1, 2254873389360)\n\n\n\na=2\na, id(a)\n\n(2, 2254873389392)\n\n\n(문자열도 불변)\n\na='boram'\na, id(a)\n\n('boram', 2254959000432)\n\n\n\na='Boram'\na, id(a)\n\n('Boram', 2254988509296)\n\n\n(리스트는 가변)\n\na=list('boram')\na, id(a)\n\n(['b', 'o', 'r', 'a', 'm'], 2254989018304)\n\n\n\na[0]='B'\n\n\na,id(a)   #id가 같다. 편집!\n\n(['B', 'o', 'r', 'a', 'm'], 2254989018304)\n\n\n\n\n집합\n\n선언\n\na={'notebook', 'desktop'}\n\n\n\n원소추출\n- 일단 인덱스로는 못한다.\n\na={'notebook', 'desktop'}\na[0]\n\nTypeError: 'set' object is not subscriptable\n\n\n- 딱히 하는 방법이 없다. 그리고 이걸 하는 의미가 없다. 원소에 접근해서 뭐하려고…!!\n원소추가\n- 이건 의미가 있다.\n\na={'notebook', 'desktop'}\n\n\na.add('ipad')\na\n\n{'desktop', 'ipad', 'notebook'}\n\n\n\na.add('notebook') # 이미 원소로 있는 건 추가 되지 않음\na\n\n{'desktop', 'ipad', 'notebook'}\n\n\n원소삭제\n\na.remove('notebook')\na\n\n{'desktop', 'ipad'}\n\n\n연산\n- in 연산자\n\n1 in [1,2,3,4]\n\nTrue\n\n\n\n5 in [1,2,3,4]\n\nFalse\n\n\n\na=('desktop','ipad','notebook')\na\n\n('desktop', 'ipad', 'notebook')\n\n\n\n'notebook' in a\n\nTrue\n\n\n- 참고로 in 연산자는 집합에서만 쓰는 것은 아님\n- 합집합, 교집합, 차집합\n\nday1 = {'notebook', 'desktop'}\nday2 = {'notebook', 'ipad'}\n\n\nday1 | day2   # 합집합\n\n{'desktop', 'ipad', 'notebook'}\n\n\n\nday1 & day2 # 교집합\n\n{'notebook'}\n\n\n\nday1 - day2  # 차집합\n\n{'desktop'}\n\n\n\nday2 - day1\n\n{'ipad'}\n\n\n- 부분집합\n\nday1={'notebook','desktop'}\nday2= day1 | {'ipad'}\n\n\nday1\n\n{'desktop', 'notebook'}\n\n\n\nday2\n\n{'desktop', 'ipad', 'notebook'}\n\n\n\nday1<day2   # day1는 day2의 부분집합인가?\n\nTrue\n\n\n\nday2<day1\n\nFalse\n\n\n메소드\n- 합집합\n\nday1= {'notebook','desktop'}\nday2 = {'notebook','ipad'}\n\n\nday1.union(day2)\n\n{'desktop', 'ipad', 'notebook'}\n\n\n\n# 나머지 메소드는 스스로 찾아보세용\n\nfor문\n\nday1= {'notebook','desktop'}\nday2 = {'notebook','ipad'}\n\n\nfor i in day1|day2:\n    print(i)\n\ndesktop\nipad\nnotebook\n\n\n(숙제) 길이가 4인 집합을 두개만들고 공통원소를 2개로 설정한 뒤 합집합을 구하는 코드를 작성하라.\n\nboram={'father','mother','me','coco'}\n\n\nlen(boram)\n\n4\n\n\n\nsu={'father','mother','su','name'}\n\n\nlen(su)\n\n4\n\n\n\nboram | su\n\n{'coco', 'father', 'me', 'mother', 'name', 'su'}"
  },
  {
    "objectID": "posts/Python/1. Basic/python 3_0316.html",
    "href": "posts/Python/1. Basic/python 3_0316.html",
    "title": "파이썬 (0316) 3주차",
    "section": "",
    "text": "- 컨테이너형타입이라는 점, 그리고 연산 및 인덱싱을 하는 방법은 리스트와 같음\n\n차이점1: [] 대신에 ()를 사용\n차이점2: 불변형이다. (원소의 값을 바꿀 수 없음)\n차이점3: 하나의 원소를 선언할 때는 (1,)와 같이 해야 한다.\n차이점4: 의미가 명확할때는 튜플의 ()를 생략가능하다.\n\n컨테이너형이라는 것이 무슨의미?\n\na=(4,6,'pencil',3.2+4.6j,[3,4])\n\n\ntype(a[3])\n\ncomplex\n\n\n\ntype(a[2])\n\nstr\n\n\n- 불변형이라는 것은 무슨 의미?\n\na[2] = 'Pencil'\n\nTypeError: 'tuple' object does not support item assignment\n\n\n참고로 a를 튜플이 아니라 리스트로 선언하면 값이 잘 바뀐다.\n- 하나의 원소로 이루어진 튜플을 만들때는 쉼표를 붙여야함\n\n[1]+[2,3,4]\n\n[1, 2, 3, 4]\n\n\n\n(1)+(2,3,4)   # int형+tuple형 이므로 계산 불가 \n\nTypeError: unsupported operand type(s) for +: 'int' and 'tuple'\n\n\n\ntype(1)\n\nint\n\n\n\n(1,)+(2,3,4)\n\n(1, 2, 3, 4)\n\n\n- 마지막차이점! 의미가 명확할때 튜플의 괄호는 생략가능하다. (중요)\n\na=(1,2)\na\n\n(1, 2)\n\n\n의미가 명확할때 생략해야함\n\n1,2 + 3,4,5\n\n(1, 5, 4, 5)\n\n\n\n(1,2)+(3,4,5)\n\n(1, 2, 3, 4, 5)\n\n\n\n\n\n- 소괄호를 이용\n\na=(1,2,3)\na\n\n(1, 2, 3)\n\n\n\ntype(a)\n\ntuple\n\n\n- 생략가능하다는 점이 포인트\n\na=1,2,3\na\n\n(1, 2, 3)\n\n\n\ntype(a)\n\ntuple\n\n\n- 원소가 하나인 튜플을 만들고 싶다면?\n\na=(1,)\na\n\n(1,)\n\n\n\n\n\n- 리스트와 동일\n\n(1,2)+(3,4,5)\n\n(1, 2, 3, 4, 5)\n\n\n\n(1,2)*2\n\n(1, 2, 1, 2)\n\n\n\n\n\n- 리스트와 동일\n\na=(1,2,3,-4,-5)\na\n\n(1, 2, 3, -4, -5)\n\n\n\na[-1]\n\n-5\n\n\n\na[-3:]\n\n(3, -4, -5)\n\n\n\n\n\n\n\n\n책의설명: 실수로 값이 변경되는 것을 방지할 수 있다.\nshaaly copy / deep copy 를 막을 수 있는 무기\n\n\n\n\n- 예제: 여러변수를 동시에 출력하고 싶을 경우 (다중출력?)\n변수를 아래와 같이 선언하였다고 하자.\n\na=1\nb=2\nc=3\n\n선언된 값을 확인하려면?\n\na\n\n1\n\n\n\nb\n\n2\n\n\n\nc\n\n3\n\n\n튜플을 이용하면?\n\na,b,c #괄호하나 생략하는 것이 편함\n\n(1, 2, 3)\n\n\n- 예제: 다중할당1 (여러개의 변수를 동시에 선언하고 싶을 경우)\n\nname, age, sex, height, weight = 'Tom', 20, 'M', 180, 70\n\n\nname, age, sex, height, weight\n\n('Tom', 20, 'M', 180, 70)\n\n\n\nheight\n\n180\n\n\n- 예제: 다중할당2, 위도와 경도\n\ncoor = (37,127) #서울\ncoor\n\n(37, 127)\n\n\n\nlat, long = coor   # (왼쪽) 가로가 생략된 튜플 \n\n\nlat\n\n37\n\n\n\nlong\n\n127\n\n\n- 잠깐만: 다중할당은 꼭 튜플에서만 가능한가?\n\n[x,y,z] = [1,2,3]\nx,y,z # 다중출력\n\n(1, 2, 3)\n\n\n\n[x,y] = 'hi'\nx,y\n\n('h', 'i')\n\n\n튜플과 같이 사용하면 가독성이 극대화 (그래서 다중할당은 거의 튜플과 세트로 사용함)\n\nx,y,z=1,2,3\nx,y,z\n\n(1, 2, 3)\n\n\n- 예제: 임시변수 사용없이 두 변수의 값을 교환\n\na=10\nb=20\n\n\na,b= b,a\n\n\na\n\n20\n\n\n\nb\n\n10\n\n\n- 예제: for문과 튜플\n\nlst = [['boram', 202212345, 'F'],\n      ['iu',202212365,'F'],\n      ['hodong',202215323,'M']]\nlst\n\n[['boram', 202212345, 'F'], ['iu', 202212365, 'F'], ['hodong', 202215323, 'M']]\n\n\n\nfor i in lst:\n    print(i)\n\n['boram', 202212345, 'F']\n['iu', 202212365, 'F']\n['hodong', 202215323, 'M']\n\n\n\nfor name, studentid, sex in lst:\n    print(name)\n\nboram\niu\nhodong\n\n\n\nfor name, studentid, sex in lst:\n    print(name, sex)\n\nboram F\niu F\nhodong M\n\n\n- 예제: for문과 튜플, dummy variable _\n\nfor name, studentid, sex in lst:\n    print(name)\n\nboram\niu\nhodong\n\n\n\nfor name, _, _ in lst:\n    print(name)   #name만 관심있으므로 그 외는 언더바를 통해 작성하는 편리함\n\nboram\niu\nhodong\n\n\n\nfor name, _ in lst:\n    print(name)\n\nValueError: too many values to unpack (expected 2)\n\n\n\nfor name, *args in lst:    #  *args 를 통해 위 오류 해결\n    print(name)\n\nboram\niu\nhodong\n\n\n- 예제: 튜플과 언패킹연산자 *\n\nhead, body, *tail = range(1,11)\nhead, body, tail\n\n(1, 2, [3, 4, 5, 6, 7, 8, 9, 10])\n\n\n\nhead1, head2, *body, tail1, tail2, tail3 = range(1,11)\nhead1, head2, body, tail1, tail2, tail3\n\n(1, 2, [3, 4, 5, 6, 7], 8, 9, 10)\n\n\n\nhead1, *body, tail1, *tail2, *tail3 = range(1,11) #명확하지 않아서 오류남\n\nSyntaxError: multiple starred expressions in assignment (2478039376.py, line 1)\n\n\n\n*head, body, tail1, tail2, tail3 = range(1,11)\nhead, body, tail1\n\n([1, 2, 3, 4, 5, 6], 7, 8)\n\n\n(관찰)\nhead1, head2, body, tail1, tail2, tail3 = (1, 2, [3, 4, 5, 6, 7], 8, 9, 10)\nhead1, head3, *body, tail1, tail2, tail3 = (1,2, 3,4,5,6,7, 8, 9, 10) \n* 를 붙이면 1차원 자료구조가 풀린다!\n\n*[1,2,3]\n\nSyntaxError: can't use starred expression here (386627056.py, line 1)\n\n\n\nprint([1,2,3])\n\n[1, 2, 3]\n\n\n\nprint(*[1,2,3])   # 풀린다!!!\n\n1 2 3\n\n\n- 예제: 함수의 입력으로 *args 를 넣을때\n[예비학습] 함수 벼락치기\n\ndef myadd(a,b):\n    return a+b\n\n\nmyadd(3,4)\n\n7\n\n\n\nmyadd(3,-3)\n\n0\n\n\n예제: 두 점 사이의 거리를 구하는 함수를 만들어 보자.\n점 \\(p=(p_x,p_y)\\) 와 \\(q=(q_x,q_y)\\)의 거리는 \\(\\sqrt{(p_x-q_x)^2, (p_y-q_y)^2}\\)이다. 이것을 계산하는 프로그램을 만들자\n\nimport numpy as np\ndef dist(px,py,qx,qy):\n    return np.sqrt((px-qx)**2 + (py-qy)**2)\n\n\n\ndist(0,3,4,0) # 헷갈려\n\n5.0\n\n\n\np=(0,3)\nq=(4,0)\ndist(p,q)\n\nTypeError: dist() missing 2 required positional arguments: 'qx' and 'qy'\n\n\n(방법1)\n\npx, py = p #또는(0,3)\nqx, qy = (4,0)\ndist(px,py,qx,qy)\n\n5.0\n\n\n(방법2)\n\ndef dist2(p, q):\n    px, py = p\n    qx, qy = q\n    return np.sqrt((px-qx)**2 + (py-qy)**2)\n\n\n#def dist2(p, q):\n#    px=p[0]\n#    py=p[1]\n#    qx=q[0]\n#    qy=q[1]\n#    return np.sqrt((px-qx)**2 + (py-qy)**2)\n\n\np=(0,3)\nq=(4,0)\ndist2(p,q)\n\n5.0\n\n\n(방법3)\n\ndist(*p, *q)    # 입력을 *(px,py), *(qx, qy) 형태로 넣기도 하고\n\n5.0\n\n\n\ndist(px, py, qx, qy)  # 입력을 px,py,qx,qy 형태로 넣기도 하고\n\n5.0\n\n\n(숙제) 원소로 자기학번을 포함하는 튜플을 만들기 (길이가 1인 튜플)\n\ntype((202250926,))\n\ntuple\n\n\n\nlen((202250926,))\n\n1\n\n\n\nㅁ"
  },
  {
    "objectID": "posts/Python/1. Basic/python 4_0328.html",
    "href": "posts/Python/1. Basic/python 4_0328.html",
    "title": "파이썬 (0328) 4주차",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zcnjAged1xIatgznRTy93c\n\n- (1/8) 파이썬이 어려웠던 이유\n- (2/8) 1세대 프로그래머\n- (3/8) 1세대 프로그래머의 삶 with python\n- (4/8) 1세대 프로그래머의 삶 with ipython\n- (5/8) 2세대 프로그래머, 3세대 프로그래머 (1)\n- (6/8) 3세대 프로그래머(2), 4세대 프로그래머\n- (7/8) 5세대 프로그래머\n- (8/8) 다양한 개발환경 구축방법 다시 리뷰, 숙제설명\n\n\n파이썬이 어려웠던 이유\n- 파이썬 배우는 초보자에게 가장 어려운것!\n\n선생님마다 설치하는 방법이 모두 다름\n\n- 왜 저렇게 설치방법이 다른가? 왜 다른 방법으로 각각 파이썬을 실행하는가? 이런것이 너무 어려움\n\n방법1: 파이썬프로그램 다운로드 -> 시작버튼 눌러서 설치\n방법2: 아나콘다 설치 (그럼 자동으로 파이썬이 설치됨)\n방법3: 아나콘다 설치 + 가상환경\n…\n\n- 심지어 실행하는것도 다름\n\n방법1: 파이썬 프롬프트\n방법2: .py를 이용하여 실행?\n방법3: IDLE\n방법4: 파이참\n방법5: 스파이더\n방법6: Visual Studio Code\n방법7: 주피터노트북, 주피터랩\n\n가상환경을 만들어서 해라..\n아나콘다 네비게이터에 주피터가 있다..\n\n…\n\n- 머리아프니까 collab을 쓰라는 사람도 있음. 아니면 도커이미지를 줄테니까 그걸 쓰라는 사람도 있음. AWS를 쓰라는 사람도 있음.. \\(\\to\\) 이게 더 머리아픔\n- 핵심: 그냥 (1) 컴퓨터에 (2) 파이썬을 깔아서 (3) 실행하는 것임\n- 의문: 그런데 방법이 왜이렇게 많은가? 엑셀처럼 프로그램 설치하고 아이콘 더블클릭하면 끝나는 식으로 만들어야 하는것 아닌가?\n\n개발환경 구축방법이 많은 이유?\n- 파이썬 개발환경 구축은 수많은 방법이 있다.\n- 이는 마치 라면의 레시피를 검색하면 수많은 방법이 나오는것과 유사함.\n\n방법1: 스프를 먼저 넣고 끓인다음 라면을 넣어야 합니다.\n방법2: 양은냄비에 물넣고 물이 끊으면 라면과 스프를 같이 넣고 마지막에 계란을 넣는다.\n방법3: 먹다남은 삼겹살을 후라이팬에 볶은다음에 물을 붓고 라면을 넣는다.\n방법4: 용기에 라면+스프+뜨거운물 랩을 씌운뒤에 젓가락으로 구멍을 뚫고 전자렌지에 돌린다.\n…\n\n- 우리는 모든 방법을 나열할 순 없지만 모든 방법을 이해할 수 있다. 왜냐하면 라면을 끓이는 공통적인 맥락을 우리는 알고 있으니까\n- 파이썬을 설치하는 다양한 방법 역시 공통맥락을 파악하면 이해하기 쉽다.\n- 제목적: 파이썬을 설치하고 실행하는 공통맥락을 설명하고 싶음\n- 설치하는 방법이 다양한 이유? 파이썬이 인기있음 + 다양한 방법을 설치를 하면 각자의 장점이 뚜렷해서\n\n\n\n1세대 프로그래머\n\npython\n- 윈도우에서 anaconda prompt 실행 -> python\n(base) C:\\Users\\python>python\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> [1,2,3]+[4]\n[1, 2, 3, 4]\n>>> a=[1,2,3]+[4]\n>>> a\n[1, 2, 3, 4]\n- 2개를 실행할 수도 있음. (두 환경은 각각 서로 독립적인 파이썬, 변수가 공유되지 않음) \\(\\star\\)\n- 아쉬운점: `?list’와 같이 도움말 기능이 동작하지 않음\n>>> ?list\n  File \"<stdin>\", line 1\n    ?list\n    ^\nSyntaxError: invalid syntax\n>>> \n\n\nipython\n- 윈도우에서 anaconda prompt 실행 -> ipython\n(base) C:\\Users\\python>ipython\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.29.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: a=[1,2,3]\n\nIn [2]: a\nOut[2]: [1, 2, 3]\n\nIn [3]: a+[4]\nOut[3]: [1, 2, 3, 4]\n- ?list가 가능\nIn [4]: ?list\nInit signature: list(iterable=(), /)\nDocstring:\nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\nType:           type\nSubclasses:     _HashedSeq, StackSummary, DeferredConfigList, SList, _ImmutableLineList, FormattedText, NodeList, _ExplodedList, Stack, _Accumulator, ...\n\n- 색깔이 알록달록해서 문법을 보기 편하다. (구문강조)\n\n\n1세대 프로그래머의 삶 with python\n- 1부터 10까지 합을 구하는 프로그램을 만들고 싶음\n- 시도1: python을 키고 아래와 같이 실행\n(base) C:\\Users\\python>python\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> total = 0\n>>> for i in range(10):\n...     total=total+i\n...\n>>> total\n45\n>>>\n- 반성: 정답은 55인데 45가 출력되었다! \\(\\to\\) range(10)을 range(1,11)으로 바꿔야겠다!\n- 시도2: range(1,11)을 바꿔야겠다고 생각하고 다시 입력하다가 오타가 발생\n>>> total =0\n>>> for i in range(1,11):\n...     total = totla +i\n...\n\n앗 totla이라고 잘못쳤다.\n\n- 반성: 다음에는 정신을 똑바로 차려야겠다.\n- 불편한점: … 다..\n\n\n1세대 프로그래머의 삶 with ipython\n- ipython을 사용한 프로그래머는 좀더 상황이 낫다\n(base) C:\\Users\\python>ipython\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.29.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: total = 0\n\nIn [2]: for i in range(1,11):\n   ...:     total = total + i\n   ...:\n\nIn [3]: total\nOut[3]: 55\n\n편한점1: 자동으로 들여쓰기가 되어서 편함\n편한점2: 화살표를 이용해서 for문을 쓰는 도중에 위아래로 이동가능\n불편한점1: 화살표로 이동할수는 있는데 마우스로는 이동할 수 없다.\n불편한점2: 내가 작성한 코드를 관리하기 어렵다.\n\n\n\n\n2세대 프로그래머: 메모장 + anconda prompt를 이용 (.py를 이용한 python활용)\n- 메모장을 키고 아래의 내용을 적는다.\ntotal = 0 \nfor i in range(1,11): \n    total = total + i\nprint(total)\n- 파일이름을 mysum.py로 저장한다.\n- anaconda prompt에서 mysum.py파일이 저장된 폴더로 이동 -> 실행\n(base) C:\\Users\\python>cd Desktop\n\n(base) C:\\Users\\python\\Desktop>dir\n C 드라이브의 볼륨에는 이름이 없습니다.\n 볼륨 일련 번호: 9AFD-A05F\n\n C:\\Users\\python\\Desktop 디렉터리\n\n2022-03-27  오전 11:32    <DIR>          .\n2022-03-27  오전 11:32    <DIR>          ..\n2022-03-27  오전 12:01             2,306 Chrome.lnk\n2022-03-26  오후 08:32             2,332 Microsoft Edge.lnk\n2022-03-27  오전 11:33                71 mysum.py\n               3개 파일               4,709 바이트\n               2개 디렉터리  743,643,467,776 바이트 남음\n\n(base) C:\\Users\\python\\Desktop>python mysum.py\n55\n\n(base) C:\\Users\\python\\Desktop>\n- 소감 - 편한점1: 마우스를 이용하여 이동가능 - 편한점2: 내가 작업한 내용은 바탕화면의 메모장에 저장이 되어있음 - 아쉬운점: ipython의 장점은 활용못함 (구문강조, 도움말기능)\n\n\n3세대 프로그래머: 메모장 + ipython\n- 전체적인 개발방식 - 메모장: 코드를 편집, 저장 - ipython: anaconda prompt처럼 메모장의 코드를 실행하고 결과를 확인 + 구문강조, 도움말확인기능 등을 이용하여 짧은 코드를 빠르게 작성\n- 기능 - ipython에서 !python mysum.py를 입력하면 anaconda prompt에서 python mysum.py를 입력한 것과 같은 효과 - ipython에서 %run mysum을 입력하면 메모장에서 mysum.py에 입력된 내용을 복사해서 ipython에 붙여넣어 실행한것과 같은 효과\n\n\n4세대 프로그래머: IDE(통합개발환경)를 사용\n- 메모장과 ipython을 하나로 통합한 프로그램이 등장! - jupyter notebook, jupyter lab - spyder - idle - VScode - …\n- 주피터의 트릭 (실제로 주피터는 ipython에 기생할 뿐 아무런 역할도 안해요)\n\n주피터를 실행\n새노트북을 생성 (파이썬으로 선택)\n\n\n컴퓨터는 내부적으로 ipython을 실행하고 그 ipython이랑 여러분이 방금만든 그 노트북과 연결\n\n\n처음보이는 cell에 1+1을 입력 -> 쉬프트엔터 -> 결과2가 출력\n\n\n처음보이는 cell하나 = 자동으로 열린 하나의 메모장\ncell 1+1을 입력 = 메모장에 1+1을 적음\n쉬프트+엔터후 결과2를 출력 = cell의 내용을 복사 -> ipython에 붙여넣음 -> ipython 계산된 결과를 복사 -> cell로 돌아와 붙여넣기\n\n\n새로운 cell을 추가하고 2+2을 입력 -> 쉬프트엔터 -> 결과4가 출력\n\n\n새로운 cell을 추가 = 새로운 메모장 추가\ncell 2+2을 입력 = 새로운 메모장에 2+2를 적음\n쉬프트+엔터후 결과4를 출력 = cell의 내용을 복사 -> ipython에 붙여넣음 -> ipython 계산된 결과를 복사 -> cell로 돌아와 붙여넣기\n\n- 중요한 사실들 - IDE는 내부적으로 연산을 수행하는 능력이 없다. (생각해볼것: 왜 R을 꼭 설치하고 Rstudio를 설치해야 했을까?)\n\n주피터에서 커널을 재시작한다는 의미는 메모장이 열린채로 ipython을 껐다가 다시 실행한다는 의미\n주피터는 단순히 ’메모장의 내용을 복사하여 붙여넣는 기계’라고 볼 수 있다. 이렇게 생각하면 주피터는 꼭 ipython에 연결할 이유는 없다. 실제로 주피터에 R을 연결해서 쓸 수 있다. 즉 하나의 IDE가 여러개의 언어와 연결될 수 있다.\nJupyterlab이라는 프로그램은 크롬에 있는 내용과 ipython간의 통신을 제어하는 프로그램일 뿐이다.\n\n\n\n5세대 프로그래머: 가상컴퓨터(anaconda), 원격컴퓨터(server), 클라우드컴퓨터(colab)의 개념 등장\n- 지금까지는 ipython이 실행되는 컴퓨터와 크롬이 실행되는 컴퓨터가 동일하다는 전제였음.\n- 생각해보니까 어차피 ipython이 실행된 컴퓨터에서 내가 크롬에 입력한 명령 “전달”되기만 하면 되므로 꼭 같은 컴퓨터일 필요는 없다.\n\n모델1: 원격컴퓨터\n- 준비상태 - 전북대컴퓨터: ipython을 실행 + 이 컴퓨터는 인터넷 연결이 되어있어야함 - 우리집노트북: 크롬실행 + 이 컴퓨터도 인터넷이 연결되어 있어야함\n- 명령입력 - 우리집노트북 크롬에서 1+1을 입력하고 쉬프트 엔터를 누름\n- 우리집노트북 -> 전북대컴퓨터 - 우리집 노트북의 내부의 어떤프로그램은 1+1이라는 명령을 복사하여 카카오톡으로 전북대 컴퓨터에 전달 - 전북대 컴퓨터의 내부의 어떤프로그램은 1+1이라는 명령을 카톡으로 받아서 그것을 ipython에게 전달\n- 전북대컴퓨터 -> 우리집노트북 - 전북대컴퓨터 내부의 ipython은 2라는 출력결과를 계산함 - 전북대컴퓨터 내부의 어떤프로그램은 계산결과를 카톡으로 우리집 노트북에 알려줌 - 나는 우리집 노트북에서 계산결과를 받아볼 수 있다.\n\n\n모델2: 원격컴퓨터 + 가상컴퓨터\n- 준비상태 - 성능좋은 전북대 컴퓨터 1개 - 내 노트북 1개 (그냥 싸고 가벼운거) - 대학원생 아이패드 1개 (그냥 싸고 가벼운거)\n- 아이디어\n\n성능좋은 전북대 컴퓨터를 논리적으로 3개로 분리 \\(\\to\\) 이를 각각 (base) (py39jl17) (py38r40) 컴퓨터라고 하자.\n나는 (py39jl17)에 접속하여 파이썬 3.9와 줄리아 1.7을 설치한뒤 실습한다.\n대학원생은 (py38r40)에 접속하여 파이썬 3.8과 R 4.0을 설치하고 실습한다.\n(base)는 예비용으로 아무것도 설치안한 깨끗한 상태 유지\n내가 뭘 실수해서 (py39jl17)컴퓨터가 망가졌으나 (py38r40)은 아무 타격없다.\n나는 (py39jl17)를 삭제하고 (base)로 부터 다시 새로운 컴퓨터를 복사하여 (py39jl17)을 다시 만든다.\n\n\n\n모델3: 가상컴퓨터\n- 여러분들 사례\n\n여러분들의 컴퓨터는 (base), (py39) 2개의 컴퓨터로 나누어져 있음\n여러분들이 (py39)에만 주피터랩을 설치\n(py39)에 있는 ipython과 여러분의 크롬창이 서로 통신하면서 실습\n장점: 서로 다른 환경에 서로다른 파이썬과 R등을 설치할 수 있다. \\(\\to\\) 패키지간의 충돌이 최소화 (파이썬 입문 수업을 듣고, 이후에 파이썬을 이용하는 어떤수업을 들음)\n\n\n\n모델4: 클라우드\n- 사례1 - 성능이 그저그런 컴퓨터 27개 - 대학원생을 포함하여 쓸 사람은 5명 - 한사람당 27/5(=5.4)대의 컴퓨터식 할당\n- 사례2: 구글코랩 - 구글에 여러가지 성능을 가진 컴퓨터가 \\(n\\)대 있음 - \\(m\\)명의 사람이 \\(n\\)대의 컴퓨터에 접속 - 적당히 컴퓨터 자언을 분배하여 사용\n\n\n\n요약 및 정리\n- 결국 (1) 컴퓨터에 (2) 파이썬을 설치하고 (3) 실행하는 과정은 생각보다 다양한 선택의 조합이 가능하다.\n\n그냥 내 노트북에 파이썬을 설치할지? 내 노트북안에 가상컴퓨터를 만들고 거기에 파이썬을 설치할지? 학교의 데스크탑에 파이썬을 설치하고 쓸지? 설치를 안하고 구글컴퓨터에 설치된 파이썬을 난 쓰기만 할지?\npython설치할지? ipython를 설치할지? 어차피 가상환경을 쓸꺼니가 anaconda를 설치할지? 아니면 코랩쓸꺼니까 설치안할지?\n어떤 IDE를 쓸지? IDE를 쓰지 않을지? 내가 IDE를 직접구성해서 만들지?\n\n하지만 공통적으로 관통하는 원리가 있다\n\n\n숙제\n- 주피터랩에서 ’myprod.py’파일을 만들고 1부터 5까지의 곱을 계산하는 코드를 작성후 %run myprod를 실행하여 출력결과를 확인\n\n%run myprod\n\n120"
  },
  {
    "objectID": "posts/Python/1. Basic/python 2_0314.html",
    "href": "posts/Python/1. Basic/python 2_0314.html",
    "title": "파이썬 (0314) 2주차",
    "section": "",
    "text": "- 리스트의 선언\n\na=[11,22]\na\n\n[11, 22]\n\n\n\ntype(a)\n\nlist\n\n\n- 비어있는 리스트의 선언\n\na=[] # 방법1\na\n\n[]\n\n\n\na=list() # 방법2\na\n\n[]\n\n\n\n\n\n- 더하기연산\n\na=[11,22]\nb=[12,13]\n\n\na\n\n[11, 22]\n\n\n\nb\n\n[12, 13]\n\n\n\na+b\n\n[11, 22, 12, 13]\n\n\n\n우리의 예상과 다른 결과가 나옴 \\(\\to\\) 파이썬은 R처럼 자체적으로 좋은 계산기능을 내장하고 있찌 않음\n\n- 브로드캐스팅과 같이 R에서는 당연히 가능했던 기능을 사용할 수 없음\n\na=[1,2,3]\nb=1\na+b\n\nTypeError: can only concatenate list (not \"int\") to list\n\n\n- 뺄셈은 정의되지 않음\n\na=[1,2]\nb=[1,2]\na-b\n\nTypeError: unsupported operand type(s) for -: 'list' and 'list'\n\n\n- 곱하기는 정의 가능\n\na=[1,2]\n\n\n2*a  #a+a\n\n[1, 2, 1, 2]\n\n\n- 나눗셈은 정의되지 않음\n\na=[1,2,1,2]\na/2\n\nTypeError: unsupported operand type(s) for /: 'list' and 'int'\n\n\n- 더하기와 곱하기는 원소의 추가와 반복추가를 의미하지만 그렇다고 해서 뺄샘과 나눗셈이 원소의 삭제를 의미하는 것은 아님\n\na=[1,2,3]\na-[3]   #이런건없다\n\nTypeError: unsupported operand type(s) for -: 'list' and 'list'\n\n\n\na=[1,2,1,2,1,2,]\na/3    # 이런건없다\n\nTypeError: unsupported operand type(s) for /: 'list' and 'int'\n\n\n- 더하기와 곱하기가 원소의 추가와 반복추가를 의미하여 편리할때도 있긴하지만, 우리는 산술적인 +, *를 원하는 경우도 있다. 이럴 경우는 어떻게 할 수 있을까?\n(예제)\n\na=[1,2]\nb=[3,4]\n\na+b=[4,6]이 되도록 하려면?\n(풀이1)\n\ntype(a)\n\nlist\n\n\n\ntype(a[0])\n\nint\n\n\n\na[0]+b[0]  #a의 첫번째 원소 추출, b의 첫번째 원소 추출, 둘을 더함\n\n4\n\n\n\na[1]+b[1]\n\n6\n\n\n\n[a[0]+b[0], a[1]+b[1]]\n\n[4, 6]\n\n\n풀이가 가능한 이유? a,b는 리스트이지만 a[0], a[1], b[0], b[1]은 각각 인트형임. 인트형은 +연산이 가능함\n(풀이2)\nnumpy패키지 (파이썬의 여러 수치연산들을 담당하는 라이브러리) - 이러한 벡터연산은 누구나 필요로 하는 연산 - 내가 아니더라도 누군가가 프로그램화 해놓았을 것임 - 그 누군가가 자신이 만든 코드를 잘 정리하여 무료로 배포했을 수도 있음 (패키지를 배포한다고 표현) - 그 패키지를 가져와서 설치한 뒤 사용하기만 하면 된다.\n패키지를 설치하는 방법 - !pip install numpy # 최신버전을 설치함 - !conda install -c conda-forge numpy -y # 안전한 버전을 설치함\n설치된 패키지를 사용하는 방법 - import numpy 한뒤에 numpy.??로 기능을 사용 - import numpy as np 한뒤에 np.??로 기능을 사용\n파이썬의 기본 패키지 numpy pandas matplotlib\n\n!pip install numpy\n\nRequirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.21.5)\n\n\n\nimport numpy # 설치한 패키지를 쓰겠다고 선언함 library(tidyverse)와 비슷.\n\n\na=[1,2]\nb=[3,4]\n\n\na+b\n\n[1, 2, 3, 4]\n\n\n\ntype(numpy.array(a))\n\nnumpy.ndarray\n\n\n\naa=numpy.array(a)   #aa는 리스트가 아니라 넘파이 어레이, numpy.array()는 numpy패키지에서 제공하는 array함수를 쓰겠다는 의미\nbb=numpy.array(b)   \n\n\naa+bb\n\narray([4, 6])\n\n\n\na+b\n\n[1, 2, 3, 4]\n\n\n이런것도 가능\n\n2*aa+1\n\narray([3, 5])\n\n\n\n2*aa+1+bb\n\narray([6, 9])\n\n\n(풀이3)\n\nimport numpy as np # 설치한 numpy라는 패키지를 쓰겠음. 그런데 numpy 말고 np라는 이름으로 쓰겠음\n\n\nnp.array(a)+np.array(b)\n\narray([4, 6])\n\n\n\n\n\n- str형과 동일한 방식\n\na=[11,22,33,44,55]\n\n\na[0:3]\n\n[11, 22, 33]"
  },
  {
    "objectID": "posts/Python/1. Basic/python 2_0314.html#콘테이너형-객체-가변객체",
    "href": "posts/Python/1. Basic/python 2_0314.html#콘테이너형-객체-가변객체",
    "title": "파이썬 (0314) 2주차",
    "section": "콘테이너형 객체, 가변객체",
    "text": "콘테이너형 객체, 가변객체\n- 객체 - Object - Something\n- 리스트의 원소는 int, float따위만 가능한 것이 아니다. (리스트는 콘테이너형 객체이므로)\n\nlst = [1,3.14,True, 'a', [1,2],\n      (1,2), {'name':'iu','age':30},{1,2,3}]\n\n\nlst\n\n[1, 3.14, True, 'a', [1, 2], (1, 2), {'name': 'iu', 'age': 30}, {1, 2, 3}]\n\n\n각 원소의 타입을 알아보자\n\ntype(lst[0])\n\nint\n\n\n\ntype(lst[1])\n\nfloat\n\n\n\ntype(lst[2])\n\nbool\n\n\n\ntype(lst[3])\n\nstr\n\n\n\ntype(lst[4])\n\nlist\n\n\n\ntype(lst[5])\n\ntuple\n\n\n\ntype(lst[6])   # dictionary\n\ndict\n\n\n\ntype(lst[7]) #집합\n\nset\n\n\n- str은 컨테이너형이 아니다\n\n# 컨테이너형이 아닌것\n'abcd'[0]\n\n'a'\n\n\n\nstr의 모든 원소는 문자임\n\n- 리스트의 원소를 수정할 수 있다. (리스트는 가변객체이므로)\n\na=[11,22,33]\n\n\na[0]\n\n11\n\n\n\na[0]=111\n\n\na\n\n[111, 22, 33]\n\n\n- 원소수정은 당연한 기능 같은데 이것이 불가능한 경우도 있다.\n(가능한경우)\n\n'boram'[1]\n\n'o'\n\n\n\na=['b','o','r','a','m']\n\n\na[0]\n\n'b'\n\n\n\na[0]='B'\n\n\na\n\n['B', 'o', 'r', 'a', 'm']\n\n\n(불가능한경우)\n\na='boram'\n\n\na\n\n'boram'\n\n\n\na[0]\n\n'b'\n\n\n\na[0]='B'\n\nTypeError: 'str' object does not support item assignment\n\n\n- 리스트 원소 삭제\n(예제)\n아래와 같이 문자로 된 리스트를 선언하자.\n\na=['b','o','r','a','m']\na\n\n['b', 'o', 'r', 'a', 'm']\n\n\n사실 더 쉽게 선언할 수 있음\n\na='boram'   #string으로 a를 선언\n\n\ntype(a)\n\nstr\n\n\n\nlist(a)\n\n['b', 'o', 'r', 'a', 'm']\n\n\n\na=list(a)  #list(a)를 통하여 str을 list로 변환 \n\n\na  # 그 결과를 a에 다시 저장\n\n['b', 'o', 'r', 'a', 'm']\n\n\n첫 번째 원소를 삭제하고 싶다면?\n\n\ndel a[0]\na\n\n['o', 'r', 'a', 'm']\n\n\n- 리스트의 원소 추가\n(예제) 비어있는 리스틀를 만들고 원소 0,1,2 를 차례로 추가하여 보자.\n(풀이1)\n\na=[]\na\n\n[]\n\n\n\na= a+[0]\na\n\n[0]\n\n\n\na=a+[1]\na\n\n[0, 1]\n\n\n\na= a+[2]\na\n\n[0, 1, 2]\n\n\n(풀이2)\n\na=[]\na\n\n[]\n\n\n\na+=[0]\na\n\n[0]\n\n\n\na+=[1]\na\n\n[0, 1]\n\n\n\na+=[2]\na\n\n[0, 1, 2]\n\n\n\n암기법: 중복되는 변수를 지우고 연산자의 순서를 바꾼다.\n\n(풀이3) 리스트 특화기능(=메소드)를 이용\n\na=[]\na\n\n[]\n\n\n\na.append?\n\n\na.append(0)\na\n\n[0]\n\n\n\na.append(1)\na\n\n[0, 1]\n\n\n\na.append(2)\na\n\n[0, 1, 2]\n\n\n- a+[4]와 a.append(4)의 차이점은?\n(관찰1)\n\na=[1,2,3]\na+[4]  ## 리스트 a와 리스트 [4]의 연산결과\n\n[1, 2, 3, 4]\n\n\n\na  # a는 그대로임. 변화없음\n\n[1, 2, 3]\n\n\n(관찰2)\n\na=[1,2,3]\na.append(4)\n\n\na    # a자체가 변화함\n\n[1, 2, 3, 4]\n\n\n비슷해보이지만 굉장히 미묘한 차이가 있음\na.append(4) : a에 4를 append하라 \\(\\to\\) a가 변함\na+[4] : a와 4를 연산하고 수행결과를 보여달라"
  },
  {
    "objectID": "posts/Python/1. Basic/python 2_0314.html#메소드리스트자료형에-특화된-특수한-함수들",
    "href": "posts/Python/1. Basic/python 2_0314.html#메소드리스트자료형에-특화된-특수한-함수들",
    "title": "파이썬 (0314) 2주차",
    "section": "메소드(리스트자료형에 특화된 특수한 함수들)",
    "text": "메소드(리스트자료형에 특화된 특수한 함수들)\n(append)\n\na=[1,2,3,4]\na.append?\n\n\na.append(5)\na\n\n[1, 2, 3, 4, 5]\n\n\n(clear)\n\na=[1,2,3,4]\na.clear?\n\n\na.clear()\n\n\na\n\n[]\n\n\n(copy)\n\na=[1,2,3,4]\na.copy?\n\n\nb=a.copy()\nb\n\n[1, 2, 3, 4]\n\n\n(count)\n\na=[1,1,2,3,3,4,4,4,]\na.count(1)\n\n2\n\n\n\na.count(2) #특정 원소가 몇개 포함되어있는지 숫자 세줌\n\n1\n\n\n(extend)\n\na=[1,2,3,4]\nb=[-1,-2,-3,-4]\n\n\na.extend(b)\na\n\n[1, 2, 3, 4, -1, -2, -3, -4]\n\n\n\na.append(b)   \na\n\n[1, 2, 3, 4, -1, -2, -3, -4, [-1, -2, -3, -4]]\n\n\n(index)\n\na=[11,22,'a',True,22]\na.index(True)\n\n3\n\n\n\na.index('a')\n\n2\n\n\n\na.index(22)\n\n1\n\n\n(insert)\n\na=[1,2,3]\n\n\na.insert(1,88)\na\n\n[1, 88, 2, 3]\n\n\n(pop)\n\na=['a',1,2,'d']\na.pop()   # index= -1이므로 마지막원소가 나타남\n\n'd'\n\n\n\na   # a는 마지막 원소가 사라진 상태\n\n['a', 1, 2]\n\n\n\na.pop(0)   # index=0 이므로 첫번째 원소가 나타남\n\n'a'\n\n\n\na    # a에서는 첫번쨰 원소가 사라진 상태\n\n[1, 2]\n\n\n(remove)\n\na=['a',2,3,'d']\na.remove('d')\n\n\na\n\n['a', 2, 3]\n\n\n\na.remove('a')\na\n\n[2, 3]\n\n\n(reverse)\n\na=[1,2,3,4]\na.reverse()\na\n\n[4, 3, 2, 1]\n\n\n(sort)\n\na=[1,3,2,4]\na.sort()\na\n\n[1, 2, 3, 4]\n\n\n(다른예제들)\n\na=list('boram')\na\n\n['b', 'o', 'r', 'a', 'm']\n\n\n\na.sort()\na\n\n['a', 'b', 'm', 'o', 'r']\n\n\n\na.sort(reverse=True)\na\n\n['r', 'o', 'm', 'b', 'a']"
  },
  {
    "objectID": "posts/Python/1. Basic/python 2_0314.html#중첩리스트",
    "href": "posts/Python/1. Basic/python 2_0314.html#중첩리스트",
    "title": "파이썬 (0314) 2주차",
    "section": "중첩리스트",
    "text": "중첩리스트\n\nA=[[1,2,3],[4,5,6],[7,8,9]]\nA\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\n- A는 아래와 같은 매트릭스로 이해할 수 있다.\n$\n\\[\\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{bmatrix}\\]\n$\n- A에서 (2,1)의 원소를 뽑고 싶다. = 1을 뽑고싶다.\n\nA[1,0]\n\nTypeError: list indices must be integers or slices, not tuple\n\n\n\n실패\n\n\nA[1][0]\n\n4\n\n\n\n성공\n\n성고의 이유를 분석해 보자.\n\nA[0]\n\n[1, 2, 3]\n\n\n\nA[0][0]\n\n1\n\n\n- 매트릭스는 아니지만 매트릭스 같음! - 1차원 배열을 다차원 배열로 확장할 수 있는 기본 아이디어를 제공함"
  },
  {
    "objectID": "posts/Python/1. Basic/python 2_0314.html#리스트컴프리헨션",
    "href": "posts/Python/1. Basic/python 2_0314.html#리스트컴프리헨션",
    "title": "파이썬 (0314) 2주차",
    "section": "리스트컴프리헨션 (★★★)",
    "text": "리스트컴프리헨션 (★★★)\n- 리스트 컴프리헨션을 이해하기 전에 for문에 대하여 알아보자.\n[예비학습] for문 벼락치기\n프로그램안에서 반복해서 무언가를 하고싶다 \\(\\to\\) for\n\nfor i in [0,1,2,3]:   # 반복실행계획\n    print(i)          # 반복실행내용, 탭을 이용하여 들여쓰기 해야한다. \n\n0\n1\n2\n3\n\n\n(예제) 1,2,3,4의 합을 for문을 이용하여 구해보자.\n\n_sum = 0\nfor i in [1,2,3,4]:\n    _sum = _sum + i\n\n\n_sum\n\n10\n\n\n- 예제: $ 2^0, 2^1, 2^2, 2^3$ 를 원소로 가지는 리스트를 생성\n(풀이1)\n\nx=[2**0, 2**1, 2**2, 2**3]    ## 2의 0승\nx\n\n[1, 2, 4, 8]\n\n\n(풀이2) for문을 이용\n\nx=[]\nfor i in [0,1,2,3]:\n    x.append(2**i)  \n\n\nx\n\n[1, 2, 4, 8]\n\n\n(풀이3) for문을 이용\n\nx=[]\nfor i in [0,1,2,3]:\n    x= x+[2**i]\nx\n\n[1, 2, 4, 8]\n\n\n(풀이4) for문을 이용\n\nx=[]\nfor i in [0,1,2,3]:\n    x+= [2**i]\nx(풀이2) for문을 이용\n\n[1, 2, 4, 8]\n\n\n(풀이5) 리스트컴프리헨션을 이용한 풀이\n\nx= [2**i for i in [0,1,2,3]]\nx\n\n[1, 2, 4, 8]\n\n\n- 리스트컴프리헨션의 문법 암기방법 - 집합에서 조건제시법을 연상 - 원소나열법, 조건제시법 - \\(\\{2^0, 2^1, 2^2, 2^3\\} = \\{2^i: \\text{for} i \\in \\{0,1,2,3\\}\\)\n- 리스트컴프리헨션이란? - 리스트를 매우 효율적으로 만드는 테크닉 - for문에 비하여 가지고 있는 장점 : 1. 코드가 간결하다. 2, 빠르다\n- 예제: 리스트 컴프리헨션을 이용하여 아래와 같은 리스트를 만들자.\n\n['SSSS','PPPP','AAAA','MMMM']\n\n['SSSS', 'PPPP', 'AAAA', 'MMMM']\n\n\n(풀이)\n\n[i*4 for i in 'SPAM']\n\n['SSSS', 'PPPP', 'AAAA', 'MMMM']\n\n\n- 예제: 리스트 컴프리헨션을 이용하여 아래와 같은 리스트를 만들자.\n- 예제: 리스트 컴프리헨션을 이용하여 아래와 같은 리스트를 만들자.\n\n['X1','X2','X3','Y1','Y2','Y3']\n\n['X1', 'X2', 'X3', 'Y1', 'Y2', 'Y3']\n\n\n(풀이)\n\nfor i in 'XY':\n    for j in '123':\n        print(i+j)\n\nX1\nX2\nX3\nY1\nY2\nY3\n\n\n\n[i+j for i in 'XY' for j in '123']\n\n['X1', 'X2', 'X3', 'Y1', 'Y2', 'Y3']\n\n\n- 예제: 리스트 컴프리헨션을 이용하여 통계1,,..,통계5,수학1,…,수학5를 만들어라\n(풀이)\n\n[i+j for i in ['stat', 'math'] for j in '12345']\n\n['stat1',\n 'stat2',\n 'stat3',\n 'stat4',\n 'stat5',\n 'math1',\n 'math2',\n 'math3',\n 'math4',\n 'math5']\n\n\n(다른풀이) 참고로 for문을 쓰면 좀 복잡해진다.\n\n_lst=[]\nfor x in ['stat', 'math']:\n    for y in '12345':\n        _lst = _lst + [x+y]\n\n\n_lst\n\n['stat1',\n 'stat2',\n 'stat3',\n 'stat4',\n 'stat5',\n 'math1',\n 'math2',\n 'math3',\n 'math4',\n 'math5']\n\n\n- 예제: ’jbnu’를 이용하여 아래와 같은 리스트르 만들어라.\n\n['j','b','n','u']\n\n['j', 'b', 'n', 'u']\n\n\n\nlist('jbnu')\n\n['j', 'b', 'n', 'u']\n\n\n(풀이)\n\n[x for x in 'jbnu']\n\n['j', 'b', 'n', 'u']\n\n\n-예제: x에는 무엇이 있을까?\n(경우1)\n\nx=1\nlst=[]\nfor x in 'jbnu':\n    lst = lst + [x]\n\n\nlst\n\n['j', 'b', 'n', 'u']\n\n\n\nx\n\n'u'\n\n\n(경우2)\n\nx=1\nlst = [x for x in 'jbnu']\nlst\n\n['j', 'b', 'n', 'u']\n\n\n\nx\n\n1\n\n\n- 예제: [X1,X2,X3,…,X100]과 같은 리스트를 만들어보자.\n(풀이)\n\n['X'+str(i) for i in [1,2,3,4]]\n\n['X1', 'X2', 'X3', 'X4']\n\n\n\n['X'+str(i) for i in [1:100]]   #오류!!\n\nSyntaxError: invalid syntax (1716365648.py, line 1)\n\n\n[예비학습]\n\nrange(0,10)\n\nrange(0, 10)\n\n\n\n_tmp = range(0,10)\n\n\ntype(_tmp)\n\nrange\n\n\n\nlist(_tmp)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nlist(range(0,10)) #0을 포함, 10을 미포함\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n이게 중요한 것. range(0,10)을 리스트화시키면 [0,1,2,…,9]와 같은기능을 얻을 수 있다.\n\n\nlist(range(10))  # 0은 생략가능\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nlist(range(2,10))  # 2는 포함, 10은 미포함\n\n[2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nlist(range(1,10,2))  # 2칸씩! \n\n[1, 3, 5, 7, 9]\n\n\n예비학습 끝\n\n['X'+str(i) for i in list(range(1,101))]  # 세로로 넘 길엉 \n\n['X1',\n 'X2',\n 'X3',\n 'X4',\n 'X5',\n 'X6',\n 'X7',\n 'X8',\n 'X9',\n 'X10',\n 'X11',\n 'X12',\n 'X13',\n 'X14',\n 'X15',\n 'X16',\n 'X17',\n 'X18',\n 'X19',\n 'X20',\n 'X21',\n 'X22',\n 'X23',\n 'X24',\n 'X25',\n 'X26',\n 'X27',\n 'X28',\n 'X29',\n 'X30',\n 'X31',\n 'X32',\n 'X33',\n 'X34',\n 'X35',\n 'X36',\n 'X37',\n 'X38',\n 'X39',\n 'X40',\n 'X41',\n 'X42',\n 'X43',\n 'X44',\n 'X45',\n 'X46',\n 'X47',\n 'X48',\n 'X49',\n 'X50',\n 'X51',\n 'X52',\n 'X53',\n 'X54',\n 'X55',\n 'X56',\n 'X57',\n 'X58',\n 'X59',\n 'X60',\n 'X61',\n 'X62',\n 'X63',\n 'X64',\n 'X65',\n 'X66',\n 'X67',\n 'X68',\n 'X69',\n 'X70',\n 'X71',\n 'X72',\n 'X73',\n 'X74',\n 'X75',\n 'X76',\n 'X77',\n 'X78',\n 'X79',\n 'X80',\n 'X81',\n 'X82',\n 'X83',\n 'X84',\n 'X85',\n 'X86',\n 'X87',\n 'X88',\n 'X89',\n 'X90',\n 'X91',\n 'X92',\n 'X93',\n 'X94',\n 'X95',\n 'X96',\n 'X97',\n 'X98',\n 'X99',\n 'X100']\n\n\n(아래와 같은 풀이도 가능)\n\n['X'+str(i) for i in range(1,13)]  # 리스트화해주지 않아도 가능 for i in 뒤에 list뿐 아니라.. str도 되고... \n\n['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12']\n\n\n(딴생각) for문 뒤에 올 수 있는 것이 무엇인지 생각해보자.\n\nfor i in '1234':\n    print(i)\n\n1\n2\n3\n4\n\n\n\nfor i in [1,2,3,4]:\n    print(i)\n\n1\n2\n3\n4\n\n\n\nfor i in (1,2,3,4):   # 튜플\n    print(i)\n\n1\n2\n3\n4\n\n\n\nfor i in {1,2,3,4}: # set\n    print(i)\n\n1\n2\n3\n4\n\n\n\nfor i in {'name':'iu','age':31}:   # 딕셔너리\n    print(i)\n\nname\nage\n\n\n\nfor i in range(1,5):\n    print(i)\n\n1\n2\n3\n4\n\n\n(숙제)\n리스트컴프리헨션을 이용하여 아래와 같은 리스트를 만들어라\n[‘X1’,‘X2X2’,‘X3X3X3’,‘X4X4X4X4’,‘X5X5X5X5X5’]\n\n[('X'+str(i))*i for i in range(1,6)]\n\n['X1', 'X2X2', 'X3X3X3', 'X4X4X4X4', 'X5X5X5X5X5']"
  },
  {
    "objectID": "posts/Python/3. Pandas/python 10_0506 .html",
    "href": "posts/Python/3. Pandas/python 10_0506 .html",
    "title": "파이썬 (0506) 10주차",
    "section": "",
    "text": "!pip install numpy\n!pip install pandas\n\nRequirement already satisfied: numpy in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (1.21.6)\nCollecting pandas\n  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 89.6 MB/s eta 0:00:00a 0:00:01\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2022.7.1)\nRequirement already satisfied: numpy>=1.17.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (1.21.6)\nRequirement already satisfied: python-dateutil>=2.7.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nInstalling collected packages: pandas\nSuccessfully installed pandas-1.3.5\n\n\n\nimport numpy as np\nimport pandas as pd\n\n\n부분 데이터 꺼내기: 판다스를 왜 써야할까?\n\n기본 인덱싱\n-예제1: 기본인덱싱\n\na='asdf'\na[2]\n\n'd'\n\n\n\na[-1]\n\n'f'\n\n\n- 예제2: 슬라이싱\n\na='asdf'\na[1:3]\n\n'sd'\n\n\n\na[-2:]\n\n'df'\n\n\n- 예제3: 스트라이딩\n\na='afsdf'\na[::2]\n\n'asf'\n\n\n- 예제4: 불가능한것\n\na='afsd'\na[[1,2]] # 리스트로 전달해서 뽑는것은 불가능 -> 정수인덱스 리스트화시켜서 인덱싱하는것\n\nTypeError: string indices must be integers\n\n\n\na='afsd'\na[[True,True,False,True]] # 리스트로 전달해서 뽑는것은 불가능 -> 정수인덱스 리스트화시켜서 인덱싱하는것\n\nTypeError: string indices must be integers\n\n\n\n\n팬시인덱싱\n- 예제1: 인덱스의 리스트(혹은 ndarray)를 전달\n\na=np.arange(5)\na[0]\n\n0\n\n\n\na[[0,1]]\n\narray([0, 1])\n\n\n\na[[0,1,-2]]\n\narray([0, 1, 3])\n\n\n- 예제2: bool로 이루어진 리스트 (혹은 ndarray)를 전달\n\na=np.arange(55,61)\na\n\narray([55, 56, 57, 58, 59, 60])\n\n\n\na[[True,True,False,True,True,False]]\n\narray([55, 56, 58, 59])\n\n\n\na<58\n\narray([ True,  True,  True, False, False, False])\n\n\n\na[a<58]\n\narray([55, 56, 57])\n\n\n\n\n2차원 자료형의 인덱싱\n- 예제1\n\na=np.arange(4*3).reshape(4,3)\na\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11]])\n\n\n\na[0:2,1]\n\narray([1, 4])\n\n\n- 예제2 : 차원을 유지하면서 인덱싱을 하고 싶으면?\n\na[0:2,[1]]\n\narray([[1],\n       [4]])\n\n\n\n\nHASH\n- 예제1 : (key, value)\n\nd={'att':67, 'rep':45, 'mid':30, 'fin':100}\nd\n\n{'att': 67, 'rep': 45, 'mid': 30, 'fin': 100}\n\n\n\nd['att'] # key를 넣으면 value가 리턴\n\n67\n\n\n- 예제2: numpy비교\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,200)\nrep = np.random.choice(np.arange(5,21)*5,200)\nmid = np.random.choice(np.arange(0,21)*5,200)\nfin = np.random.choice(np.arange(0,21)*5,200)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),200,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(200)}\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\n\n\ntest_dic\n\n{'202212377': {'att': 65, 'rep': 45, 'mid': 0, 'fin': 10},\n '202212473': {'att': 95, 'rep': 30, 'mid': 60, 'fin': 10},\n '202212310': {'att': 65, 'rep': 85, 'mid': 15, 'fin': 20},\n '202212460': {'att': 55, 'rep': 35, 'mid': 35, 'fin': 5},\n '202212320': {'att': 80, 'rep': 60, 'mid': 55, 'fin': 70},\n '202212329': {'att': 75, 'rep': 40, 'mid': 75, 'fin': 85},\n '202212408': {'att': 65, 'rep': 70, 'mid': 60, 'fin': 75},\n '202212319': {'att': 60, 'rep': 25, 'mid': 20, 'fin': 35},\n '202212348': {'att': 95, 'rep': 55, 'mid': 65, 'fin': 90},\n '202212306': {'att': 90, 'rep': 25, 'mid': 95, 'fin': 50},\n '202212308': {'att': 55, 'rep': 45, 'mid': 75, 'fin': 30},\n '202212366': {'att': 95, 'rep': 60, 'mid': 25, 'fin': 55},\n '202212367': {'att': 95, 'rep': 35, 'mid': 0, 'fin': 25},\n '202212461': {'att': 50, 'rep': 55, 'mid': 90, 'fin': 45},\n '202212354': {'att': 50, 'rep': 65, 'mid': 50, 'fin': 70},\n '202212361': {'att': 95, 'rep': 100, 'mid': 25, 'fin': 40},\n '202212400': {'att': 50, 'rep': 65, 'mid': 35, 'fin': 85},\n '202212490': {'att': 65, 'rep': 85, 'mid': 10, 'fin': 5},\n '202212404': {'att': 70, 'rep': 65, 'mid': 65, 'fin': 80},\n '202212326': {'att': 90, 'rep': 70, 'mid': 100, 'fin': 30},\n '202212452': {'att': 80, 'rep': 45, 'mid': 80, 'fin': 85},\n '202212362': {'att': 55, 'rep': 45, 'mid': 85, 'fin': 70},\n '202212396': {'att': 65, 'rep': 35, 'mid': 45, 'fin': 20},\n '202212356': {'att': 70, 'rep': 25, 'mid': 50, 'fin': 70},\n '202212305': {'att': 85, 'rep': 55, 'mid': 30, 'fin': 80},\n '202212398': {'att': 90, 'rep': 30, 'mid': 30, 'fin': 0},\n '202212410': {'att': 100, 'rep': 65, 'mid': 50, 'fin': 70},\n '202212385': {'att': 80, 'rep': 70, 'mid': 50, 'fin': 100},\n '202212430': {'att': 80, 'rep': 35, 'mid': 25, 'fin': 65},\n '202212498': {'att': 55, 'rep': 75, 'mid': 20, 'fin': 25},\n '202212423': {'att': 75, 'rep': 75, 'mid': 85, 'fin': 95},\n '202212327': {'att': 80, 'rep': 95, 'mid': 5, 'fin': 5},\n '202212347': {'att': 95, 'rep': 60, 'mid': 65, 'fin': 10},\n '202212483': {'att': 95, 'rep': 60, 'mid': 90, 'fin': 75},\n '202212447': {'att': 100, 'rep': 75, 'mid': 70, 'fin': 25},\n '202212496': {'att': 100, 'rep': 55, 'mid': 35, 'fin': 85},\n '202212358': {'att': 80, 'rep': 60, 'mid': 65, 'fin': 55},\n '202212399': {'att': 70, 'rep': 80, 'mid': 0, 'fin': 10},\n '202212459': {'att': 85, 'rep': 65, 'mid': 60, 'fin': 60},\n '202212313': {'att': 100, 'rep': 95, 'mid': 0, 'fin': 25},\n '202212304': {'att': 95, 'rep': 60, 'mid': 15, 'fin': 45},\n '202212431': {'att': 75, 'rep': 40, 'mid': 30, 'fin': 10},\n '202212325': {'att': 70, 'rep': 80, 'mid': 50, 'fin': 25},\n '202212471': {'att': 50, 'rep': 45, 'mid': 10, 'fin': 10},\n '202212463': {'att': 100, 'rep': 100, 'mid': 100, 'fin': 50},\n '202212441': {'att': 75, 'rep': 50, 'mid': 60, 'fin': 5},\n '202212445': {'att': 85, 'rep': 50, 'mid': 35, 'fin': 100},\n '202212323': {'att': 80, 'rep': 35, 'mid': 75, 'fin': 80},\n '202212442': {'att': 95, 'rep': 45, 'mid': 35, 'fin': 80},\n '202212346': {'att': 65, 'rep': 85, 'mid': 85, 'fin': 15},\n '202212411': {'att': 90, 'rep': 30, 'mid': 25, 'fin': 5},\n '202212468': {'att': 65, 'rep': 65, 'mid': 35, 'fin': 70},\n '202212331': {'att': 80, 'rep': 65, 'mid': 30, 'fin': 90},\n '202212345': {'att': 95, 'rep': 80, 'mid': 45, 'fin': 35},\n '202212339': {'att': 65, 'rep': 75, 'mid': 50, 'fin': 35},\n '202212383': {'att': 90, 'rep': 55, 'mid': 100, 'fin': 30},\n '202212462': {'att': 95, 'rep': 25, 'mid': 95, 'fin': 90},\n '202212344': {'att': 100, 'rep': 50, 'mid': 80, 'fin': 10},\n '202212472': {'att': 50, 'rep': 55, 'mid': 35, 'fin': 60},\n '202212437': {'att': 90, 'rep': 70, 'mid': 35, 'fin': 25},\n '202212336': {'att': 50, 'rep': 55, 'mid': 15, 'fin': 75},\n '202212438': {'att': 80, 'rep': 50, 'mid': 55, 'fin': 90},\n '202212454': {'att': 50, 'rep': 75, 'mid': 65, 'fin': 90},\n '202212384': {'att': 70, 'rep': 40, 'mid': 90, 'fin': 5},\n '202212402': {'att': 65, 'rep': 85, 'mid': 20, 'fin': 90},\n '202212397': {'att': 60, 'rep': 30, 'mid': 0, 'fin': 50},\n '202212318': {'att': 50, 'rep': 65, 'mid': 15, 'fin': 0},\n '202212371': {'att': 60, 'rep': 95, 'mid': 30, 'fin': 70},\n '202212469': {'att': 70, 'rep': 70, 'mid': 5, 'fin': 0},\n '202212379': {'att': 75, 'rep': 45, 'mid': 15, 'fin': 75},\n '202212364': {'att': 50, 'rep': 60, 'mid': 15, 'fin': 50},\n '202212450': {'att': 85, 'rep': 90, 'mid': 90, 'fin': 90},\n '202212337': {'att': 80, 'rep': 25, 'mid': 85, 'fin': 20},\n '202212458': {'att': 55, 'rep': 75, 'mid': 95, 'fin': 90},\n '202212494': {'att': 85, 'rep': 30, 'mid': 45, 'fin': 15},\n '202212478': {'att': 65, 'rep': 30, 'mid': 45, 'fin': 15},\n '202212373': {'att': 85, 'rep': 95, 'mid': 35, 'fin': 25},\n '202212474': {'att': 60, 'rep': 25, 'mid': 10, 'fin': 50},\n '202212455': {'att': 95, 'rep': 45, 'mid': 90, 'fin': 35},\n '202212317': {'att': 85, 'rep': 50, 'mid': 60, 'fin': 45},\n '202212341': {'att': 60, 'rep': 50, 'mid': 100, 'fin': 70},\n '202212386': {'att': 100, 'rep': 75, 'mid': 60, 'fin': 0},\n '202212328': {'att': 100, 'rep': 90, 'mid': 85, 'fin': 75},\n '202212417': {'att': 55, 'rep': 100, 'mid': 100, 'fin': 60},\n '202212370': {'att': 70, 'rep': 60, 'mid': 30, 'fin': 40},\n '202212486': {'att': 70, 'rep': 90, 'mid': 95, 'fin': 40},\n '202212333': {'att': 55, 'rep': 50, 'mid': 0, 'fin': 5},\n '202212360': {'att': 100, 'rep': 100, 'mid': 45, 'fin': 90},\n '202212350': {'att': 85, 'rep': 70, 'mid': 90, 'fin': 80},\n '202212382': {'att': 100, 'rep': 85, 'mid': 65, 'fin': 85},\n '202212392': {'att': 60, 'rep': 65, 'mid': 35, 'fin': 15},\n '202212449': {'att': 65, 'rep': 75, 'mid': 75, 'fin': 85},\n '202212394': {'att': 65, 'rep': 25, 'mid': 40, 'fin': 0},\n '202212444': {'att': 75, 'rep': 75, 'mid': 50, 'fin': 40},\n '202212487': {'att': 50, 'rep': 55, 'mid': 80, 'fin': 55},\n '202212425': {'att': 75, 'rep': 30, 'mid': 20, 'fin': 50},\n '202212312': {'att': 100, 'rep': 50, 'mid': 25, 'fin': 65},\n '202212448': {'att': 90, 'rep': 30, 'mid': 95, 'fin': 35},\n '202212434': {'att': 55, 'rep': 100, 'mid': 80, 'fin': 0},\n '202212451': {'att': 75, 'rep': 60, 'mid': 15, 'fin': 40},\n '202212433': {'att': 60, 'rep': 25, 'mid': 25, 'fin': 50},\n '202212424': {'att': 85, 'rep': 35, 'mid': 10, 'fin': 60},\n '202212351': {'att': 60, 'rep': 100, 'mid': 55, 'fin': 40},\n '202212324': {'att': 70, 'rep': 55, 'mid': 50, 'fin': 75},\n '202212314': {'att': 80, 'rep': 65, 'mid': 95, 'fin': 85},\n '202212446': {'att': 65, 'rep': 35, 'mid': 15, 'fin': 65},\n '202212401': {'att': 85, 'rep': 70, 'mid': 100, 'fin': 0},\n '202212307': {'att': 100, 'rep': 30, 'mid': 60, 'fin': 65},\n '202212300': {'att': 65, 'rep': 70, 'mid': 55, 'fin': 70},\n '202212342': {'att': 85, 'rep': 55, 'mid': 85, 'fin': 90},\n '202212479': {'att': 85, 'rep': 95, 'mid': 80, 'fin': 10},\n '202212443': {'att': 85, 'rep': 70, 'mid': 75, 'fin': 5},\n '202212387': {'att': 100, 'rep': 35, 'mid': 70, 'fin': 0},\n '202212372': {'att': 95, 'rep': 45, 'mid': 55, 'fin': 65},\n '202212376': {'att': 95, 'rep': 85, 'mid': 40, 'fin': 65},\n '202212466': {'att': 55, 'rep': 50, 'mid': 30, 'fin': 85},\n '202212391': {'att': 85, 'rep': 50, 'mid': 5, 'fin': 65},\n '202212368': {'att': 75, 'rep': 90, 'mid': 85, 'fin': 85},\n '202212427': {'att': 95, 'rep': 70, 'mid': 10, 'fin': 5},\n '202212414': {'att': 85, 'rep': 35, 'mid': 80, 'fin': 95},\n '202212426': {'att': 95, 'rep': 50, 'mid': 80, 'fin': 90},\n '202212316': {'att': 100, 'rep': 65, 'mid': 75, 'fin': 40},\n '202212355': {'att': 95, 'rep': 70, 'mid': 70, 'fin': 0},\n '202212477': {'att': 95, 'rep': 70, 'mid': 20, 'fin': 25},\n '202212484': {'att': 100, 'rep': 60, 'mid': 10, 'fin': 5},\n '202212456': {'att': 55, 'rep': 35, 'mid': 25, 'fin': 10},\n '202212500': {'att': 60, 'rep': 90, 'mid': 40, 'fin': 5},\n '202212381': {'att': 85, 'rep': 90, 'mid': 85, 'fin': 75},\n '202212335': {'att': 75, 'rep': 85, 'mid': 25, 'fin': 35},\n '202212475': {'att': 55, 'rep': 30, 'mid': 50, 'fin': 45},\n '202212343': {'att': 70, 'rep': 60, 'mid': 75, 'fin': 75},\n '202212412': {'att': 80, 'rep': 30, 'mid': 95, 'fin': 5},\n '202212428': {'att': 90, 'rep': 85, 'mid': 80, 'fin': 15},\n '202212330': {'att': 90, 'rep': 25, 'mid': 95, 'fin': 5},\n '202212375': {'att': 60, 'rep': 85, 'mid': 50, 'fin': 20},\n '202212413': {'att': 90, 'rep': 50, 'mid': 95, 'fin': 95},\n '202212303': {'att': 75, 'rep': 95, 'mid': 65, 'fin': 40},\n '202212374': {'att': 60, 'rep': 40, 'mid': 35, 'fin': 0},\n '202212409': {'att': 55, 'rep': 100, 'mid': 15, 'fin': 80},\n '202212440': {'att': 70, 'rep': 75, 'mid': 80, 'fin': 0},\n '202212393': {'att': 75, 'rep': 65, 'mid': 25, 'fin': 20},\n '202212492': {'att': 90, 'rep': 75, 'mid': 80, 'fin': 25},\n '202212357': {'att': 50, 'rep': 75, 'mid': 75, 'fin': 20},\n '202212465': {'att': 55, 'rep': 45, 'mid': 35, 'fin': 45},\n '202212415': {'att': 90, 'rep': 70, 'mid': 90, 'fin': 0},\n '202212405': {'att': 75, 'rep': 30, 'mid': 100, 'fin': 60},\n '202212435': {'att': 90, 'rep': 85, 'mid': 0, 'fin': 40},\n '202212380': {'att': 85, 'rep': 70, 'mid': 35, 'fin': 0},\n '202212369': {'att': 100, 'rep': 75, 'mid': 100, 'fin': 85},\n '202212467': {'att': 55, 'rep': 35, 'mid': 20, 'fin': 10},\n '202212429': {'att': 70, 'rep': 75, 'mid': 90, 'fin': 90},\n '202212495': {'att': 90, 'rep': 90, 'mid': 55, 'fin': 55},\n '202212420': {'att': 55, 'rep': 60, 'mid': 40, 'fin': 0},\n '202212302': {'att': 100, 'rep': 90, 'mid': 5, 'fin': 30},\n '202212481': {'att': 50, 'rep': 55, 'mid': 25, 'fin': 80},\n '202212422': {'att': 100, 'rep': 100, 'mid': 90, 'fin': 55},\n '202212388': {'att': 70, 'rep': 45, 'mid': 70, 'fin': 75},\n '202212480': {'att': 85, 'rep': 95, 'mid': 85, 'fin': 90},\n '202212378': {'att': 55, 'rep': 25, 'mid': 95, 'fin': 45},\n '202212457': {'att': 75, 'rep': 30, 'mid': 10, 'fin': 95},\n '202212419': {'att': 65, 'rep': 85, 'mid': 15, 'fin': 60},\n '202212432': {'att': 70, 'rep': 90, 'mid': 70, 'fin': 0},\n '202212395': {'att': 60, 'rep': 85, 'mid': 70, 'fin': 85},\n '202212464': {'att': 100, 'rep': 25, 'mid': 10, 'fin': 20},\n '202212476': {'att': 75, 'rep': 25, 'mid': 80, 'fin': 25},\n '202212332': {'att': 90, 'rep': 95, 'mid': 40, 'fin': 80},\n '202212301': {'att': 95, 'rep': 90, 'mid': 50, 'fin': 50},\n '202212497': {'att': 90, 'rep': 90, 'mid': 65, 'fin': 85},\n '202212309': {'att': 95, 'rep': 75, 'mid': 50, 'fin': 40},\n '202212493': {'att': 55, 'rep': 60, 'mid': 70, 'fin': 5},\n '202212311': {'att': 95, 'rep': 85, 'mid': 0, 'fin': 15},\n '202212416': {'att': 65, 'rep': 60, 'mid': 35, 'fin': 20},\n '202212489': {'att': 65, 'rep': 50, 'mid': 5, 'fin': 5},\n '202212359': {'att': 90, 'rep': 25, 'mid': 60, 'fin': 25},\n '202212349': {'att': 100, 'rep': 40, 'mid': 40, 'fin': 15},\n '202212403': {'att': 70, 'rep': 25, 'mid': 100, 'fin': 75},\n '202212418': {'att': 100, 'rep': 30, 'mid': 70, 'fin': 70},\n '202212406': {'att': 50, 'rep': 55, 'mid': 55, 'fin': 5},\n '202212485': {'att': 70, 'rep': 35, 'mid': 70, 'fin': 100},\n '202212390': {'att': 70, 'rep': 60, 'mid': 60, 'fin': 80},\n '202212365': {'att': 55, 'rep': 45, 'mid': 90, 'fin': 5},\n '202212338': {'att': 55, 'rep': 55, 'mid': 10, 'fin': 95},\n '202212363': {'att': 65, 'rep': 80, 'mid': 10, 'fin': 30},\n '202212321': {'att': 90, 'rep': 25, 'mid': 35, 'fin': 55},\n '202212499': {'att': 100, 'rep': 30, 'mid': 30, 'fin': 85},\n '202212340': {'att': 70, 'rep': 85, 'mid': 70, 'fin': 65},\n '202212421': {'att': 60, 'rep': 100, 'mid': 45, 'fin': 100},\n '202212407': {'att': 70, 'rep': 25, 'mid': 100, 'fin': 15},\n '202212439': {'att': 70, 'rep': 35, 'mid': 80, 'fin': 25},\n '202212488': {'att': 65, 'rep': 60, 'mid': 30, 'fin': 35},\n '202212453': {'att': 95, 'rep': 35, 'mid': 40, 'fin': 95},\n '202212482': {'att': 50, 'rep': 80, 'mid': 65, 'fin': 90},\n '202212334': {'att': 100, 'rep': 40, 'mid': 80, 'fin': 80},\n '202212322': {'att': 55, 'rep': 30, 'mid': 95, 'fin': 100},\n '202212353': {'att': 65, 'rep': 40, 'mid': 65, 'fin': 70},\n '202212491': {'att': 55, 'rep': 70, 'mid': 40, 'fin': 95},\n '202212352': {'att': 65, 'rep': 85, 'mid': 25, 'fin': 85},\n '202212315': {'att': 85, 'rep': 85, 'mid': 100, 'fin': 10},\n '202212470': {'att': 80, 'rep': 65, 'mid': 35, 'fin': 60},\n '202212436': {'att': 50, 'rep': 95, 'mid': 45, 'fin': 85}}\n\n\n학번 ’202212460’에 해당하는 학생의 출석점수를 알고 싶다면?\n(풀이1)\n\ntest_dic['202212460']['att']\n\n55\n\n\n(풀이2)\n\ntest_ndarray\n\narray([['202212377', '202212473', '202212310', '202212460', '202212320',\n        '202212329', '202212408', '202212319', '202212348', '202212306',\n        '202212308', '202212366', '202212367', '202212461', '202212354',\n        '202212361', '202212400', '202212490', '202212404', '202212326',\n        '202212452', '202212362', '202212396', '202212356', '202212305',\n        '202212398', '202212410', '202212385', '202212430', '202212498',\n        '202212423', '202212327', '202212347', '202212483', '202212447',\n        '202212496', '202212358', '202212399', '202212459', '202212313',\n        '202212304', '202212431', '202212325', '202212471', '202212463',\n        '202212441', '202212445', '202212323', '202212442', '202212346',\n        '202212411', '202212468', '202212331', '202212345', '202212339',\n        '202212383', '202212462', '202212344', '202212472', '202212437',\n        '202212336', '202212438', '202212454', '202212384', '202212402',\n        '202212397', '202212318', '202212371', '202212469', '202212379',\n        '202212364', '202212450', '202212337', '202212458', '202212494',\n        '202212478', '202212373', '202212474', '202212455', '202212317',\n        '202212341', '202212386', '202212328', '202212417', '202212370',\n        '202212486', '202212333', '202212360', '202212350', '202212382',\n        '202212392', '202212449', '202212394', '202212444', '202212487',\n        '202212425', '202212312', '202212448', '202212434', '202212451',\n        '202212433', '202212424', '202212351', '202212324', '202212314',\n        '202212446', '202212401', '202212307', '202212300', '202212342',\n        '202212479', '202212443', '202212387', '202212372', '202212376',\n        '202212466', '202212391', '202212368', '202212427', '202212414',\n        '202212426', '202212316', '202212355', '202212477', '202212484',\n        '202212456', '202212500', '202212381', '202212335', '202212475',\n        '202212343', '202212412', '202212428', '202212330', '202212375',\n        '202212413', '202212303', '202212374', '202212409', '202212440',\n        '202212393', '202212492', '202212357', '202212465', '202212415',\n        '202212405', '202212435', '202212380', '202212369', '202212467',\n        '202212429', '202212495', '202212420', '202212302', '202212481',\n        '202212422', '202212388', '202212480', '202212378', '202212457',\n        '202212419', '202212432', '202212395', '202212464', '202212476',\n        '202212332', '202212301', '202212497', '202212309', '202212493',\n        '202212311', '202212416', '202212489', '202212359', '202212349',\n        '202212403', '202212418', '202212406', '202212485', '202212390',\n        '202212365', '202212338', '202212363', '202212321', '202212499',\n        '202212340', '202212421', '202212407', '202212439', '202212488',\n        '202212453', '202212482', '202212334', '202212322', '202212353',\n        '202212491', '202212352', '202212315', '202212470', '202212436'],\n       ['65', '95', '65', '55', '80', '75', '65', '60', '95', '90', '55',\n        '95', '95', '50', '50', '95', '50', '65', '70', '90', '80', '55',\n        '65', '70', '85', '90', '100', '80', '80', '55', '75', '80',\n        '95', '95', '100', '100', '80', '70', '85', '100', '95', '75',\n        '70', '50', '100', '75', '85', '80', '95', '65', '90', '65',\n        '80', '95', '65', '90', '95', '100', '50', '90', '50', '80',\n        '50', '70', '65', '60', '50', '60', '70', '75', '50', '85', '80',\n        '55', '85', '65', '85', '60', '95', '85', '60', '100', '100',\n        '55', '70', '70', '55', '100', '85', '100', '60', '65', '65',\n        '75', '50', '75', '100', '90', '55', '75', '60', '85', '60',\n        '70', '80', '65', '85', '100', '65', '85', '85', '85', '100',\n        '95', '95', '55', '85', '75', '95', '85', '95', '100', '95',\n        '95', '100', '55', '60', '85', '75', '55', '70', '80', '90',\n        '90', '60', '90', '75', '60', '55', '70', '75', '90', '50', '55',\n        '90', '75', '90', '85', '100', '55', '70', '90', '55', '100',\n        '50', '100', '70', '85', '55', '75', '65', '70', '60', '100',\n        '75', '90', '95', '90', '95', '55', '95', '65', '65', '90',\n        '100', '70', '100', '50', '70', '70', '55', '55', '65', '90',\n        '100', '70', '60', '70', '70', '65', '95', '50', '100', '55',\n        '65', '55', '65', '85', '80', '50'],\n       ['45', '30', '85', '35', '60', '40', '70', '25', '55', '25', '45',\n        '60', '35', '55', '65', '100', '65', '85', '65', '70', '45',\n        '45', '35', '25', '55', '30', '65', '70', '35', '75', '75', '95',\n        '60', '60', '75', '55', '60', '80', '65', '95', '60', '40', '80',\n        '45', '100', '50', '50', '35', '45', '85', '30', '65', '65',\n        '80', '75', '55', '25', '50', '55', '70', '55', '50', '75', '40',\n        '85', '30', '65', '95', '70', '45', '60', '90', '25', '75', '30',\n        '30', '95', '25', '45', '50', '50', '75', '90', '100', '60',\n        '90', '50', '100', '70', '85', '65', '75', '25', '75', '55',\n        '30', '50', '30', '100', '60', '25', '35', '100', '55', '65',\n        '35', '70', '30', '70', '55', '95', '70', '35', '45', '85', '50',\n        '50', '90', '70', '35', '50', '65', '70', '70', '60', '35', '90',\n        '90', '85', '30', '60', '30', '85', '25', '85', '50', '95', '40',\n        '100', '75', '65', '75', '75', '45', '70', '30', '85', '70',\n        '75', '35', '75', '90', '60', '90', '55', '100', '45', '95',\n        '25', '30', '85', '90', '85', '25', '25', '95', '90', '90', '75',\n        '60', '85', '60', '50', '25', '40', '25', '30', '55', '35', '60',\n        '45', '55', '80', '25', '30', '85', '100', '25', '35', '60',\n        '35', '80', '40', '30', '40', '70', '85', '85', '65', '95'],\n       ['0', '60', '15', '35', '55', '75', '60', '20', '65', '95', '75',\n        '25', '0', '90', '50', '25', '35', '10', '65', '100', '80', '85',\n        '45', '50', '30', '30', '50', '50', '25', '20', '85', '5', '65',\n        '90', '70', '35', '65', '0', '60', '0', '15', '30', '50', '10',\n        '100', '60', '35', '75', '35', '85', '25', '35', '30', '45',\n        '50', '100', '95', '80', '35', '35', '15', '55', '65', '90',\n        '20', '0', '15', '30', '5', '15', '15', '90', '85', '95', '45',\n        '45', '35', '10', '90', '60', '100', '60', '85', '100', '30',\n        '95', '0', '45', '90', '65', '35', '75', '40', '50', '80', '20',\n        '25', '95', '80', '15', '25', '10', '55', '50', '95', '15',\n        '100', '60', '55', '85', '80', '75', '70', '55', '40', '30', '5',\n        '85', '10', '80', '80', '75', '70', '20', '10', '25', '40', '85',\n        '25', '50', '75', '95', '80', '95', '50', '95', '65', '35', '15',\n        '80', '25', '80', '75', '35', '90', '100', '0', '35', '100',\n        '20', '90', '55', '40', '5', '25', '90', '70', '85', '95', '10',\n        '15', '70', '70', '10', '80', '40', '50', '65', '50', '70', '0',\n        '35', '5', '60', '40', '100', '70', '55', '70', '60', '90', '10',\n        '10', '35', '30', '70', '45', '100', '80', '30', '40', '65',\n        '80', '95', '65', '40', '25', '100', '35', '45'],\n       ['10', '10', '20', '5', '70', '85', '75', '35', '90', '50', '30',\n        '55', '25', '45', '70', '40', '85', '5', '80', '30', '85', '70',\n        '20', '70', '80', '0', '70', '100', '65', '25', '95', '5', '10',\n        '75', '25', '85', '55', '10', '60', '25', '45', '10', '25', '10',\n        '50', '5', '100', '80', '80', '15', '5', '70', '90', '35', '35',\n        '30', '90', '10', '60', '25', '75', '90', '90', '5', '90', '50',\n        '0', '70', '0', '75', '50', '90', '20', '90', '15', '15', '25',\n        '50', '35', '45', '70', '0', '75', '60', '40', '40', '5', '90',\n        '80', '85', '15', '85', '0', '40', '55', '50', '65', '35', '0',\n        '40', '50', '60', '40', '75', '85', '65', '0', '65', '70', '90',\n        '10', '5', '0', '65', '65', '85', '65', '85', '5', '95', '90',\n        '40', '0', '25', '5', '10', '5', '75', '35', '45', '75', '5',\n        '15', '5', '20', '95', '40', '0', '80', '0', '20', '25', '20',\n        '45', '0', '60', '40', '0', '85', '10', '90', '55', '0', '30',\n        '80', '55', '75', '90', '45', '95', '60', '0', '85', '20', '25',\n        '80', '50', '85', '40', '5', '15', '20', '5', '25', '15', '75',\n        '70', '5', '100', '80', '5', '95', '30', '55', '85', '65', '100',\n        '15', '25', '35', '95', '90', '80', '100', '70', '95', '85',\n        '10', '60', '85']], dtype='<U21')\n\n\n\ntest_ndarray.T #학번이 string으로 들어가있어서 모든 자료가 string으로 되어있음.. \n\narray([['202212377', '65', '45', '0', '10'],\n       ['202212473', '95', '30', '60', '10'],\n       ['202212310', '65', '85', '15', '20'],\n       ['202212460', '55', '35', '35', '5'],\n       ['202212320', '80', '60', '55', '70'],\n       ['202212329', '75', '40', '75', '85'],\n       ['202212408', '65', '70', '60', '75'],\n       ['202212319', '60', '25', '20', '35'],\n       ['202212348', '95', '55', '65', '90'],\n       ['202212306', '90', '25', '95', '50'],\n       ['202212308', '55', '45', '75', '30'],\n       ['202212366', '95', '60', '25', '55'],\n       ['202212367', '95', '35', '0', '25'],\n       ['202212461', '50', '55', '90', '45'],\n       ['202212354', '50', '65', '50', '70'],\n       ['202212361', '95', '100', '25', '40'],\n       ['202212400', '50', '65', '35', '85'],\n       ['202212490', '65', '85', '10', '5'],\n       ['202212404', '70', '65', '65', '80'],\n       ['202212326', '90', '70', '100', '30'],\n       ['202212452', '80', '45', '80', '85'],\n       ['202212362', '55', '45', '85', '70'],\n       ['202212396', '65', '35', '45', '20'],\n       ['202212356', '70', '25', '50', '70'],\n       ['202212305', '85', '55', '30', '80'],\n       ['202212398', '90', '30', '30', '0'],\n       ['202212410', '100', '65', '50', '70'],\n       ['202212385', '80', '70', '50', '100'],\n       ['202212430', '80', '35', '25', '65'],\n       ['202212498', '55', '75', '20', '25'],\n       ['202212423', '75', '75', '85', '95'],\n       ['202212327', '80', '95', '5', '5'],\n       ['202212347', '95', '60', '65', '10'],\n       ['202212483', '95', '60', '90', '75'],\n       ['202212447', '100', '75', '70', '25'],\n       ['202212496', '100', '55', '35', '85'],\n       ['202212358', '80', '60', '65', '55'],\n       ['202212399', '70', '80', '0', '10'],\n       ['202212459', '85', '65', '60', '60'],\n       ['202212313', '100', '95', '0', '25'],\n       ['202212304', '95', '60', '15', '45'],\n       ['202212431', '75', '40', '30', '10'],\n       ['202212325', '70', '80', '50', '25'],\n       ['202212471', '50', '45', '10', '10'],\n       ['202212463', '100', '100', '100', '50'],\n       ['202212441', '75', '50', '60', '5'],\n       ['202212445', '85', '50', '35', '100'],\n       ['202212323', '80', '35', '75', '80'],\n       ['202212442', '95', '45', '35', '80'],\n       ['202212346', '65', '85', '85', '15'],\n       ['202212411', '90', '30', '25', '5'],\n       ['202212468', '65', '65', '35', '70'],\n       ['202212331', '80', '65', '30', '90'],\n       ['202212345', '95', '80', '45', '35'],\n       ['202212339', '65', '75', '50', '35'],\n       ['202212383', '90', '55', '100', '30'],\n       ['202212462', '95', '25', '95', '90'],\n       ['202212344', '100', '50', '80', '10'],\n       ['202212472', '50', '55', '35', '60'],\n       ['202212437', '90', '70', '35', '25'],\n       ['202212336', '50', '55', '15', '75'],\n       ['202212438', '80', '50', '55', '90'],\n       ['202212454', '50', '75', '65', '90'],\n       ['202212384', '70', '40', '90', '5'],\n       ['202212402', '65', '85', '20', '90'],\n       ['202212397', '60', '30', '0', '50'],\n       ['202212318', '50', '65', '15', '0'],\n       ['202212371', '60', '95', '30', '70'],\n       ['202212469', '70', '70', '5', '0'],\n       ['202212379', '75', '45', '15', '75'],\n       ['202212364', '50', '60', '15', '50'],\n       ['202212450', '85', '90', '90', '90'],\n       ['202212337', '80', '25', '85', '20'],\n       ['202212458', '55', '75', '95', '90'],\n       ['202212494', '85', '30', '45', '15'],\n       ['202212478', '65', '30', '45', '15'],\n       ['202212373', '85', '95', '35', '25'],\n       ['202212474', '60', '25', '10', '50'],\n       ['202212455', '95', '45', '90', '35'],\n       ['202212317', '85', '50', '60', '45'],\n       ['202212341', '60', '50', '100', '70'],\n       ['202212386', '100', '75', '60', '0'],\n       ['202212328', '100', '90', '85', '75'],\n       ['202212417', '55', '100', '100', '60'],\n       ['202212370', '70', '60', '30', '40'],\n       ['202212486', '70', '90', '95', '40'],\n       ['202212333', '55', '50', '0', '5'],\n       ['202212360', '100', '100', '45', '90'],\n       ['202212350', '85', '70', '90', '80'],\n       ['202212382', '100', '85', '65', '85'],\n       ['202212392', '60', '65', '35', '15'],\n       ['202212449', '65', '75', '75', '85'],\n       ['202212394', '65', '25', '40', '0'],\n       ['202212444', '75', '75', '50', '40'],\n       ['202212487', '50', '55', '80', '55'],\n       ['202212425', '75', '30', '20', '50'],\n       ['202212312', '100', '50', '25', '65'],\n       ['202212448', '90', '30', '95', '35'],\n       ['202212434', '55', '100', '80', '0'],\n       ['202212451', '75', '60', '15', '40'],\n       ['202212433', '60', '25', '25', '50'],\n       ['202212424', '85', '35', '10', '60'],\n       ['202212351', '60', '100', '55', '40'],\n       ['202212324', '70', '55', '50', '75'],\n       ['202212314', '80', '65', '95', '85'],\n       ['202212446', '65', '35', '15', '65'],\n       ['202212401', '85', '70', '100', '0'],\n       ['202212307', '100', '30', '60', '65'],\n       ['202212300', '65', '70', '55', '70'],\n       ['202212342', '85', '55', '85', '90'],\n       ['202212479', '85', '95', '80', '10'],\n       ['202212443', '85', '70', '75', '5'],\n       ['202212387', '100', '35', '70', '0'],\n       ['202212372', '95', '45', '55', '65'],\n       ['202212376', '95', '85', '40', '65'],\n       ['202212466', '55', '50', '30', '85'],\n       ['202212391', '85', '50', '5', '65'],\n       ['202212368', '75', '90', '85', '85'],\n       ['202212427', '95', '70', '10', '5'],\n       ['202212414', '85', '35', '80', '95'],\n       ['202212426', '95', '50', '80', '90'],\n       ['202212316', '100', '65', '75', '40'],\n       ['202212355', '95', '70', '70', '0'],\n       ['202212477', '95', '70', '20', '25'],\n       ['202212484', '100', '60', '10', '5'],\n       ['202212456', '55', '35', '25', '10'],\n       ['202212500', '60', '90', '40', '5'],\n       ['202212381', '85', '90', '85', '75'],\n       ['202212335', '75', '85', '25', '35'],\n       ['202212475', '55', '30', '50', '45'],\n       ['202212343', '70', '60', '75', '75'],\n       ['202212412', '80', '30', '95', '5'],\n       ['202212428', '90', '85', '80', '15'],\n       ['202212330', '90', '25', '95', '5'],\n       ['202212375', '60', '85', '50', '20'],\n       ['202212413', '90', '50', '95', '95'],\n       ['202212303', '75', '95', '65', '40'],\n       ['202212374', '60', '40', '35', '0'],\n       ['202212409', '55', '100', '15', '80'],\n       ['202212440', '70', '75', '80', '0'],\n       ['202212393', '75', '65', '25', '20'],\n       ['202212492', '90', '75', '80', '25'],\n       ['202212357', '50', '75', '75', '20'],\n       ['202212465', '55', '45', '35', '45'],\n       ['202212415', '90', '70', '90', '0'],\n       ['202212405', '75', '30', '100', '60'],\n       ['202212435', '90', '85', '0', '40'],\n       ['202212380', '85', '70', '35', '0'],\n       ['202212369', '100', '75', '100', '85'],\n       ['202212467', '55', '35', '20', '10'],\n       ['202212429', '70', '75', '90', '90'],\n       ['202212495', '90', '90', '55', '55'],\n       ['202212420', '55', '60', '40', '0'],\n       ['202212302', '100', '90', '5', '30'],\n       ['202212481', '50', '55', '25', '80'],\n       ['202212422', '100', '100', '90', '55'],\n       ['202212388', '70', '45', '70', '75'],\n       ['202212480', '85', '95', '85', '90'],\n       ['202212378', '55', '25', '95', '45'],\n       ['202212457', '75', '30', '10', '95'],\n       ['202212419', '65', '85', '15', '60'],\n       ['202212432', '70', '90', '70', '0'],\n       ['202212395', '60', '85', '70', '85'],\n       ['202212464', '100', '25', '10', '20'],\n       ['202212476', '75', '25', '80', '25'],\n       ['202212332', '90', '95', '40', '80'],\n       ['202212301', '95', '90', '50', '50'],\n       ['202212497', '90', '90', '65', '85'],\n       ['202212309', '95', '75', '50', '40'],\n       ['202212493', '55', '60', '70', '5'],\n       ['202212311', '95', '85', '0', '15'],\n       ['202212416', '65', '60', '35', '20'],\n       ['202212489', '65', '50', '5', '5'],\n       ['202212359', '90', '25', '60', '25'],\n       ['202212349', '100', '40', '40', '15'],\n       ['202212403', '70', '25', '100', '75'],\n       ['202212418', '100', '30', '70', '70'],\n       ['202212406', '50', '55', '55', '5'],\n       ['202212485', '70', '35', '70', '100'],\n       ['202212390', '70', '60', '60', '80'],\n       ['202212365', '55', '45', '90', '5'],\n       ['202212338', '55', '55', '10', '95'],\n       ['202212363', '65', '80', '10', '30'],\n       ['202212321', '90', '25', '35', '55'],\n       ['202212499', '100', '30', '30', '85'],\n       ['202212340', '70', '85', '70', '65'],\n       ['202212421', '60', '100', '45', '100'],\n       ['202212407', '70', '25', '100', '15'],\n       ['202212439', '70', '35', '80', '25'],\n       ['202212488', '65', '60', '30', '35'],\n       ['202212453', '95', '35', '40', '95'],\n       ['202212482', '50', '80', '65', '90'],\n       ['202212334', '100', '40', '80', '80'],\n       ['202212322', '55', '30', '95', '100'],\n       ['202212353', '65', '40', '65', '70'],\n       ['202212491', '55', '70', '40', '95'],\n       ['202212352', '65', '85', '25', '85'],\n       ['202212315', '85', '85', '100', '10'],\n       ['202212470', '80', '65', '35', '60'],\n       ['202212436', '50', '95', '45', '85']], dtype='<U21')\n\n\n\ntest_ndarray\n\narray([[202212377,        65,        45,         0,        10],\n       [202212473,        95,        30,        60,        10],\n       [202212310,        65,        85,        15,        20],\n       [202212460,        55,        35,        35,         5],\n       [202212320,        80,        60,        55,        70],\n       [202212329,        75,        40,        75,        85],\n       [202212408,        65,        70,        60,        75],\n       [202212319,        60,        25,        20,        35],\n       [202212348,        95,        55,        65,        90],\n       [202212306,        90,        25,        95,        50],\n       [202212308,        55,        45,        75,        30],\n       [202212366,        95,        60,        25,        55],\n       [202212367,        95,        35,         0,        25],\n       [202212461,        50,        55,        90,        45],\n       [202212354,        50,        65,        50,        70],\n       [202212361,        95,       100,        25,        40],\n       [202212400,        50,        65,        35,        85],\n       [202212490,        65,        85,        10,         5],\n       [202212404,        70,        65,        65,        80],\n       [202212326,        90,        70,       100,        30],\n       [202212452,        80,        45,        80,        85],\n       [202212362,        55,        45,        85,        70],\n       [202212396,        65,        35,        45,        20],\n       [202212356,        70,        25,        50,        70],\n       [202212305,        85,        55,        30,        80],\n       [202212398,        90,        30,        30,         0],\n       [202212410,       100,        65,        50,        70],\n       [202212385,        80,        70,        50,       100],\n       [202212430,        80,        35,        25,        65],\n       [202212498,        55,        75,        20,        25],\n       [202212423,        75,        75,        85,        95],\n       [202212327,        80,        95,         5,         5],\n       [202212347,        95,        60,        65,        10],\n       [202212483,        95,        60,        90,        75],\n       [202212447,       100,        75,        70,        25],\n       [202212496,       100,        55,        35,        85],\n       [202212358,        80,        60,        65,        55],\n       [202212399,        70,        80,         0,        10],\n       [202212459,        85,        65,        60,        60],\n       [202212313,       100,        95,         0,        25],\n       [202212304,        95,        60,        15,        45],\n       [202212431,        75,        40,        30,        10],\n       [202212325,        70,        80,        50,        25],\n       [202212471,        50,        45,        10,        10],\n       [202212463,       100,       100,       100,        50],\n       [202212441,        75,        50,        60,         5],\n       [202212445,        85,        50,        35,       100],\n       [202212323,        80,        35,        75,        80],\n       [202212442,        95,        45,        35,        80],\n       [202212346,        65,        85,        85,        15],\n       [202212411,        90,        30,        25,         5],\n       [202212468,        65,        65,        35,        70],\n       [202212331,        80,        65,        30,        90],\n       [202212345,        95,        80,        45,        35],\n       [202212339,        65,        75,        50,        35],\n       [202212383,        90,        55,       100,        30],\n       [202212462,        95,        25,        95,        90],\n       [202212344,       100,        50,        80,        10],\n       [202212472,        50,        55,        35,        60],\n       [202212437,        90,        70,        35,        25],\n       [202212336,        50,        55,        15,        75],\n       [202212438,        80,        50,        55,        90],\n       [202212454,        50,        75,        65,        90],\n       [202212384,        70,        40,        90,         5],\n       [202212402,        65,        85,        20,        90],\n       [202212397,        60,        30,         0,        50],\n       [202212318,        50,        65,        15,         0],\n       [202212371,        60,        95,        30,        70],\n       [202212469,        70,        70,         5,         0],\n       [202212379,        75,        45,        15,        75],\n       [202212364,        50,        60,        15,        50],\n       [202212450,        85,        90,        90,        90],\n       [202212337,        80,        25,        85,        20],\n       [202212458,        55,        75,        95,        90],\n       [202212494,        85,        30,        45,        15],\n       [202212478,        65,        30,        45,        15],\n       [202212373,        85,        95,        35,        25],\n       [202212474,        60,        25,        10,        50],\n       [202212455,        95,        45,        90,        35],\n       [202212317,        85,        50,        60,        45],\n       [202212341,        60,        50,       100,        70],\n       [202212386,       100,        75,        60,         0],\n       [202212328,       100,        90,        85,        75],\n       [202212417,        55,       100,       100,        60],\n       [202212370,        70,        60,        30,        40],\n       [202212486,        70,        90,        95,        40],\n       [202212333,        55,        50,         0,         5],\n       [202212360,       100,       100,        45,        90],\n       [202212350,        85,        70,        90,        80],\n       [202212382,       100,        85,        65,        85],\n       [202212392,        60,        65,        35,        15],\n       [202212449,        65,        75,        75,        85],\n       [202212394,        65,        25,        40,         0],\n       [202212444,        75,        75,        50,        40],\n       [202212487,        50,        55,        80,        55],\n       [202212425,        75,        30,        20,        50],\n       [202212312,       100,        50,        25,        65],\n       [202212448,        90,        30,        95,        35],\n       [202212434,        55,       100,        80,         0],\n       [202212451,        75,        60,        15,        40],\n       [202212433,        60,        25,        25,        50],\n       [202212424,        85,        35,        10,        60],\n       [202212351,        60,       100,        55,        40],\n       [202212324,        70,        55,        50,        75],\n       [202212314,        80,        65,        95,        85],\n       [202212446,        65,        35,        15,        65],\n       [202212401,        85,        70,       100,         0],\n       [202212307,       100,        30,        60,        65],\n       [202212300,        65,        70,        55,        70],\n       [202212342,        85,        55,        85,        90],\n       [202212479,        85,        95,        80,        10],\n       [202212443,        85,        70,        75,         5],\n       [202212387,       100,        35,        70,         0],\n       [202212372,        95,        45,        55,        65],\n       [202212376,        95,        85,        40,        65],\n       [202212466,        55,        50,        30,        85],\n       [202212391,        85,        50,         5,        65],\n       [202212368,        75,        90,        85,        85],\n       [202212427,        95,        70,        10,         5],\n       [202212414,        85,        35,        80,        95],\n       [202212426,        95,        50,        80,        90],\n       [202212316,       100,        65,        75,        40],\n       [202212355,        95,        70,        70,         0],\n       [202212477,        95,        70,        20,        25],\n       [202212484,       100,        60,        10,         5],\n       [202212456,        55,        35,        25,        10],\n       [202212500,        60,        90,        40,         5],\n       [202212381,        85,        90,        85,        75],\n       [202212335,        75,        85,        25,        35],\n       [202212475,        55,        30,        50,        45],\n       [202212343,        70,        60,        75,        75],\n       [202212412,        80,        30,        95,         5],\n       [202212428,        90,        85,        80,        15],\n       [202212330,        90,        25,        95,         5],\n       [202212375,        60,        85,        50,        20],\n       [202212413,        90,        50,        95,        95],\n       [202212303,        75,        95,        65,        40],\n       [202212374,        60,        40,        35,         0],\n       [202212409,        55,       100,        15,        80],\n       [202212440,        70,        75,        80,         0],\n       [202212393,        75,        65,        25,        20],\n       [202212492,        90,        75,        80,        25],\n       [202212357,        50,        75,        75,        20],\n       [202212465,        55,        45,        35,        45],\n       [202212415,        90,        70,        90,         0],\n       [202212405,        75,        30,       100,        60],\n       [202212435,        90,        85,         0,        40],\n       [202212380,        85,        70,        35,         0],\n       [202212369,       100,        75,       100,        85],\n       [202212467,        55,        35,        20,        10],\n       [202212429,        70,        75,        90,        90],\n       [202212495,        90,        90,        55,        55],\n       [202212420,        55,        60,        40,         0],\n       [202212302,       100,        90,         5,        30],\n       [202212481,        50,        55,        25,        80],\n       [202212422,       100,       100,        90,        55],\n       [202212388,        70,        45,        70,        75],\n       [202212480,        85,        95,        85,        90],\n       [202212378,        55,        25,        95,        45],\n       [202212457,        75,        30,        10,        95],\n       [202212419,        65,        85,        15,        60],\n       [202212432,        70,        90,        70,         0],\n       [202212395,        60,        85,        70,        85],\n       [202212464,       100,        25,        10,        20],\n       [202212476,        75,        25,        80,        25],\n       [202212332,        90,        95,        40,        80],\n       [202212301,        95,        90,        50,        50],\n       [202212497,        90,        90,        65,        85],\n       [202212309,        95,        75,        50,        40],\n       [202212493,        55,        60,        70,         5],\n       [202212311,        95,        85,         0,        15],\n       [202212416,        65,        60,        35,        20],\n       [202212489,        65,        50,         5,         5],\n       [202212359,        90,        25,        60,        25],\n       [202212349,       100,        40,        40,        15],\n       [202212403,        70,        25,       100,        75],\n       [202212418,       100,        30,        70,        70],\n       [202212406,        50,        55,        55,         5],\n       [202212485,        70,        35,        70,       100],\n       [202212390,        70,        60,        60,        80],\n       [202212365,        55,        45,        90,         5],\n       [202212338,        55,        55,        10,        95],\n       [202212363,        65,        80,        10,        30],\n       [202212321,        90,        25,        35,        55],\n       [202212499,       100,        30,        30,        85],\n       [202212340,        70,        85,        70,        65],\n       [202212421,        60,       100,        45,       100],\n       [202212407,        70,        25,       100,        15],\n       [202212439,        70,        35,        80,        25],\n       [202212488,        65,        60,        30,        35],\n       [202212453,        95,        35,        40,        95],\n       [202212482,        50,        80,        65,        90],\n       [202212334,       100,        40,        80,        80],\n       [202212322,        55,        30,        95,       100],\n       [202212353,        65,        40,        65,        70],\n       [202212491,        55,        70,        40,        95],\n       [202212352,        65,        85,        25,        85],\n       [202212315,        85,        85,       100,        10],\n       [202212470,        80,        65,        35,        60],\n       [202212436,        50,        95,        45,        85]])\n\n\n(풀이2)\n\ntest_ndarray[test_ndarray[:,0] == 202212460]\n\narray([[202212460,        55,        35,        35,         5]])\n\n\n\ntest_ndarray[test_ndarray[:,0] == 202212460,1]   # 이게뭐여? 가독성이 떨어짐\n\narray([55])\n\n\n(풀이2)가 (풀이1)에 비하여 불편한 점 - test_ndarray의 첫칼럼은 student id이고 두번째 칼럼은 att라는 사실을 암기하고 있어야 한다. - student id가 아니고 만약에 학생이름(문자형)을 써서 데이터를 정리한다면 모든 자료형은 문자형이 되어야 한다. - 작성한 코드 가독성이 없다. (위치로 접근하므로)\n- 요약: hash 스타일로 정보를 추출하는 것이 유용할 때가 있다. 그리고 보통 hash 스타일로 정보를 뽑는것이 유리함.\nnumpy는 정보추출을 위해 개발된 자료형이 아니라 행렬 및 벡터의 수학연산을 지원하기 위해 개발된 자료형이다.)\n- 소망: 정보를 추출할때는 hash 스타일도 유용하다는 것은 ㅇㅋ \\(\\to\\) 하지만 난 가끔 넘파이스타일로 정보를 뽑고 싶엉. 그리고 딕셔너리 형태가 아니고 엑셀처럼(행렬처럼) 데이터를 보고 ㅅ피다!!! \\(\\to\\) pandas 개발\n\n\n\npandas 개발동기\n\n엑셀처럼 데이터를 테이블 형태로 정리하고 싶다.\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(20)}\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\n\n\ntest_dic\n\n{'202212380': {'att': 65, 'rep': 55, 'mid': 50, 'fin': 40},\n '202212370': {'att': 95, 'rep': 100, 'mid': 50, 'fin': 80},\n '202212363': {'att': 65, 'rep': 90, 'mid': 60, 'fin': 30},\n '202212488': {'att': 55, 'rep': 80, 'mid': 75, 'fin': 80},\n '202212312': {'att': 80, 'rep': 30, 'mid': 30, 'fin': 100},\n '202212377': {'att': 75, 'rep': 40, 'mid': 100, 'fin': 15},\n '202212463': {'att': 65, 'rep': 45, 'mid': 45, 'fin': 90},\n '202212471': {'att': 60, 'rep': 60, 'mid': 25, 'fin': 0},\n '202212400': {'att': 95, 'rep': 65, 'mid': 20, 'fin': 10},\n '202212469': {'att': 90, 'rep': 80, 'mid': 80, 'fin': 20},\n '202212318': {'att': 55, 'rep': 75, 'mid': 35, 'fin': 25},\n '202212432': {'att': 95, 'rep': 95, 'mid': 45, 'fin': 0},\n '202212443': {'att': 95, 'rep': 55, 'mid': 15, 'fin': 35},\n '202212367': {'att': 50, 'rep': 80, 'mid': 40, 'fin': 30},\n '202212458': {'att': 50, 'rep': 55, 'mid': 15, 'fin': 85},\n '202212396': {'att': 95, 'rep': 30, 'mid': 30, 'fin': 95},\n '202212482': {'att': 50, 'rep': 50, 'mid': 45, 'fin': 10},\n '202212452': {'att': 65, 'rep': 55, 'mid': 15, 'fin': 45},\n '202212387': {'att': 70, 'rep': 70, 'mid': 40, 'fin': 35},\n '202212354': {'att': 90, 'rep': 90, 'mid': 80, 'fin': 90}}\n\n\n\n테이블 형태로 보고 싶다.\n\n(방법1) - 행렬이기는 하지만 방법 2,3,4에 비하여 우리가 원하는 만큼 가독성을 주는 형태는 아님\n\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n(방법2)\n\npd.DataFrame(test_dic).T\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법3)\n\ntest_dic2 = {'att':{key[i]:att[i] for i in range(20)},\n             'rep':{key[i]:rep[i] for i in range(20)},\n             'mid':{key[i]:mid[i] for i in range(20)},\n             'fin':{key[i]:fin[i] for i in range(20)}}\n\n\ntest_dic2\n\n{'att': {'202212380': 65,\n  '202212370': 95,\n  '202212363': 65,\n  '202212488': 55,\n  '202212312': 80,\n  '202212377': 75,\n  '202212463': 65,\n  '202212471': 60,\n  '202212400': 95,\n  '202212469': 90,\n  '202212318': 55,\n  '202212432': 95,\n  '202212443': 95,\n  '202212367': 50,\n  '202212458': 50,\n  '202212396': 95,\n  '202212482': 50,\n  '202212452': 65,\n  '202212387': 70,\n  '202212354': 90},\n 'rep': {'202212380': 55,\n  '202212370': 100,\n  '202212363': 90,\n  '202212488': 80,\n  '202212312': 30,\n  '202212377': 40,\n  '202212463': 45,\n  '202212471': 60,\n  '202212400': 65,\n  '202212469': 80,\n  '202212318': 75,\n  '202212432': 95,\n  '202212443': 55,\n  '202212367': 80,\n  '202212458': 55,\n  '202212396': 30,\n  '202212482': 50,\n  '202212452': 55,\n  '202212387': 70,\n  '202212354': 90},\n 'mid': {'202212380': 50,\n  '202212370': 50,\n  '202212363': 60,\n  '202212488': 75,\n  '202212312': 30,\n  '202212377': 100,\n  '202212463': 45,\n  '202212471': 25,\n  '202212400': 20,\n  '202212469': 80,\n  '202212318': 35,\n  '202212432': 45,\n  '202212443': 15,\n  '202212367': 40,\n  '202212458': 15,\n  '202212396': 30,\n  '202212482': 45,\n  '202212452': 15,\n  '202212387': 40,\n  '202212354': 80},\n 'fin': {'202212380': 40,\n  '202212370': 80,\n  '202212363': 30,\n  '202212488': 80,\n  '202212312': 100,\n  '202212377': 15,\n  '202212463': 90,\n  '202212471': 0,\n  '202212400': 10,\n  '202212469': 20,\n  '202212318': 25,\n  '202212432': 0,\n  '202212443': 35,\n  '202212367': 30,\n  '202212458': 85,\n  '202212396': 95,\n  '202212482': 10,\n  '202212452': 45,\n  '202212387': 35,\n  '202212354': 90}}\n\n\n\npd.DataFrame(test_dic2)\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법4)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin}, index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법5)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      55\n      50\n      40\n    \n    \n      1\n      95\n      100\n      50\n      80\n    \n    \n      2\n      65\n      90\n      60\n      30\n    \n    \n      3\n      55\n      80\n      75\n      80\n    \n    \n      4\n      80\n      30\n      30\n      100\n    \n    \n      5\n      75\n      40\n      100\n      15\n    \n    \n      6\n      65\n      45\n      45\n      90\n    \n    \n      7\n      60\n      60\n      25\n      0\n    \n    \n      8\n      95\n      65\n      20\n      10\n    \n    \n      9\n      90\n      80\n      80\n      20\n    \n    \n      10\n      55\n      75\n      35\n      25\n    \n    \n      11\n      95\n      95\n      45\n      0\n    \n    \n      12\n      95\n      55\n      15\n      35\n    \n    \n      13\n      50\n      80\n      40\n      30\n    \n    \n      14\n      50\n      55\n      15\n      85\n    \n    \n      15\n      95\n      30\n      30\n      95\n    \n    \n      16\n      50\n      50\n      45\n      10\n    \n    \n      17\n      65\n      55\n      15\n      45\n    \n    \n      18\n      70\n      70\n      40\n      35\n    \n    \n      19\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf=df.set_index([key])   #인덱스를 set_index로 설정해줄 수 있음\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n\n해싱으로 원하는 정보를 뽑으면 좋겠다. (마치 딕셔너리처럼)\n- 예제1: 출설점수를 출력\n\ntest_dic2['att']\n\n{'202212380': 65,\n '202212370': 95,\n '202212363': 65,\n '202212488': 55,\n '202212312': 80,\n '202212377': 75,\n '202212463': 65,\n '202212471': 60,\n '202212400': 95,\n '202212469': 90,\n '202212318': 55,\n '202212432': 95,\n '202212443': 95,\n '202212367': 50,\n '202212458': 50,\n '202212396': 95,\n '202212482': 50,\n '202212452': 65,\n '202212387': 70,\n '202212354': 90}\n\n\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 예제2 : 학번 202212380의 출석점수 출력\n\ntest_dic2['att']['202212380']\n\n65\n\n\n\ndf['att']['202212380']\n\n65\n\n\n\n\n인덱싱으로 정보를 뽑는 기능도 지원을 하면 좋겠따. (마치 리스트나 넘파이처럼)\n- 예제1: 첫번째 학생의 기말고사 성적을 출력하고 싶다.\n\ntest_ndarray[0,-1]\n\n40\n\n\n\ndf.iloc[0,-1]  \n\n40\n\n\n\n벼락치기: df에서 iloc라는 특수기능을 이용하면 넘파이 인덱싱처럼 원소출력이 가능하다.\n\n-예제2: 홀수번째 학생의 점수를 뽑고 싶다.\n\ntest_ndarray[::2]\n\narray([[202212380,        65,        55,        50,        40],\n       [202212363,        65,        90,        60,        30],\n       [202212312,        80,        30,        30,       100],\n       [202212463,        65,        45,        45,        90],\n       [202212400,        95,        65,        20,        10],\n       [202212318,        55,        75,        35,        25],\n       [202212443,        95,        55,        15,        35],\n       [202212458,        50,        55,        15,        85],\n       [202212482,        50,        50,        45,        10],\n       [202212387,        70,        70,        40,        35]])\n\n\n\ndf.iloc[0::2]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 예제3: 맨 끝에서 3명의 점수를 출력하고 싶다.\n\ntest_ndarray[-3:]\n\narray([[202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ndf.iloc[-3:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제4: 맨 끝에서 3명의 점수를 마지막 2개의 칼럼만 출력하고 싶다.\n\ntest_ndarray[-3:,-2:]\n\narray([[15, 45],\n       [40, 35],\n       [80, 90]])\n\n\n\ndf.iloc[-3:,-2:]\n\n\n\n\n\n  \n    \n      \n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      15\n      45\n    \n    \n      202212387\n      40\n      35\n    \n    \n      202212354\n      80\n      90\n    \n  \n\n\n\n\n\n\n궁극: 해싱과 인덱싱을 모두 지원하는 아주 우수한 자료형을 만들고 싶어!\n- 예제1: 중간고사 점수가 20점 이상이면서 동시에 출석점수가 60점미만인 학생들의 기말고사 점수를 출력\n(방법1) 데이터베이스 스타일\n\ndf.query(\"mid>=20 and att<60\")\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n  \n\n\n\n\n\ndf.query(\"mid>=20 and att<60\")['fin']\n\n202212488    80\n202212318    25\n202212367    30\n202212482    10\nName: fin, dtype: int64\n\n\n(방법2) 넘파이 스타일\n\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ntest_ndarray[:,3]>=20 # 중간고사 점수 20점 이상\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True,  True, False,\n        True,  True])\n\n\n\ntest_ndarray[:,1] < 60 # 출석이 60미만 \n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True,  True, False,  True, False,\n       False, False])\n\n\n\n(test_ndarray[:,3]>=20) & (test_ndarray[:,1] < 60)\n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True, False, False,  True, False,\n       False, False])\n\n\n\nnote: test_ndarray[:,3]>=20 & test_ndarray[:,1] < 60 와 같이 하면 에러가 난다. 가로로 묶어줘야 함\n\n\ntest_ndarray[(test_ndarray[:,3]>=20) & (test_ndarray[:,1] < 60),-1] \n\narray([80, 25, 30, 10])\n\n\n\n구현난이도 어려움, 가독성 꽝\n\n- 예제2: ’중간고사점수<기말고사점수’인 학생들의 출석점수 평균을 구하자.\n\ndf.query('mid<fin')['att'].mean()\n\n76.66666666666667\n\n\n\n\n\npandas 사용법\n\npandas 공부 1단계\n\n데이터프레임 선언\n- 방법1: dictionary에서 만든다.\n\npd.DataFrame({'att':[30,40,50],'mid':[50,60,70]})  # 리스트\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':(30,40,50),'mid':(50,60,70)})  # 튜플\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':np.array([30,40,50]),'mid':np.array([50,60,70])})  # 넘파이어레이\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: 2차원 ndarray에서 형태변환 통해 만든다.\n\nnp.arange(2*3).reshape(2,3)\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\npd.DataFrame(np.arange(2*3).reshape(2,3))\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n열의 이름 부여\n- 방법1: 딕셔너리를 통하여 만들면 딕셔너리의 key가 자동으로 열의 이름이 된다.\n\npd.DataFrame({'att':np.array([30,40,50]),'mid':np.array([50,60,70])})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: pd.DataFrame()의 옵션에 columns를 이용\n\npd.DataFrame(np.arange(2*3).reshape(2,3),columns=['X1','X2','X3'])\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n- 방법3: df.columns에 원하는 열이름을 덮어씀(1)\n\ndf=pd.DataFrame(np.arange(2*3).reshape(2,3))\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns\n\nRangeIndex(start=0, stop=3, step=1)\n\n\n\ndf.columns=['X1','X2','X3']\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n- 방법4: df.columns에 원하는 열이름을 덮어씀(2)\n\ndf.columns=pd.Index(['X1','X2','X3'])  # 위와 같은 코드\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n방법4가 방법3의 방식보다 컴퓨터가 이해하기 좋다. (=불필요한 에러를 방지할 수 있다.)\n\ndf.columns\n\nIndex(['X1', 'X2', 'X3'], dtype='object')\n\n\n\ntype(df.columns)\n\npandas.core.indexes.base.Index\n\n\n\n['X1','X2','X3'], type(['X1','X2','X3'])\n\n(['X1', 'X2', 'X3'], list)\n\n\n\npd.Index(['X1','X2','X3'])\n\nIndex(['X1', 'X2', 'X3'], dtype='object')\n\n\n\n\n행의 이름 부여\n- 방법1: 중첩 dict이면 nested dic의 key가 알아서 행의 이름으로 된다. (안쪽..)\n\n{'att': {'boram':30, 'iu':40, 'hynn':50}, 'mid':{'boram':5, 'iu':45, 'hynn':90}}\n\n{'att': {'boram': 30, 'iu': 40, 'hynn': 50},\n 'mid': {'boram': 5, 'iu': 45, 'hynn': 90}}\n\n\n\npd.DataFrame({'att': {'boram':30, 'iu':40, 'hynn':50}, 'mid':{'boram':5, 'iu':45, 'hynn':90}})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법2: index옵션 이용\n\npd.DataFrame({'att': [30, 40,50], 'mid':[5,45, 90]}, index=['boram','iu','hynn'])\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법3: df.index에 덮어씌움\n\ndf=pd.DataFrame({'att': [30, 40,50], 'mid':[5,45, 90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.index\n\nRangeIndex(start=0, stop=3, step=1)\n\n\n\ndf.index=['boram','iu','hynn']\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n\ndf.index= pd.Index(['boram','iu','hynn'])  #이게 컴퓨터가 볼 때 더 안전한 코드!\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법4: df.set_index() 를 이용하여 덮어 씌운다.\n\ndf=pd.DataFrame({'att': [30, 40,50], 'mid':[5,45, 90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.set_index(pd.Index(['boram','iu','hynn']))\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n(주의) 아래는 에러가 난다.\n\ndf.set_index(['boram','iu','hynn'])\n\nKeyError: \"None of ['boram', 'iu', 'hynn'] are in the columns\"\n\n\n\ndf.set_index([['boram','iu','hynn']]) # 꺽쇠를 한번 더 넣어주면 에러를 피할 수 있따.\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      boram\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n\n\n자료형, len, shape, for문의 반복변수\n\ndf= pd.DataFrame({'att':[30,40,50],'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n- type\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n- len\n\nlen(df) #row의 갯수\n\n3\n\n\n- shape\n\ndf.shape\n\n(3, 2)\n\n\n- for문의 반복변수\n\nfor k in df:\n    print(k) #딕셔너리와 같다.\n\natt\nmid\n\n\n\nfor k in {'att':[30,40,50],'mid':[5,45,90]}: #딕셔너리\n    print(k)\n\natt\nmid\n\n\n\n\npd.Series\n- 2차원 ndarray가 pd.DataFrame에 대응한다면 1차원 ndarray는 pd.Series에 대응한다.\n\na=pd.Series(np.random.randn(10))\na\n\n0    0.106173\n1    0.723759\n2    0.217990\n3    0.194022\n4   -0.688990\n5   -0.351670\n6    0.990933\n7    1.212147\n8   -0.608965\n9    0.032549\ndtype: float64\n\n\n\ntype(a)\n\npandas.core.series.Series\n\n\n\nlen(a)\n\n10\n\n\n\na.shape\n\n(10,)\n\n\n\nfor value in a:\n    print(value)   #값들이 반복 넘파이어레이처럼..\n\n0.10617283591748639\n0.7237590624253404\n0.21798967912700873\n0.1940223087322443\n-0.6889899757985083\n-0.3516696436204985\n0.9909329773184973\n1.2121468150185186\n-0.6089654373693767\n0.03254898346416765\n\n\n\n\n\npandas공부 2단계\n- 데이터\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\n\n\ndf=pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin}, index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n첫번째 칼럼을 선택\n- 방법1\n\ndf.att \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법2 : dict스타일\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n\ntype(df['att'])\n\npandas.core.series.Series\n\n\n- 방법3 : dict스타일\n\ndf[['att']]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ntype(df[['att']])\n\npandas.core.frame.DataFrame\n\n\n\ndf.att 나 df[‘att’]는 series를 리턴하고 df[[‘att’]]는 dataframe을 리턴한다.\n\n- 방법4 : ndarray 스타일\n\ndf.iloc[:,0] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법5: ndarray스타일\n\ndf.iloc[:,[0]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,0]은 series를 리턴하고 df.iloc[:,[0]]은 dataframe을 리턴한다.\n\n- 방법6: ndarray 스타일과 dict 스타일의 혼합\n\ndf.loc[:,'att'] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법7: ndarray 스타일과 dict 스타일의 혼합\n\ndf.loc[:,['att']] \n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ndf.loc[:,‘att’]은 series를 리턴하고 df.loc[:,[‘att’]]은 dataframe을 리턴한다.\n\n- 방법7: nparray 스타일 + bool 인덱싱\n\ndf.iloc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n- 방법8: ndarray와 dict의 홉합형 + bool 인덱싱\n\ndf.loc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\n\n여러개의 칼럼을 선택\n- 방법1: dict스타일\n\ndf[['att','fin']]\n\n\n\n\n\n  \n    \n      \n      att\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      40\n    \n    \n      202212370\n      95\n      80\n    \n    \n      202212363\n      65\n      30\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      100\n    \n    \n      202212377\n      75\n      15\n    \n    \n      202212463\n      65\n      90\n    \n    \n      202212471\n      60\n      0\n    \n    \n      202212400\n      95\n      10\n    \n    \n      202212469\n      90\n      20\n    \n    \n      202212318\n      55\n      25\n    \n    \n      202212432\n      95\n      0\n    \n    \n      202212443\n      95\n      35\n    \n    \n      202212367\n      50\n      30\n    \n    \n      202212458\n      50\n      85\n    \n    \n      202212396\n      95\n      95\n    \n    \n      202212482\n      50\n      10\n    \n    \n      202212452\n      65\n      45\n    \n    \n      202212387\n      70\n      35\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n- 방법2: ndarray 스타일 (정수리스트로 인덱싱, 슬라이싱, 스트라이딩)\n\ndf.iloc[:,[0,1]] #정수의 리스트를 전달하여 칼럼추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,0:2]  #슬라이싱, 0,1,2에서 마지막 2는 제외되고 0,1에 해당하는 것만 추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,2:]  #슬라이싱\n\n\n\n\n\n  \n    \n      \n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      50\n      40\n    \n    \n      202212370\n      50\n      80\n    \n    \n      202212363\n      60\n      30\n    \n    \n      202212488\n      75\n      80\n    \n    \n      202212312\n      30\n      100\n    \n    \n      202212377\n      100\n      15\n    \n    \n      202212463\n      45\n      90\n    \n    \n      202212471\n      25\n      0\n    \n    \n      202212400\n      20\n      10\n    \n    \n      202212469\n      80\n      20\n    \n    \n      202212318\n      35\n      25\n    \n    \n      202212432\n      45\n      0\n    \n    \n      202212443\n      15\n      35\n    \n    \n      202212367\n      40\n      30\n    \n    \n      202212458\n      15\n      85\n    \n    \n      202212396\n      30\n      95\n    \n    \n      202212482\n      45\n      10\n    \n    \n      202212452\n      15\n      45\n    \n    \n      202212387\n      40\n      35\n    \n    \n      202212354\n      80\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,::2]  #슬라이싱, 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n- 방법3: ndarray와 dict의 혼합형\n\ndf.loc[:,['att','mid']]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,'att':'rep']  # key로 하는 슬라이싱은 마지막 'rep'까지 표시되어 나온다\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.loc[:,:'rep']\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.loc[:,'rep':]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212370\n      100\n      50\n      80\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212312\n      30\n      30\n      100\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212400\n      65\n      20\n      10\n    \n    \n      202212469\n      80\n      80\n      20\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      45\n      0\n    \n    \n      202212443\n      55\n      15\n      35\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212396\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 방법4: bool을 이용한 인덱싱\n\ndf.iloc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ntest_ndarray[:,range(2)]\n\narray([[202212380,        65],\n       [202212370,        95],\n       [202212363,        65],\n       [202212488,        55],\n       [202212312,        80],\n       [202212377,        75],\n       [202212463,        65],\n       [202212471,        60],\n       [202212400,        95],\n       [202212469,        90],\n       [202212318,        55],\n       [202212432,        95],\n       [202212443,        95],\n       [202212367,        50],\n       [202212458,        50],\n       [202212396,        95],\n       [202212482,        50],\n       [202212452,        65],\n       [202212387,        70],\n       [202212354,        90]])\n\n\n\ndf.iloc[:,range(2)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\n\n첫번째 행을 선택\n- 방법1\n\ntest_ndarray[0,:]\n\narray([202212380,        65,        55,        50,        40])\n\n\n\ntest_ndarray[0]\n\narray([202212380,        65,        55,        50,        40])\n\n\n\ndf.iloc[0]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n- 방법2\n\ndf.iloc[[0]]  # 데이터프레임처럼\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n- 방법3\n\ndf.iloc[0,:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n- 방법4\n\ndf.iloc[[0],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n- 방법5\n\ndf.loc['202212380']\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n- 방법6\n\ndf.loc[['202212380']]  # 데이터프레임처럼\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n- 방법7\n\ndf.loc['202212380',:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n- 방법8\n\ndf.loc[['202212380'],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n- 방법9\n\nlen(df)\n\n20\n\n\n\n[True]+[False]*19\n\n[True,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False]\n\n\n\n_lst = [True]+[False]*19\n\n\ndf.iloc[_lst]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.iloc[_lst,:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst,:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\n\n여러개의 행을 선택\n- 방법1\n\ndf.iloc[[0,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.iloc[[0,2],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 방법2\n\ndf.loc[['202212380','202212363']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.loc[['202212380','202212363'],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 그 밖의 방법들\n\ndf.iloc[::4]  # 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n  \n\n\n\n\n\ndf.iloc[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.loc[:'202212312']\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.att < 80\n\n202212380     True\n202212370    False\n202212363     True\n202212488     True\n202212312    False\n202212377     True\n202212463     True\n202212471     True\n202212400    False\n202212469    False\n202212318     True\n202212432    False\n202212443    False\n202212367     True\n202212458     True\n202212396    False\n202212482     True\n202212452     True\n202212387     True\n202212354    False\nName: att, dtype: bool\n\n\n\ndf.loc[df.att<80]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.loc[list(df.att<80),'rep':]  # 리스트로 바꿔주는게 컴퓨터에게 좀 더 명확한 전달\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.loc[df.att<80,'rep':] # 하지만 리스트화 안해도 되긴 한다..\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.iloc[list(df.att<80),1:]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 아래는 에러가 난다.\n\ndf.iloc[df.att<80,1:]\n\nValueError: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types\n\n\n\n\nquery (중요!!!)\n- 예제1\n\ndf.query('att==90 and mid>30')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제2\n\ndf.query('att<rep and mid<fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n  \n\n\n\n\n- 예제3\n\ndf.query('att<rep<80')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n  \n\n\n\n\n- 예제4\n\ndf.query('50<att<=90 and mid<fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제5\n\ndf.query('(mid+fin)/2 >= 60')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제6\n\n_mean = df.att.mean()\n_mean\n\n73.0\n\n\n\ndf.query('att>=73')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf.query('att>=_mean')  # keyError 가 난다!\n\nUndefinedVariableError: name '_mean' is not defined\n\n\n\ndf.query('att>=@_mean')   # 앞에 @ 골뱅이를 붙여주면 에러 안난다.\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제7\n\ndf.query('index <= \"202212354\"')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf.query('index <= \"202212354\" or index==\"202212387\"')  # 밖에를 큰따옴표 하고 안쪽을 작은따옴표 해도 된다.\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n사실 이 기능은 시계열자료에서 꽃핀다.\n- 예제8\n\npd.date_range('20230101',periods=10)\n\nDatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10'],\n              dtype='datetime64[ns]', freq='D')\n\n\n\n_df=pd.DataFrame(np.random.normal(size=(10,4)),columns=list('ABCD'), index=pd.date_range('20230101',periods=10))\n_df\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      2023-01-01\n      -0.259429\n      0.369731\n      -0.279944\n      0.099409\n    \n    \n      2023-01-02\n      -0.932515\n      -0.311629\n      0.828348\n      -0.225257\n    \n    \n      2023-01-03\n      -0.011607\n      0.927334\n      -0.753145\n      1.013249\n    \n    \n      2023-01-04\n      -1.050379\n      -0.323094\n      0.813898\n      1.035724\n    \n    \n      2023-01-05\n      -0.921175\n      0.513109\n      -0.905361\n      0.893707\n    \n    \n      2023-01-06\n      -1.521594\n      0.856883\n      -0.401441\n      -1.111551\n    \n    \n      2023-01-07\n      0.958028\n      -0.015302\n      0.891259\n      -0.826834\n    \n    \n      2023-01-08\n      1.822226\n      -1.258543\n      -0.705506\n      -0.519831\n    \n    \n      2023-01-09\n      -0.593394\n      -1.399224\n      -1.616172\n      -0.626952\n    \n    \n      2023-01-10\n      -0.083539\n      0.528519\n      0.051522\n      0.126757\n    \n  \n\n\n\n\n\n_df.query(\"'2023-01-02' < index <= '2023-01-09'\")\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      2023-01-03\n      -0.011607\n      0.927334\n      -0.753145\n      1.013249\n    \n    \n      2023-01-04\n      -1.050379\n      -0.323094\n      0.813898\n      1.035724\n    \n    \n      2023-01-05\n      -0.921175\n      0.513109\n      -0.905361\n      0.893707\n    \n    \n      2023-01-06\n      -1.521594\n      0.856883\n      -0.401441\n      -1.111551\n    \n    \n      2023-01-07\n      0.958028\n      -0.015302\n      0.891259\n      -0.826834\n    \n    \n      2023-01-08\n      1.822226\n      -1.258543\n      -0.705506\n      -0.519831\n    \n    \n      2023-01-09\n      -0.593394\n      -1.399224\n      -1.616172\n      -0.626952\n    \n  \n\n\n\n\n\n_df.query(\"'2023-01-02' < index <= '2023-01-09' and A+B<C\")\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      2023-01-04\n      -1.050379\n      -0.323094\n      0.813898\n      1.035724\n    \n    \n      2023-01-06\n      -1.521594\n      0.856883\n      -0.401441\n      -1.111551\n    \n    \n      2023-01-09\n      -0.593394\n      -1.399224\n      -1.616172\n      -0.626952\n    \n  \n\n\n\n\n- query가 만능은 아니다.\n\ndf.columns = pd.Index(['att score', 'rep score', 'mid score','fin score'])\n\n\ndf.query(\"att score < 90\")  # 변수이름에 띄어쓰기가 들어가면 에러가 난다.\n\nSyntaxError: invalid syntax (<unknown>, line 1)\n\n\n\ndf.att socre\n\nSyntaxError: invalid syntax (<ipython-input-285-4116dfe6888b>, line 1)\n\n\n\ndf.loc[df[\"att score\"] < 90, :] # 이렇게 하면 됨\n\n\n\n\n\n  \n    \n      \n      att score\n      rep score\n      mid score\n      fin score\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n\n\n\npandas 공부 3단계\n\n전치\n\nndarray = np.arange(2*3).reshape(2,3)\ndf=pd.DataFrame(ndarray)\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\nndarray.T\n\narray([[0, 3],\n       [1, 4],\n       [2, 5]])\n\n\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      0\n      0\n      3\n    \n    \n      1\n      1\n      4\n    \n    \n      2\n      2\n      5\n    \n  \n\n\n\n\n\n\n합\n\nndarray.sum(axis=0)\n\narray([3, 5, 7])\n\n\n\ndf.sum(axis=0)\n\n0    3\n1    5\n2    7\ndtype: int64\n\n\n\nndarray.sum(axis=1)\n\narray([ 3, 12])\n\n\n\ndf.sum(axis=1)\n\n0     3\n1    12\ndtype: int64\n\n\n\n\ncumsum\n\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\nndarray.cumsum(axis=0) #누적해서 더해짐\n\narray([[0, 1, 2],\n       [3, 5, 7]])\n\n\n\ndf.cumsum(axis=0)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      5\n      7\n    \n  \n\n\n\n\n\nndarray.cumsum(axis=1)\n\narray([[ 0,  1,  3],\n       [ 3,  7, 12]])\n\n\n\ndf.cumsum(axis=1)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      3\n    \n    \n      1\n      3\n      7\n      12\n    \n  \n\n\n\n\n\n\n형태변환\n\nndarray.tolist()\n\n[[0, 1, 2], [3, 4, 5]]\n\n\n\ndf.to_numpy()\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\ndf.to_numpy().tolist()\n\n[[0, 1, 2], [3, 4, 5]]\n\n\n\ndf.to_dict()\n\n{0: {0: 0, 1: 3}, 1: {0: 1, 1: 4}, 2: {0: 2, 1: 5}}\n\n\n\n\n\npandas 공부 4단계 (생략)\n\n\n숙제\n- 아래의 DF에서 1,3번째 열을 추출하라.\n\ndf= pd.DataFrame({'att':[90,90,95],'rep':[80,90,90],'mid':[50,60,70], 'fin':[70,80,50]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      90\n      80\n      50\n      70\n    \n    \n      1\n      90\n      90\n      60\n      80\n    \n    \n      2\n      95\n      90\n      70\n      50\n    \n  \n\n\n\n\n\ndf[['att','mid']]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      90\n      50\n    \n    \n      1\n      90\n      60\n    \n    \n      2\n      95\n      70\n    \n  \n\n\n\n\n\ndf.iloc[:,[0,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      90\n      50\n    \n    \n      1\n      90\n      60\n    \n    \n      2\n      95\n      70\n    \n  \n\n\n\n\n\ndf.iloc[:,::2]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      90\n      50\n    \n    \n      1\n      90\n      60\n    \n    \n      2\n      95\n      70\n    \n  \n\n\n\n\n\ndf.loc[:,['att','mid']]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      90\n      50\n    \n    \n      1\n      90\n      60\n    \n    \n      2\n      95\n      70"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0418.html",
    "href": "posts/Python/2. Numpy/python 7_0418.html",
    "title": "파이썬 (0418) 7주차",
    "section": "",
    "text": "import numpy as np"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0418.html#numpy공부-7단계",
    "href": "posts/Python/2. Numpy/python 7_0418.html#numpy공부-7단계",
    "title": "파이썬 (0418) 7주차",
    "section": "numpy공부 7단계",
    "text": "numpy공부 7단계\n\nnote 1: 메소드 도움말 확인하기\n- 파이썬에서 함수를 적용하는 2가지 방식 - np.sum(a) - a.sum()\n\na=np.array([1,2,3,4,5])\na\n\narray([1, 2, 3, 4, 5])\n\n\n\na.sum()\n\n15\n\n\n\nnp.sum(a)\n\n15\n\n\n- 넘파이에서 a.sum에 대한 도움말은 보통 np.sum()에 자세히 나와있음 \\(\\to\\) np.sum()의 도움말을 확인하고 np.sum(a)와 a.sum()이 동일함을 이용하여 a.sum()의 사용법을 미루어 유추해야함\n\na.sum?\n\n\nnp.sum?\n\n\nnp.sum([0.5, 1.5])\n\n2.0\n\n\n\n\nnote2: hstack, vstack\n- hstack, vstack를 쓰는 사람도 있다.\n\na=np.arange(6)\nb=-a\n\n\nnp.vstack([a,b])\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 0, -1, -2, -3, -4, -5]])\n\n\n\nnp.stack([a,b],axis=0)\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 0, -1, -2, -3, -4, -5]])\n\n\n\nnp.hstack([a,b])\n\narray([ 0,  1,  2,  3,  4,  5,  0, -1, -2, -3, -4, -5])\n\n\n\nnp.concatenate([a,b],axis=0)\n\narray([ 0,  1,  2,  3,  4,  5,  0, -1, -2, -3, -4, -5])\n\n\n\nnote3: append\n- 기능1:reshape(-1) + concat\n\na=np.arange(30).reshape(5,6)\nb= -np.arange(8).reshape(2,2,2)\n\n\na.shape, b.shape\n\n((5, 6), (2, 2, 2))\n\n\n\nnp.append(a,b)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0, -1, -2, -3,\n       -4, -5, -6, -7])\n\n\n\nnp.concatenate([a.reshape(-1), b.reshape(-1)])\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0, -1, -2, -3,\n       -4, -5, -6, -7])\n\n\n- 기능2: concat\n\na=np.arange(2*3*4).reshape(2,3,4)\nb=-a\n\n\na.shape, b.shape, np.append(a,b, axis=0).shape   # 대괄호를 쓰지 않아도 됨\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\na.shape, b.shape, np.append(a,b, axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\na.shape, b.shape, np.append(a,b, axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n- concat과의 차이?\n\na=np.arange(2*3*4).reshape(2,3,4)\nb=-a\nc=2*a\n\n\nnp.concatenate([a,b,c],axis=0)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]])\n\n\n\n\nnote4: revel, flatten\n\na=np.arange(2*3*4).reshape(2,3,4)\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\na.reshape(-1) #디멘전 1차원으로\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.ravel()\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.flatten()\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\n\nnote 5: 기타 통계함수들\n- 평균, 중앙값, 표준편차, 분산\n\na=np.random.normal(loc=0, scale=2, size=(100,))\na\n\narray([-2.01759369e+00,  1.70831942e+00, -7.66284153e-01,  2.15177363e+00,\n        1.93917905e+00, -2.74073590e-01, -2.04642372e+00, -1.98463689e+00,\n        1.83815582e+00,  4.49207271e+00, -5.40520993e-03,  1.45933943e+00,\n       -1.88730370e+00,  2.53422937e+00, -1.43846951e+00, -2.69938884e-01,\n       -2.68912083e+00,  6.01230062e-01,  1.21155692e+00, -1.78259314e+00,\n        3.08941967e-01,  1.22338707e+00, -1.03232597e+00, -1.79667669e+00,\n        2.19458228e+00,  5.75514508e-01, -3.02570319e+00, -1.21868604e+00,\n       -9.60932070e-01,  1.11771254e+00, -5.34063250e-01, -2.68962004e+00,\n       -4.62864312e+00,  4.64113175e+00, -1.05051461e+00, -6.14152261e-01,\n       -1.56320062e+00,  1.18863285e-01,  1.71819177e+00,  5.04434396e-01,\n       -1.59021839e+00, -8.40274272e-01, -1.92903415e+00, -3.31025301e+00,\n       -5.44121948e+00,  1.71770231e+00,  1.78729433e+00,  1.04315736e+00,\n       -1.44847729e+00,  3.41070754e+00,  2.81655462e+00,  2.88886247e-01,\n        2.61248115e+00, -5.28811327e-01, -2.47391400e+00, -6.04240520e-02,\n       -2.86388739e+00,  2.50495252e+00,  5.34019240e+00,  8.27782165e-01,\n       -2.19088172e+00, -7.82626427e-01, -1.12548033e+00, -2.09109091e+00,\n       -2.06466297e+00, -5.36374068e-01, -3.65861892e+00, -1.42345921e+00,\n       -6.67080354e-01, -2.57114581e+00, -2.37356246e-01, -1.01485014e-02,\n       -3.65219208e+00,  1.30174327e+00,  9.43287089e-01, -5.41965726e-01,\n        1.89596089e+00, -3.26373304e+00, -1.66761926e+00, -1.14963754e+00,\n        4.34701574e-01, -4.87043020e-01, -5.10792557e-01, -9.05609502e-01,\n        3.51588424e-01, -9.72910253e-01, -1.11823422e+00, -8.02920775e-01,\n       -1.51091269e+00,  4.97543437e-01, -8.98957916e-03,  1.47902427e+00,\n       -8.44007525e-01, -5.03900902e-01,  1.26720080e+00, -5.25199252e+00,\n       -3.15857694e+00,  2.43006841e+00, -6.43759610e-01,  1.16296529e+00])\n\n\n\nnp.mean(a)\n\n-0.34664187661644286\n\n\n\nnp.median(a)\n\n-0.5352186588272133\n\n\n\nnp.std(a)\n\n2.0168674618593685\n\n\n\nnp.var(a)\n\n4.0677543587070515\n\n\n- corr matrix, cov matrix\n\nnp.random.seed(43052)\nx=np.random.randn(10000)\ny=np.random.randn(10000)*2\nz=np.random.randn(10000)*0.5\n\n\nnp.corrcoef([x,y,z]).round(2)\n\narray([[ 1.  , -0.01,  0.01],\n       [-0.01,  1.  ,  0.  ],\n       [ 0.01,  0.  ,  1.  ]])\n\n\n\nnp.cov([x,y,z]).round(2)\n\narray([[ 0.99, -0.02,  0.  ],\n       [-0.02,  4.06,  0.  ],\n       [ 0.  ,  0.  ,  0.25]])\n\n\n\n\nnote 6 : dtype\n- np.array는 항상 dtype이 있다.\n\na=np.array([1,2,3])\na\n\narray([1, 2, 3])\n\n\n\na.dtype\n\ndtype('int32')\n\n\n\na=np.array([1.0,2.0,3.0])\na\n\narray([1., 2., 3.])\n\n\n\na.dtype\n\ndtype('float64')\n\n\n\na=1\ntype(a)\n\nint\n\n\n\na=1.0\ntype(a)\n\nfloat\n\n\n- 같은 int라도 int16, int32, int64으로 나누어진다.\n\na= np.array([1,2,3], dtype=np.int64)\na\n\narray([1, 2, 3], dtype=int64)\n\n\n\na= np.array([1,2,3], dtype=np.int32)\na\n\narray([1, 2, 3])\n\n\n\na.dtype\n\ndtype('int32')\n\n\n- float도 float16, float32, float64가 있다.\n\na=np.array([1,2,3],dtype=np.float64) #64는 기본이라 표시가 안된당. \na\n\narray([1., 2., 3.])\n\n\n\na=np.array([1,2,3],dtype=np.float32)\na\n\narray([1., 2., 3.], dtype=float32)\n\n\n- 데이터타입은 아래와 같은 방법으로 변환시킬 수 있다.\n\na = np.array([1,2,3],dtype=np.int32)\na\n\narray([1, 2, 3])\n\n\n\na=a.astype(dtype=np.int64)\n\n\na.dtype\n\ndtype('int64')\n\n\n- 문자열의 경우\n\na= np.array(['a','b','c'])\na\n\narray(['a', 'b', 'c'], dtype='<U1')\n\n\n\na= np.array(['ab','b','c'])\na\n\narray(['ab', 'b', 'c'], dtype='<U2')\n\n\n\na= np.array(['absfd','b','c'])\na\n\narray(['absfd', 'b', 'c'], dtype='<U5')\n\n\n- 문자열+숫자혼합 => 문자열로 통일\n\na=np.array(['a',1])\na\n\narray(['a', '1'], dtype='<U11')\n\n\n\na=np.array(['a',1423])\na\n\narray(['a', '1423'], dtype='<U11')\n\n\n\na=np.array(['a',1.0])\na\n\narray(['a', '1.0'], dtype='<U32')\n\n\n- 숫자를 문자열로 전환:\n\na=np.array([1,2,3])\na\n\narray([1, 2, 3])\n\n\n\na.astype(np.str_)\n\n# 문자열 타입으로 바뀌는\n\narray(['1', '2', '3'], dtype='<U11')\n\n\n\n\nnote 7: 브로드캐스팅과 시간측정\n(예비학습)\n\nimport time\n\n\nt1=time.time()\n\n\nt2=time.time()\nt2-t1\n\n14.808058738708496\n\n\n예비학습끝\n(예제) x=[0,1,2,3,4]인 벡터가 있다고 하자. (i,j)의 원소는 (x[i]-x[j])**2를 의미하는 \\(5\\times5\\) 매트릭스를 구하라..\n(풀이)\n\nx=np.array(range(5))\nx\n\narray([0, 1, 2, 3, 4])\n\n\n\ndist= np.zeros([5,5])\ndist\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n\n\n\nfor i in range(5):\n    for j in range(5):\n        dist[i,j] = (x[i]-x[j])**2\n\n\ndist\n\narray([[ 0.,  1.,  4.,  9., 16.],\n       [ 1.,  0.,  1.,  4.,  9.],\n       [ 4.,  1.,  0.,  1.,  4.],\n       [ 9.,  4.,  1.,  0.,  1.],\n       [16.,  9.,  4.,  1.,  0.]])\n\n\n(풀이2)\n\nx1=x.reshape(5,1).astype(dtype=np.float64)\nx2=x.reshape(1,5).astype(dtype=np.float64)\n\n\nx1\n\narray([[0.],\n       [1.],\n       [2.],\n       [3.],\n       [4.]])\n\n\n\nx2\n\narray([[0., 1., 2., 3., 4.]])\n\n\n\nx1-x2\n\narray([[ 0., -1., -2., -3., -4.],\n       [ 1.,  0., -1., -2., -3.],\n       [ 2.,  1.,  0., -1., -2.],\n       [ 3.,  2.,  1.,  0., -1.],\n       [ 4.,  3.,  2.,  1.,  0.]])\n\n\n\n(i,j)th element = x[i] - x[j]\n\n\n(x1-x2)**2\n\narray([[ 0,  1,  4,  9, 16],\n       [ 1,  0,  1,  4,  9],\n       [ 4,  1,  0,  1,  4],\n       [ 9,  4,  1,  0,  1],\n       [16,  9,  4,  1,  0]], dtype=int32)\n\n\n\n\ny=x=np.array(range(10000))\n\n\ndist= np.zeros([10000,10000])\ndist\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n\nt1=time.time()\nfor i in range(10000):\n    for j in range(10000):\n        dist[i,j] = (y[i]-y[j])**2\nt2=time.time()\nt2-t1\n\n66.71002793312073\n\n\n\ny1=y.reshape(10000,1).astype(np.float64)\ny2=y.reshape(1,10000).astype(np.float64)\n\n\nt1=time.time()\ndist2=(y1-y2)**2\nt2=time.time()\nt2-t1\n\n0.426450252532959\n\n\n\ndist[:5,:5], dist2[:5,:5]\n\n(array([[ 0.,  1.,  4.,  9., 16.],\n        [ 1.,  0.,  1.,  4.,  9.],\n        [ 4.,  1.,  0.,  1.,  4.],\n        [ 9.,  4.,  1.,  0.,  1.],\n        [16.,  9.,  4.,  1.,  0.]]),\n array([[ 0.,  1.,  4.,  9., 16.],\n        [ 1.,  0.,  1.,  4.,  9.],\n        [ 4.,  1.,  0.,  1.,  4.],\n        [ 9.,  4.,  1.,  0.,  1.],\n        [16.,  9.,  4.,  1.,  0.]]))\n\n\n\n(dist-dist2).sum()\n\n0.0"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0418.html#matplotlib",
    "href": "posts/Python/2. Numpy/python 7_0418.html#matplotlib",
    "title": "파이썬 (0418) 7주차",
    "section": "matplotlib",
    "text": "matplotlib\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot\n- 기본그림\n\nplt.plot([1,2,3],[3,4,5],'.')\n\n\n\n\n\nplt.plot(np.array([1,2,3]),np.array([3,4,5]),'.')\n\n\n\n\n- 예제들\n\nt=np.linspace(-6,6,100)\nt\n\narray([-6.        , -5.87878788, -5.75757576, -5.63636364, -5.51515152,\n       -5.39393939, -5.27272727, -5.15151515, -5.03030303, -4.90909091,\n       -4.78787879, -4.66666667, -4.54545455, -4.42424242, -4.3030303 ,\n       -4.18181818, -4.06060606, -3.93939394, -3.81818182, -3.6969697 ,\n       -3.57575758, -3.45454545, -3.33333333, -3.21212121, -3.09090909,\n       -2.96969697, -2.84848485, -2.72727273, -2.60606061, -2.48484848,\n       -2.36363636, -2.24242424, -2.12121212, -2.        , -1.87878788,\n       -1.75757576, -1.63636364, -1.51515152, -1.39393939, -1.27272727,\n       -1.15151515, -1.03030303, -0.90909091, -0.78787879, -0.66666667,\n       -0.54545455, -0.42424242, -0.3030303 , -0.18181818, -0.06060606,\n        0.06060606,  0.18181818,  0.3030303 ,  0.42424242,  0.54545455,\n        0.66666667,  0.78787879,  0.90909091,  1.03030303,  1.15151515,\n        1.27272727,  1.39393939,  1.51515152,  1.63636364,  1.75757576,\n        1.87878788,  2.        ,  2.12121212,  2.24242424,  2.36363636,\n        2.48484848,  2.60606061,  2.72727273,  2.84848485,  2.96969697,\n        3.09090909,  3.21212121,  3.33333333,  3.45454545,  3.57575758,\n        3.6969697 ,  3.81818182,  3.93939394,  4.06060606,  4.18181818,\n        4.3030303 ,  4.42424242,  4.54545455,  4.66666667,  4.78787879,\n        4.90909091,  5.03030303,  5.15151515,  5.27272727,  5.39393939,\n        5.51515152,  5.63636364,  5.75757576,  5.87878788,  6.        ])\n\n\n\nx=np.sin(t)\ny=np.cos(t)\n\n\nplt.plot(t,x)\n\n\n\n\n\nplt.plot(t,y)\n\n\n\n\n\nplt.plot(t,x)\nplt.plot(t,y)\n\n\n\n\n\nplt.plot(t,x)\nplt.plot(t,y,'.')\n\n\n\n\n\nplt.plot(t,x)\nplt.plot(t,y,'--')\n\n\n\n\n\n\nplt.hist\n\nX=np.random.randn(1000)\n\n\nplt.hist(X)\n\n(array([  3.,  14.,  66., 157., 232., 245., 155.,  92.,  28.,   8.]),\n array([-3.29472542, -2.65210581, -2.0094862 , -1.36686658, -0.72424697,\n        -0.08162736,  0.56099226,  1.20361187,  1.84623148,  2.4888511 ,\n         3.13147071]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nY=np.random.rand(1000)\nplt.hist(Y)\n\n(array([ 98., 127., 107.,  87.,  83.,  86.,  85., 118., 110.,  99.]),\n array([0.00162071, 0.10140453, 0.20118836, 0.30097218, 0.40075601,\n        0.50053983, 0.60032366, 0.70010748, 0.79989131, 0.89967513,\n        0.99945896]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(X)\nplt.hist(Y)\n\n(array([ 98., 127., 107.,  87.,  83.,  86.,  85., 118., 110.,  99.]),\n array([0.00162071, 0.10140453, 0.20118836, 0.30097218, 0.40075601,\n        0.50053983, 0.60032366, 0.70010748, 0.79989131, 0.89967513,\n        0.99945896]),\n <BarContainer object of 10 artists>)"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 5_0406.html",
    "href": "posts/Python/2. Numpy/python 5_0406.html",
    "title": "파이썬 (0406) 5주차",
    "section": "",
    "text": "!pip install numpy \n\nCollecting numpy\n  Downloading numpy-1.24.1-cp39-cp39-win_amd64.whl (14.9 MB)\n     --------------------------------------- 14.9/14.9 MB 10.7 MB/s eta 0:00:00\nInstalling collected packages: numpy\nSuccessfully installed numpy-1.24.1\n\n\n\nimport numpy as np"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 5_0406.html#넘파이-공부-1단계",
    "href": "posts/Python/2. Numpy/python 5_0406.html#넘파이-공부-1단계",
    "title": "파이썬 (0406) 5주차",
    "section": "넘파이 공부 1단계",
    "text": "넘파이 공부 1단계\n\n선언\n\nlist([1,2,3])\n\n[1, 2, 3]\n\n\n\n[1,2,3]\n\n[1, 2, 3]\n\n\n\na=np.array([1,2,3])  # list만들고 ndarray화 시킴\nl=[1,2,3]\n\n\n\n기본연산 브로드캐스팅\n\na\n\narray([1, 2, 3])\n\n\n\nl\n\n[1, 2, 3]\n\n\n\na+1 ## [1,2,3] + 1 = [2,3,4]\n\narray([2, 3, 4])\n\n\n\nl+1\n\nTypeError: can only concatenate list (not \"int\") to list\n\n\n\na+np.array([-1,-2,-3])\n\narray([0, 0, 0])\n\n\n\na-a\n\narray([0, 0, 0])\n\n\n\nl-l  # 리스트는 안됨\n\nTypeError: unsupported operand type(s) for -: 'list' and 'list'\n\n\n\na*2\n\narray([2, 4, 6])\n\n\n\nl*2\n\n[1, 2, 3, 1, 2, 3]\n\n\n\na/2\n\narray([0.5, 1. , 1.5])\n\n\n\nl/2\n\nTypeError: unsupported operand type(s) for /: 'list' and 'int'\n\n\n\na**2\n\narray([1, 4, 9])\n\n\n\nl**2\n\nTypeError: unsupported operand type(s) for ** or pow(): 'list' and 'int'\n\n\n\na%2   # %2 = 2로 나눈 나머지 리턴\n\narray([1, 0, 1], dtype=int32)\n\n\n\nl%2\n\nTypeError: unsupported operand type(s) for %: 'list' and 'int'\n\n\n\n\n기타 수학연산 지원\n\nnp.sqrt(2)\n\n1.4142135623730951\n\n\n\nnp.sqrt(a), np.sqrt(l)\n\n(array([1.        , 1.41421356, 1.73205081]),\n array([1.        , 1.41421356, 1.73205081]))\n\n\n\nnp.log(a), np.log(l)\n\n(array([0.        , 0.69314718, 1.09861229]),\n array([0.        , 0.69314718, 1.09861229]))\n\n\n\nnp.exp(a), np.exp(l)\n\n(array([ 2.71828183,  7.3890561 , 20.08553692]),\n array([ 2.71828183,  7.3890561 , 20.08553692]))\n\n\n\nnp.sin(a), np.sin(l)\n\n(array([0.84147098, 0.90929743, 0.14112001]),\n array([0.84147098, 0.90929743, 0.14112001]))"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 5_0406.html#넘파이-공부-2단계",
    "href": "posts/Python/2. Numpy/python 5_0406.html#넘파이-공부-2단계",
    "title": "파이썬 (0406) 5주차",
    "section": "넘파이 공부 2단계",
    "text": "넘파이 공부 2단계\n\n인덱싱 1차원\n- 선언\n\nl=[11,22,33,44,55,66]\na=np.array(l)\n\n- 인덱스로 접근\n\nl[0], l[1], l[2], l[3], l[4], l[5]\n\n(11, 22, 33, 44, 55, 66)\n\n\n\na[0], a[1], a[2], a[3], a[4], a[5]\n\n(11, 22, 33, 44, 55, 66)\n\n\n- : 이용 (슬라이싱)\n\nl[2:4] # index 2에서 시작, index 4는 포함하지 않음\n\n[33, 44]\n\n\n\na[2:4]\n\narray([33, 44])\n\n\n- 점수배열에 의한 익덱싱\n\na\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\n  a[[0,2,4]]  # index=0, index=2, index=4 에 해당하는 원소를 뽑고 싶다 -> 가능\n\narray([11, 33, 55])\n\n\n\n l[[0,2,4]]    # 리스트는 불가능\n\nTypeError: list indices must be integers or slices, not list\n\n\n- 부울값에 의한 인덱싱\n\na\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\na[[True, True, False, True, False, False]]\n\narray([11, 22, 44])\n\n\n응용하면?\n\na<33\n\narray([ True,  True, False, False, False, False])\n\n\n\na[[ True,  True, False, False, False, False]]\n\narray([11, 22])\n\n\n\na[a<33]\n\narray([11, 22])\n\n\n리스트는 불가능\n\nl<33\n\nTypeError: '<' not supported between instances of 'list' and 'int'\n\n\n\nl[[True, True, False, True, False, False]]\n\nTypeError: list indices must be integers or slices, not list\n\n\n\n\n인덱싱 2차원\n- 중첩리스트와 2차원 np.array 선언\n\nA = [[1,2,3,4],[-1,-2,-3,-4],[5,6,7,8],[-5,-6,-7,-8]]\nA2 = np.array(A)\n\n\nA2\n\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4],\n       [ 5,  6,  7,  8],\n       [-5, -6, -7, -8]])\n\n\n\nA\n\n[[1, 2, 3, 4], [-1, -2, -3, -4], [5, 6, 7, 8], [-5, -6, -7, -8]]\n\n\n- A의 원소 인덱싱\n\nA[0][0] # A의 (1,1)의 원소\n\n1\n\n\n\nA[1][2] # A의 (2,3)의 원소\n\n-3\n\n\n\nA[-1][0] # A의 (4,1)의 원소\n\n-5\n\n\n- A2의 원소 인덱싱\n\nA2[0][0]\n\n1\n\n\n\nA2[1][2] # A2의 (2,3)의 원소\n\n-3\n\n\n\nA2[-1][0] # A2의 (4,1)의 원소\n\n-5\n\n\n- A2에서만 되는 기술 (넘파이에서 제시하는 신기술, R에서는 기본적으로 쓰던것, 이중list는 불가능)\n\nA2[0,0]\n\n1\n\n\n\nA2[1,2] # A2의 (2,3)의 원소\n\n-3\n\n\n\nA2[-1,0] # A2의 (4,1)의 원소\n\n-5\n\n\n- 정수배열에 의한 인덱싱 & 슬라이싱!\n\nA2\n\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4],\n       [ 5,  6,  7,  8],\n       [-5, -6, -7, -8]])\n\n\n\nA2[0,0:2]   # 1행 1열, 1행 2열\n\narray([1, 2])\n\n\n\nA2[0,:]  # 1행\n\narray([1, 2, 3, 4])\n\n\n\nA2[0]  # 1행\n\narray([1, 2, 3, 4])\n\n\n\nA2[[0,2],:]   # 1행, 3행\n\narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n\n\n\nA2[[0,2]]   # 1행, 3행\n\narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n\n\n\nA2[:,0] # 1열\n\narray([ 1, -1,  5, -5])\n\n\n\nA2[:,[0]] # 1열\n\narray([[ 1],\n       [-1],\n       [ 5],\n       [-5]])\n\n\n\nA2[:,[0,2]] # 1열, 3열\n\narray([[ 1,  3],\n       [-1, -3],\n       [ 5,  7],\n       [-5, -7]])\n\n\n\nA2[0:2,[0,2]]  # 1행-2행 / 1열-3열\n\narray([[ 1,  3],\n       [-1, -3]])\n\n\n\n\n1차원 배열의 선언\n- 리스트나 튜플을 선언하고 형변환\n\nnp.array((1,2,3)) # 튜플->넘파이어레이\n\narray([1, 2, 3])\n\n\n\nnp.array([1,2,3]) # 리스트->넘파이어레이\n\narray([1, 2, 3])\n\n\n- range()를 이용해서 선언하고 형변환\n\nnp.array(range(10))  # range(10)->넘파이어레이\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n- np.zeros, np.ones\n\nnp.zeros(3)\n\narray([0., 0., 0.])\n\n\n\nnp.ones(4)\n\narray([1., 1., 1., 1.])\n\n\n- np.linspace\n\nnp.linspace(0,1,12)   # 0부터 1까지 12개로 쪼개기   (양끝점 모두 포함)\n\narray([0.        , 0.09090909, 0.18181818, 0.27272727, 0.36363636,\n       0.45454545, 0.54545455, 0.63636364, 0.72727273, 0.81818182,\n       0.90909091, 1.        ])\n\n\n\nlen(np.linspace(0,1,12))\n\n12\n\n\n- np.arange\n\nnp.arange(5)  #np.array(range(5))\n\narray([0, 1, 2, 3, 4])\n\n\n\nnp.arange(1,6)   #np.array(range(1,6))\n\narray([1, 2, 3, 4, 5])\n\n\n\n\nreshape\n- reshape: ndarray의 특수한 기능\n\na=np.array([11,22,33,44,55,66])\na  #길이가 6인 벡터\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\ntype(a)\n\nnumpy.ndarray\n\n\n\na.reshape\n\n<function ndarray.reshape>\n\n\n\na.reshape(2,3)  # (2,3) matrix라고 생각해도 무방\n\narray([[11, 22, 33],\n       [44, 55, 66]])\n\n\n\na.reshape(5,2)\n\nValueError: cannot reshape array of size 6 into shape (5,2)\n\n\nnote: reshape은 a자체를 변홧키는 것은 아님\n\na  # reshape은 a자체는 변화하지 않음\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\nb=a.reshape(2,3)  # a를 reshape한 결과를 b에 저장\nb\n\narray([[11, 22, 33],\n       [44, 55, 66]])\n\n\n\n a  # a는 여전히 그대로 있음\n\narray([11, 22, 33, 44, 55, 66])\n\n\n- 다시 b를 a처럼 바꾸고 싶다.\n\nb\n\narray([[11, 22, 33],\n       [44, 55, 66]])\n\n\n\nb.reshape(6) # b는 (2,3) matrix, 그런데 이것을 길이가 6인 벡터로 만들고 싶다.\n\narray([11, 22, 33, 44, 55, 66])\n\n\n\na.shape   # 길이가 1인 튜플\n\n(6,)\n\n\n\nb.shape   # 길이가 2인 튜플이니까 2차원 \n\n(2, 3)\n\n\n- reshape with -1\n\na=np.arange(24)  #np.array(range(24))\na\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\na.reshape(2,?) # 에러..\n\nSyntaxError: invalid syntax (2529973538.py, line 1)\n\n\n\na.reshape(2,-1)\n\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(3,-1)\n\narray([[ 0,  1,  2,  3,  4,  5,  6,  7],\n       [ 8,  9, 10, 11, 12, 13, 14, 15],\n       [16, 17, 18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(4,-1)\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23]])\n\n\n\na.reshape(7,-1)  # 나눠떨어지지 않으니까.. \n\nValueError: cannot reshape array of size 24 into shape (7,newaxis)\n\n\n\nb=a.reshape(12,-1)\nb\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 4,  5],\n       [ 6,  7],\n       [ 8,  9],\n       [10, 11],\n       [12, 13],\n       [14, 15],\n       [16, 17],\n       [18, 19],\n       [20, 21],\n       [22, 23]])\n\n\n\nb.reshape(24) # b를 다시 길이가 24인 벡터로 만들고 싶다.\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\nb.reshape(-1) # b를 다시 길이가 24인 벡터로 만들고 싶다.\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23])\n\n\n\n\n2차원 배열의 선언\n\n\nnp.zeros((3,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((3,3))\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n\n\n\nnp.eye(3) \n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.diag([1,2,3,-1])\n\narray([[ 1,  0,  0,  0],\n       [ 0,  2,  0,  0],\n       [ 0,  0,  3,  0],\n       [ 0,  0,  0, -1]])\n\n\n\n\n랜덤으로 생성\n\nnp.random.randn(10)  # 표준정규분포에서 10개를 뽑음\n\narray([-1.62694735, -0.46057632,  0.9092888 , -0.52150285, -0.0409467 ,\n        0.98561001,  1.87613924, -2.08870029,  0.28577046, -0.15794105])\n\n\n\nnp.random.rand(10)  # 0~1 사이에서 10개를 뽑음\n\narray([0.7377278 , 0.61091057, 0.17571601, 0.29298532, 0.90149596,\n       0.84002052, 0.50700681, 0.40217981, 0.30557984, 0.34392417])\n\n\n\nnp.random.randn(4).reshape(2,2)  # 표준정규분포에서 4개를 뽑고 (2,2) nparray로 형태변환\n\narray([[0.50093512, 0.74336071],\n       [0.91296027, 0.04033486]])\n\n\n\nnp.random.rand(4).reshape(2,2)  # 0~1에서 4개를 뽑고 (2,2) nparray로 형태변환\n\narray([[0.30484011, 0.57731961],\n       [0.30645542, 0.2189475 ]])\n\n\n\n\n행렬\n\nA=np.array(range(4)).reshape(2,2)\nA\n\narray([[0, 1],\n       [2, 3]])\n\n\n\nA.T #전치행렬\n\narray([[0, 2],\n       [1, 3]])\n\n\n\nnp.linalg.inv(A)   # 역행렬\n\narray([[-1.5,  0.5],\n       [ 1. ,  0. ]])\n\n\n\nA @ np.linalg.inv(A)  # 단위행렬   # @는 행렬곱을 수행\n\narray([[1., 0.],\n       [0., 1.]])"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 5_0406.html#숙제",
    "href": "posts/Python/2. Numpy/python 5_0406.html#숙제",
    "title": "파이썬 (0406) 5주차",
    "section": "숙제",
    "text": "숙제\n\nA=np.array(range(6))\nA # 길이가 6인 벡터\n\narray([0, 1, 2, 3, 4, 5])\n\n\n위와 같이 길이가 6인 벡터 A를 (2,3) ndarray로 변경\n\nA.reshape(2,3)\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\nlen(A.reshape(2,3))\n\n2"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 5_0404.html",
    "href": "posts/Python/2. Numpy/python 5_0404.html",
    "title": "파이썬 (0404) 5주차",
    "section": "",
    "text": "소스코드 관리(모듈, 패키지, 라이브러리)\nintro\n- 현재 파이썬은 길이가 2인 벡터의 덧셈을 지원하지 않음\n\na=[1,2]\nb=[3,4]\na+b\n\n[1, 2, 3, 4]\n\n\n- 아래와 같은 기능을 구현하는 함수를 만들고 싶음\n[1,2],[3,4] -> [4,6]\n- 구현\n\ndef vec2_add(a,b):\n    return [a[0]+b[0], a[1]+b[1]]\n\n- test\n\na=[1,2]\nb=[3,4]\n\n\nvec2_add(a,b)\n\n[4, 6]\n\n\nmake myfuns.py\n- 생각해보니까 vec2_add는 내가 앞으로 자주 쓸 기능임\n- 그런데 현재 사용방법으로는 내가 노트북파일을 새로 만들때마다 def vec2_add(a,b):와 같은 함수를 매번 정의해줘야 하는 불편함이 있다.\n해결1\n- 자주 사용하는 함수를 myfuns.py에 저장한다. (4주차 수업)\n# myfuns.py\ndef vec2_add(a,b):\n    return [a[0]+b[0], a[1]+b[1]]\n%run myfuns를 실행\n준비:“00” -> 커널재시작\n\n# \n\n\n%run myfuns\n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n해결 2\n- 자주 사용하는 함수를 myfuns.py에 저장한다. (4주차 수업)\n# myfuns.py\ndef vec2_add(a,b):\n    return [a[0]+b[0], a[1]+b[1]]\n- import myfuns를 이용\n(준비) “00” -> 커널 재시작\n\nimport myfuns\n\n\na=[1,2]\nb=[3,4]\nmyfuns.vec2_add(a,b)\n\n[4, 6]\n\n\n\nimport 기본\n-사용방법1\n준비: “00” -> 커널재시작\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nmyfuns.vec2_add의 의미: myfuns.py라는 파일안에 vec2_add라는 함수가 있음. 그것을 실행하라.\n.의 의미: 상위, 하위의 개념!\n\n(주의) 아래와 같이 사용 불가능 하다.\n\nvec2_add([1,2],[3,4])  #myfuns가 import가 된거지 vec2Add가 import가 된 것이 아님.\n\nNameError: name 'vec2_add' is not defined\n\n\n- 사용방법2\n준비: “00” -> 커널재시작\n\nfrom myfuns import vec2_add\n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nmyfuns.vec2_add([1,2],[3,4])  # myfuns안의 vec2_add만 임포트했지 myfuns자체를 임포트 한것은 아님..\n\nNameError: name 'myfuns' is not defined\n\n\n- 사용방법3\n준비: “00” -> 커널재시작\n\nimport myfuns\nfrom myfuns import vec2_add\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_sub([1,2],[3,4])   # vec2_sub는 import하지 않았기 때문에 오류남.. \n\nNameError: name 'vec2_sub' is not defined\n\n\n\nmyfuns.vec2_sub([1,2],[3,4])\n\n[-2, -2]\n\n\n- 사용방법4\n준비: “00” -> 커널재시작\n\nfrom myfuns import vec2_add, vec2_sub\n\n\nvec2_add([1,2],[3,4]), vec2_sub([1,2],[3,4])\n\n([4, 6], [-2, -2])\n\n\n- 사용방법5\n준비: “00” -> 커널재시작\n\nfrom myfuns import *   # *는 all의 의미\n\n\nvec2_add([1,2],[3,4]), vec2_sub([1,2],[3,4])\n\n([4, 6], [-2, -2])\n\n\n- 사용방법6\n준비: “00” -> 커널재시작\n\nimport myfuns as mf \n\n\nmf.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nmf.vec2_sub([1,2],[3,4])\n\n[-2, -2]\n\n\n(오히려 아래는 실행불가능)\n\nmyfuns.vec2_add([1,2],[3,4])\n\nNameError: name 'myfuns' is not defined\n\n\n- 잘못된 사용방법1\n준비: “00” -> 커널재시작\n\nimport myfuns as mf\nfrom mf import vec2_add\n\nModuleNotFoundError: No module named 'mf'\n\n\n- 사용방법 7\n준비: “00” -> 커널재시작\n\nimport myfuns as mf\nfrom myfuns import vec2_add as add\n\n\nmf.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_add([1,2],[3,4])   # 위에서 vec2_add를 add로 부르기로 했음. 그래서 이건 안뎀 \n\nNameError: name 'vec2_add' is not defined\n\n\n\nadd([1,2],[3,4])\n\n[4, 6]\n\n\n\n\n도움말 작성기능\n- mf란 무엇인가?\n준비: “00” -> 커널재시작\n\nimport myfuns as mf\n\n\nmf\n\n<module 'myfuns' from 'C:\\\\Users\\\\koinu\\\\python2022\\\\myfuns.py'>\n\n\n\nmf?\n\n\nType:        module\nString form: <module 'myfuns' from 'C:\\\\Users\\\\koinu\\\\python2022\\\\myfuns.py'>\nFile:        c:\\users\\koinu\\python2022\\myfuns.py\nDocstring:   <no docstring>\n\n\n\n\ntype(mf)\n\nmodule\n\n\n\nmf의 타입은 모듈이라고 나옴, 현재 단계에서는 무엇인지 알기 어려움..\n\n- Docstring의 내용을 채울 수 있을까?\n준비1: myfuns.py의 파일을 수정한다. (큰따옴표 ““” 세개)\n준비2: “00”->커널재시작\n\nimport myfuns as mf\n\n\nmf?\n\n\nType:        module\nString form: <module 'myfuns' from 'C:\\\\Users\\\\koinu\\\\python2022\\\\myfuns.py'>\nFile:        c:\\users\\koinu\\python2022\\myfuns.py\nDocstring:   이것은 길이가 2인 벡터이 합 혹은 차를 구하는 모듈입니다.\n\n\n\n\n\n주의점\n- myfuns.py는 최초 한번만 import된다.\n준비: “00” -> 커널재시작\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\nmyfuns.py파일을 열고 함수를 바꾸자.\n\"\"\"이것은 길이가 2인 벡터이 합 혹은 차를 구하는 모듈입니다.\"\"\"\n\ndef vec2_add(a,b):\n    print(\"이것은 myfuns.py에 정의된 함수입니다.\")\n    return [a[0]+b[0], a[1]+b[1]]\n\n\ndef vec2_sub(a,b):\n    return [a[0]-b[0], a[1]-b[1]]\n다시 myfuns를 로드하고 위를 실행하여 보자\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n바뀐내용이 적용되지 않는다.\n커널을 다시 시작하고 임포트해보자.\n“00” -> 커널재시작\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n이것은 myfuns.py에 정의된 함수입니다.\n\n\n[4, 6]\n\n\n- myfuns.py는 주피너노트북파일과 같은 폴더내에 존재해야 한다.\n준비1: “00”->커널재시작\n준비2: myfuns.py 을 복사하여 다른 폴더로 이동. 예를들면 IP0403폴더를 만들고 그 폴더안에 myfuns2.py파일을 만들자.\n\nimport myfuns  # 주피터노트북과 같은 폴더에 있는 myfuns는 잘 로드되지만\n\n\nimport myfuns2 # 주피터노트북과 다른 폴더에 있는 myfuns2는 그렇지 않다.\n\nModuleNotFoundError: No module named 'myfuns2'\n\n\n- IP0403 폴더에 있는 myfuns2.py를 실행하기 위해서는 아래와 같이 할 수 있다.\n준비: “00” -> 커널재시작\n\nfrom IP0403 import myfuns2\n\n\nmyfuns2.vec2_add([1,2],[3,4])\n\n이것은 myfuns2.py에 정의된 함수입니다.\n\n\n[4, 6]\n\n\n- 아래도 가능하다.\n준비: “00” -> 커널재시작\n\nfrom IP0403.myfuns2 import vec2_add as add\n\n\nadd([1,2],[3,4])\n\n이것은 myfuns2.py에 정의된 함수입니다.\n\n\n[4, 6]\n\n\n참고로 아래는 모두 정의되지 않음\n\nIP0403.myfuns2.vec2_add([1,2],[3,4])\n\nNameError: name 'IP0403' is not defined\n\n\n\nmyfuns2.vec2_add([1,2],[3,4])\n\nNameError: name 'myfuns2' is not defined\n\n\n\nvec2_add([1,2],[3,4])\n\nNameError: name 'vec2_add' is not defined\n\n\n\n\nimport 고급\n\n폴더와 함께 사용할시\n- 언뜻 생각하면 아래가 가능할 것 같다.\nimport IP0403\nIP0403.myfuns.vec2_add([1,2],[3,4])\n- 하지만 불가능\n준비: “00” -> 커널재시작\n\nimport IP0403\n\n여기까지는 됨..\n\nIP0403.myfuns2.add([1,2],[3,4])\n\nAttributeError: module 'IP0403' has no attribute 'myfuns2'\n\n\n\n여기서 불가능하다.\n\n- (암기) IP0403 폴더안에 __init__.py라는 파일을 만들고 내용에 아래와 같이 쓰면 가능하다.\n# ./IP0403/__init__.py\nform. import myfuns2\n준비1: 위의 지침을 따른다.\n준비2: “00” -> 커널재시작\n\nimport IP0403\n\n\nIP0403.myfuns2.vec2_add([1,2],[3,4])  \n\n이것은 myfuns2.py에 정의된 함수입니다.\n\n\n[4, 6]\n\n\n컴퓨터 상식\n\n. : 현재폴더를 의미\n.. : 상위폴더를 의미\n./myfuns.py : 현재폴더안에 있는 myfuns.py를 의미\n./IP0403/myfuns2.py : 현재폴더안에 IP0403폴더안의 myfuns2.py를 의미\n../myfuns.py : 현재폴더보다 한단계 상위폴더에 있는 myfuns.py를 의미\ncd ./IP0403 : 현재 폴더안에 있는 IP0403폴더로 이동해라. (cd IP0403으로 줄여쓸 수 있음)\ncd .. 현재 폴더보다 한단계 상위폴더로 이동해라.\n\n따라서 from . import myfuns2는 현재 폴더에서 myfuns2를 찾아서 임포트 하라는 의미로 해석가능\n- 의미상으로 보면 아래가 실해아능할 것 같은데 불가능하다.\n\n# import myfuns.py\nfrom . import myfuns\n\nImportError: attempted relative import with no known parent package\n\n\n\n\n\nslite-packages (실습금지)\nhttps://guebin.github.io/IP2022/2022/04/03/(5%EC%A3%BC%EC%B0%A8)-4%EC%9B%942%EC%9D%BC.html#site-packages-(%EC%8B%A4%EC%8A%B5%EA%B8%88%EC%A7%80)\n\n\n모듈, 패키지, 라이브러리?\n- 모듈의 개념은 아까 살펴본 것과 같다. (import를 하여 생기게 되는 오브젝트)\n- 교수님들: 모듈이 모이면 패키지라고 부른다. 그리고 라이브러리는 패키지보다 큰 개념이다.\n-그런데 구분이 모호하다.\n\nimport numpy as np   # 오잉 왜 안되지... \n\nModuleNotFoundError: No module named 'numpy'\n\n\n\ntype(np)\n\nNameError: name 'np' is not defined\n\n\n- python 에서 numpy의 type은 모듈\n- 그런데 numpy package라고 검색하면 검색이 된다.\n- 심지어 numpy library 라고 해도 검색가능\n- 교수님 생각: 넘파이모듈, 넘파이패키지, 넘파이라이브러리 다 맞는 말임\n(숙제)\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[5,6])\n\n이것은 myfuns.py에 정의된 함수입니다.\n\n\n[6, 8]\n\n\n\nmyfuns?\n\n\nType:        module\nString form: <module 'myfuns' from 'C:\\\\Users\\\\koinu\\\\python2022\\\\myfuns.py'>\nFile:        c:\\users\\koinu\\python2022\\myfuns.py\nDocstring:   이것은 길이가 2인 벡터이 합 혹은 차를 구하는 모듈입니다. 202250926"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0413.html",
    "href": "posts/Python/2. Numpy/python 7_0413.html",
    "title": "파이썬 (0413) 7주차",
    "section": "",
    "text": "import numpy as np"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0413.html#numpy공부-5단계-랜덤모듈",
    "href": "posts/Python/2. Numpy/python 7_0413.html#numpy공부-5단계-랜덤모듈",
    "title": "파이썬 (0413) 7주차",
    "section": "numpy공부 5단계 : 랜덤모듈",
    "text": "numpy공부 5단계 : 랜덤모듈\n\nnp.random.rand()\n- 0~1사이에서 10개의 난수 생성\n\nnp.random.rand(10)\n\narray([0.30133684, 0.33047977, 0.37682904, 0.34945581, 0.88634262,\n       0.272207  , 0.75103749, 0.55871507, 0.12304257, 0.88020941])\n\n\n- 0~2사이에서 10개의 난수 생성\n\nnp.random.rand(10)*2\n\narray([1.85950286, 0.90618509, 0.3153    , 0.47472741, 1.60545103,\n       1.07072774, 1.10650141, 0.77505785, 1.19933414, 1.76222208])\n\n\n- 1~2사이에서 10개의 난수 생성\n\nnp.random.rand(10)+1\n\narray([1.01747795, 1.52789889, 1.29223002, 1.53147587, 1.13455031,\n       1.51668185, 1.2430438 , 1.59676278, 1.8731811 , 1.36113831])\n\n\n- 1~3사이에서 10개의 난수 생성\n\nnp.random.rand(10)*2+1    # 1~3\n\narray([2.79324839, 2.37177079, 1.12638737, 1.71767497, 2.95057073,\n       1.23158048, 2.56688411, 2.94392262, 1.32675882, 2.29817471])\n\n\n\n\nnp.random.randn()\n- N(0,1) 에서 10개 추출\n\nnp.random.randn(10) # 표준정규분포에서 10개의 샘플 추출\n\narray([ 1.895967  , -0.26215342,  0.87906492,  0.45616171,  1.66244424,\n        0.72458419,  0.31057676, -0.55909889,  0.47656554,  0.35143513])\n\n\n- N(1,1)에서 10개 추출\n\nnp.random.randn(10)+1\n\narray([ 1.11007188, -0.44321876,  0.04904333, -0.10478302,  0.13301967,\n       -0.49468263,  1.7751611 , -0.84760291,  0.40840343,  0.638133  ])\n\n\n- N(0,4)에서 10개 추출 (평균이 0이고 분산이 4인 분포)\n\nnp.random.randn(10)*2\n\narray([-1.14364925,  2.60415043, -1.65488974, -0.59463897,  0.97607708,\n        2.33979589,  3.49290763, -1.50749403, -1.41447157,  0.45852112])\n\n\n- N(3,4)에서 10개 추출\n\nnp.random.randn(10)*2+3\n\narray([ 4.736406  ,  2.35419865,  2.8265146 ,  0.26470966, -0.4240817 ,\n        1.00836216,  6.23531314,  3.75134991,  0.60427655, -0.13645246])\n\n\n\n\nnp.random.randint()\n- [0,7)의 범위에서 하나의 정수를 랜덤으로 생성\n\nnp.random.randint(7)   #[0,7)의 범위에서 하나의 정수 생성\n\n3\n\n\n- [0,7)의 범위에서 20개의 정수를 랜덤으로 생성\n\nnp.random.randint(7,size=(20,))  # [0,7)의 범위에서 20개의 정수 생성\n\narray([2, 5, 5, 5, 2, 4, 3, 4, 1, 4, 1, 2, 3, 2, 4, 2, 2, 6, 1, 2])\n\n\n- [0,7)의 범우에서 (5,5) shape으로 정수를 랜덤으로 생성\n\nnp.random.randint(7,size=(5,5))  \n\narray([[1, 6, 2, 5, 0],\n       [3, 3, 3, 1, 0],\n       [4, 0, 2, 5, 6],\n       [1, 0, 1, 2, 0],\n       [6, 6, 5, 1, 3]])\n\n\n- 위와 같은 코드를 아래와 같이 구현가능\n\nnp.random.randint(low=7,size=(2,2))  # [0,7)의 범위에서 20개의 정수 생성\n\narray([[2, 4],\n       [6, 4]])\n\n\n- [10,20)의 범위에서 (5,5) shape 정수를 랜덤으로 생성\n\nnp.random.randint(low=10, high=20,size=(5,5))  \n\narray([[14, 19, 17, 14, 17],\n       [16, 11, 14, 17, 16],\n       [12, 11, 18, 17, 14],\n       [11, 15, 14, 18, 11],\n       [13, 19, 10, 17, 14]])\n\n\n- 의문: np.random.randint(low=7,size=(5,5)) 가 좀 이상하다. 사실 np.random.randint(high=7,size=(5,5))가 되어야 맞지 않는가?\n-> 저도 그렇게 생각하긴 하는데요, 구현이 이렇게 되어있습니다. 도움말 확인!\nReturn random integers from the \"discrete uniform\" distribution of the specified dtype in the \"half-open\" interval [`low`, `high`). If `high` is None (the default), then results are from [0, `low`).\n\n\nnp.random.choice()\n- ver1\n\nnp.random.choice(5,20)  # [0,5)에서 20개를 뽑음, 중복허용\n\narray([3, 2, 0, 3, 3, 3, 0, 0, 2, 2, 0, 0, 0, 1, 3, 1, 3, 2, 0, 0])\n\n\n\nnp.random.randint(5, size=(20,))\n\narray([3, 2, 2, 3, 4, 1, 0, 1, 4, 1, 3, 2, 2, 2, 4, 3, 2, 4, 2, 3])\n\n\n- ver2\n\nnp.random.choice([0,1,2,3],20) # [0,1,2,3] 에서 20개를 뽑음 , 중복허용\n\narray([2, 0, 1, 3, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 3, 3, 1])\n\n\n\nnp.random.choice([\"apple\",\"orange\",\"banana\"],20)\n\narray(['orange', 'banana', 'banana', 'orange', 'banana', 'orange',\n       'banana', 'orange', 'apple', 'orange', 'orange', 'apple', 'apple',\n       'orange', 'apple', 'apple', 'orange', 'orange', 'apple', 'apple'],\n      dtype='<U6')\n\n\n\nnp.random.choice([\"apple\",\"orange\",\"banana\"],2,replace=False) # 중복허용 X \n\narray(['apple', 'orange'], dtype='<U6')\n\n\n\n\n통계분포\n\nnp.random.binomial(n=10, p=0.1, size=(5,)) #X1, ..., X5 ~ B(10,0.2)\n\narray([1, 0, 2, 0, 2])\n\n\n\nnp.random.normal(loc=10,scale=2,size=(5,)) # X1, ..., X5 ~ N(10,4) \n\narray([8.5617943 , 8.9716337 , 7.90650741, 6.59782362, 7.90620931])\n\n\n\nnp.radom.randn(5)*2 + 10와 같은코드\n\n\nnp.random.uniform(low=2,high=4,size=(5,)) # X1, ..., X5 ~ U(2,4)  #균일분포\n\narray([2.49501161, 3.10469251, 3.89920656, 2.33160764, 2.28406983])\n\n\n\nnp.random.rand(5)*2+2와 같은 코드\n\n\nnp.random.poisson(lam=5,size=(5,)) # X1,...,X5 ~ Poi(5) \n\narray([5, 5, 7, 4, 6])"
  },
  {
    "objectID": "posts/Python/2. Numpy/python 7_0413.html#nupmy공부-6단계-기타-유용한-기본기능들",
    "href": "posts/Python/2. Numpy/python 7_0413.html#nupmy공부-6단계-기타-유용한-기본기능들",
    "title": "파이썬 (0413) 7주차",
    "section": "nupmy공부 6단계: 기타 유용한 기본기능들",
    "text": "nupmy공부 6단계: 기타 유용한 기본기능들\n\nnp.where, np.argwhere\n\na=np.array([0,0,0,1,0])\na\n\narray([0, 0, 0, 1, 0])\n\n\n\nnp.where(a==1) # 조건 a==1을 만족하는 인덱스를 출력하라\n\n(array([3], dtype=int64),)\n\n\n\nnp.argwhere(a==1)\n\narray([[3]], dtype=int64)\n\n\n\nnp.argwhere(a==0)\n\narray([[0],\n       [1],\n       [2],\n       [4]], dtype=int64)\n\n\n- 2차원\n\nnp.random.seed(43052)\na=np.random.randn(12).reshape(3,4)\na\n\narray([[ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368],\n       [ 0.23778744,  0.35595116, -1.66307542, -1.38277318],\n       [-1.92684484, -1.4862163 ,  0.00692519, -0.03488725]])\n\n\n\nnp.where(a<0) # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미\n\n(array([1, 1, 2, 2, 2], dtype=int64), array([2, 3, 0, 1, 3], dtype=int64))\n\n\n\nnp.argwhere(a<0)  # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미\n\narray([[1, 2],\n       [1, 3],\n       [2, 0],\n       [2, 1],\n       [2, 3]], dtype=int64)\n\n\n\na[np.where(a<0)]  # 조건을 만족하는 인덱스가 모두 출력=> 1차원 array로 출력\n\narray([-1.66307542, -1.38277318, -1.92684484, -1.4862163 , -0.03488725])\n\n\n\na[np.argwhere(a<0)]  # 출력불가능\n\nIndexError: index 3 is out of bounds for axis 0 with size 3\n\n\n\na[np.argwhere(a<0)[0][0],np.argwhere(a<0)[0][1]] # 어거지로 출력할수는 있음 \n\n-1.6630754187023522\n\n\n- np.where의 특수기능\n\nnp.random.seed(43052)\na=np.random.randn(12).reshape(3,4)\na\n\narray([[ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368],\n       [ 0.23778744,  0.35595116, -1.66307542, -1.38277318],\n       [-1.92684484, -1.4862163 ,  0.00692519, -0.03488725]])\n\n\n\nnp.where(a<0,0,a)   #a<0을 체크=> 조건에 맞으면 0, 조건에 안맞으면 a 출력\n\narray([[0.38342049, 1.0841745 , 1.14277825, 0.30789368],\n       [0.23778744, 0.35595116, 0.        , 0.        ],\n       [0.        , 0.        , 0.00692519, 0.        ]])\n\n\n\nnp.where(a<0,0,1) # #a<0을 체크=> 조건에 맞으면 0, 조건에 안맞으면 1 출력\n\narray([[1, 1, 1, 1],\n       [1, 1, 0, 0],\n       [0, 0, 1, 0]])\n\n\n- 요약 - np.where : 인덱스의 좌표를 읽는 가독성은 떨어짐. 그러나 조건에 맞는 원소를 출력하거나 조건에 맞는 특수기능을 처리하는 목적으로 좋은 함수 - np.argwhere : 인덱스의 좌표를 읽는 가독성은 좋은 편임. 그러나 조건에 맞는 원소를 출력하거나 처리하는 기능은 떨어짐\n\n\n인덱싱고급\n- 원래 a는 2d array\n\na=np.arange(12).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n- 경우 1: 인덱싱 결과가 1d array로 나올 수 있음\n\na[0,:] # 인덱싱의 결과 축의 갯수가 바뀐다. 2d array -> 1d array\n\narray([0, 1, 2, 3])\n\n\n- 경우2: 인덱싱 결과가 2d array로 나올 수 있음\n\na[[0,1],:] # 이것은 축의 숫자가 유지됨 2d array-> 2d array\n\narray([[0, 1, 2, 3],\n       [4, 5, 6, 7]])\n\n\n- 경우1의 상황에서도 축의 갯수를 유지하면서 인덱싱하려면?\n\na[[0],:] # 인덱싱의 결과 축의 갯수가 유지된다. 2d array->2d array\n\narray([[0, 1, 2, 3]])\n\n\n- 미묘한 차이를 이해할 것\n\na[:,0], a[:,[0]]\n\n(array([0, 4, 8]),\n array([[0],\n        [4],\n        [8]]))\n\n\n\n\nnp.ix_\n- 아래의 인덱싱을 비교하자\n\na=np.arange(12).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\na[0:2,0:2]\n\narray([[0, 1],\n       [4, 5]])\n\n\n\na[[0,1],0:2]\n\narray([[0, 1],\n       [4, 5]])\n\n\n\na[0:2,[0,1]]\n\narray([[0, 1],\n       [4, 5]])\n\n\n- 언뜻 생각하면 위의 결과와 a[[0,1],[0,1]의 결과가 동일할 것 같다.\n\na[[0,1],[0,1]]\n\narray([0, 5])\n\n\n\n실제로는 [a[0,0],a[1,1]]이 array로 나옴\n\n- 사실 np.where에서 이미 관찰하였음\n\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\nnp.where(a % 5 ==0)\n\n(array([0, 1, 2], dtype=int64), array([0, 1, 2], dtype=int64))\n\n\n\na[np.where(a % 5 ==0)]\n\narray([ 0,  5, 10])\n\n\n\na[[0, 1, 2],[0, 1, 2]]\n\narray([ 0,  5, 10])\n\n\n- a[[0,1],[0,1]]이 a[0:2,0:2]를 의미하게 하려면 아래와 같이 하면 된다.\n\na[np.ix_([0,1],[0,1])] # 유용해보이지만 생각보다 잘 쓰이는건 아님 \n\narray([[0, 1],\n       [4, 5]])\n\n\n(숙제)\n\nnp.random.uniform(low=1.3,high=1.7,size=(10,))\n\narray([1.65411132, 1.42531485, 1.54567744, 1.44735207, 1.33217747,\n       1.48856969, 1.47329978, 1.38976795, 1.30469965, 1.66634909])\n\n\n위와 같은코드를 np.random.rand()를 이용하여 구현하라."
  },
  {
    "objectID": "posts/Python/2. Numpy/python 6_0411.html",
    "href": "posts/Python/2. Numpy/python 6_0411.html",
    "title": "파이썬 (0411) 6주차",
    "section": "",
    "text": "imports\n\nimport numpy as np\n\n\n\nnumpy공부 3단계: 차원\n\n2차원 배열과 연립 1차 방정식\n- 아래의 연립방정식 고려\n\\(\\begin{cases} y+z+w = 3 \\\\ x+z+w = 3 \\\\ x+y+w = 3 \\\\ x+y+z = 3 \\end{cases}\\)\n- 행렬표현?\n\\(\\begin{bmatrix} 0 & 1 & 1 & 1 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 \\\\ 1 & 1 & 1 & 0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\\\ w \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 3 \\\\ 3 \\\\ 3 \\end{bmatrix}\\)\n- 풀이\n\nA = np.array([[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,0]])\nA\n\narray([[0, 1, 1, 1],\n       [1, 0, 1, 1],\n       [1, 1, 0, 1],\n       [1, 1, 1, 0]])\n\n\n\nb= np.array([3,3,3,3]).reshape(4,1)\nb\n\narray([[3],\n       [3],\n       [3],\n       [3]])\n\n\n\nnp.linalg.inv(A) @ b \n\narray([[1.],\n       [1.],\n       [1.],\n       [1.]])\n\n\n- 다른풀이\nb를 아래와 같이 만들어도 된다.\n\nb=np.array([3,3,3,3])\nb\n\narray([3, 3, 3, 3])\n\n\n\nb.shape # b.shape은 길이가 1인 튜플로 나온다. \n\n(4,)\n\n\n\nnp.linalg.inv(A) @ b \n\narray([1., 1., 1., 1.])\n\n\n\n\n@의 유연성\n- 엄밀하게는 아래의 행렬곱이 가능하다. - (2,2) @ (2,1) => (2,1) - (1,2) @ (2,2) => (1,2)\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(2,1) \nA@b\n\narray([[ 5],\n       [11]])\n\n\n\nA.shape, b.shape, (A@b).shape\n\n((2, 2), (2, 1), (2, 1))\n\n\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(1,2) \nb@A \n\narray([[ 7, 10]])\n\n\n\nA.shape, b.shape, (b@A).shape\n\n((2, 2), (1, 2), (1, 2))\n\n\n- 당연히 아래는 성립안한다.\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(2,1) \nb@A\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)\n\n\n\nA = np.array([1,2,3,4]).reshape(2,2) \nb = np.array([1,2]).reshape(1,2) \nA@b\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)\n\n\n- 아래는 어떨까? 계산가능할까? \\(\\to\\) 모두 계산가능! - (2,) @ (2,2) = (2,) - (2,2) @ (2,) = (2,)\n\nA = np.array([1,2,3,4]).reshape(2,2)\nb = np.array([1,2]) \nA@b\n\narray([ 5, 11])\n\n\n\nA.shape, b.shape, (A@b).shape \n\n((2, 2), (2,), (2,))\n\n\n\nb를 마치 (2,1)처럼 해석하여 행렬곱하고 결과는 다시 (2,) 로 만든것 같다.\n\n\nb@A\n\narray([ 7, 10])\n\n\n\nA.shape, b.shape, (b@A).shape \n\n((2, 2), (2,), (2,))\n\n\n\n이때는 \\(b\\)를 마치 (1,2)처럼 해석하여 행렬곱하고 결과는 다시 (2,)로 만든것 같다.\n\n- 아래는 어떠할까?\n\nb1 = np.array([1,2,3,4]) \nb2 = np.array([1,2,3,4]) \nb1@b2 \n\n30\n\n\n\nb1.shape, b2.shape, (b1@b2).shape \n\n((4,), (4,), ())\n\n\n\n(1,4) @ (4,1) = (1,1) 로 생각\n\n- 즉 위는 아래와 같이 해석하고 행렬곱한것과 결과가 같다.\n\nb1 = np.array([1,2,3,4]).reshape(1,4) \nb2 = np.array([1,2,3,4]).reshape(4,1) \nb1@b2 \n\narray([[30]])\n\n\n\nb1.shape, b2.shape, (b1@b2).shape \n\n((1, 4), (4, 1), (1, 1))\n\n\n- 때로는 (4,1) @ (1,4)와 같은 계산결과를 얻고 싶을 수 있는데 이때는 차원을 명시해야함\n\nb1 = np.array([1,2,3,4]).reshape(4,1) \nb2 = np.array([1,2,3,4]).reshape(1,4) \nb1@b2 \n\narray([[ 1,  2,  3,  4],\n       [ 2,  4,  6,  8],\n       [ 3,  6,  9, 12],\n       [ 4,  8, 12, 16]])\n\n\n\n\n차원\n- 넘파이배열의 차원은 .shape 으로 확인가능\n- 아래는 모두 미묘하게 다르다.\n\na=np.array(3.14) # 스칼라, 0d array \na, a.shape\n\n(array(3.14), ())\n\n\n\na=np.array([3.14]) # 벡터, 1d array \na, a.shape\n\n(array([3.14]), (1,))\n\n\n\na=np.array([[3.14]]) # 매트릭스, 2d array \na, a.shape\n\n(array([[3.14]]), (1, 1))\n\n\n\na=np.array([[[3.14]]]) # 텐서, 3d array \na, a.shape\n\n(array([[[3.14]]]), (1, 1, 1))\n\n\n\n\n\nnumpy공부 4단계: 축\n\nnp.concatenate\n- 기본예제\n\na=np.array([1,2]) \nb=-a\n\n\nnp.concatenate([a,b]) \n\narray([ 1,  2, -1, -2])\n\n\n- 응용\n\na=np.array([1,2])\nb=-a \nc=np.array([3,4,5])\n\n\nnp.concatenate([a,b,c])\n\narray([ 1,  2, -1, -2,  3,  4,  5])\n\n\n\n여기까진 딱히 칸캐터네이트의 메리트가 없어보임\n리스트였다면 a+b+c 하면 되는 기능이니까?\n\n- 2d array에 적용해보자.\n\na=np.arange(4).reshape(2,2) \nb=-a\n\n\nnp.concatenate([a,b]) \n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n- 옆으로 붙일려면?\n\nnp.concatenate([a,b],axis=1)\n\narray([[ 0,  1,  0, -1],\n       [ 2,  3, -2, -3]])\n\n\n- 위의 코드에서 axis=1 이 뭐지? axis=0,2 등을 치면 결과가 어떻게 될까?\n\nnp.concatenate([a,b],axis=0)\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n이건 그냥 np.concatenate([a,b])와 같다.\nnp.concatenate([a,b])는 np.concatenate([a,b],axis=0)의 생략버전이군?\n\n\nnp.concatenate([a,b],axis=2)\n\nAxisError: axis 2 is out of bounds for array of dimension 2\n\n\n\n이런건 없다.\n\n- axis의 의미가 뭔지 궁금함. 좀 더 예제를 살펴보자.\n\na=np.array(range(2*3*4)).reshape(2,3,4)\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\nb=-a\nb\n\narray([[[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=0) \n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=1) \n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=2) \n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\n이번에는 axis=2까지 된다?\n\n\nnp.concatenate([a,b],axis=3) \n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\naxis=3까지는 안된다?\n\n- 뭔가 나름의 방식으로 합쳐지는데 원리가 뭘까?\n(분석1) np.concatenate([a,b],axis=0)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\na.shape, b.shape, np.concatenate([a,b],axis=0).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n첫번째차원이 바뀌었다 => 첫번째 축이 바뀌었다 => axis=0 (파이썬은 0부터 시작하니까!)\n\n(분석2) np.concatenate([a,b],axis=1)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\na.shape, b.shape, np.concatenate([a,b],axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n두번째차원이 바뀌었다 => 두번째 축이 바뀌었다 => axis=1\n\n(분석3) np.concatenate([a,b],axis=2)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\na.shape, b.shape, np.concatenate([a,b],axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n세번째차원이 바뀌었다 => 세번째 축이 바뀌었다 => axis=2\n\n(분석4) np.concatenate([a,b],axis=3)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\na.shape, b.shape, np.concatenate([a,b],axis=3).shape\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\n네번째차원이 없다 => 네번째 축이 없다 => axis=3으로 하면 에러가 난다.\n\n(보너스1)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\nnp.concatenate([a,b],axis=-1)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b],axis=-1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n마지막 차원이 바뀌었다 => 마지막 축이 바뀌었다 => axis = -1\n\n(보너스2)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\nnp.concatenate([a,b],axis=-2)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b],axis=-2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n마지막에서 2번째 차원이 바뀌었다 => 마지막에서 2번째 축이 바뀌었다 => axis = -2\n\n(보너스3)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\nnp.concatenate([a,b],axis=-3)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b],axis=-3).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n마지막에서 3번째 차원이 바뀌었다 => 마지막에서 3번째 축이 바뀌었다 => axis = -3\n\n(보너스3)\n\na=np.array(range(2*3*4)).reshape(2,3,4) \nb=-a \n\n\nnp.concatenate([a,b],axis=-4)\n\nAxisError: axis -4 is out of bounds for array of dimension 3\n\n\n\n마지막에서 4번째 차원은 없다 => 마지막에서 4번째 축이 없다 => axis = -4는 에러가 난다.\n\n- 0차원은 축이 없으므로 concatenate를 쓸 수 없다.\n\na= np.array(1)\nb= np.array(-1) \n\n\na.shape, b.shape\n\n((), ())\n\n\n\nnp.concatenate([a,b])\n\nValueError: zero-dimensional arrays cannot be concatenated\n\n\n- 꼭 a,b가 같은 차원일 필요는 없다.\n\na=np.array(range(4)).reshape(2,2) \nb=np.array(range(2)).reshape(2,1)  \n\n\nnp.concatenate([a,b],axis=1)\n\narray([[0, 1, 0],\n       [2, 3, 1]])\n\n\n\na.shape, b.shape, np.concatenate([a,b],axis=1).shape\n\n((2, 2), (2, 1), (2, 3))\n\n\n\n\nnp.stack\n- 혹시 아래가 가능할까?\n\n(3,) 결합 (3,) => (3,2)\n\n\na=np.array([1,2,3])\nb=-a\n\n\na,b\n\n(array([1, 2, 3]), array([-1, -2, -3]))\n\n\n\nnp.concatenate([a,b],axis=1)\n\nAxisError: axis 1 is out of bounds for array of dimension 1\n\n\n\n불가능\n\n- 아래와 같이 하면 해결가능\n\na=np.array([1,2,3]).reshape(3,1) \nb=-a\n\n\na,b\n\n(array([[1],\n        [2],\n        [3]]),\n array([[-1],\n        [-2],\n        [-3]]))\n\n\n\nnp.concatenate([a,b],axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n\n분석: (3) (3) => (3,1) (3,1) => (3,1) concat (3,1)\n\n- 위의 과정을 줄여서 아래와 같이 할 수 있다.\n\na=np.array([1,2,3])\nb=-a\n\n\nnp.stack([a,b],axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n- 아래도 가능\n\nnp.stack([a,b],axis=0)\n\narray([[ 1,  2,  3],\n       [-1, -2, -3]])\n\n\n- 분석해보고 외우자\n(분석1)\n\na=np.array([1,2,3])\nb=-a\n\n\na.shape, b.shape, np.stack([a,b],axis=0).shape\n\n((3,), (3,), (2, 3))\n\n\n\n\n\n=> 첫 위치에 축을 추가 (axis=0) => (1,3) (1,3) => (2,3)\n\n\n\n(분석2)\n\na=np.array([1,2,3])\nb=-a\n\n\na.shape, b.shape, np.stack([a,b],axis=1).shape\n\n((3,), (3,), (3, 2))\n\n\n\n\n\n=> 두 위치에 축을 추가 (axis=1) => (3,1) (3,1) => (3,2)\n\n\n\n- 고차원예제\n\na=np.arange(3*4*5).reshape(3,4,5) \nb=-a\n\n\na.shape, b.shape\n\n((3, 4, 5), (3, 4, 5))\n\n\n\nnp.stack([a,b],axis=0).shape # (3,4,5) => (1,3,4,5) // 첫 위치에 축이 추가되고 스택 \n\n(2, 3, 4, 5)\n\n\n\nnp.stack([a,b],axis=1).shape # (3,4,5) => (3,1,4,5) // 두번째 위치에 축이 추가되고 스택 \n\n(3, 2, 4, 5)\n\n\n\nnp.stack([a,b],axis=2).shape # (3,4,5) => (3,4,1,5) // 세번째 위치에 축이 추가되고 스택 \n\n(3, 4, 2, 5)\n\n\n\nnp.stack([a,b],axis=3).shape # (3,4,5) => (3,4,5,1) // 네번째 위치에 축이 추가되고 스택 \n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b],axis=-1).shape # axis=-1 <=> axis=3 \n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b],axis=-2).shape # axis=-2 <=> axis=2\n\n(3, 4, 2, 5)\n\n\nnp.concatenate 는 축의 총 갯수를 유지하면서 결합, np.stack은 축의 갯수를 하나 증가시키면서 결합\n\n\nsum\n- 1차원\n\na = np.array([1,2,3]) \na\n\narray([1, 2, 3])\n\n\n\na.sum()\n\n6\n\n\n\na.sum(axis=0)\n\n6\n\n\n- 2차원\n\na=np.array(range(6)).reshape(2,3)\na\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\na.sum() # 전체합\n\n15\n\n\n\na.sum(axis=0) \n\narray([3, 5, 7])\n\n\n\na.sum(axis=1) \n\narray([ 3, 12])\n\n\n- 2차원 결과 분석\n\na.shape, a.sum(axis=0).shape\n\n((2, 3), (3,))\n\n\n\n첫번째 축이 삭제됨 => axis=0\n\n\na.shape, a.sum(axis=1).shape\n\n((2, 3), (2,))\n\n\n\n두번째 축이 삭제됨 => axis=1\n\n- 연습\n\na=np.array(range(10)).reshape(5,2) \na\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\n\n(문제1) 1열의 합, 2열의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => (2,) 로 나와야 한다. (그럼 첫번째 축이 삭제되어야 하네?)\n\na.sum(axis=0)\n\narray([20, 25])\n\n\n(문제2) 1행의 합, 2행의 합, … , 5행의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => (5,)로 나와야 한다. (그럼 두번째 축이 삭제되어야 하네?)\n\na.sum(axis=1)\n\narray([ 1,  5,  9, 13, 17])\n\n\n(문제3) a의 모든원소의 합을 계산하고 싶다면?\n(풀이) 차원이 (5,2) => () 로 나와야 한다. (첫번째축, 두번째축이 모두 삭제되어야 하네?)\n\na.sum(axis=(0,1))\n\n45\n\n\n\na.sum() # 즉 a.sum(axis=(0,1))이 디폴트값임 \n\n45\n\n\n\n\nmean, std, max, min, prod\n- 모두 sum이랑 유사한 논리\n\na=np.array(range(10)).reshape(5,2)\na\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\n\n\na.mean(axis=0), a.std(axis=0), a.max(axis=0), a.min(axis=0), a.prod(axis=0)\n\n(array([4., 5.]),\n array([2.82842712, 2.82842712]),\n array([8, 9]),\n array([0, 1]),\n array([  0, 945]))\n\n\n\na.mean(axis=1), a.std(axis=1), a.max(axis=1), a.min(axis=1), a.prod(axis=1)\n\n(array([0.5, 2.5, 4.5, 6.5, 8.5]),\n array([0.5, 0.5, 0.5, 0.5, 0.5]),\n array([1, 3, 5, 7, 9]),\n array([0, 2, 4, 6, 8]),\n array([ 0,  6, 20, 42, 72]))\n\n\n- 참고로 std는 분포를 n으로 나눈다.\n\na=np.array([1,2,3,4])\na.std()\n\n1.118033988749895\n\n\n\nnp.sqrt(sum((a-a.mean())**2)/4)\n\n1.118033988749895\n\n\n- 분모를 n-1로 나눌려면?\n\na=np.array([1,2,3,4])\na.std(ddof=1)\n\n1.2909944487358056\n\n\n\nnp.sqrt(sum((a-a.mean())**2)/3)\n\n1.2909944487358056\n\n\n\n\nargmax, argmin\n- 1차원\n\na= np.array([1,-2,3,10,4])\na\n\narray([ 1, -2,  3, 10,  4])\n\n\n\na.argmax() # 가장 큰 값이 위치한 원소의 인덱스를 리턴 \n\n3\n\n\n\na.argmin() # 가장 작은 값이 위치한 원소의 인덱스를 리턴 \n\n1\n\n\n- 2차원\n\nnp.random.seed(43052)\na=np.random.randn(4*5).reshape(4,5)\na\n\narray([[ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368,  0.23778744],\n       [ 0.35595116, -1.66307542, -1.38277318, -1.92684484, -1.4862163 ],\n       [ 0.00692519, -0.03488725, -0.34357323,  0.70895648, -1.55100608],\n       [ 1.34565583, -0.05654272, -0.83017342, -1.46395159, -0.35459593]])\n\n\n\na.argmin(), a.min()\n\n(8, -1.9268448358915802)\n\n\n\na.argmax(), a.max()\n\n(15, 1.3456558341738827)\n\n\n\na.argmin(axis=0), a.argmin(axis=1)\n\n(array([2, 1, 1, 1, 2]), array([4, 3, 4, 3]))\n\n\n\na.argmax(axis=0), a.argmax(axis=1)\n\n(array([3, 0, 0, 2, 0]), array([2, 0, 3, 0]))\n\n\n\n\ncumsum, cumprod\n- 1차원\n\na=np.array([1,2,3,4])\na\n\narray([1, 2, 3, 4])\n\n\n\na.cumsum()\n\narray([ 1,  3,  6, 10])\n\n\n\na.cumprod()\n\narray([ 1,  2,  6, 24])\n\n\n- 2차원\n\na=np.array(range(3*4)).reshape(3,4)\na\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\na.cumsum(axis=0), a.cumsum(axis=1)\n\n(array([[ 0,  1,  2,  3],\n        [ 4,  6,  8, 10],\n        [12, 15, 18, 21]]),\n array([[ 0,  1,  3,  6],\n        [ 4,  9, 15, 22],\n        [ 8, 17, 27, 38]]))\n\n\n\na.cumprod(axis=0), a.cumprod(axis=1)\n\n(array([[  0,   1,   2,   3],\n        [  0,   5,  12,  21],\n        [  0,  45, 120, 231]]),\n array([[   0,    0,    0,    0],\n        [   4,   20,  120,  840],\n        [   8,   72,  720, 7920]]))\n\n\n\n\ndiff\n- 1차차분\n\na=np.array([1,2,4,6,7])\na\n\narray([1, 2, 4, 6, 7])\n\n\n\nnp.diff(a)\n\narray([1, 2, 2, 1])\n\n\n- 2차차분\n\nnp.diff(np.diff(a))\n\narray([ 1,  0, -1])\n\n\n- prepend, append\n\na=np.array([1,2,4,6,7])\na\n\narray([1, 2, 4, 6, 7])\n\n\n\nnp.diff(a,prepend=100)\n#np.diff(np.array([100]+a.tolist()) )\n\narray([-99,   1,   2,   2,   1])\n\n\n\n[1,2,4,6,7] -> [100,1,2,3,4,6] -> np.diff\n\n\nnp.diff(a,append=100)\n#np.diff(np.array(a.tolist()+[100]) )\n\narray([ 1,  2,  2,  1, 93])\n\n\n(예제) a=[1,2,4,6,7]의 앞에 1을 추가하여 차분하라.\n\nnp.diff(a,prepend=a[0])\n#np.diff(a,prepend=1)\n\narray([0, 1, 2, 2, 1])\n\n\n(예제) a=[1,2,4,6,7]의 뒤에 7을 추가하여 차분하라.\n\nnp.diff(a,append=a[-1])\n#np.diff(a,append=7)\n\narray([1, 2, 2, 1, 0])\n\n\n- 2차원 array의 차분\n\na=np.arange(24).reshape(4,6)\na\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23]])\n\n\n\nnp.diff(a,axis=0) \n\narray([[6, 6, 6, 6, 6, 6],\n       [6, 6, 6, 6, 6, 6],\n       [6, 6, 6, 6, 6, 6]])\n\n\n\nnp.diff(a,axis=1) \n\narray([[1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1]])\n\n\n(숙제)\n\na=np.arange(24).reshape(4,6)\na\n\narray([[ 0,  1,  2,  3,  4,  5],\n       [ 6,  7,  8,  9, 10, 11],\n       [12, 13, 14, 15, 16, 17],\n       [18, 19, 20, 21, 22, 23]])\n\n\n에서 axis=1 옵션으로 np.diff를 적용하여 (4,5) array를 만들고 왼쪽열에 1이 포함된 column을 추가하여 최종 결과가 아래와 같이 되도록 하라.\narray([[1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1]])"
  },
  {
    "objectID": "posts/est/2. 데이터 분석 준비하기.html",
    "href": "posts/est/2. 데이터 분석 준비하기.html",
    "title": "3: 데이터 분석 준비하기",
    "section": "",
    "text": "Zen of Python\n\n파이썬의 철학이 잘 담겨있는 Zen of Python을 출력해 봅니다. (아래의 실습을 통해 확인해 보세요!)\n\n\nimport this # improt를 통해 파이썬의 라이브러리나 패키지를 가져올 수 있음\n\n\n\nboolean\n\n파이썬에서는 명시적인 것이 암시적인 것보다 낫다라는 철학이 있습니다.\nTrue나 False는 0과 1로도 표현할 수 있으나 명시적으로 표현하기 위해 True와 False를 사용합니다.\n\n\nTrue\n\nTrue\n\n\n\nFalse\n\nFalse\n\n\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue == \"1\" # True와 문자 1과는 다르다! 1따옴포=문자열\n\nFalse\n\n\n\nTrue != \"1\"\n\nTrue\n\n\n\nFalse == \"0\"\n\nFalse\n\n\n\nFalse != \"0\"\n\nTrue\n\n\n\nTrue and True\n\nTrue\n\n\n\nTrue and False\n\nFalse\n\n\n\nTrue or False #or연산자: 하나만 true여도 true\n\nTrue\n\n\n\n\nnumber and String\n\n숫자 1과 문자 “1”은 다르다! 데이터 타입 “type” 사용\n\n\n\"1\"\n\n'1'\n\n\n\ntype(1)\n\nint\n\n\n\ntype(\"1\")\n\nstr\n\n\n\n\nStrings and Lists\n\ntil = \"Today I learned\"\ntil\n\n'Today I learned'\n\n\n\ntil.lower() #다 소문자로 변경\n\n'today i learned'\n\n\n\ntil.upper() #대문자 변경\n\n'TODAY I LEARNED'\n\n\n\n# 비어있는 리스트 만들기. lang라는 변수에 담기\nlang = []\nlang\n\n[]\n\n\n\nlang.append(\"python\")\nlang.append(\"java\")\nlang.append(\"c\")\nlang\n\n['python', 'java', 'c']\n\n\n\nlang[0] #lnag이라는 변수에 담겨있는 언어명을 인덱싱을 통해 가져오기\n\n'python'\n\n\n\nlang[1]\n\n'java'\n\n\n\nlang[-1]\n\n'c'\n\n\n\n\nControl Flow\n\n제어문-조건문, 반복문\n\n\nfor i in lang:\n    print(i)\n\npython\njava\nc\n\n\n\nfor i in lang:\n    if i == \"python\":\n        print(\"python\")\n    else:\n            print(\"기타\") # indent를 맞춰줘야 한다.\n\npython\n기타\n기타\n\n\n\n# 특정 횟수만큼 반복문 실행\ncount = len(lang)\nfor i in range(count):\n    print(lang[i]) \n\npython\njava\nc\n\n\n\n# 짝수일때 python을 홀수일때 java출력\nfor i in range(1,10): # `1에서 9까지\n    if i % 2 == 0: #짝수만 출력\n        print(\"python\")\n    else:\n        print(\"java\")\n\njava\npython\njava\npython\njava\npython\njava\npython\njava\n\n\n\n# enumerate를 사용하면 인덱스 번호와 원소를 같이 가져온다\nfor i, val in enumerate(lang):\n    print(i,val)\n\n0 python\n1 java\n2 c\n\n\n\n문자열\n\naddress = \" 경기도 성남시 분당구 불정로 6 NAVER 그린팩토리 16층 \"\naddress\n\n' 경기도 성남시 분당구 불정로 6 NAVER 그린팩토리 16층 '\n\n\n\n# 앞뒤 공백 제거 \n# 데이터 전처리 시 주로 사용\naddress = address.strip() \naddress\n\n'경기도 성남시 분당구 불정로 6 NAVER 그린팩토리 16층'\n\n\n\n# 문자열 길이\nlen(address)\n\n33\n\n\n\n# 공백으로 문자열 분리\naddress_list = address.split()\naddress_list\n\n['경기도', '성남시', '분당구', '불정로', '6', 'NAVER', '그린팩토리', '16층']\n\n\n\n\n슬라이싱, startswith, in 을 통해 문자열에 경기아 있는지 확인하기\n\naddress[:2]\n\n'경기'\n\n\n\naddress.startswith(\"경기\")\n\nTrue\n\n\n\n\"경기\" in address \n\nTrue\n\n\n\n\n리스트\n\n문자열에서 쓰는 방법과 비슷한 메소드 등을 사용\n\n\naddress_list[2]\n\n'분당구'\n\n\n\nstreet = address_list[3]\nstreet\n\n'불정로'\n\n\n\naddress_list[-1]\n\n'16층'\n\n\n\n# \"\".join(리스트)를 사용하면 리스트를 공백 문자열로 연결 한다\n\"-\".join(address_list)\n\n'경기도-성남시-분당구-불정로-6-NAVER-그린팩토리-16층'\n\n\n\n\"경기\" in address_list\n\nFalse\n\n\n\n\"경기도\" in address_list\n\nTrue\n\n\n\n\"분당구\" in address_list\n\nTrue\n\n\n\n# pandas (패널 데이터 앤 시스템의 약자)\n# 수식과 그래프를 통해 계산 및 시각화하는 도구\n# 엑셀을 사용 했을때보다 대용량 데이터를 쓸수 있고 소스 코드 파일만 데이터 프레임 로드를 해서 소스코드들을 재사용 할 수 있다.\n# 월별 작업과 같은 반복작업.. \n# 아래에 첨부된 10 minutes to pandas를 한 번씩 실행해보시면 판다스의 전반적인 것을 익힐 수 있습니다.\n\n\n# 추가로 같이 첨부된 Pandas Cheat Sheet도 추천드립니다.\n\n\nimport pandas as pd\n\n\npd.DataFrame?\n\n\n# 공식문서 (도움말) 활용하기\npd.DataFrame()\n# shift+tab+tab\n\n\n\n\n\n  \n    \n      \n    \n  \n  \n  \n\n\n\n\n\n\nDataFrame\n\ndf = pd.DataFrame(\n{\"a\" : [4, 5, 6, 6],\n\"b\" : [7, 8, 9, 9],\n\"c\" : [10, 11, 12, 12]},\nindex = [1, 2, 3, 4])\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      1\n      4\n      7\n      10\n    \n    \n      2\n      5\n      8\n      11\n    \n    \n      3\n      6\n      9\n      12\n    \n    \n      4\n      6\n      9\n      12\n    \n  \n\n\n\n\n\n\nSeries\n\n# 1차원 자료구조.. (벡터!)\ndf[\"a\"]\n# 출력된 형태: series 데이터\n\n1    4\n2    5\n3    6\nName: a, dtype: int64\n\n\n\n# dataframe으로 변경 (2차원 자료구조) (행렬!)\ndf[[\"a\"]]\n\n\n\n\n\n  \n    \n      \n      a\n    \n  \n  \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n    \n      3\n      6\n    \n  \n\n\n\n\n\n\nSubset\n\ndf[df[\"a\"] > 4]\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      2\n      5\n      8\n      11\n    \n    \n      3\n      6\n      9\n      12\n    \n  \n\n\n\n\n\ndf[\"a\"]\n\n1    4\n2    5\n3    6\nName: a, dtype: int64\n\n\n\ndf[[\"a\",\"b\"]]\n# df[\"a\",\"b\"] 이렇게 쓰면 오류가 난다. 대괄호를 또 해주기 \n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      1\n      4\n      7\n    \n    \n      2\n      5\n      8\n    \n    \n      3\n      6\n      9\n    \n  \n\n\n\n\n\n\nSummarize Data\n\ndf[\"a\"].value_counts()\n# 빈도수 계산\n\n6    2\n4    1\n5    1\nName: a, dtype: int64\n\n\n\nlen(df)\n\n4\n\n\n\n\nReahaping\n\nsort_values, drop\n\n\ndf.sort_values(\"a\",ascending=False)\n#ascending= 역수 \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      3\n      6\n      9\n      12\n    \n    \n      4\n      6\n      9\n      12\n    \n    \n      2\n      5\n      8\n      11\n    \n    \n      1\n      4\n      7\n      10\n    \n  \n\n\n\n\n\ndf = df.drop([\"c\"], axis=1)\n# 기본 설정은 axis=0 으로 되어있으므로 axis를 바꿔줘야 함 \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      1\n      4\n      7\n    \n    \n      2\n      5\n      8\n    \n    \n      3\n      6\n      9\n    \n    \n      4\n      6\n      9\n    \n  \n\n\n\n\n\n\nGroup Data\n\nGroupby, pivot_table\n\n\n# \"a\" 컬럼값을 Groupby하여 \"b\"의 컬럼값 구하기\ndf.groupby([\"a\"])[\"b\"].mean()\n\na\n4    7.0\n5    8.0\n6    9.0\nName: b, dtype: float64\n\n\n\ndf.groupby([\"a\"])[\"b\"].agg([\"mean\", \"sum\", \"count\"])\n\n\n\n\n\n  \n    \n      \n      mean\n      sum\n      count\n    \n    \n      a\n      \n      \n      \n    \n  \n  \n    \n      4\n      7.0\n      7\n      1\n    \n    \n      5\n      8.0\n      8\n      1\n    \n    \n      6\n      9.0\n      18\n      2\n    \n  \n\n\n\n\n\ndf.groupby([\"a\"])[\"b\"].describe() #요약하는거\n\n\n\n\n\n  \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      a\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      4\n      1.0\n      7.0\n      NaN\n      7.0\n      7.0\n      7.0\n      7.0\n      7.0\n    \n    \n      5\n      1.0\n      8.0\n      NaN\n      8.0\n      8.0\n      8.0\n      8.0\n      8.0\n    \n    \n      6\n      2.0\n      9.0\n      0.0\n      9.0\n      9.0\n      9.0\n      9.0\n      9.0\n    \n  \n\n\n\n\n\npd.pivot_table(df, index=\"a\", values=\"b\", aggfunc=\"sum\")\n\n\n\n\n\n  \n    \n      \n      b\n    \n    \n      a\n      \n    \n  \n  \n    \n      4\n      7\n    \n    \n      5\n      8\n    \n    \n      6\n      18\n    \n  \n\n\n\n\n\n\nPlotting\n\ndf.plot.bar()\n\n<AxesSubplot:>\n\n\n\n\n\n\n!conda env list\n\n# conda environments:\n#\nbase                     /home/koinup4/anaconda3\npy37                  *  /home/koinup4/anaconda3/envs/py37\npy39                     /home/koinup4/anaconda3/envs/py39"
  },
  {
    "objectID": "posts/est/0. jupyter basic.html",
    "href": "posts/est/0. jupyter basic.html",
    "title": "1: 주피터 노트북 사용법",
    "section": "",
    "text": "주피터 노트북 사용법\n\nShift+Enter 키를 누르면 셀이 실행되고 커서가 다음셀로 이동\nEnter 키 누르면 편집상태로 돌아온다.\nESC 키를 누르고\n\na 키를 누르면 위에 셀이 추가 된다.\nb 키를 누르면 아래에 셀이 추가 된다.\ndd 키를 누르면 셀이 삭제 된다.\nm 키를 누르면 문서 셀로 변경 된다.\ny 키를 누르면 코드 셀로 변경 된다.\n\n단축키는 h 버튼 눌러서 확인이 가능하다\n\n\n마크다운(Markdown)이란?\n\n코드와 함께 문서화를 할 수 있다.\n문서화를 할 수 있는 문법\n\n여러 줄의 설명을\n줄바꿈으로 쓰고자 할 때\n\nprint(\"Hello World\")\n\nHello World\n\n\n\na=1\nb=2\na+b\n\n3\n\n\n\nfor i in range(10000000):\n    print(i)"
  },
  {
    "objectID": "posts/est/3. 서울 종합병원 분포 확인하기.html",
    "href": "posts/est/3. 서울 종합병원 분포 확인하기.html",
    "title": "4: 서울 종합병원 분포 확인하기",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n\n\n\n\n# ctrl(cmd) + / : 주석처리를 풀었다 했다 \n\nimport matplotlib.pyplot as plt\n # window의 한글 폰트 설정\nplt.rc('font',family='Malgun Gothic') #윈도우의 경우\n\n# plt.rc('font', family='AppleGothic') #맥의 경우\n\nplt.rc('axes', unicode_minus=False) #마이너스 폰트 깨지는 것 대비\n\n# 그래프가 노트북 안에 보이게 하기 위해\n%matplotlib inline\n\n\nfrom IPython.display import set_matplotlib_formats\n#폰트가 선명하게 보이기 위해\n\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n!move \"C:\\Users\\user\\Downloads\\소상공인시장진흥공단_상가업소정보_의료기관_201909.csv\"\n\n지정된 파일을 찾을 수 없습니다.\n\n\n\ndf = pd.read_csv(\"data/소상공인시장진흥공단_상가업소정보_의료기관_201909.csv\", low_memory=False)\n# low_memory=False로 설정이 되어야 한다. 안그럼 오류남.\ndf.shape # 데이터의 행과 열 크기를 찍어볼 수 있따\n\n(91335, 39)\n\n\n\n\n\n\nhead, tail을 통해 데이터를 미리 볼수 있따\n\n\n# shift + tab 키를 누르면 docstring을 볼 수 있다\n# head: 데이터 미리보기\ndf.head(1)\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      지점명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      표준산업분류코드\n      ...\n      건물관리번호\n      건물명\n      도로명주소\n      구우편번호\n      신우편번호\n      동정보\n      층정보\n      호정보\n      경도\n      위도\n    \n  \n  \n    \n      0\n      19956873\n      하나산부인과\n      NaN\n      S\n      의료\n      S01\n      병원\n      S01B10\n      산부인과\n      Q86201\n      ...\n      4127310900110810000010857\n      산호한양아파트\n      경기도 안산시 단원구 달미로 10\n      425764.0\n      15236.0\n      NaN\n      NaN\n      NaN\n      126.814295\n      37.336344\n    \n  \n\n1 rows × 39 columns\n\n\n\n\n# tail: 마지막 데이터 불러오기\ndf.tail(1)\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      지점명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      표준산업분류코드\n      ...\n      건물관리번호\n      건물명\n      도로명주소\n      구우편번호\n      신우편번호\n      동정보\n      층정보\n      호정보\n      경도\n      위도\n    \n  \n  \n    \n      91334\n      16109073\n      천안김안과천안역본점의원\n      NaN\n      S\n      의료\n      S01\n      병원\n      S01B13\n      안과의원\n      Q86201\n      ...\n      4413110700102660017016314\n      김안과\n      충청남도 천안시 동남구 중앙로 92\n      330952.0\n      31127.0\n      NaN\n      NaN\n      NaN\n      127.152651\n      36.80664\n    \n  \n\n1 rows × 39 columns\n\n\n\n\n\n\n\n\n\n# 요약정보가 나타난다\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 91335 entries, 0 to 91334\nData columns (total 39 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   상가업소번호     91335 non-null  int64  \n 1   상호명        91335 non-null  object \n 2   지점명        1346 non-null   object \n 3   상권업종대분류코드  91335 non-null  object \n 4   상권업종대분류명   91335 non-null  object \n 5   상권업종중분류코드  91335 non-null  object \n 6   상권업종중분류명   91335 non-null  object \n 7   상권업종소분류코드  91335 non-null  object \n 8   상권업종소분류명   91335 non-null  object \n 9   표준산업분류코드   86413 non-null  object \n 10  표준산업분류명    86413 non-null  object \n 11  시도코드       90956 non-null  float64\n 12  시도명        90956 non-null  object \n 13  시군구코드      90956 non-null  float64\n 14  시군구명       90956 non-null  object \n 15  행정동코드      91335 non-null  int64  \n 16  행정동명       90956 non-null  object \n 17  법정동코드      91280 non-null  float64\n 18  법정동명       91280 non-null  object \n 19  지번코드       91335 non-null  int64  \n 20  대지구분코드     91335 non-null  int64  \n 21  대지구분명      91335 non-null  object \n 22  지번본번지      91335 non-null  int64  \n 23  지번부번지      72079 non-null  float64\n 24  지번주소       91335 non-null  object \n 25  도로명코드      91335 non-null  int64  \n 26  도로명        91335 non-null  object \n 27  건물본번지      91335 non-null  int64  \n 28  건물부번지      10604 non-null  float64\n 29  건물관리번호     91335 non-null  object \n 30  건물명        46453 non-null  object \n 31  도로명주소      91335 non-null  object \n 32  구우편번호      91323 non-null  float64\n 33  신우편번호      91333 non-null  float64\n 34  동정보        7406 non-null   object \n 35  층정보        44044 non-null  object \n 36  호정보        15551 non-null  object \n 37  경도         91335 non-null  float64\n 38  위도         91335 non-null  float64\ndtypes: float64(9), int64(7), object(23)\nmemory usage: 27.2+ MB\n\n\n\n# object : 문자열로 된 데이터 타입\n# int: 정수형\n# float : 실수형\n\n\n\n\n\n# 컬럼명만 추출해보기\ndf.columns\n\nIndex(['상가업소번호', '상호명', '지점명', '상권업종대분류코드', '상권업종대분류명', '상권업종중분류코드',\n       '상권업종중분류명', '상권업종소분류코드', '상권업종소분류명', '표준산업분류코드', '표준산업분류명', '시도코드',\n       '시도명', '시군구코드', '시군구명', '행정동코드', '행정동명', '법정동코드', '법정동명', '지번코드',\n       '대지구분코드', '대지구분명', '지번본번지', '지번부번지', '지번주소', '도로명코드', '도로명', '건물본번지',\n       '건물부번지', '건물관리번호', '건물명', '도로명주소', '구우편번호', '신우편번호', '동정보', '층정보',\n       '호정보', '경도', '위도'],\n      dtype='object')\n\n\n\n\n\n\n# 데이터 타입만 출력\ndf.dtypes\n\n상가업소번호         int64\n상호명           object\n지점명           object\n상권업종대분류코드     object\n상권업종대분류명      object\n상권업종중분류코드     object\n상권업종중분류명      object\n상권업종소분류코드     object\n상권업종소분류명      object\n표준산업분류코드      object\n표준산업분류명       object\n시도코드         float64\n시도명           object\n시군구코드        float64\n시군구명          object\n행정동코드          int64\n행정동명          object\n법정동코드        float64\n법정동명          object\n지번코드           int64\n대지구분코드         int64\n대지구분명         object\n지번본번지          int64\n지번부번지        float64\n지번주소          object\n도로명코드          int64\n도로명           object\n건물본번지          int64\n건물부번지        float64\n건물관리번호        object\n건물명           object\n도로명주소         object\n구우편번호        float64\n신우편번호        float64\n동정보           object\n층정보           object\n호정보           object\n경도           float64\n위도           float64\ndtype: object\n\n\n\n\n\n\n\ndf.isnull()\n# true로 표시되는 값은 null 값! \n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      지점명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      표준산업분류코드\n      ...\n      건물관리번호\n      건물명\n      도로명주소\n      구우편번호\n      신우편번호\n      동정보\n      층정보\n      호정보\n      경도\n      위도\n    \n  \n  \n    \n      0\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      False\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n    \n      1\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      True\n      False\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n    \n    \n      2\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      False\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n    \n      3\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      True\n      ...\n      False\n      True\n      False\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n    \n    \n      4\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      True\n      False\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      91330\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      True\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n    \n      91331\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      False\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n    \n      91332\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      False\n      False\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n    \n    \n      91333\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      True\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n    \n      91334\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      ...\n      False\n      False\n      False\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n    \n  \n\n91335 rows × 39 columns\n\n\n\n\nnull_count = df.isnull().sum()\nnull_count\n\n상가업소번호           0\n상호명              0\n지점명          89989\n상권업종대분류코드        0\n상권업종대분류명         0\n상권업종중분류코드        0\n상권업종중분류명         0\n상권업종소분류코드        0\n상권업종소분류명         0\n표준산업분류코드      4922\n표준산업분류명       4922\n시도코드           379\n시도명            379\n시군구코드          379\n시군구명           379\n행정동코드            0\n행정동명           379\n법정동코드           55\n법정동명            55\n지번코드             0\n대지구분코드           0\n대지구분명            0\n지번본번지            0\n지번부번지        19256\n지번주소             0\n도로명코드            0\n도로명              0\n건물본번지            0\n건물부번지        80731\n건물관리번호           0\n건물명          44882\n도로명주소            0\n구우편번호           12\n신우편번호            2\n동정보          83929\n층정보          47291\n호정보          75784\n경도               0\n위도               0\ndtype: int64\n\n\n\n# 결측치를 막대그래프로 표현\nnull_count.plot() # 선그래프로 표시되는데.. 적합하지 않은 거 같아!\n\n<AxesSubplot:>\n\n\n\n\n\n\nnull_count.plot.bar(rot=60)\n# rot = 글자 돌려보는것\n\n<AxesSubplot:>\n\n\n\n\n\n\nnull_count.plot.barh()\n\n<AxesSubplot:>\n\n\n\n\n\n\nnull_count.plot.barh(figsize=(5,7)) # 그래프 사이즈 지정\n\n<AxesSubplot:>\n\n\n\n\n\n\n# 위에서 계산한 결측치 수를 reset_index 통해 데이터 프레임으로 만들기\n# df_null_coount 변수에 결과를 담아 head로 미리보기 해보기\n\ndf_null_count = null_count.reset_index()\ndf_null_count.head()\n\n\n\n\n\n  \n    \n      \n      index\n      0\n    \n  \n  \n    \n      0\n      상가업소번호\n      0\n    \n    \n      1\n      상호명\n      0\n    \n    \n      2\n      지점명\n      89989\n    \n    \n      3\n      상권업종대분류코드\n      0\n    \n    \n      4\n      상권업종대분류명\n      0\n    \n  \n\n\n\n\n\n\n\n\n# 변수에 담겨있는 컬럼이름 변경\n\ndf_null_count.columns = [\"컬럼명\", \"결측치수\"]\ndf_null_count.head()\n\n\n\n\n\n  \n    \n      \n      컬럼명\n      결측치수\n    \n  \n  \n    \n      0\n      상가업소번호\n      0\n    \n    \n      1\n      상호명\n      0\n    \n    \n      2\n      지점명\n      89989\n    \n    \n      3\n      상권업종대분류코드\n      0\n    \n    \n      4\n      상권업종대분류명\n      0\n    \n  \n\n\n\n\n\n\n\n\n# sort_values 통해 정렬\n# 결측치가 많은 순으로 상위 10개 출력\n\ndf_null_count_top = df_null_count.sort_values(by=\"결측치수\", ascending=False).head(10)\ndf_null_count_top \n\n\n\n\n\n  \n    \n      \n      컬럼명\n      결측치수\n    \n  \n  \n    \n      2\n      지점명\n      89989\n    \n    \n      34\n      동정보\n      83929\n    \n    \n      28\n      건물부번지\n      80731\n    \n    \n      36\n      호정보\n      75784\n    \n    \n      35\n      층정보\n      47291\n    \n    \n      30\n      건물명\n      44882\n    \n    \n      23\n      지번부번지\n      19256\n    \n    \n      9\n      표준산업분류코드\n      4922\n    \n    \n      10\n      표준산업분류명\n      4922\n    \n    \n      11\n      시도코드\n      379\n    \n  \n\n\n\n\n\n\n\n\n# 지점명 컬럼 불러오기\n# NaN == Not a Number의 약자로 결측치를 의미한다.\n\ndf[\"지점명\"].head()\n\n0    NaN\n1    NaN\n2    NaN\n3    NaN\n4    수지점\nName: 지점명, dtype: object\n\n\n\n# \"컬럼명\" 이라는 컬럼 값만 가져와서 drop_columns 라는 변수에 담기\n\ndrop_columns = df_null_count_top[\"컬럼명\"].tolist()    # tolist : list로 만들어줌\ndrop_columns \n\n['지점명',\n '동정보',\n '건물부번지',\n '호정보',\n '층정보',\n '건물명',\n '지번부번지',\n '표준산업분류코드',\n '표준산업분류명',\n '시도코드']\n\n\n\n# drop_columns 변수로 해당 컬럼 정보만 데이터프레임에서 가져오기\ndf[drop_columns].head()\n\n\n\n\n\n  \n    \n      \n      지점명\n      동정보\n      건물부번지\n      호정보\n      층정보\n      건물명\n      지번부번지\n      표준산업분류코드\n      표준산업분류명\n      시도코드\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      산호한양아파트\n      NaN\n      Q86201\n      일반 의원\n      41.0\n    \n    \n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      4\n      NaN\n      14.0\n      Q86201\n      일반 의원\n      11.0\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      한라프라자\n      1.0\n      Q86201\n      일반 의원\n      41.0\n    \n    \n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      5\n      NaN\n      1.0\n      NaN\n      NaN\n      26.0\n    \n    \n      4\n      수지점\n      NaN\n      NaN\n      NaN\n      1\n      NaN\n      2.0\n      G47811\n      의약품 및 의료용품 소매업\n      41.0\n    \n  \n\n\n\n\n\n\n\n\nprint(df.shape)\n\ndf = df.drop(drop_columns, axis=1) \n# axis=1 컬럼기준으로 drop axis > 행(0), 열 (1)\n\nprint(df.shape)\n\n(91335, 39)\n(91335, 29)\n\n\n\n# 제거 결과 info로 확인\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 91335 entries, 0 to 91334\nData columns (total 29 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   상가업소번호     91335 non-null  int64  \n 1   상호명        91335 non-null  object \n 2   상권업종대분류코드  91335 non-null  object \n 3   상권업종대분류명   91335 non-null  object \n 4   상권업종중분류코드  91335 non-null  object \n 5   상권업종중분류명   91335 non-null  object \n 6   상권업종소분류코드  91335 non-null  object \n 7   상권업종소분류명   91335 non-null  object \n 8   시도명        90956 non-null  object \n 9   시군구코드      90956 non-null  float64\n 10  시군구명       90956 non-null  object \n 11  행정동코드      91335 non-null  int64  \n 12  행정동명       90956 non-null  object \n 13  법정동코드      91280 non-null  float64\n 14  법정동명       91280 non-null  object \n 15  지번코드       91335 non-null  int64  \n 16  대지구분코드     91335 non-null  int64  \n 17  대지구분명      91335 non-null  object \n 18  지번본번지      91335 non-null  int64  \n 19  지번주소       91335 non-null  object \n 20  도로명코드      91335 non-null  int64  \n 21  도로명        91335 non-null  object \n 22  건물본번지      91335 non-null  int64  \n 23  건물관리번호     91335 non-null  object \n 24  도로명주소      91335 non-null  object \n 25  구우편번호      91323 non-null  float64\n 26  신우편번호      91333 non-null  float64\n 27  경도         91335 non-null  float64\n 28  위도         91335 non-null  float64\ndtypes: float64(6), int64(7), object(16)\nmemory usage: 20.2+ MB\n\n\n\n\n\n\n\n\n\ndf.dtypes\n\n상가업소번호         int64\n상호명           object\n상권업종대분류코드     object\n상권업종대분류명      object\n상권업종중분류코드     object\n상권업종중분류명      object\n상권업종소분류코드     object\n상권업종소분류명      object\n시도명           object\n시군구코드        float64\n시군구명          object\n행정동코드          int64\n행정동명          object\n법정동코드        float64\n법정동명          object\n지번코드           int64\n대지구분코드         int64\n대지구분명         object\n지번본번지          int64\n지번주소          object\n도로명코드          int64\n도로명           object\n건물본번지          int64\n건물관리번호        object\n도로명주소         object\n구우편번호        float64\n신우편번호        float64\n경도           float64\n위도           float64\ndtype: object\n\n\n\n#평균값\ndf[\"위도\"].mean()\n\n36.62471119236673\n\n\n\n# 중앙값\ndf[\"위도\"].median()\n\n37.2346523177033\n\n\n\n# 최댓값\ndf[\"위도\"].max()\n\n38.4996585705598\n\n\n\n# 최솟값\ndf[\"위도\"].min()\n\n33.2192896688307\n\n\n\n# 갯수\ndf[\"위도\"].count()\n\n91335\n\n\n\n\n\n데이터를 요약해서 볼 수 있음\n\n# 위도를 descibe로 요약\n\ndf[\"위도\"].describe()\n\ncount    91335.000000\nmean        36.624711\nstd          1.041361\nmin         33.219290\n25%         35.811830\n50%         37.234652\n75%         37.507463\nmax         38.499659\nName: 위도, dtype: float64\n\n\n\n# 2개의 컬럼을 describe로 요약\ndf[\"위도\", \"경도\"] \n\n# pandas에서는 리스트 형태로 가져와야한다. 위와 같이 하면 오류남\n\nKeyError: ('위도', '경도')\n\n\n\ndf[[\"위도\", \"경도\"]]\n\n\n\n\n\n  \n    \n      \n      위도\n      경도\n    \n  \n  \n    \n      0\n      37.336344\n      126.814295\n    \n    \n      1\n      37.488742\n      127.053198\n    \n    \n      2\n      37.344955\n      126.734841\n    \n    \n      3\n      35.166872\n      129.115438\n    \n    \n      4\n      37.323528\n      127.095522\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      91330\n      36.352728\n      127.389865\n    \n    \n      91331\n      37.627530\n      126.830144\n    \n    \n      91332\n      35.227138\n      129.082790\n    \n    \n      91333\n      37.540993\n      127.143958\n    \n    \n      91334\n      36.806640\n      127.152651\n    \n  \n\n91335 rows × 2 columns\n\n\n\n\ndf[[\"위도\", \"경도\"]].describe()\n\n\n\n\n\n  \n    \n      \n      위도\n      경도\n    \n  \n  \n    \n      count\n      91335.000000\n      91335.000000\n    \n    \n      mean\n      36.624711\n      127.487524\n    \n    \n      std\n      1.041361\n      0.842877\n    \n    \n      min\n      33.219290\n      124.717632\n    \n    \n      25%\n      35.811830\n      126.914297\n    \n    \n      50%\n      37.234652\n      127.084550\n    \n    \n      75%\n      37.507463\n      128.108919\n    \n    \n      max\n      38.499659\n      130.909912\n    \n  \n\n\n\n\n\n# describe로 문자열 데이터타입 요약\n\ndf.describe() # 기본값은 수치형으로 되어있음!\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      시군구코드\n      행정동코드\n      법정동코드\n      지번코드\n      대지구분코드\n      지번본번지\n      도로명코드\n      건물본번지\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      count\n      9.133500e+04\n      90956.000000\n      9.133500e+04\n      9.128000e+04\n      9.133500e+04\n      91335.000000\n      91335.000000\n      9.133500e+04\n      91335.000000\n      91323.000000\n      91333.00000\n      91335.000000\n      91335.000000\n    \n    \n      mean\n      2.121818e+07\n      32898.381877\n      3.293232e+09\n      3.293385e+09\n      3.293191e+18\n      1.001336\n      587.534549\n      3.293207e+11\n      251.200482\n      428432.911085\n      28085.47698\n      127.487524\n      36.624711\n    \n    \n      std\n      5.042828e+06\n      12985.393171\n      1.297387e+09\n      1.297706e+09\n      1.297393e+18\n      0.036524\n      582.519364\n      1.297391e+11\n      477.456487\n      193292.339066\n      18909.01455\n      0.842877\n      1.041361\n    \n    \n      min\n      2.901108e+06\n      11110.000000\n      1.111052e+09\n      1.111010e+09\n      1.111010e+18\n      1.000000\n      1.000000\n      1.111020e+11\n      0.000000\n      100011.000000\n      1000.00000\n      124.717632\n      33.219290\n    \n    \n      25%\n      2.001931e+07\n      26350.000000\n      2.635065e+09\n      2.635011e+09\n      2.635011e+18\n      1.000000\n      162.000000\n      2.635042e+11\n      29.000000\n      302120.000000\n      11681.00000\n      126.914297\n      35.811830\n    \n    \n      50%\n      2.211900e+07\n      41117.000000\n      4.111758e+09\n      4.111710e+09\n      4.111711e+18\n      1.000000\n      462.000000\n      4.111743e+11\n      92.000000\n      440300.000000\n      24353.00000\n      127.084550\n      37.234652\n    \n    \n      75%\n      2.480984e+07\n      43113.000000\n      4.311370e+09\n      4.311311e+09\n      4.311311e+18\n      1.000000\n      858.000000\n      4.311332e+11\n      257.000000\n      602811.000000\n      46044.00000\n      128.108919\n      37.507463\n    \n    \n      max\n      2.852470e+07\n      50130.000000\n      5.013061e+09\n      5.013032e+09\n      5.013061e+18\n      2.000000\n      7338.000000\n      5.013049e+11\n      8795.000000\n      799801.000000\n      63643.00000\n      130.909912\n      38.499659\n    \n  \n\n\n\n\n\ndf.describe(include=\"object\")\n\n# top : 가장 많이 나타난걸 보여줌\n# freq : frequency : 빈도수.. 리원이라는 상호명이 152번 등장한다.\n# 결측치는 제외하고 보여줌! \n\n\n\n\n\n  \n    \n      \n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구명\n      행정동명\n      법정동명\n      대지구분명\n      지번주소\n      도로명\n      건물관리번호\n      도로명주소\n    \n  \n  \n    \n      count\n      91335\n      91335\n      91335\n      91335\n      91335\n      91335\n      91335\n      90956\n      90956\n      90956\n      91280\n      91335\n      91335\n      91335\n      91335\n      91335\n    \n    \n      unique\n      56910\n      1\n      1\n      5\n      5\n      34\n      34\n      17\n      228\n      2791\n      2822\n      2\n      53118\n      16610\n      54142\n      54031\n    \n    \n      top\n      리원\n      S\n      의료\n      S01\n      병원\n      S02A01\n      약국\n      경기도\n      서구\n      중앙동\n      중동\n      대지\n      서울특별시 동대문구 제기동 965-1\n      서울특별시 강남구 강남대로\n      1123010300109650001031604\n      서울특별시 동대문구 약령중앙로8길 10\n    \n    \n      freq\n      152\n      91335\n      91335\n      60774\n      60774\n      18964\n      18964\n      21374\n      3165\n      1856\n      874\n      91213\n      198\n      326\n      198\n      198\n    \n  \n\n\n\n\n\n# 모든 데이터 요약\ndf.describe(include=\"all\")\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      count\n      9.133500e+04\n      91335\n      91335\n      91335\n      91335\n      91335\n      91335\n      91335\n      90956\n      90956.000000\n      ...\n      91335\n      9.133500e+04\n      91335\n      91335.000000\n      91335\n      91335\n      91323.000000\n      91333.00000\n      91335.000000\n      91335.000000\n    \n    \n      unique\n      NaN\n      56910\n      1\n      1\n      5\n      5\n      34\n      34\n      17\n      NaN\n      ...\n      53118\n      NaN\n      16610\n      NaN\n      54142\n      54031\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      top\n      NaN\n      리원\n      S\n      의료\n      S01\n      병원\n      S02A01\n      약국\n      경기도\n      NaN\n      ...\n      서울특별시 동대문구 제기동 965-1\n      NaN\n      서울특별시 강남구 강남대로\n      NaN\n      1123010300109650001031604\n      서울특별시 동대문구 약령중앙로8길 10\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      freq\n      NaN\n      152\n      91335\n      91335\n      60774\n      60774\n      18964\n      18964\n      21374\n      NaN\n      ...\n      198\n      NaN\n      326\n      NaN\n      198\n      198\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      mean\n      2.121818e+07\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      32898.381877\n      ...\n      NaN\n      3.293207e+11\n      NaN\n      251.200482\n      NaN\n      NaN\n      428432.911085\n      28085.47698\n      127.487524\n      36.624711\n    \n    \n      std\n      5.042828e+06\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12985.393171\n      ...\n      NaN\n      1.297391e+11\n      NaN\n      477.456487\n      NaN\n      NaN\n      193292.339066\n      18909.01455\n      0.842877\n      1.041361\n    \n    \n      min\n      2.901108e+06\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      11110.000000\n      ...\n      NaN\n      1.111020e+11\n      NaN\n      0.000000\n      NaN\n      NaN\n      100011.000000\n      1000.00000\n      124.717632\n      33.219290\n    \n    \n      25%\n      2.001931e+07\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      26350.000000\n      ...\n      NaN\n      2.635042e+11\n      NaN\n      29.000000\n      NaN\n      NaN\n      302120.000000\n      11681.00000\n      126.914297\n      35.811830\n    \n    \n      50%\n      2.211900e+07\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      41117.000000\n      ...\n      NaN\n      4.111743e+11\n      NaN\n      92.000000\n      NaN\n      NaN\n      440300.000000\n      24353.00000\n      127.084550\n      37.234652\n    \n    \n      75%\n      2.480984e+07\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      43113.000000\n      ...\n      NaN\n      4.311332e+11\n      NaN\n      257.000000\n      NaN\n      NaN\n      602811.000000\n      46044.00000\n      128.108919\n      37.507463\n    \n    \n      max\n      2.852470e+07\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      50130.000000\n      ...\n      NaN\n      5.013049e+11\n      NaN\n      8795.000000\n      NaN\n      NaN\n      799801.000000\n      63643.00000\n      130.909912\n      38.499659\n    \n  \n\n11 rows × 29 columns\n\n\n\n\n\n\n\nunique로 중복 제거 nuique 갯수 세기\n\n\n# 상권업종대분류명\n\ndf[\"상권업종대분류명\"].unique()\n\narray(['의료'], dtype=object)\n\n\n\ndf[\"상권업종대분류명\"].nunique()\n\n1\n\n\n\n# 상권업종중분류명\ndf[\"상권업종중분류명\"].unique()\n\narray(['병원', '약국/한약방', '수의업', '유사의료업', '의료관련서비스업'], dtype=object)\n\n\n\ndf[\"상권업종중분류명\"].nunique()\n\n5\n\n\n\n# 상권업종소분류명\ndf[\"상권업종소분류명\"].unique()\n\narray(['산부인과', '내과/외과', '신경외과', '기타병원', '약국', '동물병원', '한약방', '탕제원',\n       '정형/성형외과', '소아과', '이비인후과의원', '노인/치매병원', '언어치료', '수의업-종합', '한의원',\n       '치과의원', '침구원', '일반병원', '안과의원', '조산원', '한방병원', '종합병원', '유사의료업기타',\n       '응급구조대', '혈액원', '치과병원', '척추교정치료', '피부과', '비뇨기과', '치과기공소', '산후조리원',\n       '접골원', '수의업-기타', '제대혈'], dtype=object)\n\n\n\ndf[\"상권업종소분류명\"].nunique()\n\n34\n\n\n\nlen(df[\"상권업종소분류명\"].unique())\n\n34\n\n\n\n\n\n\n카테고리 형태의 데이터 갯수를 셀 수 있다.\n\n\n# 시도코드 세어보기 -> 결측치...\ndf[\"시도명\"].head()\n\n0      경기도\n1    서울특별시\n2      경기도\n3    부산광역시\n4      경기도\nName: 시도명, dtype: object\n\n\n\n# 시도명 세보면\ncity = df[\"시도명\"].value_counts()\ncity\n\n경기도        21374\n서울특별시      18943\n부산광역시       6473\n경상남도        4973\n인천광역시       4722\n대구광역시       4597\n경상북도        4141\n전라북도        3894\n충청남도        3578\n전라남도        3224\n광주광역시       3214\n대전광역시       3067\n충청북도        2677\n강원도         2634\n울산광역시       1997\n제주특별자치도     1095\n세종특별자치시      353\nName: 시도명, dtype: int64\n\n\n\n# normalize=True 옵션 사용시 비율을 구할 수 있다.\n\ncity_normalize= df[\"시도명\"].value_counts(normalize=True)\ncity_normalize\n\n경기도        0.234993\n서울특별시      0.208266\n부산광역시      0.071166\n경상남도       0.054675\n인천광역시      0.051915\n대구광역시      0.050541\n경상북도       0.045528\n전라북도       0.042812\n충청남도       0.039338\n전라남도       0.035446\n광주광역시      0.035336\n대전광역시      0.033720\n충청북도       0.029432\n강원도        0.028959\n울산광역시      0.021956\n제주특별자치도    0.012039\n세종특별자치시    0.003881\nName: 시도명, dtype: float64\n\n\n\ncity.plot()\n\n<AxesSubplot:>\n\n\n\n\n\n\n # 막대그래프 표현\ncity.plot.barh()\n\n<AxesSubplot:>\n\n\n\n\n\n\n# plto.pie() 사용하여 파이그래프 그리기\ncity_normalize.plot.pie(figsize=(7,7))\n\n<AxesSubplot:ylabel='시도명'>\n\n\n\n\n\n\n# seaborn의 countplot 그리기\nsns.countplot(data=df, y=\"시도명\" )\n\n<AxesSubplot:xlabel='count', ylabel='시도명'>\n\n\n\n\n\n\nc=sns.countplot(data=df, y=\"시도명\" ) \n# 변수명에 담아주면 밑에 글씨가 없어진당 \n\n\n\n\n\ndf[\"상권업종대분류명\"].value_counts()\n\n의료    91335\nName: 상권업종대분류명, dtype: int64\n\n\n\nd= df[\"상권업종중분류명\"].value_counts()\nd\n\n병원          60774\n약국/한약방      20923\n수의업          5323\n유사의료업        3774\n의료관련서비스업      541\nName: 상권업종중분류명, dtype: int64\n\n\n\nn =df[\"상권업종중분류명\"].value_counts(normalize=True)\nn\n\n병원          0.665397\n약국/한약방      0.229080\n수의업         0.058280\n유사의료업       0.041320\n의료관련서비스업    0.005923\nName: 상권업종중분류명, dtype: float64\n\n\n\nd.plot()\n\n<AxesSubplot:>\n\n\n\n\n\n\nd.plot.bar()\n\n<AxesSubplot:>\n\n\n\n\n\n\nd.plot.bar(rot=0) # x축 레이블 값 회전\n\n<AxesSubplot:>\n\n\n\n\n\n\nn.plot.pie()\n\n<AxesSubplot:ylabel='상권업종중분류명'>\n\n\n\n\n\n\nc = df[\"상권업종소분류명\"].value_counts()\nc\n\n약국         18964\n치과의원       13731\n한의원        13211\n내과/외과      11374\n기타병원        4922\n일반병원        3385\n동물병원        3098\n정형/성형외과     2562\n소아과         2472\n수의업-종합      2216\n치과기공소       1724\n이비인후과의원     1486\n한약방         1442\n피부과         1273\n산부인과        1116\n노인/치매병원     1055\n안과의원        1042\n비뇨기과         809\n종합병원         762\n치과병원         756\n언어치료         664\n유사의료업기타      629\n탕제원          517\n산후조리원        511\n신경외과         421\n한방병원         397\n척추교정치료       338\n침구원          154\n혈액원          130\n응급구조대        125\n조산원           30\n접골원            9\n수의업-기타         9\n제대혈            1\nName: 상권업종소분류명, dtype: int64\n\n\n\nc.plot.barh(figsize=(7, 8), grid= True) #gird: 격자 표시\n\n<AxesSubplot:>\n\n\n\n\n\n\n\n\n\n\n# 상권업종분류명이 약국/한약방인 데이터만 가져와서\n# df_medical이라는 변수에 담고\n# head()통해 미리보기\n\ndf_medical = df[df[\"상권업종중분류명\"] == \"약국/한약방\"].copy()\ndf_medical.head(1)\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      4\n      20364049\n      더블유스토어수지점\n      S\n      의료\n      S02\n      약국/한약방\n      S02A01\n      약국\n      경기도\n      41465.0\n      ...\n      경기도 용인시 수지구 풍덕천동 712-2\n      414653205024\n      경기도 용인시 수지구 문정로\n      32\n      4146510100107120002026238\n      경기도 용인시 수지구 문정로 32\n      448170.0\n      16837.0\n      127.095522\n      37.323528\n    \n  \n\n1 rows × 29 columns\n\n\n\n\n# 상권업종대분류명이 의료만 가져오기\n# df.loc 사용하면 행, 열을 함께 가져온다.\n# 이 기능을 통해 상권업종중뷴려망만 가져온다\n# 가져온 결과를 value_counts를 통해 중분류의 갯수를 세본다.\n\ndf.loc[df[\"상권업종대분류명\"] == \"의료\", \"상권업종중분류명\"].value_counts()\n\n병원          60774\n약국/한약방      20923\n수의업          5323\n유사의료업        3774\n의료관련서비스업      541\nName: 상권업종중분류명, dtype: int64\n\n\n\n# 위와 같은 기능을 수행하는 코드\n# df.loc[df[\"상권업종대분류명\"] == \"의료\"][\"상권업종중분류명\"] 근데 이건 느리다!! \n\n\nm = df[\"상권업종대분류명\"] == \"의료\"\ndf.loc[m, \"상권업종중분류명\"].value_counts()\n\n병원          60774\n약국/한약방      20923\n수의업          5323\n유사의료업        3774\n의료관련서비스업      541\nName: 상권업종중분류명, dtype: int64\n\n\n\n# 유사의료업\ndf[df[\"상권업종중분류명\"] == \"유사의료업\"]\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      22\n      21013731\n      세종언어치료센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B07\n      언어치료\n      부산광역시\n      26410.0\n      ...\n      부산광역시 금정구 구서동 84-1\n      264102000010\n      부산광역시 금정구 중앙대로\n      1817\n      2641010700100840001017686\n      부산광역시 금정구 중앙대로 1817-11\n      609310.0\n      46273.0\n      129.091662\n      35.246528\n    \n    \n      40\n      20933900\n      고려수지침학회\n      S\n      의료\n      S03\n      유사의료업\n      S03B03\n      침구원\n      경상남도\n      48123.0\n      ...\n      경상남도 창원시 성산구 상남동 5-2\n      481234784088\n      경상남도 창원시 성산구 마디미로4번길\n      9\n      4812312700100050002026799\n      경상남도 창원시 성산구 마디미로4번길 9\n      642832.0\n      51495.0\n      128.684678\n      35.224113\n    \n    \n      97\n      21717820\n      청명원\n      S\n      의료\n      S03\n      유사의료업\n      S03B09\n      유사의료업기타\n      충청북도\n      43760.0\n      ...\n      충청북도 괴산군 청안면 금신리 241\n      437604538132\n      충청북도 괴산군 청안면 금신로1길\n      93\n      4376037022102410000007293\n      충청북도 괴산군 청안면 금신로1길 93\n      367831.0\n      28050.0\n      127.635740\n      36.768935\n    \n    \n      102\n      21865854\n      응급환자이송센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B01\n      응급구조대\n      대전광역시\n      30140.0\n      ...\n      대전광역시 중구 대사동 248-237\n      301404295026\n      대전광역시 중구 계룡로921번길\n      40\n      3014011000102480237013097\n      대전광역시 중구 계룡로921번길 40\n      301846.0\n      34946.0\n      127.417693\n      36.321801\n    \n    \n      108\n      21914637\n      태화아동발달지원센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B07\n      언어치료\n      대전광역시\n      30140.0\n      ...\n      대전광역시 중구 문화동 27\n      301404295402\n      대전광역시 중구 보문산로333번길\n      29\n      3014011600100270000008172\n      대전광역시 중구 보문산로333번길 29\n      301130.0\n      35020.0\n      127.412725\n      36.312953\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      91300\n      16131218\n      으뜸치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      경상남도\n      48170.0\n      ...\n      경상남도 진주시 수정동 39-11\n      481704797625\n      경상남도 진주시 향교로18번길\n      8\n      4817011600100390011004490\n      경상남도 진주시 향교로18번길 8\n      660180.0\n      52753.0\n      128.084600\n      35.197029\n    \n    \n      91310\n      16199325\n      보령치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      서울특별시\n      11290.0\n      ...\n      서울특별시 성북구 동소문동4가 103-11\n      112903107003\n      서울특별시 성북구 동소문로\n      47\n      1129010700101030014050661\n      서울특별시 성북구 동소문로 47-15\n      136821.0\n      2832.0\n      127.010602\n      37.591455\n    \n    \n      91311\n      16199088\n      점프셈교실\n      S\n      의료\n      S03\n      유사의료업\n      S03B09\n      유사의료업기타\n      경상북도\n      47130.0\n      ...\n      경상북도 경주시 황성동 446\n      471304715895\n      경상북도 경주시 용담로104번길\n      16\n      4713012400104460000024894\n      경상북도 경주시 용담로104번길 16\n      780954.0\n      38084.0\n      129.211755\n      35.865600\n    \n    \n      91319\n      16108560\n      씨앤디자인치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      서울특별시\n      11545.0\n      ...\n      서울특별시 금천구 가산동 60-25\n      115453116013\n      서울특별시 금천구 벚꽃로\n      234\n      1154510100100600025000001\n      서울특별시 금천구 벚꽃로 234\n      153798.0\n      8513.0\n      126.886122\n      37.475986\n    \n    \n      91327\n      16190388\n      오피스알파\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      경기도\n      41173.0\n      ...\n      경기도 안양시 동안구 호계동 970-24\n      411734349013\n      경기도 안양시 동안구 경수대로507번길\n      28\n      4117310400109700024005182\n      경기도 안양시 동안구 경수대로507번길 28\n      431849.0\n      14120.0\n      126.956365\n      37.367779\n    \n  \n\n3774 rows × 29 columns\n\n\n\n\n\ndf[df[\"상권업종중분류명\"] == \"유사의료업\"].shape\n\n(3774, 29)\n\n\n\n# 상호명 그룹화해서 갯수\n# value_counts를 사용해 상위 10개 출력\n\ndf[\"상호명\"].value_counts().head(10)\n\n리원       152\n온누리약국    149\n경희한의원    141\n우리약국     119\n중앙약국     111\n전자담배      98\n조은약국      95\n건강약국      87\n제일약국      79\n사랑약국      73\nName: 상호명, dtype: int64\n\n\n\n\ndf[\"상호명\"].value_counts().tail()\n\n메리디언치과          1\n이엘피부과성형외과       1\n금오중국한의원         1\n오케이연합의원         1\n천안김안과천안역본점의원    1\nName: 상호명, dtype: int64\n\n\n\n\ndf_medi = df[df[\"상권업종중분류명\"] == \"유사의료업\"]\ndf_medi\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      22\n      21013731\n      세종언어치료센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B07\n      언어치료\n      부산광역시\n      26410.0\n      ...\n      부산광역시 금정구 구서동 84-1\n      264102000010\n      부산광역시 금정구 중앙대로\n      1817\n      2641010700100840001017686\n      부산광역시 금정구 중앙대로 1817-11\n      609310.0\n      46273.0\n      129.091662\n      35.246528\n    \n    \n      40\n      20933900\n      고려수지침학회\n      S\n      의료\n      S03\n      유사의료업\n      S03B03\n      침구원\n      경상남도\n      48123.0\n      ...\n      경상남도 창원시 성산구 상남동 5-2\n      481234784088\n      경상남도 창원시 성산구 마디미로4번길\n      9\n      4812312700100050002026799\n      경상남도 창원시 성산구 마디미로4번길 9\n      642832.0\n      51495.0\n      128.684678\n      35.224113\n    \n    \n      97\n      21717820\n      청명원\n      S\n      의료\n      S03\n      유사의료업\n      S03B09\n      유사의료업기타\n      충청북도\n      43760.0\n      ...\n      충청북도 괴산군 청안면 금신리 241\n      437604538132\n      충청북도 괴산군 청안면 금신로1길\n      93\n      4376037022102410000007293\n      충청북도 괴산군 청안면 금신로1길 93\n      367831.0\n      28050.0\n      127.635740\n      36.768935\n    \n    \n      102\n      21865854\n      응급환자이송센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B01\n      응급구조대\n      대전광역시\n      30140.0\n      ...\n      대전광역시 중구 대사동 248-237\n      301404295026\n      대전광역시 중구 계룡로921번길\n      40\n      3014011000102480237013097\n      대전광역시 중구 계룡로921번길 40\n      301846.0\n      34946.0\n      127.417693\n      36.321801\n    \n    \n      108\n      21914637\n      태화아동발달지원센터\n      S\n      의료\n      S03\n      유사의료업\n      S03B07\n      언어치료\n      대전광역시\n      30140.0\n      ...\n      대전광역시 중구 문화동 27\n      301404295402\n      대전광역시 중구 보문산로333번길\n      29\n      3014011600100270000008172\n      대전광역시 중구 보문산로333번길 29\n      301130.0\n      35020.0\n      127.412725\n      36.312953\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      91300\n      16131218\n      으뜸치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      경상남도\n      48170.0\n      ...\n      경상남도 진주시 수정동 39-11\n      481704797625\n      경상남도 진주시 향교로18번길\n      8\n      4817011600100390011004490\n      경상남도 진주시 향교로18번길 8\n      660180.0\n      52753.0\n      128.084600\n      35.197029\n    \n    \n      91310\n      16199325\n      보령치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      서울특별시\n      11290.0\n      ...\n      서울특별시 성북구 동소문동4가 103-11\n      112903107003\n      서울특별시 성북구 동소문로\n      47\n      1129010700101030014050661\n      서울특별시 성북구 동소문로 47-15\n      136821.0\n      2832.0\n      127.010602\n      37.591455\n    \n    \n      91311\n      16199088\n      점프셈교실\n      S\n      의료\n      S03\n      유사의료업\n      S03B09\n      유사의료업기타\n      경상북도\n      47130.0\n      ...\n      경상북도 경주시 황성동 446\n      471304715895\n      경상북도 경주시 용담로104번길\n      16\n      4713012400104460000024894\n      경상북도 경주시 용담로104번길 16\n      780954.0\n      38084.0\n      129.211755\n      35.865600\n    \n    \n      91319\n      16108560\n      씨앤디자인치과기공소\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      서울특별시\n      11545.0\n      ...\n      서울특별시 금천구 가산동 60-25\n      115453116013\n      서울특별시 금천구 벚꽃로\n      234\n      1154510100100600025000001\n      서울특별시 금천구 벚꽃로 234\n      153798.0\n      8513.0\n      126.886122\n      37.475986\n    \n    \n      91327\n      16190388\n      오피스알파\n      S\n      의료\n      S03\n      유사의료업\n      S03B06\n      치과기공소\n      경기도\n      41173.0\n      ...\n      경기도 안양시 동안구 호계동 970-24\n      411734349013\n      경기도 안양시 동안구 경수대로507번길\n      28\n      4117310400109700024005182\n      경기도 안양시 동안구 경수대로507번길 28\n      431849.0\n      14120.0\n      126.956365\n      37.367779\n    \n  \n\n3774 rows × 29 columns\n\n\n\n\ndf_medi[\"상호명\"].value_counts().head(10)\n\n리원          32\n고려수지침       22\n대한적십자사      17\n헌혈의집        12\n고려수지침학회     10\n수치과기공소      10\n제일치과기공소      9\n미소치과기공소      8\n아트치과기공소      8\n이사랑치과기공소     8\nName: 상호명, dtype: int64\n\n\n\n\n\n# 상권업종소분류명이 약국이고 시도명이 서울특별시인 데이터\ndf[\"상권업종소분류명\"] == \"약국\"  and df[\"시도명\"] == \"서울특별시\"\n# 오류! 판다스에서는 & 써야함. \n\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n\n\n\n\ndf[\"상권업종소분류명\"] == \"약국\"  & df[\"시도명\"] == \"서울특별시\"\n# 오류! 연산자 우선순위 때문에 오류가 났다.\n\nTypeError: Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]\n\n\n\n\ndf_seoul_drug = df[(df[\"상권업종소분류명\"] == \"약국\")  & (df[\"시도명\"] == \"서울특별시\")]\nprint(df_seoul_drug.shape)\ndf_seoul_drug.head(1)\n\n(3579, 29)\n\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      33\n      20816709\n      이즈타워약\n      S\n      의료\n      S02\n      약국/한약방\n      S02A01\n      약국\n      서울특별시\n      11680.0\n      ...\n      서울특별시 강남구 역삼동 821\n      116803122010\n      서울특별시 강남구 테헤란로\n      101\n      1168010100108210001000001\n      서울특별시 강남구 테헤란로 101\n      135080.0\n      6134.0\n      127.028023\n      37.498656\n    \n  \n\n1 rows × 29 columns\n\n\n\n\n\n\n\n# 시군구명으로 그룹화해서 갯수 세어보기\n# 구별로 약국이 몇개가 있는지 확인\nc = df_seoul_drug[\"시군구명\"].value_counts()\nc.head()\n\n강남구     374\n동대문구    261\n광진구     212\n서초구     191\n송파구     188\nName: 시군구명, dtype: int64\n\n\n\nn = df_seoul_drug[\"시군구명\"].value_counts(normalize=True)\nn.head()\n\n강남구     0.104498\n동대문구    0.072925\n광진구     0.059234\n서초구     0.053367\n송파구     0.052529\nName: 시군구명, dtype: float64\n\n\n\nc.plot.bar(rot=60) #rot:글씨를 기울인다\n\n<AxesSubplot:>\n\n\n\n\n\n\n# 상권업종소분류명이 종합병원\n# 시도명이 서울특별시인 데이터\n\ndf_seoul_hospital = df[(df[\"상권업종소분류명\"] == \"종합병원\") & (df[\"시도명\"] == \"서울특별시\")].copy()\n# copy를 해줘야 df_soeul_hospital 이 바뀐다. df까지 바뀌지 않는다. \ndf_seoul_hospital\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      305\n      25155642\n      대진의료재단\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11215.0\n      ...\n      서울특별시 광진구 중곡동 58-25\n      112153104006\n      서울특별시 광진구 긴고랑로\n      119\n      1121510100100580025000733\n      서울특별시 광진구 긴고랑로 119\n      143220.0\n      4944.0\n      127.088279\n      37.559048\n    \n    \n      353\n      20471487\n      홍익병원별관\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11470.0\n      ...\n      서울특별시 양천구 신정동 897-13\n      114702005008\n      서울특별시 양천구 국회대로\n      250\n      1147010100108970013001044\n      서울특별시 양천구 국회대로 250\n      158070.0\n      7937.0\n      126.862805\n      37.529213\n    \n    \n      385\n      20737057\n      SNUH\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11680.0\n      ...\n      서울특별시 강남구 역삼동 736-55\n      116804166727\n      서울특별시 강남구 테헤란로26길\n      10\n      1168010100107360055027688\n      서울특별시 강남구 테헤란로26길 10\n      135080.0\n      6236.0\n      127.035825\n      37.499630\n    \n    \n      1917\n      23210677\n      평화드림여의도성모병원의료기매장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11560.0\n      ...\n      서울특별시 영등포구 여의도동 62\n      115603118001\n      서울특별시 영등포구 63로\n      10\n      1156011000100620000031477\n      서울특별시 영등포구 63로 10\n      150713.0\n      7345.0\n      126.936693\n      37.518296\n    \n    \n      2461\n      20024045\n      한양\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11200.0\n      ...\n      서울특별시 성동구 행당동 15-1\n      112003103002\n      서울특별시 성동구 마조로\n      22\n      1120010700100150001019623\n      서울특별시 성동구 마조로 22-2\n      133070.0\n      4763.0\n      127.041325\n      37.559469\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      71991\n      28505952\n      서울성모병원응급의료센터\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 505\n      116502121003\n      서울특별시 서초구 반포대로\n      222\n      1165010700101230000017226\n      서울특별시 서초구 반포대로 222\n      137701.0\n      6591.0\n      127.005841\n      37.502382\n    \n    \n      76508\n      12292992\n      라마르의원\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11740.0\n      ...\n      서울특별시 강동구 천호동 453-8\n      117404172367\n      서울특별시 강동구 천호대로157길\n      18\n      1174010900104530021010314\n      서울특별시 강동구 천호대로157길 18\n      134864.0\n      5335.0\n      127.127466\n      37.538485\n    \n    \n      90492\n      16031909\n      가톨릭대학교여의도성모병원\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11140.0\n      ...\n      서울특별시 중구 명동2가 1-1\n      111404103165\n      서울특별시 중구 명동길\n      74\n      1114012700100010001019574\n      서울특별시 중구 명동길 74\n      100809.0\n      4537.0\n      126.986758\n      37.563662\n    \n    \n      90581\n      16332576\n      씨엠병원\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11560.0\n      ...\n      서울특별시 영등포구 영등포동4가 90\n      115604154717\n      서울특별시 영등포구 영등포로36길\n      13\n      1156010500100900000035097\n      서울특별시 영등포구 영등포로36길 13\n      150030.0\n      7301.0\n      126.903857\n      37.518807\n    \n    \n      90788\n      16162338\n      성베드로병원\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11680.0\n      ...\n      서울특별시 강남구 도곡동 910-27\n      116802000003\n      서울특별시 강남구 남부순환로\n      2649\n      1168011800109100027000895\n      서울특별시 강남구 남부순환로 2649\n      135859.0\n      6271.0\n      127.039567\n      37.485604\n    \n  \n\n91 rows × 29 columns\n\n\n\n\ndf_seoul_hospital[\"시군구명\"].value_counts()\n\n강남구     15\n영등포구     8\n광진구      6\n서초구      6\n강동구      5\n중구       5\n송파구      5\n강북구      4\n도봉구      4\n서대문구     4\n양천구      4\n성북구      3\n강서구      2\n중랑구      2\n종로구      2\n동대문구     2\n구로구      2\n노원구      2\n금천구      2\n성동구      2\n관악구      2\n동작구      1\n마포구      1\n용산구      1\n은평구      1\nName: 시군구명, dtype: int64\n\n\n\n\n\n\n# 색인 전 상호명 중에 종합병원이 아닌 데이터 찾기\ndf_seoul_hospital.loc[~df_seoul_hospital[\"상호명\"].str.contains(\"종합병원\"),\"상호명\"].unique()\n\n# str.contains하면 특정 값만 찾을 수 있다. \n# 앞에 물결 표시를 하게 되면 종합병원이 안들어간 것만 찾을 수 있다. \n\narray(['대진의료재단', '홍익병원별관', 'SNUH', '평화드림여의도성모병원의료기매장', '한양', '백산의료재단친구병원',\n       '서울보훈병원', '서울성모병원장례식장꽃배달', '서울대학교병원', '알콜중독및정신질환상담소',\n       '강남성모병원장례식장꽃배달', '제일병원', '이랜드클리닉', '사랑나눔의료재단', '우울증센터', '성심의료재단',\n       '다나의료재단', '서울아산병원신관', '원자력병원장례식장', '국민의원', '고려대학교구로병원', '학교법인일송학원',\n       '삼성의료원장례식장', '희명스포츠의학센터인공신장실', '연세대학교의과대학강남세브란스', '국립정신병원',\n       '코아클리닉', '수서제일의원', '사랑의의원', '한국전력공사부속한일병원', '신촌연세병원', '창동제일의원',\n       '영동세브란스병원', '제일성심의원', '삼성의료재단강북삼성태', '서울시립보라매병원', '서울이의원',\n       '서울대학교병원비상계획외래', '평화드림서울성모병원의료', '홍익병원', '사랑나눔의료재단서', '독일의원',\n       '서울연합의원', '우신향병원', '동부제일병원', '아산재단금강병원', '명곡안연구소', '아산재단서울중앙병원',\n       '메디힐특수여객', '삼성생명공익재단삼성서', '성광의료재단차병원', '한국건강관리협회서울특',\n       '정해복지부설한신메디피아', '성베드로병원', '성애의료재단', '실로암의원', 'Y&T성모마취과', '광진성모의원',\n       '서울현대의원', '이노신경과의원', '송정훼밀리의원', '서울중앙의원', '영남의료재단', '인제대학교서울백병원',\n       '한국필의료재단', '세브란스의원', '가톨릭대학교성바오로병원장례식장', '서울연세의원', '사랑의병원',\n       '성삼의료재단미즈메디병원', '씨엠충무병원', '성신의원', '원진재단부설녹색병원', '송파제일의원',\n       '카톨릭성모의원', '한양성심의원', '관악성모의원', '강남센트럴병원', '우이한솔의원', '우리들병원',\n       '서울성모병원어린이집', '건국대학교병원', '서울적십자병원', '북부성모의원', '한림대학교부속한강성심병원장례식장',\n       '서울성모병원응급의료센터', '라마르의원', '가톨릭대학교여의도성모병원', '씨엠병원'], dtype=object)\n\n\n\ndf_seoul_hospital[df_seoul_hospital[\"상호명\"].str.contains(\"꽃배달\")]\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      2803\n      20895655\n      서울성모병원장례식장꽃배달\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 551\n      116504163330\n      서울특별시 서초구 사평대로28길\n      55\n      1165010700105510000017194\n      서울특별시 서초구 사평대로28길 55\n      137040.0\n      6578.0\n      127.000682\n      37.498257\n    \n    \n      4644\n      22020310\n      강남성모병원장례식장꽃배달\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 547-6\n      116504163242\n      서울특별시 서초구 반포대로39길\n      56\n      1165010700105470006016762\n      서울특별시 서초구 반포대로39길 56-24\n      137040.0\n      6578.0\n      127.001756\n      37.499095\n    \n  \n\n2 rows × 29 columns\n\n\n\n\ndf_seoul_hospital[df_seoul_hospital[\"상호명\"].str.contains(\"의료기\")]\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      1917\n      23210677\n      평화드림여의도성모병원의료기매장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11560.0\n      ...\n      서울특별시 영등포구 여의도동 62\n      115603118001\n      서울특별시 영등포구 63로\n      10\n      1156011000100620000031477\n      서울특별시 영등포구 63로 10\n      150713.0\n      7345.0\n      126.936693\n      37.518296\n    \n  \n\n1 rows × 29 columns\n\n\n\n\ndf_seoul_hospital[df_seoul_hospital[\"상호명\"].str.contains(\"꽃배달|의료기|장례식장|상담소|어린이집\")]\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      1917\n      23210677\n      평화드림여의도성모병원의료기매장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11560.0\n      ...\n      서울특별시 영등포구 여의도동 62\n      115603118001\n      서울특별시 영등포구 63로\n      10\n      1156011000100620000031477\n      서울특별시 영등포구 63로 10\n      150713.0\n      7345.0\n      126.936693\n      37.518296\n    \n    \n      2803\n      20895655\n      서울성모병원장례식장꽃배달\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 551\n      116504163330\n      서울특별시 서초구 사평대로28길\n      55\n      1165010700105510000017194\n      서울특별시 서초구 사평대로28길 55\n      137040.0\n      6578.0\n      127.000682\n      37.498257\n    \n    \n      4431\n      21781516\n      알콜중독및정신질환상담소\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11320.0\n      ...\n      서울특별시 도봉구 창동 181-52\n      113204127202\n      서울특별시 도봉구 마들로13길\n      153\n      1132010700101810052014414\n      서울특별시 도봉구 마들로13길 153\n      132040.0\n      1411.0\n      127.046203\n      37.657046\n    \n    \n      4644\n      22020310\n      강남성모병원장례식장꽃배달\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 547-6\n      116504163242\n      서울특별시 서초구 반포대로39길\n      56\n      1165010700105470006016762\n      서울특별시 서초구 반포대로39길 56-24\n      137040.0\n      6578.0\n      127.001756\n      37.499095\n    \n    \n      7938\n      20625484\n      원자력병원장례식장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11350.0\n      ...\n      서울특별시 노원구 공릉동 215-4\n      113503110002\n      서울특별시 노원구 노원로\n      75\n      1135010300102150004014400\n      서울특별시 노원구 노원로 75\n      139706.0\n      1812.0\n      127.082670\n      37.628808\n    \n    \n      10283\n      20024377\n      삼성의료원장례식장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11680.0\n      ...\n      서울특별시 강남구 일원동 50\n      116803122009\n      서울특별시 강남구 일원로\n      81\n      1168011400100500000002609\n      서울특별시 강남구 일원로 81\n      135710.0\n      6351.0\n      127.089579\n      37.490334\n    \n    \n      47008\n      21738670\n      가톨릭대학교성바오로병원장례식장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11230.0\n      ...\n      서울특별시 동대문구 전농동 620-56\n      112303105008\n      서울특별시 동대문구 왕산로\n      180\n      1123010400106200056027814\n      서울특별시 동대문구 왕산로 180\n      130709.0\n      2559.0\n      127.043471\n      37.579246\n    \n    \n      60645\n      27670796\n      서울성모병원어린이집\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11650.0\n      ...\n      서울특별시 서초구 반포동 505\n      116502121003\n      서울특별시 서초구 반포대로\n      222\n      1165010700101230000017226\n      서울특별시 서초구 반포대로 222\n      137701.0\n      6591.0\n      127.005841\n      37.502382\n    \n    \n      70177\n      11537223\n      한림대학교부속한강성심병원장례식장\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11560.0\n      ...\n      서울특별시 영등포구 영등포동7가 94-200\n      115604154428\n      서울특별시 영등포구 버드나루로7길\n      12\n      1156010800100940200033663\n      서울특별시 영등포구 버드나루로7길 12\n      150030.0\n      7247.0\n      126.909676\n      37.523168\n    \n  \n\n9 rows × 29 columns\n\n\n\n\ndf_seoul_hospital[df_seoul_hospital[\"상호명\"].str.contains(\"꽃배달|의료기|장례식장|상담소|어린이집\")].index\n\nInt64Index([1917, 2803, 4431, 4644, 7938, 10283, 47008, 60645, 70177], dtype='int64')\n\n\n\n# 종합병원과 무관한 데이터를 전처리를 위해 해당 텍스트 한번에 검색\n# 제거할 데이터의 인덱스만 drop_row에 담아주고 list 형태로 변환\n\ndrop_row = df_seoul_hospital[df_seoul_hospital[\"상호명\"].str.contains(\"꽃배달|의료기|장례식장|상담소|어린이집\")].index\ndrop_row = drop_row.tolist() \ndrop_row\n\n[1917, 2803, 4431, 4644, 7938, 10283, 47008, 60645, 70177]\n\n\n\n# 의원으로 끝나는 데이터 인덱스 찾기\n# drop_row2 에 담고 list 변환\n# str.endswith() : ~로 끝나는거\n\ndrop_row2 = df_seoul_hospital[df_seoul_hospital[\"상호명\"].str.endswith(\"의원\")].index\ndrop_row2 = drop_row2.tolist()\ndrop_row2\n\n[8479,\n 12854,\n 13715,\n 14966,\n 16091,\n 18047,\n 20200,\n 20415,\n 30706,\n 32889,\n 34459,\n 34720,\n 35696,\n 37251,\n 45120,\n 49626,\n 51575,\n 55133,\n 56320,\n 56404,\n 56688,\n 57551,\n 62113,\n 76508]\n\n\n\n# 삭제할 행을 drop_row에 합치기\ndrop_row = drop_row + drop_row2\nlen(drop_row)\n\n33\n\n\n\n# 해당 셀을 삭제하고 삭제 전 후의 행의 갯수 비교\nprint(df_seoul_hospital.shape)\ndf_seoul_hospital = df_seoul_hospital.drop(drop_row, axis=0)\nprint(df_seoul_hospital.shape)\n\n(91, 29)\n(58, 29)\n\n\n\n# 시군구명에 따라 종합병원의 숫자\ndf_seoul_hospital[\"시군구명\"].value_counts().plot.bar()\n\n<AxesSubplot:>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df_seoul_hospital, x=\"시군구명\", order=df_seoul_hospital[\"시군구명\"].value_counts().index)\n\n<AxesSubplot:xlabel='시군구명', ylabel='count'>\n\n\n\n\n\n\ndf_seoul_hospital[\"상호명\"].unique()\n\narray(['대진의료재단', '홍익병원별관', 'SNUH', '한양', '백산의료재단친구병원', '서울보훈병원',\n       '서울대학교병원', '제일병원', '이랜드클리닉', '사랑나눔의료재단', '우울증센터', '성심의료재단',\n       '다나의료재단', '서울아산병원신관', '고려대학교구로병원', '학교법인일송학원', '희명스포츠의학센터인공신장실',\n       '연세대학교의과대학강남세브란스', '국립정신병원', '코아클리닉', '한국전력공사부속한일병원', '신촌연세병원',\n       '영동세브란스병원', '삼성의료재단강북삼성태', '서울시립보라매병원', '서울대학교병원비상계획외래',\n       '평화드림서울성모병원의료', '홍익병원', '사랑나눔의료재단서', '우신향병원', '동부제일병원', '아산재단금강병원',\n       '명곡안연구소', '아산재단서울중앙병원', '메디힐특수여객', '삼성생명공익재단삼성서', '성광의료재단차병원',\n       '한국건강관리협회서울특', '정해복지부설한신메디피아', '성베드로병원', '성애의료재단', 'Y&T성모마취과',\n       '영남의료재단', '인제대학교서울백병원', '한국필의료재단', '사랑의병원', '성삼의료재단미즈메디병원',\n       '씨엠충무병원', '원진재단부설녹색병원', '강남센트럴병원', '우리들병원', '건국대학교병원', '서울적십자병원',\n       '서울성모병원응급의료센터', '가톨릭대학교여의도성모병원', '씨엠병원'], dtype=object)\n\n\n\n\n\n\n# 서울에 있는 데이터의 위도와 경도 보기\n# 결과를 df_seoul 이라는 df에 저장\n# 새로운 변수에 데이터프레임 저장시 copy()를 사용\n\ndf_seoul= df[df[\"시도명\"] == \"서울특별시\"].copy()\ndf_seoul.shape\n\n(18943, 29)\n\n\n\n# seaborn 의 countplot를 사용해 위에서 만든 데이터프레ㅣㅁ의 시군구명 시각화\ndf_seoul[\"시군구명\"].value_counts().head()\ndf_seoul[\"시군구명\"].value_counts().plot.bar(figsize=(10,4), rot=30)\n\n<AxesSubplot:>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df_seoul, x=\"시군구명\")\n# x축 y축 두개 중 하나만 지정해주면 된다.\n\n<AxesSubplot:xlabel='시군구명', ylabel='count'>\n\n\n\n\n\n\n# pandas의 plot.scatter를 통해 경도와 위도 표시\ndf_seoul[[\"경도\", \"위도\", \"시군구명\"]].plot.scatter()\n# scatter는 x축과 y축이 꼭 들어가야 한다!!\n\nTypeError: scatter() missing 2 required positional arguments: 'x' and 'y'\n\n\n\ndf_seoul[[\"경도\", \"위도\", \"시군구명\"]].plot.scatter(x=\"경도\", y=\"위도\", figsize=(8,7), grid=True)\n\n<AxesSubplot:xlabel='경도', ylabel='위도'>\n\n\n\n\n\n\nplt.figure(figsize=(9,8))\nsns.scatterplot(data=df_seoul,x=\"경도\", y=\"위도\", hue=\"시군구명\") \n# hue: 색상 다르게\n\n<AxesSubplot:xlabel='경도', ylabel='위도'>\n\n\n\n\n\n\nplt.figure(figsize=(9,8))\nsns.scatterplot(data=df_seoul,x=\"경도\", y=\"위도\", hue=\"상권업종중분류명\") \n\n<AxesSubplot:xlabel='경도', ylabel='위도'>\n\n\n\n\n\n\nplt.figure(figsize=(16,12))\nsns.scatterplot(data=df,x=\"경도\", y=\"위도\", hue=\"시도명\") \n\n<AxesSubplot:xlabel='경도', ylabel='위도'>\n\n\n\n\n\n\n\n\n\n\nimport folium\n# 아나콘다에서 folium 별도 설치해야함\n# conda install -c conda-forge folium\n# 지도 시각화를 위한 라이브러리\n\nm= folium.Map(location=[45.5236, -122.6750])\n\n\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nfolium.Map()\n# 세계 지도 출력! \n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nfolium.Map()\n\n\n# 지도의 중심을 지정하기 위해 위도와 경도의 평균을 구한다.\n\ndf_seoul_hospital[\"위도\"].mean()\ndf_seoul_hospital[\"경도\"].mean()\n\n126.9963589356625\n\n\n\nmap = folium.Map(location=[df_seoul_hospital[\"위도\"].mean(),df_seoul_hospital[\"경도\"].mean()], zoom_start=12)\n\n\ndf_seoul_hospital.head(1)\n\n\n\n\n\n  \n    \n      \n      상가업소번호\n      상호명\n      상권업종대분류코드\n      상권업종대분류명\n      상권업종중분류코드\n      상권업종중분류명\n      상권업종소분류코드\n      상권업종소분류명\n      시도명\n      시군구코드\n      ...\n      지번주소\n      도로명코드\n      도로명\n      건물본번지\n      건물관리번호\n      도로명주소\n      구우편번호\n      신우편번호\n      경도\n      위도\n    \n  \n  \n    \n      305\n      25155642\n      대진의료재단\n      S\n      의료\n      S01\n      병원\n      S01B01\n      종합병원\n      서울특별시\n      11215.0\n      ...\n      서울특별시 광진구 중곡동 58-25\n      112153104006\n      서울특별시 광진구 긴고랑로\n      119\n      1121510100100580025000733\n      서울특별시 광진구 긴고랑로 119\n      143220.0\n      4944.0\n      127.088279\n      37.559048\n    \n  \n\n1 rows × 29 columns\n\n\n\n\nfor n in df_seoul_hospital.index:\n    name = df_seoul_hospital.loc[n, \"상호명\"]\n    address = df_seoul_hospital.loc[n, \"도로명주소\"]\n    popup = f\"{name}-{address}\"\n    location = [df_seoul_hospital.loc[n, \"위도\"], df_seoul_hospital.loc[n, \"경도\"]]\n    folium.Marker(\n        location = location,\n        popup = popup,\n    ).add_to(map)\nmap\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/est/1. file-path-setting.html",
    "href": "posts/est/1. file-path-setting.html",
    "title": "2: file-path-setting",
    "section": "",
    "text": "!move \"C:\\Users\\user\\Downloads\\도로교통공단_사망 교통사고 정보_20211231.csv\" .\n# mv: 다운로드 받은 파일을 같은 경로로 옮긴다. 근데 이건 맥에서만..\n# !move: 이게 윈도우즈 환경. 윈도우즈 환경에서는 맥과 다르게 작성하는듯 \n\n        1개 파일을 이동했습니다.\n\n\n\n# 주피터 노트북이 있는 폴더의 경로를 출력한다.\n%pwd\n\n'C:\\\\Users\\\\user\\\\Untitled Folder'\n\n\n\n%ls\n\n C 드라이브의 볼륨: system\n 볼륨 일련 번호: 0819-B8FC\n\n C:\\Users\\user\\Untitled Folder 디렉터리\n\n2022-10-27  오전 10:43    <DIR>          .\n2022-10-27  오전 10:43    <DIR>          ..\n2022-10-27  오전 10:35    <DIR>          .ipynb_checkpoints\n2022-10-26  오후 02:24            45,288 2. 데이터 분석 준비하기.ipynb\n2022-10-27  오전 10:43             1,498 file-path-setting.ipynb\n2022-10-25  오후 01:57             2,883 jupyter basic.ipynb\n2022-10-27  오전 10:37           459,343 도로교통공단_사망 교통사고 정보_20211231.csv\n               4개 파일             509,012 바이트\n               3개 디렉터리  113,083,060,224 바이트 남음\n\n\n\nimport pandas as pd\n\n\npd.read_csv(\"data/도로교통공단_사망 교통사고 정보_20211231.csv\", encoding=\"cp949\")\n# UnicodeDecodeError 이파일의 인코딩이 UTF8이 아니라는 뜻이다.\n# ()안에서 shift+tab키를 누르면 도움말 본다.\n# 옵션에 encording=None 으로 설정되어 있음. 인코딩 지정을 해줘야 한다. 엑셀은 cp949 \n\n# 파일 옮겨주면 FileNotFoundError 가 난다. -> 파일이 속해있는 곳을  적어주기 \n\n\n\n\n\n  \n    \n      \n      발생년\n      발생년월일시\n      주야\n      요일\n      사망자수\n      부상자수\n      중상자수\n      경상자수\n      부상신고자수\n      발생지시도\n      ...\n      사고유형\n      가해자법규위반\n      도로형태_대분류\n      도로형태\n      가해자_당사자종별\n      피해자_당사자종별\n      발생위치X(UTMK)\n      발생위치Y(UTMK)\n      경도\n      위도\n    \n  \n  \n    \n      0\n      2021\n      2021-01-01 03:00\n      야\n      금\n      1\n      3\n      0\n      3\n      0\n      경북\n      ...\n      추돌\n      안전운전 의무 불이행\n      교차로\n      교차로부근\n      승용차\n      승용차\n      1097010.0\n      1793385.0\n      128.578152\n      36.132653\n    \n    \n      1\n      2021\n      2021-01-01 09:00\n      주\n      금\n      1\n      0\n      0\n      0\n      0\n      충남\n      ...\n      공작물충돌\n      안전운전 의무 불이행\n      단일로\n      기타단일로\n      승용차\n      없음\n      902369.0\n      1847109.0\n      126.408201\n      36.616845\n    \n    \n      2\n      2021\n      2021-01-01 15:00\n      주\n      금\n      1\n      0\n      0\n      0\n      0\n      강원\n      ...\n      측면충돌\n      안전운전 의무 불이행\n      교차로\n      교차로내\n      원동기장치자전거\n      승용차\n      1123975.0\n      1974509.0\n      128.907484\n      37.761842\n    \n    \n      3\n      2021\n      2021-01-01 19:00\n      야\n      금\n      1\n      0\n      0\n      0\n      0\n      전남\n      ...\n      횡단중\n      안전운전 의무 불이행\n      단일로\n      기타단일로\n      화물차\n      보행자\n      886507.0\n      1613961.0\n      126.263573\n      34.513391\n    \n    \n      4\n      2021\n      2021-01-01 21:00\n      야\n      금\n      1\n      0\n      0\n      0\n      0\n      경기\n      ...\n      기타\n      기타\n      단일로\n      기타단일로\n      승용차\n      보행자\n      953522.0\n      1915403.0\n      126.976011\n      37.236327\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2811\n      2021\n      2021-12-31 16:00\n      주\n      금\n      1\n      0\n      0\n      0\n      0\n      경북\n      ...\n      정면충돌\n      안전운전 의무 불이행\n      교차로\n      교차로내\n      승용차\n      이륜차\n      1119020.0\n      1766895.0\n      128.818730\n      35.891434\n    \n    \n      2812\n      2021\n      2021-12-31 17:00\n      주\n      금\n      1\n      0\n      0\n      0\n      0\n      제주\n      ...\n      추돌\n      안전운전 의무 불이행\n      단일로\n      기타단일로\n      화물차\n      화물차\n      940588.0\n      1503049.6\n      126.860248\n      33.517699\n    \n    \n      2813\n      2021\n      2021-12-31 18:00\n      야\n      금\n      1\n      0\n      0\n      0\n      0\n      강원\n      ...\n      횡단중\n      보행자 보호의무 위반\n      단일로\n      기타단일로\n      승용차\n      보행자\n      1023127.0\n      1982332.0\n      127.762845\n      37.840465\n    \n    \n      2814\n      2021\n      2021-12-31 19:00\n      야\n      금\n      1\n      0\n      0\n      0\n      0\n      경북\n      ...\n      횡단중\n      보행자 보호의무 위반\n      교차로\n      교차로횡단보도내\n      승용차\n      보행자\n      1058805.0\n      1824755.0\n      128.155943\n      36.418521\n    \n    \n      2815\n      2021\n      2021-12-31 21:00\n      야\n      금\n      1\n      0\n      0\n      0\n      0\n      강원\n      ...\n      전복\n      중앙선 침범\n      단일로\n      기타단일로\n      승용차\n      없음\n      1042559.0\n      2010975.0\n      127.985386\n      38.097913\n    \n  \n\n2816 rows × 23 columns"
  },
  {
    "objectID": "posts/est/5. K-beauty.html",
    "href": "posts/est/5. K-beauty.html",
    "title": "6: K-beauty",
    "section": "",
    "text": "e:추정지, p:잠정치, -:자료없음, …:미상자료, x: 비밀번호"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#기간에서-연도를-분리하기",
    "href": "posts/est/5. K-beauty.html#기간에서-연도를-분리하기",
    "title": "6: K-beauty",
    "section": "기간에서 연도를 분리하기",
    "text": "기간에서 연도를 분리하기\n\ndf[\"기간\"]\n# object : string데이터를 의미\n\n0        2014.1/4\n1        2014.1/4\n2        2014.1/4\n3        2014.1/4\n4        2014.1/4\n           ...   \n10795    2019.4/4\n10796    2019.4/4\n10797    2019.4/4\n10798    2019.4/4\n10799    2019.4/4\nName: 기간, Length: 10800, dtype: object\n\n\ndf[“기간”].map?\n\n\ndf[\"연도\"] = list(map(lambda x : int(x.split(\".\")[0]), df[\"기간\"])) \n\n\n# 기간에서 분기만 분리하기\ndf[\"분기\"] = list(map(lambda x : int(x.split(\".\")[1].split()[0].split(\"/\")[0]), df[\"기간\"])) \n\n\n# (1) \".\" 을 기준으로 split하고 ([\"2022\", \"1/4 p\"]) 1번째 인덱스를 취함 -> \"1/4 p\"\n\n# (2) \" \" 을 기준으로 split하고 ([\"1/4\", \"p\"]) 0번째 인덱스를 취함 -> \"1/4\"\n\n# (3) \"/\"을 기준으로 split하고 ([\"1\", \"4\"]) 0번째 인덱스를 취함\n\n# (4) \"1\"에 int() 형변환 함수를 씌워 int64형으로 변환\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      0\n      합계\n      합계\n      계\n      2014.1/4\n      148272\n      2014\n      1\n    \n    \n      1\n      합계\n      합계\n      면세점\n      2014.1/4\n      -\n      2014\n      1\n    \n    \n      2\n      합계\n      합계\n      면세점 이외\n      2014.1/4\n      -\n      2014\n      1\n    \n    \n      3\n      합계\n      컴퓨터 및 주변기기\n      계\n      2014.1/4\n      4915\n      2014\n      1\n    \n    \n      4\n      합계\n      컴퓨터 및 주변기기\n      면세점\n      2014.1/4\n      -\n      2014\n      1"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#금액을-수치데이터로-표현하기-위해-데이터-타입-변경하기",
    "href": "posts/est/5. K-beauty.html#금액을-수치데이터로-표현하기-위해-데이터-타입-변경하기",
    "title": "6: K-beauty",
    "section": "금액을 수치데이터로 표현하기 위해 데이터 타입 변경하기",
    "text": "금액을 수치데이터로 표현하기 위해 데이터 타입 변경하기\n\n# - 문자를 결측치로 변경하고 float타입으로 변경하기\ndf[\"백만원\"] = df[\"백만원\"].replace(\"-\",pd.np.nan).astype(float)\ndf[\"백만원\"]\n\nC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_117660\\99655999.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n  df[\"백만원\"] = df[\"백만원\"].replace(\"-\",pd.np.nan).astype(float)\n\n\n0        148272.0\n1             NaN\n2             NaN\n3          4915.0\n4             NaN\n           ...   \n10795         0.0\n10796       531.0\n10797      1094.0\n10798         1.0\n10799      1093.0\nName: 백만원, Length: 10800, dtype: float64\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      0\n      합계\n      합계\n      계\n      2014.1/4\n      148272.0\n      2014\n      1\n    \n    \n      1\n      합계\n      합계\n      면세점\n      2014.1/4\n      NaN\n      2014\n      1\n    \n    \n      2\n      합계\n      합계\n      면세점 이외\n      2014.1/4\n      NaN\n      2014\n      1\n    \n    \n      3\n      합계\n      컴퓨터 및 주변기기\n      계\n      2014.1/4\n      4915.0\n      2014\n      1\n    \n    \n      4\n      합계\n      컴퓨터 및 주변기기\n      면세점\n      2014.1/4\n      NaN\n      2014\n      1"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#필요없는-데이터-제거하기",
    "href": "posts/est/5. K-beauty.html#필요없는-데이터-제거하기",
    "title": "6: K-beauty",
    "section": "필요없는 데이터 제거하기",
    "text": "필요없는 데이터 제거하기\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10800 entries, 0 to 10799\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   국가(대륙)별  10800 non-null  object \n 1   상품군별     10800 non-null  object \n 2   판매유형별    10800 non-null  object \n 3   기간       10800 non-null  object \n 4   백만원      7200 non-null   float64\n 5   연도       10800 non-null  int64  \n 6   분기       10800 non-null  int64  \ndtypes: float64(1), int64(2), object(4)\nmemory usage: 590.8+ KB\n\n\n\n# 합계 데이터는 따로 구할 수 있으므로 전체 데이터에서 제거한다.\n\ndf = df[(df[\"국가(대륙)별\"] != \"합계\") & (df[\"상품군별\"] != \"합계\")].copy()\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 9072 entries, 48 to 10799\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   국가(대륙)별  9072 non-null   object \n 1   상품군별     9072 non-null   object \n 2   판매유형별    9072 non-null   object \n 3   기간       9072 non-null   object \n 4   백만원      6048 non-null   float64\n 5   연도       9072 non-null   int64  \n 6   분기       9072 non-null   int64  \ndtypes: float64(1), int64(2), object(4)\nmemory usage: 567.0+ KB\n\n\n\n# 결측치 보기\ndf.isnull().sum()\n\n국가(대륙)별       0\n상품군별          0\n판매유형별         0\n기간            0\n백만원        3024\n연도            0\n분기            0\ndtype: int64"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#전체-상품군-판매액",
    "href": "posts/est/5. K-beauty.html#전체-상품군-판매액",
    "title": "6: K-beauty",
    "section": "전체 상품군 판매액",
    "text": "전체 상품군 판매액\n\n# 판매유형별 데이터는 일부 기간에는 \"계\"만 존재하기 때문에\n# 판매유형별 == \"계\" 데이터만 가져와서 봐야지\n# 평균값을 구하는 그래프에서 올바른 값을 표현할 수 있다.\n\ndf_total=df[df[\"판매유형별\"] == \"계\"].copy()\ndf_total.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      48\n      미국\n      컴퓨터 및 주변기기\n      계\n      2014.1/4\n      2216.0\n      2014\n      1\n    \n    \n      51\n      미국\n      가전·전자·통신기기\n      계\n      2014.1/4\n      2875.0\n      2014\n      1\n    \n    \n      54\n      미국\n      소프트웨어\n      계\n      2014.1/4\n      47.0\n      2014\n      1\n    \n    \n      57\n      미국\n      서 적\n      계\n      2014.1/4\n      962.0\n      2014\n      1\n    \n    \n      60\n      미국\n      사무·문구\n      계\n      2014.1/4\n      25.0\n      2014\n      1\n    \n  \n\n\n\n\n\n# 연도, 판매액 lineplot으로 그리기\n\nsns.lineplot(data=df_total, x=\"연도\", y=\"백만원\")\n\n<AxesSubplot:xlabel='연도', ylabel='백만원'>\n\n\n\n\n\n\n# 연도, 판매액 lineplot으로 그리고 상품군별로 다른 색상으로 표시하기\nsns.lineplot(data=df_total, x=\"연도\", y=\"백만원\", hue=\"상품군별\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n# 오른쪽으로 범례 옮기는거 \n\n<matplotlib.legend.Legend at 0x15f495c10a0>\n\n\n\n\n\n\n# 위에 그린 그래프를 자세히 보기 위해 서브플롯으로 표시하기\nsns.relplot(data=df_total, x=\"연도\", y=\"백만원\", hue=\"상품군별\", kind=\"line\", col=\"상품군별\", col_wrap=4)\n\n<seaborn.axisgrid.FacetGrid at 0x15f48b4bf70>\n\n\n\n\n\n\n# isin을 사용해 화장품만 제외하고 df_sb이라는 변수에 담기\n\ndf_sub=df_total[~df_total[\"상품군별\"].isin([\"화장품\",\"의류 및 패션 관련상품\"])].copy()\n\n# 앞에 ~ 물결 표시해ㅜㅈ면 화장품만 빼고...\n\n\n# 연도별 판매액을 상품군별로 relplot을 활용해 서브플롯으로 그려보기\n\nsns.relplot(data=df_sub, x=\"연도\", y=\"백만원\", hue=\"상품군별\", col=\"상품군별\", col_wrap=4, kind=\"line\")\n#kind기본값은 scatter\n\n<seaborn.axisgrid.FacetGrid at 0x15f4a3a35e0>"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#화장품의-온라인-쇼핑-해외직접판매액",
    "href": "posts/est/5. K-beauty.html#화장품의-온라인-쇼핑-해외직접판매액",
    "title": "6: K-beauty",
    "section": "화장품의 온라인 쇼핑 해외직접판매액",
    "text": "화장품의 온라인 쇼핑 해외직접판매액\n\n# df_cosmetic이라는 변수에 상품군별이 화장품인 데이터만 가져오기\n\ndf_cosmetic = df_total[df_total[\"상품군별\"]==\"화장품\"].copy()\ndf_cosmetic.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      72\n      미국\n      화장품\n      계\n      2014.1/4\n      3740.0\n      2014\n      1\n    \n    \n      117\n      중국\n      화장품\n      계\n      2014.1/4\n      32235.0\n      2014\n      1\n    \n    \n      162\n      일본\n      화장품\n      계\n      2014.1/4\n      1034.0\n      2014\n      1\n    \n    \n      207\n      아세안(ASEAN)\n      화장품\n      계\n      2014.1/4\n      398.0\n      2014\n      1\n    \n    \n      252\n      유럽연합(EU)\n      화장품\n      계\n      2014.1/4\n      937.0\n      2014\n      1\n    \n  \n\n\n\n\n\ndf_cosmetic[\"상품군별\"].unique()\n\narray(['화장품'], dtype=object)\n\n\n\n# 연도와 판매액을 lineplot으로 그리고 분기별로 다른 색상으로 표현해 보기\nplt.figure(figsize=(15,4))\nsns.lineplot(data=df_cosmetic, x=\"연도\", y=\"백만원\", hue=\"분기\")\n\n<AxesSubplot:xlabel='연도', ylabel='백만원'>\n\n\n\n\n\n\ndf_cosmetic.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      72\n      미국\n      화장품\n      계\n      2014.1/4\n      3740.0\n      2014\n      1\n    \n    \n      117\n      중국\n      화장품\n      계\n      2014.1/4\n      32235.0\n      2014\n      1\n    \n    \n      162\n      일본\n      화장품\n      계\n      2014.1/4\n      1034.0\n      2014\n      1\n    \n    \n      207\n      아세안(ASEAN)\n      화장품\n      계\n      2014.1/4\n      398.0\n      2014\n      1\n    \n    \n      252\n      유럽연합(EU)\n      화장품\n      계\n      2014.1/4\n      937.0\n      2014\n      1\n    \n  \n\n\n\n\n\n# 화장품 판매액에 대한 기간별 금액 데이터 시각화 하기\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\nsns.lineplot(data=df_cosmetic, x=\"기간\", y=\"백만원\")\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>\n\n\n\n\n\n\n# 화장품 판매액에 대한 기간별 금액 데이터 시각화하고 \"국가(대륙)별\"로 다른 색상으로 표시하기\n\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\nsns.lineplot(data=df_cosmetic, x=\"기간\", y=\"백만원\", hue=\"국가(대륙)별\")\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>\n\n\n\n\n\n\n# 중국빼고 보기\n\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\nsns.lineplot(data=df_cosmetic[df_cosmetic[\"국가(대륙)별\"]!=\"중국\"], x=\"기간\", y=\"백만원\", hue=\"국가(대륙)별\")\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>\n\n\n\n\n\n\n# 화장품 판매액에 대한 기간별 금액 데이터를 시각화하고 \"판매유형별\"로 다른색상으로 표현하기\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\ndf_sub = df[df[\"판매유형별\"] != \"계\"].copy()\nsns.lineplot(data=df_sub, x=\"기간\", y=\"백만원\", hue=\"판매유형별\")\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>\n\n\n\n\n\n\n# 화장품 판매액에 대한 기간별 금액 데이터를 시각화하고 \"판매유형별\"로 다른색상으로 표현하기\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\ndf_sub = df[(df[\"판매유형별\"] != \"계\") & (df[\"판매유형별\"]!=\"면세점\")].copy()\nsns.lineplot(data=df_sub, x=\"기간\", y=\"백만원\", hue=\"판매유형별\", ci=None)\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#의류-및-패션관련-상품-온라인쇼핑-해외직접판매액",
    "href": "posts/est/5. K-beauty.html#의류-및-패션관련-상품-온라인쇼핑-해외직접판매액",
    "title": "6: K-beauty",
    "section": "의류 및 패션관련 상품 온라인쇼핑 해외직접판매액",
    "text": "의류 및 패션관련 상품 온라인쇼핑 해외직접판매액\n\n# df_fashion 이라는 변수에 의류 데이터만 가져와 따로 담아두기\n\n\ndf_fashion = df[(df[\"상품군별\"] == \"의류 및 패션 관련상품\") & (df[\"판매유형별\"]==\"계\")].copy()\ndf_fashion.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      66\n      미국\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      9810.0\n      2014\n      1\n    \n    \n      111\n      중국\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      12206.0\n      2014\n      1\n    \n    \n      156\n      일본\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      13534.0\n      2014\n      1\n    \n    \n      201\n      아세안(ASEAN)\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      3473.0\n      2014\n      1\n    \n    \n      246\n      유럽연합(EU)\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      1364.0\n      2014\n      1\n    \n  \n\n\n\n\n\n# 의류 및 패션 관련상품 판매액에 대한 기간별 금액 데이터를 시각화하고\n# 국가별로 다른색상으로 표시하기\n\nplt.figure(figsize=(15,4))\nplt.xticks(rotation=30) #x축 기울기\nsns.lineplot(data=df_fashion, x=\"기간\", y=\"백만원\", hue=\"국가(대륙)별\")\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>\n\n\n\n\n\n\n# 의류 및 패션관련 상품 판매엑에 대한 기간별 금액 데이터 시각화\n# 판매유형별로 다른 색상 표시\n\ndf_fashion2 = df[(df[\"상품군별\"] == \"의류 및 패션 관련상품\") & (df[\"판매유형별\"] != \"계\")].copy()\n\nplt.figure(figsize=(15, 4))\nplt.xticks(rotation=30)\nsns.lineplot(data=df_fashion2, x=\"기간\", y=\"백만원\", hue=\"판매유형별\", ci=None)\n\n<AxesSubplot:xlabel='기간', ylabel='백만원'>"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#데이터-집계하기",
    "href": "posts/est/5. K-beauty.html#데이터-집계하기",
    "title": "6: K-beauty",
    "section": "데이터 집계하기",
    "text": "데이터 집계하기\n\n# 피봇테이블로 \"국가(대륙)별\", \"연도\"별로 합계 금액을 표 형ㅇ태로 구하기\n\ndf_fashion.pivot_table?\n\n\ndf_fashion[\"판매유형별\"].value_counts()\n\n\ndf_fashion.head()\n\n\n\n\n\n  \n    \n      \n      국가(대륙)별\n      상품군별\n      판매유형별\n      기간\n      백만원\n      연도\n      분기\n    \n  \n  \n    \n      66\n      미국\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      9810.0\n      2014\n      1\n    \n    \n      111\n      중국\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      12206.0\n      2014\n      1\n    \n    \n      156\n      일본\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      13534.0\n      2014\n      1\n    \n    \n      201\n      아세안(ASEAN)\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      3473.0\n      2014\n      1\n    \n    \n      246\n      유럽연합(EU)\n      의류 및 패션 관련상품\n      계\n      2014.1/4\n      1364.0\n      2014\n      1\n    \n  \n\n\n\n\n\nresult = df_fashion.pivot_table(index=\"국가(대륙)별\", columns=\"연도\", values=\"백만원\", aggfunc=\"sum\")\n# 기본은 평균으로 되어있음.. aggfunc\n\nresult\n\n\n\n\n\n  \n    \n      연도\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n    \n    \n      국가(대륙)별\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      기타\n      9683.0\n      7248.0\n      5918.0\n      14387.0\n      23901.0\n      6475.0\n    \n    \n      대양주\n      3392.0\n      2349.0\n      3401.0\n      2266.0\n      2725.0\n      2489.0\n    \n    \n      미국\n      33223.0\n      38066.0\n      48451.0\n      50353.0\n      47875.0\n      55536.0\n    \n    \n      아세안(ASEAN)\n      14936.0\n      19639.0\n      24478.0\n      22671.0\n      23068.0\n      31247.0\n    \n    \n      유럽연합(EU)\n      4485.0\n      3374.0\n      4899.0\n      3736.0\n      4114.0\n      3694.0\n    \n    \n      일본\n      48960.0\n      57594.0\n      79905.0\n      90584.0\n      136800.0\n      134637.0\n    \n    \n      중국\n      57531.0\n      142339.0\n      190932.0\n      225407.0\n      288848.0\n      330267.0\n    \n    \n      중남미\n      975.0\n      616.0\n      649.0\n      762.0\n      576.0\n      544.0\n    \n    \n      중동\n      1172.0\n      1018.0\n      968.0\n      772.0\n      879.0\n      951.0"
  },
  {
    "objectID": "posts/est/5. K-beauty.html#연산결과를-시각적으로-보기",
    "href": "posts/est/5. K-beauty.html#연산결과를-시각적으로-보기",
    "title": "6: K-beauty",
    "section": "연산결과를 시각적으로 보기",
    "text": "연산결과를 시각적으로 보기\n\n# 피봇테이블로 구한 결과를 값의 많고 적음에 따라 시각적으로 표현\n\nplt.figure(figsize=(15,4)\nsns.heatmap(result, cmap=\"Blues\", annot= True, fmt=\".0f\")\n# annot=true 숫자값 표시 \n\n<AxesSubplot:xlabel='연도', ylabel='국가(대륙)별'>\n\n\n\n\n\n\nsns.heatmap(result, cmap=\"Blues_r\")\n# _r 하면 위에랑 반대로.. \n\n<AxesSubplot:xlabel='연도', ylabel='국가(대륙)별'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#데이터-미리보기",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#데이터-미리보기",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "데이터 미리보기",
    "text": "데이터 미리보기\n\n# sample, head, tail 통해 데이터 미리보기\ndf.head()\n\n\n\n\n\n  \n    \n      \n      기준년도\n      가입자일련번호\n      성별코드\n      연령대코드(5세단위)\n      시도코드\n      신장(5Cm단위)\n      체중(5Kg 단위)\n      허리둘레\n      시력(좌)\n      시력(우)\n      ...\n      감마지티피\n      흡연상태\n      음주여부\n      구강검진 수검여부\n      치아우식증유무\n      결손치유무\n      치아마모증유무\n      제3대구치(사랑니)이상\n      치석\n      데이터공개일자\n    \n  \n  \n    \n      0\n      2017\n      1\n      1\n      13\n      46\n      170.0\n      65.0\n      91.0\n      1.0\n      1.2\n      ...\n      25.0\n      3.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      20181126\n    \n    \n      1\n      2017\n      2\n      2\n      8\n      41\n      150.0\n      45.0\n      73.4\n      1.2\n      1.0\n      ...\n      10.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      20181126\n    \n    \n      2\n      2017\n      3\n      1\n      8\n      45\n      175.0\n      75.0\n      94.0\n      1.0\n      0.8\n      ...\n      136.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      3\n      2017\n      4\n      2\n      12\n      11\n      155.0\n      55.0\n      67.5\n      0.9\n      1.0\n      ...\n      30.0\n      1.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      4\n      2017\n      5\n      1\n      8\n      41\n      175.0\n      75.0\n      93.0\n      1.5\n      1.5\n      ...\n      68.0\n      3.0\n      0.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n  \n\n5 rows × 34 columns\n\n\n\n\ndf.tail()\n\n\n\n\n\n  \n    \n      \n      기준년도\n      가입자일련번호\n      성별코드\n      연령대코드(5세단위)\n      시도코드\n      신장(5Cm단위)\n      체중(5Kg 단위)\n      허리둘레\n      시력(좌)\n      시력(우)\n      ...\n      감마지티피\n      흡연상태\n      음주여부\n      구강검진 수검여부\n      치아우식증유무\n      결손치유무\n      치아마모증유무\n      제3대구치(사랑니)이상\n      치석\n      데이터공개일자\n    \n  \n  \n    \n      999995\n      2017\n      999996\n      2\n      9\n      41\n      165.0\n      55.0\n      70.0\n      1.5\n      1.5\n      ...\n      11.0\n      1.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      999996\n      2017\n      999997\n      2\n      9\n      11\n      165.0\n      50.0\n      68.0\n      1.2\n      1.5\n      ...\n      11.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      999997\n      2017\n      999998\n      2\n      12\n      27\n      155.0\n      50.0\n      83.8\n      0.2\n      1.0\n      ...\n      12.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      999998\n      2017\n      999999\n      1\n      11\n      47\n      160.0\n      70.0\n      99.0\n      0.8\n      0.9\n      ...\n      35.0\n      2.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      999999\n      2017\n      1000000\n      2\n      9\n      27\n      165.0\n      60.0\n      74.0\n      1.2\n      1.2\n      ...\n      15.0\n      1.0\n      0.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n  \n\n5 rows × 34 columns\n\n\n\n\ndf.sample()\n\n\n\n\n\n  \n    \n      \n      기준년도\n      가입자일련번호\n      성별코드\n      연령대코드(5세단위)\n      시도코드\n      신장(5Cm단위)\n      체중(5Kg 단위)\n      허리둘레\n      시력(좌)\n      시력(우)\n      ...\n      감마지티피\n      흡연상태\n      음주여부\n      구강검진 수검여부\n      치아우식증유무\n      결손치유무\n      치아마모증유무\n      제3대구치(사랑니)이상\n      치석\n      데이터공개일자\n    \n  \n  \n    \n      1931\n      2017\n      1932\n      1\n      10\n      43\n      165.0\n      80.0\n      92.0\n      1.2\n      1.0\n      ...\n      104.0\n      1.0\n      1.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n  \n\n1 rows × 34 columns"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#groupby",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#groupby",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "groupby",
    "text": "groupby\n\n# 성별코드로 그룹화 한 데이터 세어보기\ndf.groupby?\n\n\ndf.groupby([\"성별코드\"])[\"가입자일련번호\"].count()\n\n성별코드\n1    531172\n2    468828\nName: 가입자일련번호, dtype: int64\n\n\n\n# 성별코드와 음주여부로 그룹화 하고 갯수 세기\ndf.groupby([\"성별코드\", \"음주여부\"])[\"가입자일련번호\"].count()\n\n성별코드  음주여부\n1     0.0     175150\n      1.0     355826\n2     0.0     327579\n      1.0     140920\nName: 가입자일련번호, dtype: int64\n\n\n\n# 성별코드와 음주여부로 그룹화 하고 감마지티피의 평균 구하기\n\ndf.groupby([\"성별코드\", \"음주여부\"])[\"감마지티피\"].mean()\n\n성별코드  음주여부\n1     0.0     34.710544\n      1.0     56.707919\n2     0.0     22.660238\n      1.0     25.115149\nName: 감마지티피, dtype: float64\n\n\n\n# 성별코드와 음주여부로 그룹화를 하고 감마지티피의 요약수치를 구한다.\n\ndf.groupby([\"성별코드\", \"음주여부\"])[\"감마지티피\"].describe()\n\n\n\n\n\n  \n    \n      \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      성별코드\n      음주여부\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      0.0\n      175139.0\n      34.710544\n      37.715218\n      1.0\n      18.0\n      25.0\n      38.0\n      999.0\n    \n    \n      1.0\n      355819.0\n      56.707919\n      69.039084\n      1.0\n      24.0\n      37.0\n      63.0\n      999.0\n    \n    \n      2\n      0.0\n      327559.0\n      22.660238\n      25.181300\n      1.0\n      13.0\n      17.0\n      24.0\n      999.0\n    \n    \n      1.0\n      140913.0\n      25.115149\n      35.870812\n      1.0\n      13.0\n      17.0\n      25.0\n      999.0\n    \n  \n\n\n\n\n\n# agg를 사용하면 여러 수치를 함께 구할 수 있다.\ndf.groupby([\"성별코드\", \"음주여부\"])[\"감마지티피\"].agg([\"count\",\"mean\",\"median\"])\n\n\n\n\n\n  \n    \n      \n      \n      count\n      mean\n      median\n    \n    \n      성별코드\n      음주여부\n      \n      \n      \n    \n  \n  \n    \n      1\n      0.0\n      175139\n      34.710544\n      25.0\n    \n    \n      1.0\n      355819\n      56.707919\n      37.0\n    \n    \n      2\n      0.0\n      327559\n      22.660238\n      17.0\n    \n    \n      1.0\n      140913\n      25.115149\n      17.0"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#pivot_table",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#pivot_table",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "pivot_table",
    "text": "pivot_table\n\n\n# 음주여부에 따른 그룹화된 수 피봇테이블 구하기\ndf.pivot_table(index=\"음주여부\")\n\n\n\n\n\n  \n    \n      \n      (혈청지오티)ALT\n      (혈청지오티)AST\n      HDL콜레스테롤\n      LDL콜레스테롤\n      가입자일련번호\n      감마지티피\n      구강검진 수검여부\n      기준년도\n      데이터공개일자\n      성별코드\n      ...\n      청력(우)\n      청력(좌)\n      체중(5Kg 단위)\n      총콜레스테롤\n      치석\n      트리글리세라이드\n      허리둘레\n      혈색소\n      혈청크레아티닌\n      흡연상태\n    \n    \n      음주여부\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      0.0\n      24.107862\n      25.094792\n      56.161852\n      114.467632\n      499800.113284\n      26.858541\n      0.358768\n      2017\n      20181126\n      1.651602\n      ...\n      1.041086\n      1.042881\n      60.082827\n      194.699007\n      0.573111\n      122.063887\n      80.269019\n      13.748950\n      0.837132\n      1.320330\n    \n    \n      1.0\n      27.634991\n      27.069879\n      57.606351\n      111.444394\n      500196.825986\n      47.745678\n      0.439257\n      2017\n      20181126\n      1.283686\n      ...\n      1.020745\n      1.021758\n      66.778226\n      196.346568\n      0.626153\n      144.077696\n      82.484576\n      14.704997\n      0.892460\n      1.896158\n    \n  \n\n2 rows × 29 columns\n\n\n\n\ndf.pivot_table(index=\"음주여부\", values=\"가입자일련번호\", aggfunc=\"count\")\n# mean값이 기본 세팅값이므로 aggfunc로 바꿔주기. \n\n\n\n\n\n  \n    \n      \n      가입자일련번호\n    \n    \n      음주여부\n      \n    \n  \n  \n    \n      0.0\n      502729\n    \n    \n      1.0\n      496746\n    \n  \n\n\n\n\n\ndf.pivot_table(index=\"성별코드\", values=\"가입자일련번호\", aggfunc=\"count\")\n# data frame으로 출력된다! \n\n\n\n\n\n  \n    \n      \n      가입자일련번호\n    \n    \n      성별코드\n      \n    \n  \n  \n    \n      1\n      531172\n    \n    \n      2\n      468828\n    \n  \n\n\n\n\n\n# 음주여부에 따른 감마지티피의 평균 구하기\n\npd.pivot_table(df, index=\"음주여부\", values=\"감마지티피\")\n\n\n\n\n\n  \n    \n      \n      감마지티피\n    \n    \n      음주여부\n      \n    \n  \n  \n    \n      0.0\n      26.858541\n    \n    \n      1.0\n      47.745678\n    \n  \n\n\n\n\n\n# 기본값은 평균을 구하지만 aggfunc를 통해 지정이 가능하다.\n\npd.pivot_table(df, index=\"음주여부\", values=\"감마지티피\", aggfunc=[\"mean\", \"median\"])\n\n\n\n\n\n  \n    \n      \n      mean\n      median\n    \n    \n      \n      감마지티피\n      감마지티피\n    \n    \n      음주여부\n      \n      \n    \n  \n  \n    \n      0.0\n      26.858541\n      19.0\n    \n    \n      1.0\n      47.745678\n      30.0\n    \n  \n\n\n\n\n\n# aggfunc에 describe를 사용해 통계요약값을 볼수있다.\n\npd.pivot_table(df, index=[\"성별코드\", \"음주여부\"], values=\"감마지티피\", aggfunc=\"describe\")\n\n\n\n\n\n  \n    \n      \n      \n      25%\n      50%\n      75%\n      count\n      max\n      mean\n      min\n      std\n    \n    \n      성별코드\n      음주여부\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      0.0\n      18.0\n      25.0\n      38.0\n      175139.0\n      999.0\n      34.710544\n      1.0\n      37.715218\n    \n    \n      1.0\n      24.0\n      37.0\n      63.0\n      355819.0\n      999.0\n      56.707919\n      1.0\n      69.039084\n    \n    \n      2\n      0.0\n      13.0\n      17.0\n      24.0\n      327559.0\n      999.0\n      22.660238\n      1.0\n      25.181300\n    \n    \n      1.0\n      13.0\n      17.0\n      25.0\n      140913.0\n      999.0\n      25.115149\n      1.0\n      35.870812"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#히스토그램",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#히스토그램",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "히스토그램",
    "text": "히스토그램\n\ndf.hist(figsize=(12,12))\n\narray([[<AxesSubplot:title={'center':'기준년도'}>,\n        <AxesSubplot:title={'center':'가입자일련번호'}>,\n        <AxesSubplot:title={'center':'성별코드'}>,\n        <AxesSubplot:title={'center':'연령대코드(5세단위)'}>,\n        <AxesSubplot:title={'center':'시도코드'}>,\n        <AxesSubplot:title={'center':'신장(5Cm단위)'}>],\n       [<AxesSubplot:title={'center':'체중(5Kg 단위)'}>,\n        <AxesSubplot:title={'center':'허리둘레'}>,\n        <AxesSubplot:title={'center':'시력(좌)'}>,\n        <AxesSubplot:title={'center':'시력(우)'}>,\n        <AxesSubplot:title={'center':'청력(좌)'}>,\n        <AxesSubplot:title={'center':'청력(우)'}>],\n       [<AxesSubplot:title={'center':'수축기혈압'}>,\n        <AxesSubplot:title={'center':'이완기혈압'}>,\n        <AxesSubplot:title={'center':'식전혈당(공복혈당)'}>,\n        <AxesSubplot:title={'center':'총콜레스테롤'}>,\n        <AxesSubplot:title={'center':'트리글리세라이드'}>,\n        <AxesSubplot:title={'center':'HDL콜레스테롤'}>],\n       [<AxesSubplot:title={'center':'LDL콜레스테롤'}>,\n        <AxesSubplot:title={'center':'혈색소'}>,\n        <AxesSubplot:title={'center':'요단백'}>,\n        <AxesSubplot:title={'center':'혈청크레아티닌'}>,\n        <AxesSubplot:title={'center':'(혈청지오티)AST'}>,\n        <AxesSubplot:title={'center':'(혈청지오티)ALT'}>],\n       [<AxesSubplot:title={'center':'감마지티피'}>,\n        <AxesSubplot:title={'center':'흡연상태'}>,\n        <AxesSubplot:title={'center':'음주여부'}>,\n        <AxesSubplot:title={'center':'구강검진 수검여부'}>,\n        <AxesSubplot:title={'center':'치아우식증유무'}>,\n        <AxesSubplot:title={'center':'결손치유무'}>],\n       [<AxesSubplot:title={'center':'치아마모증유무'}>,\n        <AxesSubplot:title={'center':'제3대구치(사랑니)이상'}>,\n        <AxesSubplot:title={'center':'치석'}>,\n        <AxesSubplot:title={'center':'데이터공개일자'}>, <AxesSubplot:>,\n        <AxesSubplot:>]], dtype=object)\n\n\n\n\n\n\nh = df.hist(figsize=(12,12))"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#슬라이싱을-사용해-히스토그램-그래기",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#슬라이싱을-사용해-히스토그램-그래기",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "슬라이싱을 사용해 히스토그램 그래기",
    "text": "슬라이싱을 사용해 히스토그램 그래기\n\n# [행, 열]\ndf.iloc[:,:] # 몇번째에 있는 행인지, 컬럼인지 지정 가능\n# [:,:] 전체데이터\n\n\n\n\n\n  \n    \n      \n      기준년도\n      가입자일련번호\n      성별코드\n      연령대코드(5세단위)\n      시도코드\n      신장(5Cm단위)\n      체중(5Kg 단위)\n      허리둘레\n      시력(좌)\n      시력(우)\n      ...\n      감마지티피\n      흡연상태\n      음주여부\n      구강검진 수검여부\n      치아우식증유무\n      결손치유무\n      치아마모증유무\n      제3대구치(사랑니)이상\n      치석\n      데이터공개일자\n    \n  \n  \n    \n      0\n      2017\n      1\n      1\n      13\n      46\n      170.0\n      65.0\n      91.0\n      1.0\n      1.2\n      ...\n      25.0\n      3.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      20181126\n    \n    \n      1\n      2017\n      2\n      2\n      8\n      41\n      150.0\n      45.0\n      73.4\n      1.2\n      1.0\n      ...\n      10.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      20181126\n    \n    \n      2\n      2017\n      3\n      1\n      8\n      45\n      175.0\n      75.0\n      94.0\n      1.0\n      0.8\n      ...\n      136.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      3\n      2017\n      4\n      2\n      12\n      11\n      155.0\n      55.0\n      67.5\n      0.9\n      1.0\n      ...\n      30.0\n      1.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      4\n      2017\n      5\n      1\n      8\n      41\n      175.0\n      75.0\n      93.0\n      1.5\n      1.5\n      ...\n      68.0\n      3.0\n      0.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      999995\n      2017\n      999996\n      2\n      9\n      41\n      165.0\n      55.0\n      70.0\n      1.5\n      1.5\n      ...\n      11.0\n      1.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      999996\n      2017\n      999997\n      2\n      9\n      11\n      165.0\n      50.0\n      68.0\n      1.2\n      1.5\n      ...\n      11.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      999997\n      2017\n      999998\n      2\n      12\n      27\n      155.0\n      50.0\n      83.8\n      0.2\n      1.0\n      ...\n      12.0\n      1.0\n      0.0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      0.0\n      20181126\n    \n    \n      999998\n      2017\n      999999\n      1\n      11\n      47\n      160.0\n      70.0\n      99.0\n      0.8\n      0.9\n      ...\n      35.0\n      2.0\n      1.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n    \n      999999\n      2017\n      1000000\n      2\n      9\n      27\n      165.0\n      60.0\n      74.0\n      1.2\n      1.2\n      ...\n      15.0\n      1.0\n      0.0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      20181126\n    \n  \n\n1000000 rows × 34 columns\n\n\n\n\ndf.iloc[:,:12].hist(figsize=(12,12))\n\narray([[<AxesSubplot:title={'center':'기준년도'}>,\n        <AxesSubplot:title={'center':'가입자일련번호'}>,\n        <AxesSubplot:title={'center':'성별코드'}>],\n       [<AxesSubplot:title={'center':'연령대코드(5세단위)'}>,\n        <AxesSubplot:title={'center':'시도코드'}>,\n        <AxesSubplot:title={'center':'신장(5Cm단위)'}>],\n       [<AxesSubplot:title={'center':'체중(5Kg 단위)'}>,\n        <AxesSubplot:title={'center':'허리둘레'}>,\n        <AxesSubplot:title={'center':'시력(좌)'}>],\n       [<AxesSubplot:title={'center':'시력(우)'}>,\n        <AxesSubplot:title={'center':'청력(좌)'}>,\n        <AxesSubplot:title={'center':'청력(우)'}>]], dtype=object)\n\n\n\n\n\n\n# 슬라이싱을 사용해 앞에서 12번째부터 23번쨰까지 (12:24) \nh = df.iloc[:,12:24].hist(figsize=(12,12), bins=100)   # bins : 막대 개수를 더 ...  연속된 수치데이터를 카테고리 형태로!!"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#countplot---음주여부",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#countplot---음주여부",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "countplot - 음주여부",
    "text": "countplot - 음주여부\n\n# 음주여부에 따른 countplot을 그린다\ndf[\"음주여부\"].value_counts().plot.bar()\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.countplot(x=\"음주여부\", data=df)\n\n<AxesSubplot:xlabel='음주여부', ylabel='count'>\n\n\n\n\n\n\nsns.countplot(x=\"흡연상태\", data=df)\n\n<AxesSubplot:xlabel='흡연상태', ylabel='count'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#hue-옵션-사용하기",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#hue-옵션-사용하기",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "hue 옵션 사용하기",
    "text": "hue 옵션 사용하기\n\n#window\n# sns.set(font_scale=1.5, font=\"Malgun Gothic\") 이렇게도 사용 가능\n\nsns.countplot(data=df, x=\"음주여부\", hue=\"성별코드\")\n\n<AxesSubplot:xlabel='음주여부', ylabel='count'>\n\n\n\n\n\n\n\nsns.countplot(data=df, x=\"연령대코드(5세단위)\", hue=\"음주여부\") \n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='count'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#countplot---키와-몸무게",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#countplot---키와-몸무게",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "countplot - 키와 몸무게",
    "text": "countplot - 키와 몸무게\n\n키와 몸무게는 연속형 데이터이다.\n하지만 데이터는 키는 5cm, 체중은 5kg 단위로 되어 있다.\n이렇게 특정 범위로 묶게 되면 연속형 데이터라기 보다는 범주형 데이터라고 본다.\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df, x=\"신장(5Cm단위)\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='count'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df, x=\"체중(5Kg 단위)\")\n\n<AxesSubplot:xlabel='체중(5Kg 단위)', ylabel='count'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df, x=\"신장(5Cm단위)\", hue=\"성별코드\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='count'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df, x=\"체중(5Kg 단위)\", hue=\"성별코드\")\n\n<AxesSubplot:xlabel='체중(5Kg 단위)', ylabel='count'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.countplot(data=df, x=\"체중(5Kg 단위)\", hue=\"음주여부\")\n\n<AxesSubplot:xlabel='체중(5Kg 단위)', ylabel='count'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#braplot---수치형-vs-범주형",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#braplot---수치형-vs-범주형",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "14. 4 braplot - 수치형 vs 범주형",
    "text": "14. 4 braplot - 수치형 vs 범주형\n\n# 연령대코드와 총 콜레스테롤 보기\n# hue로 색상 다르게 표현. 음주여부 같이 보기\n\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"총콜레스테롤\", hue=\"음주여부\")\n\n# 느리다! countplot와 비교했을때 ! 백만개의 데이터가 있는데.. 연령대 코드별로 총 콜레스테롤을 그리긴 했지만. .\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='총콜레스테롤'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"총콜레스테롤\", hue=\"흡연상태\")\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='총콜레스테롤'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.barplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"총콜레스테롤\", hue=\"흡연상태\")\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='총콜레스테롤'>\n\n\n\n\n\n\n#트리글리세라이드(중성지방)에 따른 연령대코드(5세단위)를 음주여부에 따라 barplot로 그리기\nsns.barplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"트리글리세라이드\", hue=\"음주여부\", ci=95)\n\n# 검은색 막대: 신뢰구간을 의미 (ci: 95)-> 95%의 신뢰구간을 표시한다.\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='트리글리세라이드'>\n\n\n\n\n\n\nsns.barplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"트리글리세라이드\", hue=\"음주여부\", ci=\"sd\") #sd:표준편차\n# sample로 그려서 편차가 커보인다. \n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='트리글리세라이드'>\n\n\n\n\n\n\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"트리글리세라이드\", hue=\"음주여부\", ci=\"sd\") #sd:표준편차\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='트리글리세라이드'>\n\n\n\n\n\n\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"트리글리세라이드\", hue=\"음주여부\", ci=None) #sd:표준편차\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='트리글리세라이드'>\n\n\n\n\n\n\n# 연령대코드와 체중(5kg 단위)을 성별에 따라서.\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"체중(5Kg 단위)\", hue=\"성별코드\", ci=None) \n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nsns.barplot(data=df, x=\"연령대코드(5세단위)\", y=\"체중(5Kg 단위)\", hue=\"음주여부\", ci=None)\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='체중(5Kg 단위)'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#lineplot-and-pointplot",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#lineplot-and-pointplot",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "lineplot and pointplot",
    "text": "lineplot and pointplot\n\nsns.lineplot(data=df, x=\"연령대코드(5세단위)\", y=\"체중(5Kg 단위)\", hue=\"성별코드\", ci=None)\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nsns.lineplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"체중(5Kg 단위)\", hue=\"성별코드\")\n# 그림자로 표시!! \n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.lineplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"체중(5Kg 단위)\", hue=\"성별코드\", ci=\"sd\")\n# 그림자로 표시!! \n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.lineplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"신장(5Cm단위)\", hue=\"성별코드\", ci=\"sd\")\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='신장(5Cm단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.lineplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"신장(5Cm단위)\", hue=\"음주여부\", ci=\"sd\")\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='신장(5Cm단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.pointplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"신장(5Cm단위)\", hue=\"음주여부\", ci=\"sd\")\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='신장(5Cm단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.barplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"신장(5Cm단위)\", hue=\"음주여부\", ci=\"sd\")\nsns.pointplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"신장(5Cm단위)\", hue=\"음주여부\", ci=\"sd\")\n# 두개를 겹쳐서 그릴 수도 있다.\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='신장(5Cm단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.lineplot(data=df, x=\"연령대코드(5세단위)\", y=\"혈색소\", hue=\"음주여부\", ci=None)\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='혈색소'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#boxplot",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#boxplot",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "boxplot",
    "text": "boxplot\n\n# boxplot으로 신장에 따른 체중을 그리며, 성별코드에 따른 색상으로 표현하기\nplt.figure(figsize=(15,4))\nsns.boxplot(data=df, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\", hue=\"성별코드\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.boxplot(data=df, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\", hue=\"음주여부\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#violinplot",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#violinplot",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "violinplot",
    "text": "violinplot\n\nplt.figure(figsize=(15,4))\nsns.violinplot(data=df, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.violinplot(data=df_sample, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\", hue=\"음주여부\")\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.violinplot(data=df_sample, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\", hue=\"음주여부\", split=True)\n# split : 두개의 값을 합쳐서 그림\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.violinplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"혈색소\", hue=\"음주여부\", split=True)\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='혈색소'>"
  },
  {
    "objectID": "posts/est/4. 건강검진 데이터로 가설검정.html#swarm-plot",
    "href": "posts/est/4. 건강검진 데이터로 가설검정.html#swarm-plot",
    "title": "5: 건강검진 데이터로 가설검정",
    "section": "swarm plot",
    "text": "swarm plot\n\n범주형 데이터를 산점도로 시각화하고자 할 대 사용한다.\n\n\nplt.figure(figsize=(15,4))\nsns.swarmplot(data=df_sample, x=\"신장(5Cm단위)\", y=\"체중(5Kg 단위)\", hue=\"음주여부\")\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 37.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 52.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 51.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 55.4% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 48.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 26.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\n\n\n<AxesSubplot:xlabel='신장(5Cm단위)', ylabel='체중(5Kg 단위)'>\n\n\n\n\n\n\nplt.figure(figsize=(15,4))\nsns.swarmplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"혈색소\", hue=\"음주여부\")\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.1% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 12.8% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 9.3% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 11.2% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\n\n\n<AxesSubplot:xlabel='연령대코드(5세단위)', ylabel='혈색소'>\n\n\n\n\n\n\n# lmplot 으로 그리기\nsns.lmplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"혈색소\", hue=\"음주여부\")\n# 회귀선을 그려서 상관관계를 보여준다.\n\n<seaborn.axisgrid.FacetGrid at 0x294282b0790>\n\n\n\n\n\n\n# lmplot 으로 그리기\nsns.lmplot(data=df_sample, x=\"연령대코드(5세단위)\", y=\"혈색소\", hue=\"음주여부\", col=\"성별코드\")\n# 회귀선을 그려서 상관관계를 보여준다.\n# col통해서 여러게 나오게 한다. \n\n<seaborn.axisgrid.FacetGrid at 0x294289fddf0>"
  },
  {
    "objectID": "posts/ref/Ref.html",
    "href": "posts/ref/Ref.html",
    "title": "Ref",
    "section": "",
    "text": "- ref: https://3months.tistory.com/392\n\n주피터 랩 단축키\n\n- ref: Markdown 문법\n\n- ref: Quarto, Quarto\n\nQuarto 블로그"
  },
  {
    "objectID": "posts/ref/Ref.html#essi-alizadeh",
    "href": "posts/ref/Ref.html#essi-alizadeh",
    "title": "Ref",
    "section": "Essi Alizadeh",
    "text": "Essi Alizadeh"
  },
  {
    "objectID": "posts/ref/Untitled.html",
    "href": "posts/ref/Untitled.html",
    "title": "coco",
    "section": "",
    "text": "1+1\n\n2"
  },
  {
    "objectID": "posts/Machine Learning/MachineLearning_midterm(202250926).html",
    "href": "posts/Machine Learning/MachineLearning_midterm(202250926).html",
    "title": "기계학습 midterm",
    "section": "",
    "text": "import torch \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom fastai.vision.all import *\n\n\n1. 크롤링을 통한 이미지 분석 및 CAM\n\n#\n# 크롤링에 필요한 준비작업들\n!pip install -Uqq duckduckgo_search\nfrom duckduckgo_search import ddg_images\nfrom fastdownload import download_url\nfrom fastcore.all import *\ndef search_images(term, max_images=200): return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n\n\n\n# \n# 폴더만드는코드 -- 사실 손으로 만들어도 무방함.. \n!mkdir images\n!mkdir images/train\n!mkdir images/test \n!mkdir images/train/Harry Potter\n!mkdir images/train/Ronald Bilius Weasley\n!mkdir images/test/Harry Potter\n!mkdir images/test/Ronald Bilius Weasley\n\nmkdir: cannot create directory ‘images’: File exists\nmkdir: cannot create directory ‘images/train’: File exists\nmkdir: cannot create directory ‘images/test’: File exists\nmkdir: cannot create directory ‘Potter’: File exists\nmkdir: cannot create directory ‘Bilius’: File exists\nmkdir: cannot create directory ‘Weasley’: File exists\n\n\n\ndownload_images(dest='./images/train/Harry Potter',urls=search_images('Harry Potter',max_images=200))\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Ronald Bilius Weasley',urls=search_images('Ronald Bilius Weasley',max_images=200)) \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Harry Potter',urls=search_images('Harry Potter movie',max_images=200))  \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Ronald Bilius Weasley',urls=search_images('Ronald Weasley',max_images=200))\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\ndownload_images(dest='./images/test/Harry Potter',urls=search_images('Harry Potter photo',max_images=50)) \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/Ronald Bilius Weasley',urls=search_images('Ronald Bilius Weasley photo',max_images=50))  \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n\n(#62) [Path('images/train/Harry Potter/d75f9d42-7db5-418a-bc65-8a10c4dd6df3.jpg'),Path('images/train/Harry Potter/fbdce828-967e-4ee0-99dc-74b065cec931.jpg'),Path('images/train/Harry Potter/f2216c3c-9d40-4551-8dbc-0812b61be308.jpg'),Path('images/train/Harry Potter/72319413-8aed-4ff8-bd15-9247c9e6b9fc.jpg'),Path('images/train/Harry Potter/5a5656d6-b298-43f1-88dd-526eb597258a.jpg'),Path('images/train/Harry Potter/cfa5a057-4bbe-43a1-9bdd-7e6214fef746.jpg'),Path('images/train/Harry Potter/6902097c-8e55-4fc7-b5c8-aa6cb88a287e.jpg'),Path('images/train/Harry Potter/e1af5803-a0f0-4311-9c54-95b1506ee512.jpg'),Path('images/train/Harry Potter/1a6e2dd5-d8d0-4220-969f-05aa234af09d.jpg'),Path('images/train/Harry Potter/506feddc-f171-4808-9643-66183bc85d6d.jpg')...]\n\n\n\nbad_images.map(Path.unlink)\n\n(#62) [None,None,None,None,None,None,None,None,None,None...]\n\n\n\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \n\n\ndls.show_batch()\n\n\n\n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.944444\n      1.663112\n      0.458763\n      01:01\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.539615\n      1.090526\n      0.567010\n      01:03\n    \n  \n\n\n\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(), \n    torch.nn.Linear(512,2,bias=False) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy)\n\n\nlrnr2.fine_tune(5) \n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00<?]\n    \n    \n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n  \n\n\n    \n      \n      0.00% [0/140 00:00<?]\n    \n    \n\n\nRuntimeError: ignored\n\n\n\ndls.vocab\n# net(x)에서 뒤쪽의 값이 클수록 \"yunakim\" 을 의미한다.\n\n['yeonkyungkim', 'yunakim']\n\n\n\nximg = PILImage.create('/content/images/test/yeonkyungkim/5f00874f-87e0-47ea-b299-411238c078f3.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij->acij',net2[2].weight,net1(x))\n\n\nnet2[0](why)\n\nTensorImage([[[[0.2771]],\n\n              [[0.0351]]]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nnet(x)\n\nTensorImage([[0.2771, 0.0351]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nximg\n\n\n\n\n\nnet2(net1(x))\n\nTensorImage([[0.2771, 0.0351]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n0.2771>0.0421 이므로 ximg는 yenkyungkim일 확률이 더 높다.\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(0.2771, device='cuda:0', grad_fn=<AliasBackward0>),\n TensorImage(0.0351, device='cuda:0', grad_fn=<AliasBackward0>))\n\n\n\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0,  0, -2, -3, -2, -1,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0, -1, -3, -3, -1,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0, -3, -3, -2,  0,  1,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [-1, -4, -3,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0],\n             [-2, -3, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  1],\n             [-1, -2, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  3],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  2,  2],\n             [ 0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  1,  2,  2,  1,  2,  2,  2,  1,  0,  0,  0,  0,  0,  0,  0]],\n            device='cuda:0')\n\n\n\nwhy_yeonkyungkim = why[0,0,:,:]\nwhy_yunakim = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_yeonkyungkim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_yunakim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n<matplotlib.image.AxesImage at 0x7f48ffaa2ad0>\n\n\n\n\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_yeonkyungkim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_yunakim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n<matplotlib.image.AxesImage at 0x7f4844ce5d10>\n\n\n\n\n\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\npath = './images'\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=100\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\n\n2. Overparameterized Model\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\nx[:5]\n\ntensor([[ 0.5621],\n        [-0.7204],\n        [ 0.2043],\n        [-0.9416],\n        [ 0.7436]])\n\n\n\n# (1) y= beta0 + beta1*x1 + e \nnet = torch.nn.Linear(1,1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[6.3128]]), tensor([3.1519]))\n\n\nbeta0 = 3.1519, beta1=6.3128\n\n# (2) y= beta0 + e\nw0hat = torch.tensor([0.00],requires_grad=True) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = x*0 + w0hat \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    w0hat.data = w0hat.data - 0.1 * w0hat.grad\n    w0hat.grad = None\n\n\n# 학습 후\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\n\n\n\n\n\nw0hat\n\ntensor([3.1982], requires_grad=True)\n\n\n\nbeta0 = 3.1982\n\n\n# (3) y=beta1*x + e \n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nnet.weight\n\nParameter containing:\ntensor([[6.3822]], requires_grad=True)\n\n\n\nbeta1 = 6.3822\n\n\n# (4) y= alpha0 + beta0 + beta1*x + e\n_1 = torch.ones([1000,1])\nX = torch.concat([_1,x],axis=1)\n\n\nnet = torch.nn.Linear(in_features=2,out_features=1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([1.3951], requires_grad=True), Parameter containing:\n tensor([[1.7568, 6.3125]], requires_grad=True))\n\n\n\n# alpha0 + beta0\n1.3951+1.7568\n\n3.1519\n\n\n\nalpha0 + beat0 = 3.1519 이며 (1)에서 구한 beta0 값인 3.1519와 동일하다.\n\n\n# (5) y=alpha0 + beta0 + beta1*x + alpha1*x + e\nX = torch.concat([_1,_1,x,x],axis=1) \nX\n\ntensor([[ 1.0000,  1.0000,  0.5621,  0.5621],\n        [ 1.0000,  1.0000, -0.7204, -0.7204],\n        [ 1.0000,  1.0000,  0.2043,  0.2043],\n        ...,\n        [ 1.0000,  1.0000, -0.6327, -0.6327],\n        [ 1.0000,  1.0000,  0.8546,  0.8546],\n        [ 1.0000,  1.0000,  0.3835,  0.3835]])\n\n\n\nnet = torch.nn.Linear(in_features=4,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[1.7991, 1.3527, 3.3789, 2.9408]], requires_grad=True), None)\n\n\n\n# alpha0 + beta0\n1.7991+1.3527\n\n3.1517999999999997\n\n\n\n# alpha1 + beta1\n3.3789+2.9408\n\n6.319699999999999\n\n\n\nalpha0+beta0 = 3.1518, alpha1+beta1 = 6.3197로 (1)에서 구한 값과 비슷하다.\n\n\n민정, 슬기, 성재, 세민, 구환 모두 옳은 설명\n\n\n\n3. 차원축소기법과 표현학습\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/STML2022/master/posts/iris.csv\")\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n      Species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      145\n      6.7\n      3.0\n      5.2\n      2.3\n      virginica\n    \n    \n      146\n      6.3\n      2.5\n      5.0\n      1.9\n      virginica\n    \n    \n      147\n      6.5\n      3.0\n      5.2\n      2.0\n      virginica\n    \n    \n      148\n      6.2\n      3.4\n      5.4\n      2.3\n      virginica\n    \n    \n      149\n      5.9\n      3.0\n      5.1\n      1.8\n      virginica\n    \n  \n\n150 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nX = torch.tensor(df.drop(columns=['Species']).to_numpy(), dtype=torch.float32)\n\n\nX.shape\n\ntorch.Size([150, 4])\n\n\n\nl1 = torch.nn.Linear(in_features=4, out_features=2, bias=False)\nprint(l1(X).shape)\n\ntorch.Size([150, 2])\n\n\n\n# k=3이상인 경우 softmax와 crossentropyloss사용\n\na1=torch.nn.Softmax(dim=1)\nZ=a1(l1(X))\n\n\nl2 = torch.nn.Linear(in_features=2, out_features=4, bias=False)\n\n\nXhat = l2(l1(X))\n\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // before learning',size=25);\n\n\n\n\n\nnet = torch.nn.Sequential(\n    l1,   # 선형변환 \n    l2,\n)\n\nloss_fn= torch.nn.MSELoss()\noptimizr= torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1000): \n    ## 1 \n    Z = net[0](X)\n    Xhat = net[1](Z) \n    ## 2 \n    loss=loss_fn(Xhat,X) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // after learning',size=25);\n\n\n\n\n\n# (4) Z -> y 로 가는 네트워크 설계\n\nnet=torch.nn.Linear(2,4)\n\n\nnet(Z)[:5]\n\ntensor([[ 1.9397, -2.4390,  4.0082, -4.5496],\n        [ 1.8009, -2.3025,  3.7815, -4.3085],\n        [ 1.8454, -2.2254,  3.7054, -4.1847],\n        [ 1.8578, -2.2069,  3.6879, -4.1551],\n        [ 1.9715, -2.4088,  3.9845, -4.5026]], grad_fn=<SliceBackward0>)\n\n\n\nloss_fn= torch.nn.BCEWithLogitsLoss()\noptimizr= torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1000): \n    ## 1 \n    Xhat = net(Z)\n    ## 2 \n    loss=loss_fn(Xhat,X) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n    # 오류가 나는데 밑에 글을 봐도 잘 모르겠어용.. ㅠㅠ \n\nRuntimeError: ignored\n\n\n\n규빈, 민정, 성재, 슬기 모두 옳은 설명이다."
  },
  {
    "objectID": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html",
    "href": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html",
    "title": "기계학습 final(교수님)",
    "section": "",
    "text": "기말고사"
  },
  {
    "objectID": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#hihello-90점",
    "href": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#hihello-90점",
    "title": "기계학습 final(교수님)",
    "section": "1. hi?hello!! (90점)",
    "text": "1. hi?hello!! (90점)\n아래와 같은 데이터가 있다고 하자.\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['h', 'i', '?', 'h', 'e'], ['i', '?', 'h', 'e', 'l'])\n\n\ntxt_x와 txt_y를 이용하여 아래와 같은 순서로 다음문자를 예측하고 싶은 신경망을 설계하고 싶다.\nh \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) l \\(\\to\\) l \\(\\to\\) o \\(\\to\\) ! \\(\\to\\) ! \\(\\to\\) h \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) \\(\\dots\\)\n(1)-(6) 의 풀이에 공통적으로 필요한 과정 정리\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n(1) torch.nn.RNN()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nrnn = torch.nn.RNN(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, hT = rnn(x) # _water 사실 생략할 수 있어요..\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(2) torch.nn.RNNCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\ntorch.manual_seed(43052)\nrnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.008, 0.972, 0.014, 0.001, 0.   ],\n       [0.   , 0.997, 0.002, 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.001, 0.999, 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.998, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(3) torch.nn.Module을 상속받은 클래스를 정의하고 (2)의 결과와 동일한 적합값이 나오는 신경망을 설계한 뒤 학습하라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않으면 점수없음.\ntorch.nn.RNN(), torch.nn.RNNCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.RNN(), torch.nn.RNNCell()을 코드에 포함시키는 것이 가능)\n\n(풀이)\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,8)\n        self.h2h = torch.nn.Linear(8,8) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,ht):\n        ht = self.tanh(self.i2h(xt)+self.h2h(ht))\n        return ht\n\n\nrnncell = rNNCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n## 초기화의 설정을 위한 코드\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\n_linr = torch.nn.Linear(8,7).to(\"cuda:0\")\nrnncell.i2h.weight.data = _rnncell.weight_ih.data \nrnncell.h2h.weight.data = _rnncell.weight_hh.data \nrnncell.h2h.bias.data = _rnncell.bias_hh.data\nrnncell.i2h.bias.data = _rnncell.bias_ih.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht)\n        ot = linr(ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.008, 0.972, 0.014, 0.001, 0.   ],\n       [0.   , 0.997, 0.002, 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.001, 0.999, 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.998, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(4) torch.nn.LSTM()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, (hT,cT) = lstm(x)\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(5) torch.nn.LSTMCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []\n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.014, 0.084, 0.081, 0.822, 0.   , 0.   ],\n       [0.002, 0.91 , 0.   , 0.083, 0.003, 0.   , 0.001],\n       [0.001, 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.005, 0.072, 0.917, 0.004, 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.001, 0.995, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.999, 0.001],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.999],\n       [0.998, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.99 , 0.   , 0.006, 0.001, 0.   , 0.003, 0.   ],\n       [0.007, 0.   , 0.992, 0.   , 0.   , 0.001, 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(6) (5)의 결과와 동일한 적합값을 출력하는 신경망을 직접설계한 뒤 학습시켜라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않아도 무방함.\ntorch.nn.LSTM(), torch.nn.LSTMCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.LSTM(), torch.nn.LSTMCell()을 코드에 포함시키는 것은 가능)\n\n(풀이)\n\nclass lSTMCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,16)\n        self.h2h = torch.nn.Linear(4,16) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,past):\n        ht,ct = past \n        ifgo = self.i2h(xt) + self.h2h(ht) \n        it = sig(ifgo[0:4])\n        ft = sig(ifgo[4:8])\n        gt = tanh(ifgo[8:12])\n        ot = sig(ifgo[12:16])\n        ct = ft*ct + it*gt\n        ht = ot*self.tanh(ct) \n        return ht,ct\n\n\nlstmcell = lSTMCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n# 초기값셋팅\ntorch.manual_seed(43052) \n_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\nlstmcell.i2h.weight.data = _lstmcell.weight_ih.data \nlstmcell.h2h.weight.data = _lstmcell.weight_hh.data \nlstmcell.i2h.bias.data = _lstmcell.bias_ih.data\nlstmcell.h2h.bias.data = _lstmcell.bias_hh.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []     \n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);"
  },
  {
    "objectID": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "href": "posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "title": "기계학습 final(교수님)",
    "section": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)",
    "text": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)\n(1) LSTM은 RNN보다 장기기억에 유리하다. (True)\n(2) torch.nn.Embedding(num_embeddings=2,embedding_dim=1)와 torch.nn.Linear(in_features=1,out_features=1)의 학습가능한 파라메터수는 같다. (True)\n(3) 아래와 같은 네트워크를 고려하자.\nnet = torch.nn.Linear(1,1)\n차원이 (n,1) 인 임의의 텐서에 대하여 net(x)와 net.forward(x)의 출력결과는 같다. (True)\n(4) 아래와 같이 a,b,c,d 가 반복되는 문자열이 반복되는 자료에서 다음문자열을 맞추는 과업을 수행하기 위해서는 반드시 순환신경망의 형태로 설계해야만 한다. (False) –> 오타로인하여 문제삭제\na,b,c,d,a,b,c,d,...\n(5) RNN 혹은 LSTM 으로 신경망을 설계할 시 손실함수는 항상 torch.nn.CrossEntropyLoss 를 사용해야 한다. (False)"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html",
    "href": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html",
    "title": "기계학습 (1026) 8주차",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xkHPJ1DiPKfseoBl9yUY4P"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#imports",
    "href": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#imports",
    "title": "기계학습 (1026) 8주차",
    "section": "imports",
    "text": "imports\n\nimport torch \nimport torchvision\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#transfer-learning",
    "href": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#transfer-learning",
    "title": "기계학습 (1026) 8주차",
    "section": "Transfer Learning",
    "text": "Transfer Learning\n\npath = untar_data(URLs.CIFAR)\n\n\n\n\n\n\n    \n      \n      100.00% [168173568/168168549 00:04<00:00]\n    \n    \n\n\n\npath.ls()\n\n(#3) [Path('/root/.fastai/data/cifar10/train'),Path('/root/.fastai/data/cifar10/test'),Path('/root/.fastai/data/cifar10/labels.txt')]\n\n\n\n수제네트워크\n\ndls\n\n\ndls = ImageDataLoaders.from_folder(path,train='train',valid='test') \n\n\n_X,_y = dls.one_batch()\n_X.shape, _y.shape\n\n(torch.Size([64, 3, 32, 32]), torch.Size([64]))\n\n\n\n!ls /home/cgb4/.fastai/data/cifar10/train # 10개의 클래스\n\nairplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n\n\n\ndls.show_batch() #어떠한 이미지가 어떠한 라벨로 되어있는지 확인이 가능하다.\n\n\n\n\n\nlrnr 생성\n\n\nnet1 = torch.nn.Sequential( #수제네트워크: 임의로 지정한 네트워크\n    torch.nn.Conv2d(3,128,(5,5)), #conv.:선형변환 \n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\n\nnet1(_X.to(\"cpu\")).shape\n\ntorch.Size([64, 25088])\n\n\n\nnet = torch.nn.Sequential(\n    net1, \n    torch.nn.Linear(25088,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.104867\n      1.105857\n      0.620600\n      00:04\n    \n    \n      1\n      0.961969\n      1.050836\n      0.640000\n      00:04\n    \n    \n      2\n      0.902597\n      1.058793\n      0.637600\n      00:04\n    \n    \n      3\n      0.854093\n      1.036581\n      0.657200\n      00:04\n    \n    \n      4\n      0.779191\n      1.013788\n      0.663400\n      00:04\n    \n    \n      5\n      0.723487\n      1.091586\n      0.642500\n      00:04\n    \n    \n      6\n      0.694052\n      1.064836\n      0.655700\n      00:04\n    \n    \n      7\n      0.629718\n      1.044633\n      0.668900\n      00:04\n    \n    \n      8\n      0.589516\n      1.168362\n      0.645100\n      00:04\n    \n    \n      9\n      0.572035\n      1.117689\n      0.654800\n      00:04\n    \n  \n\n\n\n\n이게 생각보다 잘 안맞아요.. 70넘기 힘듬\n\n\n\n전이학습 (남이 만든 네트워크)\n\nlrnr 생성\n\n\n#collapse_output\nnet = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1)\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n\\(k=1000\\) 즉 1000개의 물체를 구분하는 모형임\n\n\nnet.fc = torch.nn.Linear(in_features=512, out_features=10) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy)\n\n\n학습\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.813139\n      0.803660\n      0.735300\n      00:10\n    \n    \n      1\n      0.667533\n      0.742656\n      0.756300\n      00:11\n    \n    \n      2\n      0.544296\n      0.735011\n      0.755900\n      00:10\n    \n    \n      3\n      0.449801\n      0.671868\n      0.784000\n      00:10\n    \n    \n      4\n      0.390996\n      0.657825\n      0.780100\n      00:11\n    \n    \n      5\n      0.310046\n      0.690071\n      0.788700\n      00:10\n    \n    \n      6\n      0.259605\n      0.671683\n      0.802500\n      00:10\n    \n    \n      7\n      0.199240\n      0.715251\n      0.796800\n      00:10\n    \n    \n      8\n      0.195551\n      0.772891\n      0.795100\n      00:10\n    \n    \n      9\n      0.150421\n      0.764864\n      0.801600\n      00:10\n    \n  \n\n\n\n\nCIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음\n일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다.\n\n\n\n전이학습 다른 구현: 순수 fastai 이용\n- 예전코드 복습\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfiles= get_image_files(path)\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.191067\n      0.027880\n      0.991881\n      00:29\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.039166\n      0.012174\n      0.996617\n      00:37\n    \n  \n\n\n\n- 사실 위의 코드가 transfer learning 이었음.\n\n#collapse_output\nlrnr.model\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#cam",
    "href": "posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#cam",
    "title": "기계학습 (1026) 8주차",
    "section": "CAM",
    "text": "CAM\n\nCAM이란?\n\nref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n- Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술\n\n\n학습에 사용할 데이터 Load\n\npath = untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:18<00:00]\n    \n    \n\n\n\npath.ls()\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_46.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_64.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pomeranian_82.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_131.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_38.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_18.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_84.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Russian_Blue_253.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_25.jpg')...]\n\n\n\nfiles= get_image_files(path)\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\n\n구현0단계– 예비학습\n\n# 하나의 이미지 선택\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nximg\n\n\n\n\n\nx = first(dls.test_dl([ximg]))[0] #이미지를 숫자 형태로 가져오고 싶음 이미지에 대응하는 숫자들.. \nx\n\nTensorImage([[[[0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8745, 0.8784, 0.8824,  ..., 0.8902, 0.8863, 0.8824],\n               [0.9059, 0.8980, 0.8902,  ..., 0.8824, 0.8863, 0.8824],\n               [0.8863, 0.8863, 0.8824,  ..., 0.8784, 0.8863, 0.8863]],\n\n              [[0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8784, 0.8824, 0.8863,  ..., 0.8745, 0.8667, 0.8588],\n               [0.9098, 0.9020, 0.8902,  ..., 0.8745, 0.8706, 0.8627],\n               [0.8902, 0.8902, 0.8784,  ..., 0.8784, 0.8745, 0.8706]],\n\n              [[0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               ...,\n               [0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n               [0.9176, 0.9137, 0.9059,  ..., 0.8745, 0.8706, 0.8667],\n               [0.8980, 0.9020, 0.8980,  ..., 0.8745, 0.8706, 0.8667]]]],\n            device='cuda:0')\n\n\n\n\n# AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1) # 데이터를 요약하는 방식 중 평균을 내는 방법 \n\n\nX = torch.arange(48).reshape(1,3,4,4)*1.0  #X는 아무 값이나 4*4의 컬러 이미지\nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) #각 채널들의 평균값 \n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nX[0,0,...].mean(),X[0,1,...].mean(),X[0,2,...].mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\n\n# torch.einsum\n(예시1)\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntorch.einsum('ij->ji',tsr) #tsr.T 해도 됨. \n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n(예시2)\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1 @ tsr2 #4X5행렬\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -> ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n(예시3)\n\nx.to(\"cpu\").shape #(1,3,512,512) -> (512,512,3)으로 바꾸고 싶다.\n\ntorch.Size([1, 3, 512, 512])\n\n\n\ntorch.einsum('ocij -> ijc',x.to(\"cpu\")).shape\n\ntorch.Size([512, 512, 3])\n\n\n\nplt.imshow(torch.einsum('ocij -> ijc',x.to(\"cpu\")))\n\n<matplotlib.image.AxesImage at 0x7f5fc4136290>\n\n\n\n\n\n\n\n\n구현1단계– 이미지분류 잘하는 네트워크 선택\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.169602\n      0.011903\n      0.996617\n      00:29\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.052203\n      0.012352\n      0.998647\n      00:38\n    \n  \n\n\n\n\n\n구현2단계– 네트워크의 끝 부분 수정\n- 모형의 분해\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n- net2를 좀더 살펴보자.\n\nnet2\n\nSequential(\n  (0): AdaptiveConcatPool2d(\n    (ap): AdaptiveAvgPool2d(output_size=1)\n    (mp): AdaptiveMaxPool2d(output_size=1)\n  )\n  (1): fastai.layers.Flatten(full=False)\n  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (3): Dropout(p=0.25, inplace=False)\n  (4): Linear(in_features=1024, out_features=512, bias=False)\n  (5): ReLU(inplace=True)\n  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (7): Dropout(p=0.5, inplace=False)\n  (8): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nprint(net1(_X).shape)\nprint(net2[0](net1(_X)).shape)\nprint(net2[1](net2[0](net1(_X))).shape)\nprint(net2[2](net2[1](net2[0](net1(_X)))).shape)\n\n# (64,512,16,16) \n# ↓AP:mean\n# (64,512,1,1) \n# ↓MP(Maxpooling):max\n# (64,512,1,1) \n\ntorch.Size([64, 512, 16, 16])\ntorch.Size([64, 1024, 1, 1])\ntorch.Size([64, 1024])\ntorch.Size([64, 1024])\n\n\n- net2를 아래와 같이 수정하고 재학습하자 (왜?)\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # (64,512,16,16) -> (64,512,1,1) \n    torch.nn.Flatten(), # (64,512,1,1) -> (64,512) \n    torch.nn.Linear(512,2,bias=False) # (64,512) -> (64,2) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy) # loss_fn??\n\n\nlrnr2.loss_func, lrnr.loss_func ## 알아서 기존의 loss function으로 잘 들어가 있음. \n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 수정해서 accuracy가 안좋아지긴 했는데 그래도 쓸만함 \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.252908\n      0.741022\n      0.755751\n      00:38\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.130946\n      0.126084\n      0.957375\n      00:38\n    \n    \n      1\n      0.143405\n      0.229703\n      0.905954\n      00:38\n    \n    \n      2\n      0.092800\n      0.104366\n      0.962788\n      00:38\n    \n    \n      3\n      0.046969\n      0.043439\n      0.983762\n      00:38\n    \n    \n      4\n      0.024211\n      0.038318\n      0.983762\n      00:38\n    \n  \n\n\n\n\n\n구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정하였을 경우 출력과정 상상\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nnet2\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nprint(net1(x).shape)\nprint(net2[0](net1(x)).shape)\nprint(net2[1](net2[0](net1(x))).shape)\nprint(net2[2](net2[1](net2[0](net1(x)))).shape)\n\ntorch.Size([1, 512, 16, 16])\ntorch.Size([1, 512, 1, 1])\ntorch.Size([1, 512])\ntorch.Size([1, 2])\n\n\n- 최종결과 확인\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\ndls.vocab\n\n['cat', 'dog']\n\n\n\nnet(x)에서 뒤쪽의 값이 클수록 ’dog’를 의미한다.\n\n- net2의 순서 바꾸기 전 전체 네트워크:\n\\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [-9.0358,  9.0926]\\]\n- 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)\n\\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [−9.0358,9.0926]\\]\n\n여기에서 (1,512,16,16) -> (1,2,16,16) 로 가는 선형변환을 적용하는 방법? (16,16) each pixel에 대하여 (512 \\(\\to\\) 2)로 가는 변환을 수행\n\n- 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까)\n\n_x =torch.tensor([1,2,3.14,4]).reshape(4,1)\n_x \n\ntensor([[1.0000],\n        [2.0000],\n        [3.1400],\n        [4.0000]])\n\n\n\n_l1 = torch.nn.Linear(1,1,bias=False)\n_l1(_x).mean() # _x -> 선형변환 -> 평균 \n\ntensor(-1.4045, grad_fn=<MeanBackward0>)\n\n\n\n_l1(_x.mean().reshape(1,1)) # _x -> 평균 -> 선형변환\n\ntensor([[-1.4045]], grad_fn=<MmBackward0>)\n\n\n- 구현해보자.\n\nwhy = torch.einsum('cb,abij->acij',net2[2].weight,net1(x))\n\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n\n잠깐 멈추고 생각\n- 이미지\n\nximg\n\n\n\n\n- 네트워크의 결과\n\nnet2(net1(x))\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n-9.0358 << 9.0926 이므로 ’ximg’는 높은 확률로 개라는 뜻이다.\n\n- 아래의네트워크를 관찰\n\\[\\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [-9.0358,9.0926]\\]\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n더 파고들어서 분석해보자.\n\nwhy.shape\n\ntorch.Size([1, 2, 16, 16])\n\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(-9.0358, device='cuda:0', grad_fn=<AliasBackward0>),\n TensorImage(9.0926, device='cuda:0', grad_fn=<AliasBackward0>))\n\n\nwhy[0,0,:,:]\n\n#collapse_output\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[   0,    0,    0,    0,    0,    0,   -1,   -4,   -5,   -4,   -1,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -12,  -26,  -33,  -28,  -14,\n                -3,    0,    0,    0,    0],\n             [   0,    0,    1,    1,    0,   -2,  -22,  -60,  -75,  -73,  -41,\n               -10,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -2,  -25,  -75, -116, -110,  -64,\n               -18,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -22,  -76, -147, -132,  -69,\n               -21,   -1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -16,  -60, -112, -110,  -59,\n               -18,   -3,    0,    0,   -7],\n             [   0,    0,    0,    0,    0,    0,   -9,  -38,  -66,  -66,  -37,\n               -12,   -2,    0,    0,   -2],\n             [   0,    1,    1,    0,    0,    0,   -4,  -25,  -34,  -27,  -18,\n                -6,   -1,    0,    0,    0],\n             [   1,    1,    1,    0,    0,    0,   -2,  -11,  -15,  -10,   -5,\n                -2,    0,    0,    0,    0],\n             [   1,    1,    0,    0,    0,    0,   -1,   -2,   -4,   -3,    0,\n                 0,    0,    0,   -1,    0],\n             [   0,    0,    0,   -1,   -3,   -1,   -1,   -1,   -2,   -2,   -2,\n                -1,   -2,   -2,    0,    0],\n             [   0,    0,    0,   -1,   -1,   -1,   -1,   -2,   -5,   -4,   -3,\n                -1,    0,    0,   -1,   -1],\n             [  -1,    0,    0,    0,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n                -2,    0,   -1,   -1,   -1],\n             [  -1,   -2,   -1,    0,   -1,   -3,   -2,    0,    2,    0,    0,\n                -1,    0,   -1,   -2,   -3],\n             [  -3,   -4,   -3,   -3,   -3,   -5,   -3,   -1,   -1,   -3,   -2,\n                -2,   -1,   -2,   -4,   -4],\n             [  -3,   -4,   -4,   -4,   -4,   -3,   -3,   -2,   -3,   -4,   -4,\n                -3,   -2,   -3,   -4,   -4]], device='cuda:0')\n\n\n\n이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다.\n\nwhy[0,1,:,:]\n\n#collapse_output\n(why[0,1,:,:]).to(torch.int64)\n\nTensorImage([[  0,   0,   0,   0,   0,   0,   1,   4,   5,   4,   1,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  12,  27,  34,  29,  15,   3,   0,\n                0,   0,   0],\n             [  0,   0,  -1,  -1,   0,   2,  23,  62,  79,  76,  43,  11,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   2,  26,  79, 122, 116,  66,  18,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  24,  81, 152, 136,  72,  21,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,  18,  64, 116, 113,  61,  19,   3,\n                0,   0,   6],\n             [  0,   0,   0,   0,   0,   0,  10,  40,  69,  68,  38,  12,   1,\n                0,   0,   2],\n             [  0,  -1,  -1,   0,   0,   0,   4,  25,  35,  28,  18,   6,   1,\n                0,   0,   0],\n             [ -1,  -1,  -1,   0,   0,   0,   2,  10,  14,  10,   5,   1,   0,\n                0,   0,   0],\n             [  0,  -1,   0,   0,   0,   0,   0,   2,   4,   3,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   3,   1,   0,   1,   2,   2,   2,   0,   1,\n                2,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   2,   5,   3,   3,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   1,   1,   0,\n                0,   0,   1],\n             [  1,   1,   1,   0,   0,   2,   1,   0,  -2,   0,   0,   1,   0,\n                0,   1,   1],\n             [  2,   2,   2,   2,   2,   4,   2,   1,   1,   2,   1,   1,   1,\n                1,   3,   3],\n             [  2,   3,   3,   3,   3,   2,   2,   2,   2,   3,   2,   2,   2,\n                2,   3,   3]], device='cuda:0')\n\n\n\n이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다.\n\n- 시각화\n\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma')\n\n<matplotlib.image.AxesImage at 0x7f5fce6d7b90>\n\n\n\n\n\n\nmagma = 검은색 < 보라색 < 빨간색 < 노란색\n왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거\n\n- why_cat, why_dog를 (16,16) \\(\\to\\) (512,512) 로 resize\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n<matplotlib.image.AxesImage at 0x7f5fbd81c890>\n\n\n\n\n\n- 겹쳐그리기\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n<matplotlib.image.AxesImage at 0x7f5fd48cd7d0>\n\n\n\n\n\n- 하니이미지 시각화\n\n#\n#!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true\nximg= PILImage.create('2022-09-06-hani01.jpeg')\nx= first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij->acij',net2[2].weight,net1(x))\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n<matplotlib.image.AxesImage at 0x7f5fbca0ad10>\n\n\n\n\n\n- 하니이미지 시각화 with prob\n\nsftmax=torch.nn.Softmax(dim=1)\n\n\nsftmax(net(x))\n\nTensorImage([[1.5489e-05, 9.9998e-01]], device='cuda:0',\n            grad_fn=<AliasBackward0>)\n\n\n\ncatprob, dogprob = sftmax(net(x))[0,0].item(), sftmax(net(x))[0,1].item()\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[0].set_title('catprob= %f' % catprob) \nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].set_title('dogprob=%f' % dogprob)\n\nText(0.5, 1.0, 'dogprob=0.999985')\n\n\n\n\n\n\n\n구현4단계– CAM 시각화\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=75\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html",
    "title": "기계학습 (1019) 7주차",
    "section": "",
    "text": "import torch\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-오버피팅",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-오버피팅",
    "title": "기계학습 (1019) 7주차",
    "section": "깊은신경망– 오버피팅",
    "text": "깊은신경망– 오버피팅\n\n데이터\n- model: \\(y_i = (0\\times x_i) + \\epsilon_i\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)\n\n\n\n\n\n\n모든 데이터를 사용하여 적합 (512, relu, 1000 epochs)\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss() #y가 연속형일때는 MSE, 0또는 1일땐 BCE\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n전체데이터를 8:2로 나누어서 8만을 학습\n- 데이터를 8:2로 나눈다 8:training 훈련 셋 2: 검증셋\n\nxtr = x[:80]\nytr = y[:80] \nxtest = x[80:] \nytest = y[80:] \n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,ytr)\nplt.plot(xtest,ytest)\n\n\n\n\n\nx.shape, xtr.shape, xtest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\ny.shape, ytr.shape, ytest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n\n\n\n\n\n# 처음 80개만 가지고 net를 학습시키면, \n\n- (xtr,ytr) 만 가지고 net를 학습시킨다.\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #               원래 yhat=net(X)  -> 80개하니까 net(xtr)  -> 변수가 많아져서.. 귀찮아져.. 그냥 loss에 바로 넣자!! \n    ## 2 \n    loss = loss_fn(net(xtr),ytr)    # 원래 loss_fn(yhat,y)  \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n#plt.plot(xtr,net(xtr).data,'--')\n#plt.plot(xtest,net(xtest).data,'--')\nplt.plot(x,net(x).data,'--k') \n\n# 보여준 파란색 데이터는 잘맞는데.. 노란색 데이터는 잘 안맞는거 같아.\n# 이런 상황을 오버피팅 이라고 한다! -> 파악하지 않아야 할 것까지 파악해 버린것.\n\n\n\n\n\n# 데이터 수에 비해 노드 수(feature수)가 많으면 오버피팅\n# 차원의 저주\n# 언더라인 외 오차항 따라가는거.. 오버피팅\n\n\n# 예시\n# y = 0,1,1,1,0,1,0,0,1\n# x1 = 0,0,0,1,0,0,0\n# x2 = \n# x3 = \n# 변수가 많으면 결정계수 값이 올라가서"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-드랍아웃",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-드랍아웃",
    "title": "기계학습 (1019) 7주차",
    "section": "깊은신경망– 드랍아웃",
    "text": "깊은신경망– 드랍아웃\n\n오버피팅의 해결\n\n# 오버피팅을 해결할 방법은 제대로 된 건 없지만.. 그 중 하나인 드랍아웃\n\n- 오버피팅의 해결책: 드랍아웃\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),   # 0.8은 0으로 0.2만 살아남음\n    torch.nn.Linear(in_features=512,out_features=1)  # 보통 linear해서 다 더하고 -> sigmoid로 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in training mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in training mode')\n\n\n\n\n\n\n# 더 오차항을 따라가는 거 같어 \n# 오잉 다시 돌려보면 그래프가 바껴 net 넣었는데 바뀌는게 이상해! \n\n- 올바른 사용법\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in evaluation mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in evaluation mode')\n\n\n\n\n\n\n\n드랍아웃 레이어\n\n# 드랍아웃 레이어는 뭔가? 왜 결과가 랜덤으로 나왔는가?\n\n\n_x = torch.linspace(0,1,101) \n_x \n\ntensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n        0.9900, 1.0000])\n\n\n\ndout = torch.nn.Dropout(0.9)\ndout(_x)\n\ntensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  2.5000,  0.0000,  2.7000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.7000,  0.0000,  3.9000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  5.9000,  0.0000,  6.1000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         7.2000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  8.3000,  8.4000,  0.0000,  0.0000,  0.0000,\n         0.0000,  8.9000,  0.0000,  0.0000,  9.2000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000, 10.0000])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 랜덤으로 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리 - 구조: 입력 -> 드랍아웃레이어 -> 출력 - 역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정 - 효과: 오버피팅을 억제하는 효과가 있음 (왜??) - 의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 로테이션으로 랜덤으로 결정됨. - 느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-data",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-data",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– data",
    "text": "이미지자료분석– data\n- download data\n\nimport torch\nimport torchvision\n\n\npath = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:00<00:00]\n    \n    \n\n\n- training set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n- test set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1]))\n\n\n\n# training 12,656개.. 2,115개는.. test set?"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-예비학습",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-예비학습",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 예비학습",
    "text": "이미지자료분석– CNN 예비학습\n\n기존의 MLP 모형\n- 교재의 모형 (fastai.book)\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n    \n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node30\"\n    \"x2\" -> \"node30\"\n    \"..\" -> \"node30\"\n    \"x784\" -> \"node30\"\n\n\n    label = \"Layer 1: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"y\"\n    \"node2\" -> \"y\"\n    \"...\" -> \"y\"\n    \"node30\" -> \"y\"\n    label = \"Layer 2: Sigmoid\"\n}\n''')\n\n\n\n\n- 왜 28$$28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n\n# nxp 매트릭스 꼴로.. 정리해서 넣으려고\n\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다.\n\n\n새로운 아키텍처의 제시\n- 예전\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\\(l_1\\): 선형변환, feature를 뻥튀기하는 역할\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처 - \\(conv\\): feature를 뻥튀기하는 역할 (2d ver \\(l_1\\) 느낌) - \\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화 - \\(pooling\\): 데이터를 요약하는 역할\n\n\nCONV 레이어 (선형변환의 2D 버전)\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.nn.Conv2d?\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,2,2).float()  #(1,2,2):흑백이미지, 2x2\n_X\n\ntensor([[[0., 1.],\n         [2., 3.]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\n_conv(_X)\n\ntensor([[[1.5410]]], grad_fn=<SqueezeBackward1>)\n\n\n(예시2) 잘하면 평균도 계산하겠다?\n\n_conv.weight.data = torch.tensor([[[[1/4, 1/4],[1/4,1/4]]]])\n_conv.bias.data = torch.tensor([0.0])\n\n\n_conv(_X) , (0+1+2+3)/4\n\n(tensor([[[1.5000]]], grad_fn=<SqueezeBackward1>), 1.5)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(0,25).float().reshape(1,5,5) \n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=<SqueezeBackward1>)\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_conv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size    (3,3) 대신 3 넣어도 됨\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n\n_X,_conv(_X)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.0000,  7.0000,  8.0000],\n          [11.0000, 12.0000, 13.0000],\n          [16.0000, 17.0000, 18.0000]]], grad_fn=<SqueezeBackward1>))\n\n\n\n(1+2+3+6+7+8+11+12+13)/9\n\n7.0\n\n\n(예시5) 피처뻥튀기\n\n_X = torch.tensor([1.0,1.0,1.0,1.0]).reshape(1,2,2)\n_X\n\ntensor([[[1., 1.],\n         [1., 1.]]])\n\n\n\n_conv = torch.nn.Conv2d(1,8,(2,2))\n_conv.weight.data.shape,_conv.bias.data.shape\n\n(torch.Size([8, 1, 2, 2]), torch.Size([8]))\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=<ReshapeAliasBackward0>)\n\n\n\ntorch.sum(_conv.weight.data[0,...])+_conv.bias.data[0],\\\ntorch.sum(_conv.weight.data[1,...])+_conv.bias.data[1]\n# 여기 이해 안감.. ㅠ \n\n(tensor(-0.3464), tensor(0.2739))\n\n\n결국 아래를 계산한다는 의미\n\ntorch.sum(_conv.weight.data,axis=(2,3)).reshape(-1)+ _conv.bias.data\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345])\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=<ReshapeAliasBackward0>)\n\n\n(잔소리) axis 사용 익숙하지 않으면 아래 꼭 들으세요..\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6주차)-4월11일.html , numpy공부 4단계: 축\n\n\n\nReLU (2d)\n\n_X = torch.randn(25).reshape(1,5,5)\n_X\n\ntensor([[[ 0.2656,  0.0780,  3.0465,  1.0151, -2.3908],\n         [ 0.4749,  1.6519,  1.5454,  1.0376,  0.9291],\n         [-0.7858,  0.4190,  2.6057, -0.4022,  0.2092],\n         [ 0.9594,  0.6408, -0.0411, -1.0720, -2.0659],\n         [-0.0996,  1.1351,  0.9758,  0.4952, -0.5475]]])\n\n\n\na1=torch.nn.ReLU()\n\n\na1(_X)\n\ntensor([[[0.2656, 0.0780, 3.0465, 1.0151, 0.0000],\n         [0.4749, 1.6519, 1.5454, 1.0376, 0.9291],\n         [0.0000, 0.4190, 2.6057, 0.0000, 0.2092],\n         [0.9594, 0.6408, 0.0000, 0.0000, 0.0000],\n         [0.0000, 1.1351, 0.9758, 0.4952, 0.0000]]])\n\n\n\n\nMaxpooling 레이어\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n\n\n_X = torch.arange(16).float().reshape(1,4,4) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]),\n tensor([[[ 5.,  7.],\n          [13., 15.]]]))\n\n\n\n_X = torch.arange(25).float().reshape(1,5,5) \n\n\n_X, _maxpooling(_X) #경계에 있는건 버린당..(데이터를 요약해주는 거니까)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.,  8.],\n          [16., 18.]]]))\n\n\n\n_X = torch.arange(36).float().reshape(1,6,6) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.],\n          [24., 25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34., 35.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.],\n          [31., 33., 35.]]]))"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-cpu",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-cpu",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 구현 (CPU)",
    "text": "이미지자료분석– CNN 구현 (CPU)\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\n(1) Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5)) #16개로뻥튀기하고싶어\nprint(X.shape)\nprint(c1(X).shape)\n\n# 1장의채널이 16장으로 뻥튀기..\n# 28->24 윈도우사이즈만큼.. 한칸씩 이동하면서 나머지 데이터 빠졌엉. 마지막 4개빠짐\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(2) ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(3) MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\n\n\n\n# 16, 12, 12 숫자가 1로 바껴야함...\n\n\n\n(4) 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,2304).shape #레이어를 통과하는 느낌이 아닌거같ㅇㅏ요\n\ntorch.Size([12665, 2304])\n\n\n\n16*12*12 \n\n2304\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape) # 레이어...\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a1(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])\n\n\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d->1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nt1= time.time()\nfor epoc in range(100): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2= time.time()\nt2-t1\n\n51.493837118148804\n\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-gpu",
    "href": "posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-gpu",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 구현 (GPU)",
    "text": "이미지자료분석– CNN 구현 (GPU)\n\n1. dls\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\nlen(X)/10  # batch_size=1266으로 하면 한 epoc을 10번 정도... 위에 epoc100했는데.. 그 세팅 맞춘거...........\n\n1266.5\n\n\n\nlen(XX)\n\n2115\n\n\n\n# 하나는 training, 하나는 test에 대응하는.. dl\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\n\n2. lrnr 생성: 아키텍처, 손실함수, 옵티마이저\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\n\n#아키텍처: 여기서는 네트워크...\n\n\nlrnr = Learner(dls,net,loss_fn) #architecture자리에 net\n\n\n\n3. 학습\n\nlrnr.fit(10) # fit (숫자:epoc 숫자를 넣는다.)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.904232\n      0.605049\n      00:01\n    \n    \n      1\n      0.661176\n      0.371011\n      00:00\n    \n    \n      2\n      0.507179\n      0.213586\n      00:00\n    \n    \n      3\n      0.392649\n      0.113123\n      00:00\n    \n    \n      4\n      0.304377\n      0.065496\n      00:00\n    \n    \n      5\n      0.238253\n      0.043172\n      00:00\n    \n    \n      6\n      0.188984\n      0.031475\n      00:00\n    \n    \n      7\n      0.151837\n      0.024563\n      00:00\n    \n    \n      8\n      0.123364\n      0.020047\n      00:00\n    \n    \n      9\n      0.101180\n      0.016816\n      00:00\n    \n  \n\n\n\n\n\n4. 예측 및 시각화\n\n# lrnr.model\n\n\n# net\n\n\n# id(net), id(lrnr.model)\n\n\nnet.to(\"cpu\")  # 네트워크으ㅔ 있는 모든 parameter를 cpu로 옮긴다\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n- 결과를 시각화하면 아래와 같다.\n\nplt.plot(net(X).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(XX).data,'.')\nplt.title(\"Test Set\",size=15)\n\nText(0.5, 1.0, 'Test Set')\n\n\n\n\n\n- 빠르고 적합결과도 좋음\n\n# accuracy차이가 별로 없어보여. \n\n\n\nLrnr 오브젝트\n\nlrnr.model\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nnet\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nid(lrnr.model), id(net)\n\n(140681387850000, 140681387850000)\n\n\n\nlrnr.model(X)\n\ntensor([[5.4047e-03],\n        [5.1475e-04],\n        [9.8561e-04],\n        ...,\n        [9.9602e-01],\n        [9.9584e-01],\n        [9.9655e-01]], grad_fn=<SigmoidBackward0>)\n\n\n\n\nBCEWithLogitsLoss\n- BCEWithLogitsLoss = Sigmoid + BCELoss - 왜 써요? 수치적으로 더 안정\n- 사용방법\n\ndls 만들기\n\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\nlrnr생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    #torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.896794\n      0.560268\n      00:00\n    \n    \n      1\n      0.613384\n      0.301413\n      00:00\n    \n    \n      2\n      0.454223\n      0.169741\n      00:00\n    \n    \n      3\n      0.346758\n      0.092166\n      00:00\n    \n    \n      4\n      0.268065\n      0.056573\n      00:00\n    \n    \n      5\n      0.210524\n      0.039757\n      00:00\n    \n    \n      6\n      0.167973\n      0.030431\n      00:00\n    \n    \n      7\n      0.135910\n      0.024560\n      00:00\n    \n    \n      8\n      0.111290\n      0.020503\n      00:00\n    \n    \n      9\n      0.092058\n      0.017516\n      00:00\n    \n  \n\n\n\n\n예측 및 시각화\n\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n)\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).data,',',color=\"C1\")\nax[1].plot(y)\nax[1].plot(a2(net(X)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(a2(net(XX)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html",
    "title": "기계학습 (1221)",
    "section": "",
    "text": "import torch\nimport numpy as np \nimport pandas as pd\nfrom fastai.collab import *"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#주절주절-intro",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#주절주절-intro",
    "title": "기계학습 (1221)",
    "section": "주절주절 intro",
    "text": "주절주절 intro\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/STML2022/main/posts/V.%20RecSys/2022-12-21-rcmdsolo.csv',index_col=0)\ndf_view \n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      영식\n      영철\n      영호\n      광수\n      상철\n      영수\n    \n  \n  \n    \n      옥순\n      3.9\n      4.1\n      NaN\n      0.5\n      0.3\n      NaN\n    \n    \n      영자\n      4.5\n      NaN\n      3.7\n      0.5\n      NaN\n      0.2\n    \n    \n      정숙\n      NaN\n      4.9\n      4.7\n      NaN\n      1.2\n      1.3\n    \n    \n      영숙\n      0.6\n      0.2\n      NaN\n      4.1\n      4.3\n      NaN\n    \n    \n      순자\n      0.7\n      0.9\n      NaN\n      4.2\n      NaN\n      3.9\n    \n    \n      현숙\n      NaN\n      0.2\n      0.3\n      NaN\n      3.5\n      3.4\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 데이터를 이해할때 필요한 가정들 – 내맘대로 한 설정임.\n\n(옥순,영자,정숙)은 (영식,영철,영호)와 성격이 잘 맞고 (영숙,순자,현숙)은 (광수,상철,영수)와 성격이 잘맞음\n((옥순,영자,정숙),(영식,영철,영호))은 MBTI가 I로 시작하고 ((영숙,순자,현숙),(광수,상철,영수))는 MBTI가 E로 시작한다.\n\n- 목표: NaN 을 추론\n- 수동추론:\n\n(옥순,영호)이 만난다면? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? \\(\\to\\) 4.0 정도?\n(정숙,영식)조합은? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? + 정숙은 다 잘맞던데..? \\(\\to\\) 4.8 정도?\n(현숙,영식)조합은? \\(\\to\\) 현숙은 E성향인데 영식은 I성향이므로 잘 안맞을 것임 + 현숙은 원래 좀 눈이 높음 \\(\\to\\) 0.25 정도?\n\n- 좀 더 체계적인 추론\n사람들이 가지고 있는 성향들을 두 개의 숫자로 표현하자.\n\n옥순의 성향 = (I성향,E성향) = (1.9, 0.0)\n영식의 성향 = (I성향,E성향) = (2.0, 0.1)\n현숙의 성향 = (I성향,E성향) = (0.0, 1.5)\n\n(1) 옥순과 영식의 궁합 \\(\\approx\\) 옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의E성향\\(\\times\\)영식의E성향 // 적합\n\na1= np.array([1.9,0.0]).reshape(2,1) # a1은 옥순의 성향, col-vec으로 선언하자. \nb1= np.array([2.0,0.1]).reshape(2,1) # b1은 영식의 성향, col-vec으로 선언하자.\n(a1*b1).sum()\n\n3.8\n\n\n(2) 현숙과 영식의 궁합 \\(\\approx\\) 현숙의I성향\\(\\times\\)영식의I성향 \\(+\\) 현숙의E성향\\(\\times\\)영식의E성향 // 예측\n\na6= np.array([0.0,1.5]).reshape(2,1)\n(a6*b1).sum()\n\n0.15000000000000002\n\n\n\n그럴듯함..\n\n- 모델링\n아래가 같음을 관찰하라. (차원만 다름)\n\n(a1*b1).sum(), a1.T@b1\n\n(3.8, array([[3.8]]))\n\n\n\n(a6*b1).sum(), a6.T@b1\n\n(0.15000000000000002, array([[0.15]]))\n\n\n만약에 여자의성향, 남자의성향을 적당한 매트릭스로 정리할 수 있다면 궁합매트릭스를 만들 수 있음\n\na1= np.array([1.9,0.0]).reshape(2,1)\na2= np.array([2.0,0.1]).reshape(2,1)\na3= np.array([2.5,1.0]).reshape(2,1)\na4= np.array([0.1,1.9]).reshape(2,1)\na5= np.array([0.2,2.1]).reshape(2,1)\na6= np.array([0.0,1.5]).reshape(2,1)\nA = np.concatenate([a1,a2,a3,a4,a5,a6],axis=1)\nA\n\narray([[1.9, 2. , 2.5, 0.1, 0.2, 0. ],\n       [0. , 0.1, 1. , 1.9, 2.1, 1.5]])\n\n\n\nb1= np.array([2.0,0.1]).reshape(2,1)\nb2= np.array([1.9,0.2]).reshape(2,1)\nb3= np.array([1.8,0.3]).reshape(2,1)\nb4= np.array([0.3,2.1]).reshape(2,1)\nb5= np.array([0.2,2.0]).reshape(2,1)\nb6= np.array([0.1,1.9]).reshape(2,1)\nB = np.concatenate([b1,b2,b3,b4,b5,b6],axis=1)\nB\n\narray([[2. , 1.9, 1.8, 0.3, 0.2, 0.1],\n       [0.1, 0.2, 0.3, 2.1, 2. , 1.9]])\n\n\n\nA.T@B\n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\na1.T@b1, a2.T@b2, a3.T@b1\n\n(array([[3.8]]), array([[3.82]]), array([[5.1]]))\n\n\n결국 모형은 아래와 같다.\n\\[\\text{궁합매트릭스} = {\\bf A}^\\top {\\bf B} + \\text{오차}\\]\n- 학습전략: 아래의 매트릭스중에서 어떤값은 관측하였고 어떤값은 관측하지 못함 \\(\\to\\) 관측한 값들만 대충 비슷하게 하면 되는거 아니야?\n\nA.T@B \n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\ndf_view\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      영식\n      영철\n      영호\n      광수\n      상철\n      영수\n    \n  \n  \n    \n      옥순\n      3.9\n      4.1\n      NaN\n      0.5\n      0.3\n      NaN\n    \n    \n      영자\n      4.5\n      NaN\n      3.7\n      0.5\n      NaN\n      0.2\n    \n    \n      정숙\n      NaN\n      4.9\n      4.7\n      NaN\n      1.2\n      1.3\n    \n    \n      영숙\n      0.6\n      0.2\n      NaN\n      4.1\n      4.3\n      NaN\n    \n    \n      순자\n      0.7\n      0.9\n      NaN\n      4.2\n      NaN\n      3.9\n    \n    \n      현숙\n      NaN\n      0.2\n      0.3\n      NaN\n      3.5\n      3.4\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 자료를 아래와 같이 정리한다면?\n\ndf = pd.DataFrame([(f,m,df_view.loc[f,m]) for f in df_view.index for m in df_view.columns if not np.isnan(df_view.loc[f,m])])\ndf.columns = ['X1','X2','y']\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      X1\n      X2\n      y\n    \n  \n  \n    \n      0\n      옥순\n      영식\n      3.9\n    \n    \n      1\n      옥순\n      영철\n      4.1\n    \n    \n      2\n      옥순\n      광수\n      0.5\n    \n    \n      3\n      옥순\n      상철\n      0.3\n    \n    \n      4\n      영자\n      영식\n      4.5\n    \n    \n      5\n      영자\n      영호\n      3.7\n    \n    \n      6\n      영자\n      광수\n      0.5\n    \n    \n      7\n      영자\n      영수\n      0.2\n    \n    \n      8\n      정숙\n      영철\n      4.9\n    \n    \n      9\n      정숙\n      영호\n      4.7\n    \n    \n      10\n      정숙\n      상철\n      1.2\n    \n    \n      11\n      정숙\n      영수\n      1.3\n    \n    \n      12\n      영숙\n      영식\n      0.6\n    \n    \n      13\n      영숙\n      영철\n      0.2\n    \n    \n      14\n      영숙\n      광수\n      4.1\n    \n    \n      15\n      영숙\n      상철\n      4.3\n    \n    \n      16\n      순자\n      영식\n      0.7\n    \n    \n      17\n      순자\n      영철\n      0.9\n    \n    \n      18\n      순자\n      광수\n      4.2\n    \n    \n      19\n      순자\n      영수\n      3.9\n    \n    \n      20\n      현숙\n      영철\n      0.2\n    \n    \n      21\n      현숙\n      영호\n      0.3\n    \n    \n      22\n      현숙\n      상철\n      3.5\n    \n    \n      23\n      현숙\n      영수\n      3.4\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nmapp1 = {k[1]:k[0] for k in enumerate(df.X1.unique())}\nmapp2 = {k[1]:k[0] for k in enumerate(df.X2.unique())}\nmapp1,mapp2\n\n({'옥순': 0, '영자': 1, '정숙': 2, '영숙': 3, '순자': 4, '현숙': 5},\n {'영식': 0, '영철': 1, '광수': 2, '상철': 3, '영호': 4, '영수': 5})\n\n\n\nX1 = torch.tensor(list(map(lambda name: mapp1[name], df.X1)))\nX2 = torch.tensor(list(map(lambda name: mapp2[name], df.X2)))\nX1 = torch.nn.functional.one_hot(X1).float()\nX2 = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df.y).float()\n\n\nX1\n\ntensor([[1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.]])\n\n\n- yhat을 구하는 과정..\n\nl1 = torch.nn.Linear(in_features=6,out_features=2) # I성향 E성향.. #여출 \nl2 = torch.nn.Linear(in_features=6,out_features=2) # 남출\n\n\nl1(X1) # 옥순~현숙의 성향들 \n\ntensor([[-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676]], grad_fn=<AddmmBackward0>)\n\n\n\nl2(X2) # 영식~영수의 성향들 \n\ntensor([[ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.2893,  0.2159],\n        [ 0.2230,  0.3115],\n        [ 0.1466, -0.0453],\n        [ 0.2852,  0.4847],\n        [-0.4553,  0.3573],\n        [-0.1752, -0.0627],\n        [ 0.1466, -0.0453],\n        [-0.2893,  0.2159],\n        [-0.4553,  0.3573],\n        [ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.2893,  0.2159],\n        [ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.4553,  0.3573],\n        [-0.1752, -0.0627],\n        [ 0.1466, -0.0453],\n        [-0.2893,  0.2159],\n        [-0.4553,  0.3573]], grad_fn=<AddmmBackward0>)\n\n\n- 몇개의 관측치만 생각해보자..\n\ndf.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      X1\n      X2\n      y\n    \n  \n  \n    \n      0\n      옥순\n      영식\n      3.9\n    \n    \n      1\n      옥순\n      영철\n      4.1\n    \n    \n      2\n      옥순\n      광수\n      0.5\n    \n    \n      3\n      옥순\n      상철\n      0.3\n    \n    \n      4\n      영자\n      영식\n      4.5\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n(l1(X1)[0]*l2(X2)[0]).sum() # (옥순의성향 * 영식의성향).sum()\n\ntensor(0.0286, grad_fn=<SumBackward0>)\n\n\n\n이 값이 실제로는 3.9 이어야 한다.\n\n\n(l1(X1)[1]*l2(X2)[1]).sum() # (옥순의성향 * 영철의성향).sum()\n\ntensor(0.0136, grad_fn=<SumBackward0>)\n\n\n\n이 값이 실제로는 4.1 이어야 한다.\n\n- yhat을 구하면!\n\nyhat = (l1(X1) * l2(X2)).sum(axis=1) # (l1(X1) * l2(X2)).sum(1)와 결과가 같음 \nyhat\n\ntensor([ 0.0286,  0.0136,  0.0537,  0.0857,  0.2065, -0.0597,  0.3316,  0.3548,\n        -0.0783, -0.0038,  0.0971,  0.1652,  0.1280, -0.0342,  0.1952,  0.0599,\n         0.1546, -0.0759,  0.2193, -0.0672,  0.0145, -0.0579,  0.1734,  0.2810],\n       grad_fn=<SumBackward1>)\n\n\n\nyhat[:2],y[:2] # 이 값들이 비슷해야 하는데..\n\n(tensor([0.0286, 0.0136], grad_fn=<SliceBackward0>), tensor([3.9000, 4.1000]))\n\n\n- 0~5 까지의 범위로 고정되어 있으니까 아래와 같이 해도 되겠음..\n\nsig = torch.nn.Sigmoid() # range: 0~1\n\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1))*5 # (l1(X1) * l2(X2)).sum(1)와 결과가 같음    #range: 0~5\nyhat\n\ntensor([2.5357, 2.5170, 2.5671, 2.6071, 2.7572, 2.4254, 2.9108, 2.9389, 2.4021,\n        2.4953, 2.6213, 2.7061, 2.6598, 2.4572, 2.7432, 2.5749, 2.6928, 2.4052,\n        2.7730, 2.4161, 2.5182, 2.4277, 2.7162, 2.8490],\n       grad_fn=<MulBackward0>)\n\n\n\nloss = torch.mean((y-yhat)**2)\nloss\n\ntensor(3.4368, grad_fn=<MeanBackward0>)"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#torch를-이용한-학습",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#torch를-이용한-학습",
    "title": "기계학습 (1221)",
    "section": "torch를 이용한 학습",
    "text": "torch를 이용한 학습\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(6,2) \nl2 = torch.nn.Linear(6,2)\nsig = torch.nn.Sigmoid() \n\n\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(list(l1.parameters())+list(l2.parameters()))\n\n\nfor epoc in range(5000):\n    ## 1 \n    feature1 = l1(X1)\n    feature2 = l2(X2) \n    matching_score = (feature1*feature2).sum(axis=1) \n    yhat = sig(matching_score)*5 # 만약에 1~3점이라면 \"1+sig(matching_score)*2\" 와 같이 하면 되었을듯 \n    ## 2 \n    loss = loss_fn(yhat,y)    \n    ## 3 \n    loss.backward()    \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat\n\ntensor([3.9382, 4.0624, 0.4665, 0.3353, 4.5038, 3.6975, 0.3562, 0.3558, 4.8614,\n        4.7208, 1.1813, 1.3158, 0.4606, 0.3573, 4.1288, 4.2734, 0.8611, 0.7347,\n        4.0493, 4.0464, 0.1810, 0.3124, 3.5031, 3.3948],\n       grad_fn=<MulBackward0>)\n\n\n\ny\n\ntensor([3.9000, 4.1000, 0.5000, 0.3000, 4.5000, 3.7000, 0.5000, 0.2000, 4.9000,\n        4.7000, 1.2000, 1.3000, 0.6000, 0.2000, 4.1000, 4.3000, 0.7000, 0.9000,\n        4.2000, 3.9000, 0.2000, 0.3000, 3.5000, 3.4000])\n\n\n\nl1(X1) # 두번째 칼럼이 I 성향 점수로 \"해석\"된다\n\ntensor([[-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201]], grad_fn=<AddmmBackward0>)\n\n\n\n포인트: 여성출연자중, 정숙은 대체로 잘 맞춰주고 현숙은 그렇지 않았음.. \\(\\to\\) 그러한 가중치가 잘 드러남!!"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#fastai를-이용한-학습",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#fastai를-이용한-학습",
    "title": "기계학습 (1221)",
    "section": "fastai를 이용한 학습",
    "text": "fastai를 이용한 학습\n(1) dls\n\ndf.head() # 앞단계 전처리의 산물\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      X1\n      X2\n      y\n    \n  \n  \n    \n      0\n      옥순\n      영식\n      3.9\n    \n    \n      1\n      옥순\n      영철\n      4.1\n    \n    \n      2\n      옥순\n      광수\n      0.5\n    \n    \n      3\n      옥순\n      상철\n      0.3\n    \n    \n      4\n      영자\n      영식\n      4.5\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndls = CollabDataLoaders.from_df(df,bs=2,valid_pct=2/24) #bs:배치사이즈\n\n(2) lrnr 생성\n\nlrnr = collab_learner(dls,n_factors=2,y_range=(0,5))\n\n(3) 학습\n\nlrnr.fit(30,lr=0.05)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.005521\n      0.306862\n      00:00\n    \n    \n      1\n      0.006144\n      0.246958\n      00:00\n    \n    \n      2\n      0.006997\n      0.300838\n      00:00\n    \n    \n      3\n      0.009465\n      0.193282\n      00:00\n    \n    \n      4\n      0.011386\n      0.157935\n      00:00\n    \n    \n      5\n      0.011837\n      0.273318\n      00:00\n    \n    \n      6\n      0.011834\n      0.170711\n      00:00\n    \n    \n      7\n      0.011649\n      0.245928\n      00:00\n    \n    \n      8\n      0.012505\n      0.198697\n      00:00\n    \n    \n      9\n      0.014821\n      0.153817\n      00:00\n    \n    \n      10\n      0.012487\n      0.144184\n      00:00\n    \n    \n      11\n      0.011637\n      0.164051\n      00:00\n    \n    \n      12\n      0.011798\n      0.189932\n      00:00\n    \n    \n      13\n      0.012036\n      0.163537\n      00:00\n    \n    \n      14\n      0.012818\n      0.203912\n      00:00\n    \n    \n      15\n      0.017325\n      0.210955\n      00:00\n    \n    \n      16\n      0.024745\n      0.143737\n      00:00\n    \n    \n      17\n      0.025496\n      0.172830\n      00:00\n    \n    \n      18\n      0.025869\n      0.138098\n      00:00\n    \n    \n      19\n      0.025482\n      0.151525\n      00:00\n    \n    \n      20\n      0.027537\n      0.193854\n      00:00\n    \n    \n      21\n      0.024163\n      0.109432\n      00:00\n    \n    \n      22\n      0.020186\n      0.167370\n      00:00\n    \n    \n      23\n      0.017565\n      0.107690\n      00:00\n    \n    \n      24\n      0.015754\n      0.160082\n      00:00\n    \n    \n      25\n      0.013752\n      0.115723\n      00:00\n    \n    \n      26\n      0.012612\n      0.105396\n      00:00\n    \n    \n      27\n      0.011966\n      0.094555\n      00:00\n    \n    \n      28\n      0.014367\n      0.162134\n      00:00\n    \n    \n      29\n      0.013150\n      0.175142\n      00:00\n    \n  \n\n\n\n(4) 예측\n적합값 확인\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      y\n      y_pred\n    \n  \n  \n    \n      0\n      1.0\n      3.0\n      3.9\n      3.740652\n    \n    \n      1\n      6.0\n      2.0\n      3.5\n      4.069994\n    \n  \n\n\n\n(옥순의 궁합)\n\ndf_new = pd.DataFrame({'X1':['옥순']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      X1\n      X2\n    \n  \n  \n    \n      0\n      옥순\n      영식\n    \n    \n      1\n      옥순\n      영철\n    \n    \n      2\n      옥순\n      영호\n    \n    \n      3\n      옥순\n      광수\n    \n    \n      4\n      옥순\n      상철\n    \n    \n      5\n      옥순\n      영수\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([3.9063, 4.1200, 3.2875, 0.5278, 0.1878, 0.3123]), None)\n\n\n비교를 위해서\n\ndf_view\n\n\n\n\n\n  \n    \n      \n      영식\n      영철\n      영호\n      광수\n      상철\n      영수\n    \n  \n  \n    \n      옥순\n      3.9\n      4.1\n      NaN\n      0.5\n      0.3\n      NaN\n    \n    \n      영자\n      4.5\n      NaN\n      3.7\n      0.5\n      NaN\n      0.2\n    \n    \n      정숙\n      NaN\n      4.9\n      4.7\n      NaN\n      1.2\n      1.3\n    \n    \n      영숙\n      0.6\n      0.2\n      NaN\n      4.1\n      4.3\n      NaN\n    \n    \n      순자\n      0.7\n      0.9\n      NaN\n      4.2\n      NaN\n      3.9\n    \n    \n      현숙\n      NaN\n      0.2\n      0.3\n      NaN\n      3.5\n      3.4\n    \n  \n\n\n\n\n(정숙의 궁합)\n\ndf_new = pd.DataFrame({'X1':['정숙']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      X1\n      X2\n    \n  \n  \n    \n      0\n      정숙\n      영식\n    \n    \n      1\n      정숙\n      영철\n    \n    \n      2\n      정숙\n      영호\n    \n    \n      3\n      정숙\n      광수\n    \n    \n      4\n      정숙\n      상철\n    \n    \n      5\n      정숙\n      영수\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([4.7749, 4.8766, 4.7028, 1.7205, 0.5784, 1.1272]), None)\n\n\n비교를 위해서\n\ndf_view\n\n\n\n\n\n  \n    \n      \n      영식\n      영철\n      영호\n      광수\n      상철\n      영수\n    \n  \n  \n    \n      옥순\n      3.9\n      4.1\n      NaN\n      0.5\n      0.3\n      NaN\n    \n    \n      영자\n      4.5\n      NaN\n      3.7\n      0.5\n      NaN\n      0.2\n    \n    \n      정숙\n      NaN\n      4.9\n      4.7\n      NaN\n      1.2\n      1.3\n    \n    \n      영숙\n      0.6\n      0.2\n      NaN\n      4.1\n      4.3\n      NaN\n    \n    \n      순자\n      0.7\n      0.9\n      NaN\n      4.2\n      NaN\n      3.9\n    \n    \n      현숙\n      NaN\n      0.2\n      0.3\n      NaN\n      3.5\n      3.4\n    \n  \n\n\n\n\n- Appedix: fastai 구조공부..\n\nlrnr.model\n\nEmbeddingDotBias(\n  (u_weight): Embedding(7, 2)\n  (i_weight): Embedding(7, 2)\n  (u_bias): Embedding(7, 1)\n  (i_bias): Embedding(7, 1)\n)\n\n\n\nlrnr.model.forward??\n\n\nSignature: lrnr.model.forward(x)\nDocstring:\nDefines the computation performed at every call.\nShould be overridden by all subclasses.\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.\nSource:   \n    def forward(self, x):\n        users,items = x[:,0],x[:,1]\n        dot = self.u_weight(users)* self.i_weight(items)\n        res = dot.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze()\n        if self.y_range is None: return res\n        return torch.sigmoid(res) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/collab.py\nType:      method\n\n\n\n\n\nbias를 제외하면 우리가 짠 모형과 같음!"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#data",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#data",
    "title": "기계학습 (1221)",
    "section": "data",
    "text": "data\n- 예전에 살펴본 예제\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      0\n      1\n      15\n      1.084308\n      홍차5\n    \n    \n      1\n      1\n      1\n      4.149209\n      커피1\n    \n    \n      2\n      1\n      11\n      1.142659\n      홍차1\n    \n    \n      3\n      1\n      5\n      4.033415\n      커피5\n    \n    \n      4\n      1\n      4\n      4.078139\n      커피4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      100\n      18\n      4.104276\n      홍차8\n    \n    \n      996\n      100\n      17\n      4.164773\n      홍차7\n    \n    \n      997\n      100\n      14\n      4.026915\n      홍차4\n    \n    \n      998\n      100\n      4\n      0.838720\n      커피4\n    \n    \n      999\n      100\n      7\n      1.094826\n      커피7\n    \n  \n\n1000 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 기억을 살리기 위해서..\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n  \n    \n      \n      커피1\n      커피2\n      커피3\n      커피4\n      커피5\n      커피6\n      커피7\n      커피8\n      커피9\n      커피10\n      홍차1\n      홍차2\n      홍차3\n      홍차4\n      홍차5\n      홍차6\n      홍차7\n      홍차8\n      홍차9\n      홍차10\n    \n  \n  \n    \n      0\n      4.149209\n      NaN\n      NaN\n      4.078139\n      4.033415\n      4.071871\n      NaN\n      NaN\n      NaN\n      NaN\n      1.142659\n      1.109452\n      NaN\n      0.603118\n      1.084308\n      NaN\n      0.906524\n      NaN\n      NaN\n      0.903826\n    \n    \n      1\n      4.031811\n      NaN\n      NaN\n      3.822704\n      NaN\n      NaN\n      NaN\n      4.071410\n      3.996206\n      NaN\n      NaN\n      0.839565\n      1.011315\n      NaN\n      1.120552\n      0.911340\n      NaN\n      0.860954\n      0.871482\n      NaN\n    \n    \n      2\n      4.082178\n      4.196436\n      NaN\n      3.956876\n      NaN\n      NaN\n      NaN\n      4.450931\n      3.972090\n      NaN\n      NaN\n      NaN\n      NaN\n      0.983838\n      NaN\n      0.918576\n      1.206796\n      0.913116\n      NaN\n      0.956194\n    \n    \n      3\n      NaN\n      4.000621\n      3.895570\n      NaN\n      3.838781\n      3.967183\n      NaN\n      NaN\n      NaN\n      4.105741\n      1.147554\n      NaN\n      1.346860\n      NaN\n      0.614099\n      1.297301\n      NaN\n      NaN\n      NaN\n      1.147545\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      3.888208\n      NaN\n      3.970330\n      3.979490\n      NaN\n      4.010982\n      NaN\n      0.920995\n      1.081111\n      0.999345\n      NaN\n      1.195183\n      NaN\n      0.818332\n      1.236331\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.511905\n      1.066144\n      NaN\n      1.315430\n      NaN\n      1.285778\n      NaN\n      0.678400\n      1.023020\n      0.886803\n      NaN\n      4.055996\n      NaN\n      NaN\n      4.156489\n      4.127622\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      96\n      NaN\n      1.035022\n      NaN\n      1.085834\n      NaN\n      0.812558\n      NaN\n      1.074543\n      NaN\n      0.852806\n      3.894772\n      NaN\n      4.071385\n      3.935935\n      NaN\n      NaN\n      3.989815\n      NaN\n      NaN\n      4.267142\n    \n    \n      97\n      NaN\n      1.115511\n      NaN\n      1.101395\n      0.878614\n      NaN\n      NaN\n      NaN\n      1.329319\n      NaN\n      4.125190\n      NaN\n      4.354638\n      3.811209\n      4.144648\n      NaN\n      NaN\n      4.116915\n      3.887823\n      NaN\n    \n    \n      98\n      NaN\n      0.850794\n      NaN\n      NaN\n      0.927884\n      0.669895\n      NaN\n      NaN\n      0.665429\n      1.387329\n      NaN\n      NaN\n      4.329404\n      4.111706\n      3.960197\n      NaN\n      NaN\n      NaN\n      3.725288\n      4.122072\n    \n    \n      99\n      NaN\n      NaN\n      1.413968\n      0.838720\n      NaN\n      NaN\n      1.094826\n      0.987888\n      NaN\n      1.177387\n      3.957383\n      4.136731\n      NaN\n      4.026915\n      NaN\n      NaN\n      4.164773\n      4.104276\n      NaN\n      NaN\n    \n  \n\n100 rows × 20 columns"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#모형",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#모형",
    "title": "기계학습 (1221)",
    "section": "모형",
    "text": "모형\n(편의상 바이어스를 제외하면)\n- 특징벡터:\n\n유저1의 취향 = [커피를 좋아하는 정도, 홍차를 좋아하는 정도]\n아이템1의 특징 = [커피의 특징, 홍차인 특징]\n\n- 평점\n\n유저1이 아이템1을 먹었을경우 평점: 유저1의 취향과 아이템1의 특징의 내적 = (유저1의 취향 \\(\\odot\\) 아이템1의 특징).sum()"
  },
  {
    "objectID": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#학습",
    "href": "posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.html#학습",
    "title": "기계학습 (1221)",
    "section": "학습",
    "text": "학습\n(1) dls\n\ndls = CollabDataLoaders.from_df(df)\n\n\ndls.items\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      192\n      20\n      1\n      3.933610\n      커피1\n    \n    \n      794\n      80\n      12\n      4.125577\n      홍차2\n    \n    \n      554\n      56\n      17\n      3.826543\n      홍차7\n    \n    \n      524\n      53\n      3\n      1.170372\n      커피3\n    \n    \n      175\n      18\n      10\n      4.170460\n      커피10\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      896\n      90\n      12\n      4.391382\n      홍차2\n    \n    \n      849\n      85\n      3\n      0.693932\n      커피3\n    \n    \n      746\n      75\n      12\n      4.301711\n      홍차2\n    \n    \n      787\n      79\n      14\n      3.930048\n      홍차4\n    \n    \n      100\n      11\n      20\n      1.145191\n      홍차10\n    \n  \n\n800 rows × 4 columns\n\n\n\n(2) lrnr\n\nlrnr = collab_learner(dls,n_factors=2) # 교재에는 y_range 를 설정하도록 되어있지만 설정 안해도 적합에는 크게 상관없음..\n\n(3) fit\n\nlrnr.fit(10,0.1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      5.409556\n      3.313535\n      00:00\n    \n    \n      1\n      3.724468\n      2.569444\n      00:00\n    \n    \n      2\n      2.855262\n      1.630986\n      00:00\n    \n    \n      3\n      2.051633\n      0.469137\n      00:00\n    \n    \n      4\n      1.483525\n      0.264474\n      00:00\n    \n    \n      5\n      1.096932\n      0.178709\n      00:00\n    \n    \n      6\n      0.824759\n      0.117894\n      00:00\n    \n    \n      7\n      0.630313\n      0.081575\n      00:00\n    \n    \n      8\n      0.487037\n      0.076569\n      00:00\n    \n    \n      9\n      0.380992\n      0.076578\n      00:00\n    \n  \n\n\n\n(4) predict\n(적합된 값 확인)\n\nlrnr.show_results() # 누를때마다 결과다름\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      rating_pred\n    \n  \n  \n    \n      0\n      61.0\n      19.0\n      4.160296\n      4.037053\n    \n    \n      1\n      22.0\n      4.0\n      4.192549\n      3.940574\n    \n    \n      2\n      17.0\n      17.0\n      1.096392\n      0.967445\n    \n    \n      3\n      14.0\n      4.0\n      3.826174\n      4.002016\n    \n    \n      4\n      88.0\n      5.0\n      1.197540\n      0.968678\n    \n    \n      5\n      53.0\n      15.0\n      3.859582\n      3.966616\n    \n    \n      6\n      83.0\n      5.0\n      0.752025\n      0.789191\n    \n    \n      7\n      10.0\n      11.0\n      0.676153\n      0.978221\n    \n    \n      8\n      46.0\n      17.0\n      0.833476\n      0.908008\n    \n  \n\n\n\n(예측값)\n\ndf_new = pd.DataFrame({'user':[1,1,1,1], 'item':[9,10,11,12]})\ndf_new\n\n\n\n\n\n  \n    \n      \n      user\n      item\n    \n  \n  \n    \n      0\n      1\n      9\n    \n    \n      1\n      1\n      10\n    \n    \n      2\n      1\n      11\n    \n    \n      3\n      1\n      12\n    \n  \n\n\n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([4.0201, 4.0401, 0.9940, 0.8291]), None)"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_07_(1주차)_9월7일_ipynb의_사본.html",
    "href": "posts/Machine Learning/2022_09_07_(1주차)_9월7일_ipynb의_사본.html",
    "title": "기계학습 (0907) 1주차",
    "section": "",
    "text": "기계학습특강\n\n# 우리의 1차 목표: 이미지 -> 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n\nfrom fastai.vision.all import *\n\n\npath=untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 01:16<00:00]\n    \n    \n\n\n\npath\n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg')\n\n\n\n\n\n_lst = '/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg','/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg'\n\n\n_lst[0]\n\n'/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg'\n\n\n\nfaaaa = get_image_files(path)\n#교수님은 filenames로 설정함\n\n\nfaaaa[0]\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/leonberger_137.jpg')\n\n\n\nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_28.jpg')\n\n\n\n\n\nPILImage.create(faaaa[0])\n\n\n\n\n\nprint(faaaa[1])\nPILImage.create(faaaa[1])\n\n/root/.fastai/data/oxford-iiit-pet/images/Birman_139.jpg\n\n\n\n\n\n\nprint(faaaa[3])\nPILImage.create(faaaa[3])\n\n/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_148.jpg\n\n\n\n\n\n\nprint(faaaa[6])\nPILImage.create(faaaa[6])\n\n/root/.fastai/data/oxford-iiit-pet/images/Siamese_79.jpg\n\n\n\n\n\n\n'A'.isupper()\n\nTrue\n\n\n\n'abdjlkfwe.jpg'[0]\n\n'a'\n\n\n\ndef f(fname):\n  if fname[0].isupper():\n    return 'cat'\n  else:\n    return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,faaaa,f,item_tfms=Resize(224))\n\n\ndls.show_batch(max_n=25)\n\n\n\n\n\n# 우리의 1차 목표: 이미지 -> 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n\n\n## 오브젝트.. 오브젝트에는 동사와 명사 가 있어요\n\n### 명사\n# (1) 데이터\n# (2) 채용한 모형의 이론\n# (3) 평가기준 matric\n\n\n\n\n### 동사\n# (1) 학습\n# (2) 판단\n\n\nysj = cnn_learner(dls,resnet34,metrics=error_rate)\n\n##저항률 확인(잘 파악하는지 확인하기 위해서 metrics=error_rate 이용)\n\nysj.fine_tune(1)                  \n              ## 3을 쓰면 1보다는 많이 한다는 뜻  \n              ## 학습하다..동사,,\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.147350\n      0.014042\n      0.004060\n      00:56\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.053051\n      0.012090\n      0.004736\n      00:52\n    \n  \n\n\n\n\n?cnn_learner\n\n\nPILImage.create(faaaa[1])\n\n\n\n\n\nysj.predict(PILImage.create(faaaa[1]))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 3.0773e-10]))\n\n\nysj.predict(PILImage.create(faaaa[6])) #동사이고.. 뒤에 점찍었으니까 함수다 생각하기 # 입력을 이미지 자체로 넣었는데, 이미지가 저장된 path만 넣어도 되지않을까?\n\nysj.predict(faaaa[6])\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.2963e-10]))\n\n\n\nysj.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n##ysj가 잘구현이 되는지 체크를 해야함\n# 체크를 하는 object를 만들어야함\nchecker = Interpretation.from_learner(ysj)\n\n\n\n\n\n\n\n\n\nchecker.plot_top_losses(16)\n\n# 첫번째 사진에서 5.59는 로스이고 1퍼의 확률로 강아지라고 생각함\n# 로스는 몇퍼의 확률로 잘못생각했느냐에 따라서 달라질 수 있음\n# 맞추는 걸 넘어서 확실해야 로스가 적다. (확신의여부)\n\n# 오버피팅 아냐..? 과대적합..? 자기들이 이미 다학습된 내용 가지고 보여주는거아냐? 생각->새로운 이미지 부여\n\n\n\n\n\n\n\n\n\n\n\n\nimg=PILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.8106e-06, 1.0000e+00]))\n\n\n\nimg=PILImage.create(requests.get('https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcnSq1X%2Fbtq4o9AdWTH%2FHTm9TZG4AszSwLPFlVfGW0%2Fimg.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([1.0909e-06, 1.0000e+00]))\n\n\n\nimg=PILImage.create(requests.get('https://image.edaily.co.kr/images/photo/files/NP/S/2022/04/PS22042501396.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.6542e-12]))\n\n\n\nimg=PILImage.create(requests.get('https://blog.kakaocdn.net/dn/zfQQi/btrydI0vGzm/3YY3KrPEwKN558e27H6t0k/img.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([0.9805, 0.0195]))\n\n\n\nPILImage.create('/강아지사진1.jpg')"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#import",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#import",
    "title": "기계학습 (1109) 10주차",
    "section": "import",
    "text": "import\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#예비학습-net.parameters의-의미",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#예비학습-net.parameters의-의미",
    "title": "기계학습 (1109) 10주차",
    "section": "예비학습: net.parameters()의 의미",
    "text": "예비학습: net.parameters()의 의미\n9월27일 강의노트 중 “net.parameters()의 의미?”를 설명한다.\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n\n# 만약  iter 가 아니면 & 했을때 빈값이 나옴 \n\n\n# for문 뒤에 오는 거.. iterable object\n# for i in [1,2,3] : 이런거.. 리스트, 스트링,, \n# lst.__ 뒤에 iter__ ~ \n\n- 무슨의미?\n\nfor param in net.parameters():\n    print(param)\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n- 그냥 이건 이런느낌인데?\n\nfor param in [net.weight,net.bias]:\n    print(param)\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트같은 iterable object로 만드는 함수라 이해할 수 있다.\n- 응용예제1\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \nx=torch.tensor(df.x).float().reshape(100,1)\ny=torch.tensor(df.y).float().reshape(100,1)\n\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10) ## 이렇게 전달하면 됩니당!!\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = b+ w*x \n    ## step2\n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n- 응용예제2\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \nx = torch.tensor(df.x).float().reshape(100,1)\ny = torch.tensor(df.y).float().reshape(100,1)\nX = torch.concat([torch.ones_like(x),x],axis=1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) # What은 iterable 하지 않지만 [What]은 iterable 함\n\n\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = X@What \n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\n스스로 학습 (중간고사 대비문제)\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하고자한다.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n아래는 이를 수행하기 위한 코드이다. ???를 적절히 채워서 코드를 완성하라.\n\n항목 추가\n항목 추가\n\n\nalpha0 = torch.tensor([0.5], requires_grad=True)\nalpha1 = torch.tensor([[0.5]], requires_grad=True)\nbeta0 = torch.tensor([0.7], requires_grad=True)\nbeta1 = torch.tensor([[0.7]], requires_grad=True)\n\n\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([alpha0,alpha1,beta0,beta1], lr=1/10)\n\n\nfor epoc in range(30):\n    ## 1\n    yhat = alpha0 + beta0 + alpha1*x + beta1*x \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nprint(alpha0+beta0)\n\ntensor([3.1593], grad_fn=<AddBackward0>)\n\n\n\n3.14 근처\n\n\nprint(alpha1+beta1)\n\ntensor([[6.0875]], grad_fn=<AddBackward0>)\n\n\n\n6.28 근처"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#define-some-funtions",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#define-some-funtions",
    "title": "기계학습 (1109) 10주차",
    "section": "Define some funtions",
    "text": "Define some funtions\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsoft = torch.nn.Softmax(dim=1)"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam2-abc",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam2-abc",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam2: abc",
    "text": "Exam2: abc\n\ndata\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=1), #a,b,c 문자 3개니까 num_embeddings=3 쓰고 \n    torch.nn.Tanh(),\n    #===#\n    torch.nn.Linear(in_features=1,out_features=3)\n    #torch.nn.Softmax() 생략!\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과해석\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data \n\n\nplt.plot(hidden[:9],'--o')\n# 가운데:a 맨위:b, 맨아래:c\n\n\n\n\n\nplt.plot(net(x).data[:9],'--o')\n\n\n\n\n\nplt.plot(yhat[:9],'--o')\n\n\n\n\n\n억지로 맞추고있긴한데 파라메터가 부족해보인다.\n\n- 결과시각화1\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n첫 그림 -> 두번째 그림\n\n# 첫번째그림 \nhidden[:9], (net[-1].weight.data).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]]),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\n# hidden : n x 1 형태\n# new[-1] : 3 x 1 형태여서 trans\n\n\nhidden[:9]@(net[-1].weight.data).T + net[-1].bias.data\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312]])\n\n\n\n(파랑,주황,초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143)\n초록 = hidden * (5.2894) + (-1.3970)\n\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음. - weight: 파랑과 초록을 구분하는 역할을 함 - weight + bias: 뭔가 교모하게 애매한 주황값을 만들어서 애매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려 맞추는 느낌, 쓸수있는 weight가 한정적이라서 생기는 현상 (양수,음수,0)\n\n참고: torch.nn.Linear()의 비밀? - 사실 \\({\\boldsymbol y}={\\boldsymbol x}{\\bf W} + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf W}\\)와 \\({\\boldsymbol b}\\)가 저장되는게 아니다. - \\({\\boldsymbol y}={\\boldsymbol x}{\\bf A}^T + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf A}\\)와 \\({\\boldsymbol b}\\)가 저장된다. - \\({\\bf W} = {\\bf A}^T\\) 인 관계에 있으므로 l1.weight 가 우리가 생각하는 \\({\\bf W}\\) 로 해석하려면 사실 transpose를 취해줘야 한다.\n왜 이렇게..? - 계산의 효율성 때문 (numpy의 구조를 알아야함) - \\({\\boldsymbol x}\\), \\({\\boldsymbol y}\\) 는 수학적으로는 col-vec 이지만 메모리에 저장할시에는 row-vec 로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)\n잠깐 딴소리!!\n(예시1)\n\n_arr = np.array(range(4)).reshape(2,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시2)\n\n_arr = np.array(range(6)).reshape(3,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시3)\n\n_arr = np.array(range(6)).reshape(2,3)\n\n\n_arr.strides\n\n(24, 8)\n\n\n\n아래로 한칸 = 24칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시4)\n\n_arr = np.array(range(4),dtype=np.int8).reshape(2,2)\n\n\n_arr\n\narray([[0, 1],\n       [2, 3]], dtype=int8)\n\n\n\n_arr.strides\n\n(2, 1)\n\n\n\n아래로한칸 = 2칸 (= 2바이트 jump = 16비트 jump)\n오른쪽으로 한칸 = 1칸 jump (= 1바이트 jump = 8비트 jump)\n\n진짜 참고..\n\n1바이트 = 8비트\n1바이트는 2^8=256 의 정보 표현\nnp.int8은 8비트로 정수를 저장한다는 의미\n\n\n2**8\n\n256\n\n\n\nprint(np.array(55,dtype=np.int8))\nprint(np.array(127,dtype=np.int8))\nprint(np.array(300,dtype=np.int8)) # overflow \n\n55\n127\n44\n\n\n딴소리 끝!!\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([299, 7])\n\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam3-abcd",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam3-abcd",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam3: abcd",
    "text": "Exam3: abcd\n\ndata\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n\n두개의 은닉노드를 이용한 풀이 – 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam4-abcde-스스로-공부",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam4-abcde-스스로-공부",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam4: abcde (스스로 공부)",
    "text": "Exam4: abcde (스스로 공부)\n\ndata\n주어진 자료가 다음과 같다고 하자.\n\ntxt = list('abcde')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'e', 'a', 'b', 'c', 'd', 'e']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'e'], ['b', 'c', 'd', 'e', 'a'])\n\n\n아래 코드를 변형하여 적절한 네트워크를 설계하고 위의 자료를 학습하라. (깔끔한 성공을 위한 최소한의 은닉노드를 설정할 것)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=??,embedding_dim=??),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=??,out_features=??)\n)\n\n\n3개의 은닉노드를 이용한 풀이\na,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다. - 1개의 은닉노드 -> 2개의 문자를 표현할 수 있음. - 2개의 은닉노드 -> 4개의 문자를 표현할 수 있음. - 3개의 은닉노드 -> 8개의 문자를 표현할 수 있음.\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=3),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=3,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 13])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(13), labels=[r'$h$',r'$h$',r'$h$',\n                              r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$y=e?$',\n                              r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=13)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam5-abacad",
    "href": "posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam5-abacad",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam5: AbAcAd",
    "text": "Exam5: AbAcAd\n\ndata\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\n\n두개의 은닉노드를 이용한 풀이 – 실패\n- 데이터정리\n\nmapping = {'A':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n실패\n\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nX\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n…\n…\n\n\n\n- 순진한 접근방식의 비판: - 결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조 - 만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함. - 그리고 실전에서는 직전 몇개의 문자를 봐야하는지 모름.\n\n# \n# x1 -> y1\n# x1, x2 -> y2\n# x1, x2, x3 -> y3\n# x1, x2, x3, x4 -> y4\n# ...\n\n이것에 대한 해결책은 순환신경망이다.\n\n\n순환망을 위하여 data 다시정리\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번엔 원핫인코딩형태까지 미리 정리하자. (임베딩 레이어 안쓸예정)\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\n\n실패했던 풀이의 재구현1\n- 방금 실패한 풀이\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n- Tanh까지만 클래스로 바꾸어서 구현 - 클래스를 이용하는 방법: https://guebin.github.io/DL2022/2022/11/01/(9주차)-11월1일.html#로지스틱-모형을-이용한-풀이\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 사용할 레이어 정의\n        self.i2h = torch.nn.Linear(in_features=4,out_features=2) #input에 들어가서 hidden을 만들어주는 ?  # 이름만들땐 self를 붙여주기\n        self.tanh = torch.nn.Tanh() # 두레이어 통과시켜서 hidden 출력! \n    def forward(self,x):\n      # yhat을 어떻게 구현할 것인지 정의 \n        hidden = self.tanh(self.i2h(x)) \n        return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n\n# hne.parameters() 안에 뭔 값이 있는데 안보이니까 list화 시키기 \n\n- for문: 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)\n\n\n\n\n실패했던 풀이의 재구현2\n- Tanh까지 구현한 클래스\n\n\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회 반복\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt) \n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)\n\n\n\n\n순환신경망의 아이디어\n\n모티브\n(예비생각1) \\({\\boldsymbol h}\\)에 대한 이해\n\\({\\boldsymbol h}\\)는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다) - (why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능 - (why2) 실제로 예시를 살펴보면 그러했다.\n결론: 사실 \\({\\boldsymbol h}\\)는 잘 숙성되어있는 입력정보 \\({\\bf X}\\) 그 자체로 해석 할 수 있다.\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듬\n* 기존방식 - \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함\n* 알고리즘의 편의상 아래와 같이 생각해도 무방\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\), \\(\\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1) “\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_t\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_t\\)”로 “\\(\\text{간장계란밥}_t\\)를 조리하는 방법이다\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘 (\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n\n\\(t=0\\)\n\n\\({\\boldsymbol h}_0=[[0,0]]\\) <– \\(\\text{간장}_0\\)은 맹물로 초기화\n\n\\(t=1\\)\n\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\) - \\({\\boldsymbol x}_1\\): (1,4) - \\({\\bf W}_{ih}\\): (4,2) - \\({\\boldsymbol h}_0\\): (1,2) - \\({\\bf W}_{hh}\\): (2,2) - \\({\\boldsymbol b}_{ih}\\): (1,2) - \\({\\boldsymbol b}_{hh}\\): (1,2)\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n\n\\(t=2\\) <– 여기서부터는 \\(t=2\\)와 비슷\n\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden)) # 더하기 위해서 linr 해준다\n    # t시점 간장              # t-1시점 간장\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n\n전체알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음\n### \nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)\n\n\n\n순환신경망 구현1 – 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) # 입력이 h로 간다...i2h\n        self.h2h = torch.nn.Linear(2,2) # h 에서 h 로~ \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수  # 학습만 했기 때문에 어디에 저장해야해~ \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f919046aed0>\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[:-15] 의 적합결과가 다르다\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까..\n\n\n\n순환신경망 구현2 (with RNNCell) – 성공\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2)\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f917546d210>\n\n\n\n\n\n\n\n순환신경망 구현3 (with RNN) – 성공\n(예비학습)\n- 아무리 생각해도 yhat구하려면 좀 귀찮음\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nsoft(cook(hidden))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2) \n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data \nrnn.bias_hh_l0.data = rnncell.bias_hh.data \nrnn.weight_ih_l0.data = rnncell.weight_ih.data \nrnn.bias_ih_l0.data = rnncell.bias_ih.data \n\n\n_water\n\ntensor([[0., 0.]])\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\n똑같음!\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\nrnn(x,_water)\n\n(tensor([[-0.2232,  0.9769],\n         [-0.9999, -0.9742],\n         [ 0.9154,  0.9992],\n         ...,\n         [ 0.9200,  0.9992],\n         [-0.9978, -0.0823],\n         [-0.9154,  0.9965]], grad_fn=<SqueezeBackward1>),\n tensor([[-0.9154,  0.9965]], grad_fn=<SqueezeBackward1>))\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\ntorch.manual_seed(43052)\nrnn = torch.nn.RNN(4,2)\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4)\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters())) # 우리가 배울것: 숙성하는 방법 + 요리하는 방법 \n\n(4) 학습\n\nfor epoc in range(5000):\n    ## 1\n    _water = torch.zeros(1,2)\n    hidden, _ = rnn(x,_water)\n    output = cook(hidden)\n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nyhat = soft(cook(rnn(x,_water)[0]))\nyhat\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7703e-02, 1.3384e-02],\n        [2.0031e-02, 1.0659e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[:15])\n\n<matplotlib.image.AxesImage at 0x7f91754970d0>\n\n\n\n\n\n\n!git add .\n!git commit -m .\n!git push\n\n[master abb1501] .\n 1 file changed, 4132 insertions(+)\n create mode 100644 \"_notebooks/2022-11-09-(10\\354\\243\\274\\354\\260\\250) 11\\354\\233\\2249\\354\\235\\274.ipynb\"\nEnumerating objects: 6, done.\nCounting objects: 100% (6/6), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 814.34 KiB | 23.95 MiB/s, done.\nTotal 4 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/guebin/STML2022.git\n   b77134c..abb1501  master -> master"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html",
    "href": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html",
    "title": "기계학습 (1031) 9주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#define-some-funtions",
    "href": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#define-some-funtions",
    "title": "기계학습 (1031) 9주차",
    "section": "Define some funtions",
    "text": "Define some funtions\n- 활성화함수들\n\nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\n_x = torch.linspace(-5,5,100)\nplt.plot(_x,tanh(_x))\nplt.title(\"tanh(x)\", size=15)\n\nText(0.5, 1.0, 'tanh(x)')\n\n\n\n\n\n- 문자열 -> 숫자로 바꾸는 함수\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n(사용예시1)\n\ntxt = ['a','b','a']\nmapping = {'a':33,'b':-22}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [33, -22, 33]\n\n\n(사용예시2)\n\ntxt = ['a','b','a']\nmapping = {'a':[1,0],'b':[0,1]}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [[1, 0], [0, 1], [1, 0]]"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#exam1-ab",
    "href": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#exam1-ab",
    "title": "기계학습 (1031) 9주차",
    "section": "Exam1: ab",
    "text": "Exam1: ab\n\ndata\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\nlen(txt)\n\n200\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5] #xa가 입력으로 들어가면 b를 뱉어내고..\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])\n\n\n\n\n선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터정리\n\nx = torch.tensor(f(txt_x,{'a':0,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,{'a':0,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5]) #밑에 노란색줄 what=0\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1),'y':y[:5].reshape(-1)})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.0\n      1.0\n    \n    \n      1\n      1.0\n      0.0\n    \n    \n      2\n      0.0\n      1.0\n    \n    \n      3\n      1.0\n      0.0\n    \n    \n      4\n      0.0\n      1.0\n    \n  \n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\) 가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황 - \\((x_i,y_i)=(0,1)\\) 이면 어떠한 \\(\\hat{w}\\)를 선택해도 \\(y_i \\approx \\hat{w}x_i\\)를 만드는 것이 불가능\n- \\((x_i,y_i)=(1,0)\\) 이면 \\(\\hat{w}=0\\)일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n\n\n(풀이2) 1개의 파라메터 – 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x,{'a':-1,'b':1})).float().reshape(-1,1) \ny = torch.tensor(f(txt_y,{'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다.\n\n\n\n\n로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터를 다시 a=0, b=1로 정리\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임 - 아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다. - \\((x_i,y_i)=(0,1)\\) 이라면 어떠한 \\(\\hat{w}\\)을 선택해도 \\(\\hat{w}x_i=0\\) 이다. 이경우 \\(\\hat{y}_i = \\text{sig}(0) = 0.5\\) 가 된다. - \\((x_i,y_i)=(1,0)\\) 이라면 \\(\\hat{w}=-5\\)와 같은 값으로 선택하면 \\(\\text{sig}(-5) \\approx 0 = y_i\\) 와 같이 만들 수 있다. - 상황을 종합하면 net의 weight는 \\(\\text{sig}(\\hat{w}x_i) \\approx 0\\) 이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-4.0070]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 – 성공\n- 동일하게 a=0, b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습후결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o') #bias가 0값을 뭉개주는..\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜초기값 – 성공\n- a=0, b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n결국 수렴하긴 할듯\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야 하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자)\n\n(예비학습1) net(x)와 사실 net.forwardx(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\n# over riding ? \n\n\nnet.forward = lambda x: 1 \n\n\n“lambda x: 1” 은 입력이 x 출력이 1인 함수를 의미 (즉 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1” 이라고 새롭게 선언하였므로 앞으론 net.forward(x), net(x) 도 입력값에 상관없이 항상 1을 출력하게 될 것임\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet1()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet2()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.RuLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet3()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        \n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x) 함수의 리턴값임\n사실, x/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstep2: def __init__(self):에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x –> yhat” 으로 가는 과정을 묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x) \n        v = self.xxx2(u)\n        yhat = self.xxx3(v) \n        ## 정의 끝\n        return yhat\n예비학습 끝\n\n- 우리가 하려고 했던 것: 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과2(ReLU): RuLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n- 실험해석 - sig: 주황색선의 변동폭이 작음 + 항상 0.5근처로 머무는 적합값이 존재 - relu: 주황색선의 변동폭이 큼 + 항상 0.5근처로 머무는 적합값이 존재 - tanh: 주황색선의 변동폭이 큼 + 0.5근처로 머무는 적합값이 존재X\n- 실험해보니까 tanh가 우수한것 같다. \\(\\to\\) 앞으로는 tanh를 쓰자.\n\n\n\n소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0],'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5],y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2,bias=False)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5][:,0]\n\ntensor([0., 1., 0., 1., 0.])\n\n\n\nplt.plot(y[:5][:,1],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f2633e40f90>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#embedding-layer",
    "href": "posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#embedding-layer",
    "title": "기계학습 (1031) 9주차",
    "section": "Embedding Layer",
    "text": "Embedding Layer\n\nmotive\n- 결국 최종적으로는 아래와 같은 맵핑방식이 확장성이 있어보인다.\n\nmapping = {'a':[1,0,0],'b':[0,1,0],'c':[0,0,1]} # 원핫인코딩 방식 \n\n- 그런데 매번 \\(X\\)를 원핫인코딩하고 Linear 변환하는것이 번거로운데 이를 한번에 구현하는 함수가 있으면 좋겠다. \\(\\to\\) torch.nn.Embedding Layer가 그 역할을 한다.\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(list('abc')*100,mapping))\ny = torch.tensor(f(list('bca')*100,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(num_embeddings=3,embedding_dim=1) # x-> Xonehot (n,1)->(n,3)\n\n\nebdd(x)[:5]\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=<SliceBackward0>)\n\n\n- 그런데 사실 언뜻보면 아래의 linr 함수와 역할의 차이가 없어보인다.\n\ntorch.manual_seed(43052)\nlinr = torch.nn.Linear(in_features=1,out_features=1)\n\n\nlinr(x.float().reshape(-1,1))[:5]\n\ntensor([[-0.8470],\n        [-1.1937],\n        [-1.5404],\n        [-0.8470],\n        [-1.1937]], grad_fn=<SliceBackward0>)\n\n\n- 차이점: 파라메터수에 차이가 있다.\n\nebdd.weight\n\nParameter containing:\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843]], requires_grad=True)\n\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n결국 ebdd는 아래의 구조에 해당하는 파라메터들이고\n\n$=\n\\[\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\]\nnet(x)=\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052  \\end{bmatrix}\\]\n$\n\nlinr는 아래의 구조에 해당하는 파라메터이다.\n\n\\(\\text{x[:5]}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\quad net(x)= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}\\)\n\n\n\n연습 (ab문제 소프트맥스로 확장한 것 다시 풀이)\n- 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))\n\n\n- torch.nn.Embedding 을 넣은 네트워크\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=2,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nplt.imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f2633f7f450>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html",
    "title": "기계학습 (1116) 11주차",
    "section": "",
    "text": "RNN(2)– AbAcAd예제, GPU실험 // LSTM– abcabC, abcdabcD, LSTM의 계산과정, LSTM은 왜 강한가?"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]), tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현1-손으로-직접구현-리뷰",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현1-손으로-직접구현-리뷰",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현1 (손으로 직접구현) – 리뷰",
    "text": "순환신경망 구현1 (손으로 직접구현) – 리뷰\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f09e935fa50>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2)",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2)\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n\n구현1과 같은 초기값 (확인용)\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell() # 숙성담당 네트워크 \n\n\nrnncell = torch.nn.RNNCell(4,2)   # 4=x , 2=h\n\nrNNCell() 는 사실 torch.nn.RNNCell()와 같은 동작을 하도록 설계를 하였음. 같은동작을 하는지 확인하기 위해서 동일한 초기상태에서 rNNCell()에 의하여 학습된 결과와 torch.nn.RNNCell()에 의하여 학습된 결과를 비교해보자.\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data\nrnncell.bias_ih.data = _rnncell.i2h.bias.data\nrnncell.weight_hh.data = _rnncell.h2h.weight.data\nrnncell.bias_hh.data = _rnncell.h2h.bias.data\n\n# 초기상태를 똑같이! 앞에서 손으로 직접구현한 것과 일치하는지 확인하기 위해서.\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nhidden = torch.zeros(T,2) \n\n\n# t=0 \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\n# t=1~T \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat[:15].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f09e0352f90>\n\n\n\n\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f09c75ffd90>\n\n\n\n\n\n\n\n새로운 초기값\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\ntorch.nn.RNNCell(4,2)\n\nRNNCell(4, 2)\n\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\nyhat을 저장한 적이 없는데? x -> h -> outfut -> yhat 이렇게 되야하는데.. 히든레이어에 출력이 T시점에만 저장되어 있고 1부터 599에 해당되는 히든레이어가 저장이 안되어있는 네트워크만 저장된 상태 시각화를 위해 hidden레이어를 재정의 해야함\n\nhidden = torch.zeros(T,2)\n#맹물을 만들자\n_water=torch.zeros(1,2)\n#t=0\nhidden[[0]] = rnncell(x[[0]],_water)\n\n#t=1~T\nfor t in range(1,T):\n  hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\n\n\nyhat = soft(cook(hidden)) \nplt.matshow(yhat[:15].data,cmap='bwr')"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현3 (with RNN, hidden node 2) – 성공",
    "text": "순환신경망 구현3 (with RNN, hidden node 2) – 성공\n(예비학습)\n- 네트워크학습이후 yhat을 구하려면 번거로웠음\nhidden = torch.zeros(T,2) \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\nyhat = soft(cook(hidden))\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2)\n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data    # 2x2 매트릭스\nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\n_water = torch.zeros(1,2)\nrnn(x,_water), hidden \n# 두개의 값이 같다! \n\n# x: tupple.. \n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          ...,\n          [-0.9935, -0.9315],\n          [ 0.5777, -1.0000],\n          [-0.9960, -0.0109]], grad_fn=<SqueezeBackward1>),\n  tensor([[-0.9960, -0.0109]], grad_fn=<SqueezeBackward1>)),\n tensor([[-0.9912, -0.9117],\n         [ 0.0698, -1.0000],\n         [-0.9927, -0.9682],\n         ...,\n         [-0.9935, -0.9315],\n         [ 0.5777, -1.0000],\n         [-0.9960, -0.0109]], grad_fn=<IndexPutBackward0>))\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7702e-02, 1.3384e-02],\n        [2.0031e-02, 1.0660e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\nrnn = torch.nn.RNN(4,2)\n\n가중치초기화\n\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(4,2)\n\n\nrnn.weight_hh_l0.data = _rnncell.weight_hh.data \nrnn.weight_ih_l0.data = _rnncell.weight_ih.data\nrnn.bias_hh_l0.data = _rnncell.bias_hh.data\nrnn.bias_ih_l0.data = _rnncell.bias_ih.data\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n# 맹물을 넣어주기 위한 세팅\n_water = torch.zeros(1,2) \n\nfor epoc in range(5000):\n    ## 1  hT: 그냥 써논거 \n    hidden,hT = rnn(x,_water)\n    output = cook(hidden) #output이 배치로 나오게 된다.\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()   #갱신\n    optimizr.zero_grad()  #초기화\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat.data[:15],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c231310>\n\n\n\n\n\n\n처음은 좀 틀렸음 ㅎㅎ\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c1c5d90>\n\n\n\n\n\n\n뒤에는 잘맞음\n\n실전팁: _water 대신에 hT를 대입 (사실 큰 차이는 없음)\n\n# hT에 값이 있음\n# rnn(x,hT)[0][:6] 값과 hidden[:6] 값을 비교해보면 비슷함 \n\n\nrnn(x[:6],_water),rnn(x[:6],hT)\n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          [ 0.5761, -1.0000],\n          [-0.9960, -0.0173],\n          [ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>),\n  tensor([[ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>)),\n (tensor([[-0.9713, -1.0000],\n          [ 0.0535, -1.0000],\n          [-0.9925, -0.9720],\n          [ 0.5759, -1.0000],\n          [-0.9960, -0.0180],\n          [ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>),\n  tensor([[ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>)))\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c13b7d0>\n\n\n\n\n\n\n히든노드의 해석이 어려움."
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현4 (with RNN, hidden node 3) – 성공",
    "text": "순환신경망 구현4 (with RNN, hidden node 3) – 성공\n(1) 숙성네트워크~ (2) 조리네트워크\n\ntorch.manual_seed(2) #1 \nrnn = torch.nn.RNN(4,3) \ncook = torch.nn.Linear(3,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,3) \nfor epoc in range(5000):\n    ## 1\n    hidden,hT = rnn(x,_water) \n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c04f550>\n\n\n\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe6747ba910>\n\n\n\n\n\n\n세번째 히든노드 = 대소문자를 구분\n1,2 히든노드 = bcd를 구분"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes",
    "title": "기계학습 (1116) 11주차",
    "section": "20000 len + 20 hidden nodes",
    "text": "20000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()   # 역전파를 하는 곳이 시간을 제일 많이 잡아먹는다. \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n93.01761960983276\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n3.2665085792541504\n\n\n\n왜 빠른지?\n\n\n# for문이 중첩이 되어있는 형태인데, hidden에서 cpu에서는 그래서 오래걸리는 거구... 근데 이것보다는 역전파 하는곳 때문에 더 오래걸린다!"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리",
    "title": "기계학습 (1116) 11주차",
    "section": "20000 len + 20 hidden nodes + 역전파주석처리",
    "text": "20000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n18.851768255233765\n\n\ngpu (역전파주석처리)\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2901742458343506"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-1",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 20 hidden nodes",
    "text": "2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.533619165420532\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.7532594203948975"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리-1",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 20 hidden nodes + 역전파주석처리",
    "text": "2000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2477965354919434\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.14130854606628418"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 5000 hidden nodes",
    "text": "2000 len + 5000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n58.99820685386658\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.7596595287323"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes-역전파주석처리",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes-역전파주석처리",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 5000 hidden nodes + 역전파주석처리",
    "text": "2000 len + 5000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n13.163657188415527\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.2989864349365234"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#실험결과-요약",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#실험결과-요약",
    "title": "기계학습 (1116) 11주차",
    "section": "실험결과 요약",
    "text": "실험결과 요약\n\n\n\nlen\n# of hidden nodes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n93.02\n3.26\n28.53\n\n\n20000\n20\nX\n18.85\n1.29\n14.61\n\n\n2000\n20\nO\n6.53\n0.75\n8.70\n\n\n2000\n20\nX\n1.25\n0.14\n8.93\n\n\n2000\n1000\nO\n58.99\n4.75\n12.41\n\n\n2000\n1000\nX\n13.16\n2.29\n5.74"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-1",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])\n\n\na1, b1, c, a2, b2, C - 보이는 문자수가 a,b,c,C 이므로 4개 - 문맥까지 고려하면 6개(a1, a2와 같이,.)"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN",
    "text": "RNN\n\ntorch.manual_seed(43052) \nrnn = torch.nn.RNN(4,3)    # 문맥의 차이 고려가 힘드니까 히든레이어를 3개 정도는 있어야 문맥에 따른걸 생각할 수 있을 거 같다!  \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+ list(linr.parameters()))\n\n\nrnn.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e032f890>\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e1078b90>\n\n\n\n\n\n- 9000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e0358590>\n\n\n\n\n\n- 12000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e2de6f10>\n\n\n\n\n\n- 15000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47cc12ae50>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM",
    "text": "LSTM\n- LSTM\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,3) #RNN->lstm\nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()))\n\n\nlstm.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))   # lstm은 물을 두개 넣어줘야 하고 hT랑 cT랑이 나온다..\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f47cc0608d0>\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f47c61dd750>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-2",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-2",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'c':2, 'd':3, 'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험-1",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임.\n\n\n# 히든레이어는 하얀색.."
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab",
    "title": "기계학습 (1116) 11주차",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'B':2}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver1-with-torch.nn.lstmcell",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver1-with-torch.nn.lstmcell",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver1 (with torch.nn.LSTMCell)",
    "text": "1 epoch ver1 (with torch.nn.LSTMCell)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) #LSTM말고 LSTMCell (LSTM을 batch버전으로..)  # 단어수가 3개니까 3!!! abB, 근데 문맥상 a1,a2,b,B 4개의 문자가 있으니까 히든노드를 2개정도로 잡자.\nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)   #lr=학습률\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)  # 히든노드가 2개니까 차원이 2인 맹물을 만들어주자.\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt)\n    loss = loss / T\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver2-완전-손으로-구현",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver2-완전-손으로-구현",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver2 (완전 손으로 구현)",
    "text": "1 epoch ver2 (완전 손으로 구현)\n\nt=0 \\(\\to\\) t=1\n- lstm_cell 을 이용한 계산 (결과비교용)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(1):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n이런결과를 어떻게 만드는걸까?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n- 직접계산\n\nht = torch.zeros(1,2)\nct = torch.zeros(1,2)\n\n\n_ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n\n\ninput_gate = sig(_ifgo[:,0:2])\nforget_gate = sig(_ifgo[:,2:4])\ngt = tanh(_ifgo[:,4:6])\noutput_gate = sig(_ifgo[:,6:8])\n\n\nct = forget_gate * ct + input_gate * gt\nht = output_gate * tanh(ct)\n\n\nht,ct\n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n\nt=0 \\(\\to\\) t=T\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        \n        ## lstm_cell step1: calculate _ifgo \n        _ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n        ## lstm_cell step2: decompose _ifgo \n        input_gate = sig(_ifgo[:,0:2])\n        forget_gate = sig(_ifgo[:,2:4])\n        gt = tanh(_ifgo[:,4:6])\n        output_gate = sig(_ifgo[:,6:8])\n        ## lstm_cell step3: calculate ht,ct \n        ct = forget_gate * ct + input_gate * gt\n        ht = output_gate * tanh(ct)\n        \n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct\n\n#LSMT_Cell로 쉽게 계산한것이랑 값이 같다.\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver3-with-torch.nn.lstm",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver3-with-torch.nn.lstm",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver3 (with torch.nn.LSTM)",
    "text": "1 epoch ver3 (with torch.nn.LSTM)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2)\nlinr = torch.nn.Linear(2,3) \n\n\nlstm = torch.nn.LSTM(3,2) \n\n\n# batch버전 통해서 확인해보기, 가중치값 덮어씌워보기\nlstm.weight_hh_l0.data = lstm_cell.weight_hh.data \nlstm.bias_hh_l0.data = lstm_cell.bias_hh.data \nlstm.weight_ih_l0.data = lstm_cell.weight_ih.data \nlstm.bias_ih_l0.data = lstm_cell.bias_ih.data \n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters()) + list(linr.parameters()), lr=0.1) \n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    # ## step2\n    # loss = loss_fn(output,y) \n    # ## step3\n    # loss.backward()\n    # ## step4 \n    # optimizr.step()\n    # optimizr.zero_grad() \n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<SqueezeBackward1>),\n tensor([[-0.0975,  0.7134]], grad_fn=<SqueezeBackward1>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab-1",
    "title": "기계학습 (1116) 11주차",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nn_words = 3\n\n\nmapping = {'a':0, 'b':1, 'B':2}\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:10],txt_y[:10]\n\n(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],\n ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.],\n         ...,\n         [1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.]]),\n tensor([[0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.],\n         ...,\n         [0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.]]))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch",
    "title": "기계학습 (1116) 11주차",
    "section": "1000 epoch",
    "text": "1000 epoch\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(3,2) \nlinr = torch.nn.Linear(2,3) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1000): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## step2\n    loss = loss_fn(output,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화",
    "text": "시각화\n\nT = len(x)\ninput_gate = torch.zeros(T,2)\nforget_gate = torch.zeros(T,2)\noutput_gate = torch.zeros(T,2)\ng = torch.zeros(T,2)\ncell = torch.zeros(T,2)\nh = torch.zeros(T,2)  # 히든노드를 2개로 잡아놨으니까.. \n\n# 계산식에 의해서 위에 값들이 다 (T,2)형태여야 한다.\n\n\n# LSTM 계산과정을 다시 따라가면,\n\nfor t in range(T): \n    ## 1: calculate _ifgo \n    _ifgo = x[[t]] @ lstm.weight_ih_l0.T + h[[t]] @ lstm.weight_hh_l0.T + lstm.bias_ih_l0 + lstm.bias_hh_l0 \n    ## 2: decompose _ifgo \n    input_gate[[t]] = sig(_ifgo[:,0:2])\n    forget_gate[[t]] = sig(_ifgo[:,2:4])\n    g[[t]] = tanh(_ifgo[:,4:6])\n    output_gate[[t]] = sig(_ifgo[:,6:8])\n    ## 3: calculate ht,ct \n    cell[[t]] = forget_gate[[t]] * cell[[t]] + input_gate[[t]] * g[[t]]\n    h[[t]] = output_gate[[t]] * tanh(cell[[t]])\n\n\ncombinded1 = torch.concat([input_gate,forget_gate,output_gate],axis=1)  # gate끼리 묶어서 시각화\ncombinded2 = torch.concat([g,cell,h,soft(output)],axis=1)               # 나머지 묶어서 시각화\n\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n\n\n\n\n상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석i",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석i",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화의 해석I",
    "text": "시각화의 해석I\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\n\nNameError: ignored\n\n\n- input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.\n파 -1 흰 0 빨 1 이니까 .. xt, ht-1 가지고 sig취해서 i,f,o를 만들었으니 0~1사이의 값을 가진다.\n- 이 값들은 각각 모두 \\({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}, \\tanh({\\boldsymbol c}_t)\\)에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)\n\ninput_gate: \\({\\boldsymbol g}_t\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\nforget_gate: \\({\\boldsymbol c}_{t-1}\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\noutput_gate: \\(\\tanh({\\boldsymbol c}_t)\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석ii",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석ii",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화의 해석II",
    "text": "시각화의 해석II\n\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n- 결국 \\({\\boldsymbol g}_t\\to {\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\to \\hat{\\boldsymbol y}\\) 의 느낌이다. (\\({\\boldsymbol h}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_t\\)가 필요했고 \\({\\boldsymbol c}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_{t-1}\\)과 \\({\\boldsymbol g}_t\\)가 필요했음)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol c}_t) \\odot {\\boldsymbol o}_t\\)\n\\({\\boldsymbol c}_t ={\\boldsymbol c}_{t-1} \\odot {\\boldsymbol f}_t + {\\boldsymbol g}_{t} \\odot {\\boldsymbol i}_t\\)\n\n- \\({\\boldsymbol g}_t,{\\boldsymbol c}_t,{\\boldsymbol h}_t\\) 모두 \\({\\boldsymbol x}_t\\)의 정보를 숙성시켜 가지고 있는 느낌이 든다.\n- \\({\\boldsymbol g}_t\\) 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})\\)\n\n- \\({\\boldsymbol c}_t\\) 특징: \\({\\boldsymbol g}_t\\)와 매우 비슷하지만 약간 다른값을 가진다. 그래서 \\({\\boldsymbol g}_t\\)와는 달리 -1,1 이외의 값도 종종 등장.\n\nprint(\"first row: gt={}, ct={}\".format(g[-8].data, cell[-8].data))\nprint(\"second row: gt={}, ct={}\".format(g[-7].data, cell[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])\n\n\n- \\({\\boldsymbol h}_t\\) 특징: (1) \\({\\boldsymbol c}_t\\)의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)\n\nprint(\"first row: gt={}, ct={}, ht={}\".format(g[-8].data, cell[-8].data,h[-8].data))\nprint(\"second row: gt={}, ct={}, ht={}\".format(g[-7].data, cell[-7].data,h[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])\n\n\n- 예전의문 해결\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-i-수식위주",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-i-수식위주",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM의 알고리즘 리뷰 I (수식위주)",
    "text": "LSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\({\\tt ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias\\)\n\\(=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\nifgo = xt @ lstm_cell.weight_ih.T +\\\n       ht @ lstm_cell.weight_hh.T +\\\n       lstm_cell.bias_ih + lstm_cell.bias_hh\n(step2) decompose \\({\\tt ifgo}\\) and get \\({\\boldsymbol i}_t\\), \\({\\boldsymbol f}_t\\), \\({\\boldsymbol g}_t\\), \\({\\boldsymbol o}_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )\\)\n\\({\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )\\)\n\\({\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )\\)\n\\({\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\({\\boldsymbol c}_t\\) and \\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)\\)"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM의 알고리즘 리뷰 II (느낌위주)",
    "text": "LSTM의 알고리즘 리뷰 II (느낌위주)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..\n\n- 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.\n\n콩물: \\({\\boldsymbol x}_t\\)\n1차숙성: \\({\\boldsymbol g}_t\\)\n2차숙성: \\({\\boldsymbol c}_t\\)\n3차숙성: \\({\\boldsymbol h}_t\\)\n\n- 느낌2: \\({\\boldsymbol g}_t\\)에 대하여\n\n계산방법: \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)를 \\({\\bf W}_{ig}, {\\bf W}_{hg}\\)를 이용해 선형결합하고 \\(\\tanh\\)를 취한 결과\nRNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\)로 바꾼것\n크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 \\(\\tanh\\)를 적용\n\n- 느낌3: \\({\\boldsymbol c}_t\\)에 대하여 (1)\n\n계산방법: \\({\\boldsymbol g}_{t}\\)와 \\({\\boldsymbol c}_{t-1}\\)를 요소별로 선택하고 더하는 과정\n\\(g_t\\)는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈\n이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)\n\n- 느낌4: \\({\\boldsymbol c}_t\\)에 대하여 (2) // \\({\\boldsymbol c}_t\\)는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?\n\\(t=1\\) 시점 계산과정관찰\n\ninput_gate[1],g[1],forget_gate[1],cell[0]    # g[1]:현재시점 cell[0]:과거시점\n\n(tensor([0.9065, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.0014], grad_fn=<SelectBackward0>),\n tensor([ 0.3592, -0.9373], grad_fn=<SelectBackward0>))\n\n\n\\([0.9,1.0] \\odot {\\boldsymbol g}_t + [1.0,0.0] \\odot {\\boldsymbol c}_{t-1}\\)\n\nforget_gate는 \\(c_{t-1}\\)의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(\\(c_{t-1}\\))의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.\ninput_gate는 \\(g_{t}\\)의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(\\(g_{t}\\))의 정보를 얼만큼 강하게 반영할지 결정한다.\n이 둘을 조합하면 \\({\\boldsymbol c}_t\\)가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.\n\n\n이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님\n\n- 느낌5: \\({\\boldsymbol c}_t\\)에 대하여 (3)\n\n사실상 LSTM 알고리즘의 꽃이라 할 수 있음.\nLSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.\nLSTM이 장기기억을 잘 활용하는 비법은 바로 \\({\\boldsymbol c}_t\\)에 있다.\n\n- 느낌6: \\({\\boldsymbol h}_t\\)에 대하여 - 계산방법: \\(\\tanh({\\boldsymbol c}_t)\\)를 요소별로 선택\n- RNN, LSTM의 변수들 비교 테이블\n\n\n\n\n\n\n\n\n\n\n\n\n\n과거정보\n현재정보\n과거와 현재의 결합방식\n활성화\n느낌\n비고\n\n\n\n\nRNN-\\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n간장\n\n\n\n\n\n\n\n\n\n\n\n\nLSTM-\\({\\boldsymbol g}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n1차간장\n\n\n\nLSTM-\\({\\boldsymbol c}_t\\)\n\\({\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol g}_t\\)\n\\(\\odot\\) \\(\\to\\) \\(+\\)\nNone\n2차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\nLSTM-\\({\\boldsymbol h}_t\\)\nNone\n\\({\\boldsymbol c}_t\\)\nNone\n\\(\\tanh\\), \\(\\odot\\)\n3차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\n\n\nRNN은 기억할 과거정보가 \\({\\boldsymbol h}_{t-1}\\) 하나이지만 LSTM은 \\({\\boldsymbol c}_{t-1}\\), \\({\\boldsymbol h}_{t-1}\\) 2개이다.\n\n- 알고리즘리뷰 :\n\n콩물,과거3차간장 \\(\\overset{\\times,+,\\tanh}{\\longrightarrow}\\) 현재1차간장\n현재1차간장, 과거2차간장 \\(\\overset{\\odot,+,\\tanh}{\\longrightarrow}\\) 현재2차간장\n현재2차간장 \\(\\overset{\\tanh,\\odot}{\\longrightarrow}\\) 현재3차간장"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm이-강한이유",
    "href": "posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm이-강한이유",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM이 강한이유",
    "text": "LSTM이 강한이유\n- LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)\n\n- 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html",
    "title": "기계학습 (1130) 12주차",
    "section": "",
    "text": "순환신경망 minor topics"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcabc",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcabc",
    "title": "기계학습 (1130) 12주차",
    "section": "data: abcabC",
    "text": "data: abcabC\n\ntxt = list('abcabC')*100\ntxt[:8]\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험",
    "title": "기계학습 (1130) 12주차",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 4\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험3\n\nHIDDEN = 8\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,8))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment3: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론",
    "title": "기계학습 (1130) 12주차",
    "section": "결론",
    "text": "결론\n- 노드수가 많으면 학습에 유리함"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcc",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcc",
    "title": "기계학습 (1130) 12주차",
    "section": "data: ab(c,C)",
    "text": "data: ab(c,C)\n\n# torch.manual_seed(43052)\n# txta = 'a'*50\n# txtb = 'b'*50\n# prob_upper = torch.bernoulli(torch.zeros(50)+0.5) \n# txtc = list(map(lambda x: 'c' if x==1 else 'C', prob_upper))\n# txt = ''.join([txta[i]+','+txtb[i]+','+txtc[i]+',' for i in range(50)]).split(',')[:-1]\n# txt_x = txt[:-1] \n# txt_y = txt[1:]\n# pd.DataFrame({'txt_x':txt_x,'txt_y':txt_y}).to_csv(\"2022-11-25-ab(c,C).csv\",index=False)\n\n\ndf= pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-ab(c%2CC).csv\")\ndf\n\n\n\n\n\n  \n    \n      \n      txt_x\n      txt_y\n    \n  \n  \n    \n      0\n      a\n      b\n    \n    \n      1\n      b\n      c\n    \n    \n      2\n      c\n      a\n    \n    \n      3\n      a\n      b\n    \n    \n      4\n      b\n      c\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      144\n      a\n      b\n    \n    \n      145\n      b\n      C\n    \n    \n      146\n      C\n      a\n    \n    \n      147\n      a\n      b\n    \n    \n      148\n      b\n      c\n    \n  \n\n149 rows × 2 columns\n\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(df.txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(df.txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험-1",
    "title": "기계학습 (1130) 12주차",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n# 2행 4열->과적합되어있음.. c,C 확실히 알수 없는데 확실하게 맞추고있네? -> 과적합이라고 보자!\n\n\n\n\n- 실험2\n\nHIDDEN = 16\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론-1",
    "title": "기계학습 (1130) 12주차",
    "section": "결론",
    "text": "결론\n- 노드수가 너무 많으면 오버피팅 경향도 있음"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5",
    "title": "기계학습 (1130) 12주차",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn",
    "title": "기계학습 (1130) 12주차",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\")                  #히든레이어 20개\nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()                    #손실함수 적당히 정의해주기\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\")\nfor epoc in range(50):\n    ## 1 \n    hidden, (hT,cT) =lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nplt.matshow(soft(output).data[-10:].to(\"cpu\"),cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6bbf69b890>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn",
    "title": "기계학습 (1130) 12주차",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)  #X의 full batch사이즈임\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy    #test에 해당하는 거.. 그냥 트레이닝이랑 똑같이 만들자. dls가 두개를 이용해서 만들어야 하니까 \ndls = DataLoaders(dl1,dl2) #데이터로드 두개를 이용해서 만들어야 한다.\n\n\n# lrnr=Learner(dls,net,loss_fn) 이렇게 하려고 했는데 \n# loss_fn은 만들 수 있어\n# 근데 net에서.. 두개의 네트워크를 같이 쓰고 있으니까 이걸 하나의 네트워크로 통일해서 넣기가 애매하다. lstm을 넣어야할지? linear를 넣어야할지? 애매함.\n# 두개이 연속동작을 한번에 해야해\n# class이용해서 해보자!\n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      1.918821\n      1.547683\n      00:00\n    \n    \n      1\n      1.731377\n      1.771274\n      00:00\n    \n    \n      2\n      1.744945\n      1.490624\n      00:00\n    \n    \n      3\n      1.679425\n      1.400951\n      00:00\n    \n    \n      4\n      1.621457\n      1.431488\n      00:00\n    \n    \n      5\n      1.588175\n      1.398044\n      00:00\n    \n    \n      6\n      1.559340\n      1.291965\n      00:00\n    \n    \n      7\n      1.523507\n      1.127941\n      00:00\n    \n    \n      8\n      1.475921\n      0.959611\n      00:00\n    \n    \n      9\n      1.419471\n      0.861778\n      00:00\n    \n    \n      10\n      1.363497\n      0.815888\n      00:00\n    \n    \n      11\n      1.312624\n      0.780459\n      00:00\n    \n    \n      12\n      1.266544\n      0.742232\n      00:00\n    \n    \n      13\n      1.223979\n      0.715809\n      00:00\n    \n    \n      14\n      1.185103\n      0.671282\n      00:00\n    \n    \n      15\n      1.147897\n      0.620188\n      00:00\n    \n    \n      16\n      1.111588\n      0.575581\n      00:00\n    \n    \n      17\n      1.076424\n      0.529901\n      00:00\n    \n    \n      18\n      1.042135\n      0.475089\n      00:00\n    \n    \n      19\n      1.008015\n      0.418487\n      00:00\n    \n    \n      20\n      0.973913\n      0.368120\n      00:00\n    \n    \n      21\n      0.940148\n      0.322788\n      00:00\n    \n    \n      22\n      0.906926\n      0.285818\n      00:00\n    \n    \n      23\n      0.874595\n      0.254371\n      00:00\n    \n    \n      24\n      0.843313\n      0.218208\n      00:00\n    \n    \n      25\n      0.812716\n      0.187723\n      00:00\n    \n    \n      26\n      0.782985\n      0.158780\n      00:00\n    \n    \n      27\n      0.754088\n      0.133884\n      00:00\n    \n    \n      28\n      0.726112\n      0.112403\n      00:00\n    \n    \n      29\n      0.699107\n      0.093460\n      00:00\n    \n    \n      30\n      0.673082\n      0.075678\n      00:00\n    \n    \n      31\n      0.647987\n      0.059713\n      00:00\n    \n    \n      32\n      0.623807\n      0.047068\n      00:00\n    \n    \n      33\n      0.600592\n      0.037162\n      00:00\n    \n    \n      34\n      0.578363\n      0.029585\n      00:00\n    \n    \n      35\n      0.557125\n      0.023816\n      00:00\n    \n    \n      36\n      0.536864\n      0.019337\n      00:00\n    \n    \n      37\n      0.517551\n      0.015811\n      00:00\n    \n    \n      38\n      0.499145\n      0.013043\n      00:00\n    \n    \n      39\n      0.481606\n      0.010892\n      00:00\n    \n    \n      40\n      0.464891\n      0.009220\n      00:00\n    \n    \n      41\n      0.448957\n      0.007893\n      00:00\n    \n    \n      42\n      0.433761\n      0.006812\n      00:00\n    \n    \n      43\n      0.419261\n      0.005925\n      00:00\n    \n    \n      44\n      0.405417\n      0.005203\n      00:00\n    \n    \n      45\n      0.392191\n      0.004621\n      00:00\n    \n    \n      46\n      0.379547\n      0.004154\n      00:00\n    \n    \n      47\n      0.367454\n      0.003775\n      00:00\n    \n    \n      48\n      0.355879\n      0.003463\n      00:00\n    \n    \n      49\n      0.344794\n      0.003202\n      00:00\n    \n  \n\n\n\n\nplt.matshow(soft(lrnr.model(x)[-10:]).data.to(\"cpu\"),cmap = 'bwr', vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6bbbb779d0>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello",
    "title": "기계학습 (1130) 12주차",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략",
    "title": "기계학습 (1130) 12주차",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,4).to(\"cuda:0\")\nlstm(x, (_water,_water))\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=<SqueezeBackward1>),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>)))\n\n\n\n# 히든레이거 값\n# HT\n# CT\n\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=<SqueezeBackward1>),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>)))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-x.shape-l-h_in-or-lnh_in",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-x.shape-l-h_in-or-lnh_in",
    "title": "기계학습 (1130) 12주차",
    "section": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))",
    "text": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))\n- 파라메터 설명\n\n\\(L\\) = sequece length = 시계열의 길이 = 간장을 몇 년 전통으로 이어갈지 (time시리지의 length)\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 <– 왜 이걸 해야해?\n\\(H_{in}\\) = input_size = 시점을 고정하였을 경우 입력자료의 차원 = 입력시계열이 시점별로 몇개의 변수로 나타내어 지는지? = 만약에 원핫인코딩으로 단어를 정리하면 단어수를 의미함\n\n\n# x.shape = [999,7]  <- len가 999이고 구별되는 것이 7개 \n# 7개 이거를 Hin으로 생각.. \n# Hin: Hnet 라고 생각..\n# x,shape=[999,N,Hin] 이렇게 생긴 N이 있대 \n\n# Hin \"시점을 고정했을때\"   만약 x[0] = 0., 0., 1., 0., 0.,  h를 2로 맵핑했으니까 저 1은 h를 의미해 \n# 즉 하나의 시점에는 7개 차원인 정보들에 대한 입력..! \n\n# 만약 x.shape=[1000,7] dlaus 1000x7인데, 반으로 쪼개서 500x7, 500x7로 만들면 여기서 N=2이다.\n# 지금우리는 쪼개고 있지 않고 N=1로ㅓ만 진행하눈중 \n\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=<SqueezeBackward1>),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=<SqueezeBackward1>)))\n\n\n- 코드3: x의 차원은 사실 엄밀하게는 (\\(L\\),\\(N\\),\\(H_{in}\\)) 와 같다…\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x.reshape(999,1,7))\n# lstm(x) 한것과 같은 숫자가 나온당.\n# batch_first=False가 기본 \n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=<CudnnRnnBackward0>),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>)))\n\n\n- 코드4: batch_first=True옵션을 사용하여 lstm을 만든경우\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4,batch_first=True).to(\"cuda:0\")\n\n\n# lstm(x.reshape(999,1,7)) 하면 값이 이상하게 나온다! \n# batch_first=true옵션을 사용하면 (N,L,Hin) 으로 써줘야 한당. \n\n\nlstm(x.reshape(1,999,7))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563],\n          [-0.0786, -0.1430, -0.0250,  0.1189],\n          [-0.0300, -0.2256, -0.1324,  0.1439],\n          ...,\n          [-0.0723,  0.0620,  0.1913,  0.2015],\n          [-0.1155,  0.0746,  0.1747,  0.2938],\n          [-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=<CudnnRnnBackward0>),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>)))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "title": "기계학습 (1130) 12주차",
    "section": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))\n- 파라메터 설명\n\n\\(D\\) = 2 if bidirectional=True otherwise 1 = 양방향이면 2, 단방향이면 1 (우리는 단방향만 배움)\nnum_layres = 중첩된 RNN일 경우 (우리는 중첩을 안시켰음)\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 <– 왜 이걸 해야해?\n\\(H_{out}\\) = 히든노드의 수\n\n\n# _water는 (1,히든)이였는데 여기서 1은 D X num_layers의 계산값이였다. \n# num_layres는 중첩시킨적없어서 이값도 1\n# N= 쪼갠적없으니까 1\n\n- 코드5: x.shape = (\\(L\\),\\(1\\),\\(H_{in}\\)) \\(\\to\\) hidden.shape = (\\(1\\),\\(1\\),\\(H_{out}\\))\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,1,4).to(\"cuda:0\")    #zeros(1,4)하면 차원 에러가남 \nlstm(x.reshape(999,1,7),(_water,_water))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=<CudnnRnnBackward0>),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=<CudnnRnnBackward0>)))\n\n\n- 사실 _water.shape = (1,\\(H_{out}\\)) 에서 1은 observation의 차원을 의미하는게 아님 (그런데 대충 그렇게 생각해도 무방함)\n\n한 시점의 콩물에 대하여 양방향으로 간장을 만들면 _water.shape = (2,h)\n한 시점의 콩물에 대하여 3중첩으로 간장을 만들면 _water.shape = (3,h)\n한 시점의 콩물에 대하여 3중첩간장을 양방향으로 만들면 _water.shape = (6,h)\n\n\n# 원래 1은 D X 넘버오브레이어인데"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello-1",
    "title": "기계학습 (1130) 12주차",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략-1",
    "title": "기계학습 (1130) 12주차",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\n_water = torch.zeros(1,4).to(\"cuda:0\")\nxt.shape, _water.shape\n\n(torch.Size([1, 7]), torch.Size([1, 4]))\n\n\n\nlstmcell(xt,(_water,_water))\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>))\n\n\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-xt.shape-nh_in-or-h_in",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-xt.shape-nh_in-or-h_in",
    "title": "기계학습 (1130) 12주차",
    "section": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))",
    "text": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=<ThnnFusedLstmCellBackward0>))\n\n\n- 코드3:\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\nxt.shape\n\ntorch.Size([7])\n\n\n\nlstmcell(xt)\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=<SqueezeBackward1>),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=<SqueezeBackward1>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-nh_out-or-h_out",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-nh_out-or-h_out",
    "title": "기계학습 (1130) 12주차",
    "section": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))\n- 코드4: xt.shape = (\\(H_{in}\\)) \\(\\to\\) _water.shape = \\((H_{out})\\)\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\n_water = torch.zeros(4).to(\"cuda:0\")\nxt.shape,_water.shape\n\n(torch.Size([7]), torch.Size([4]))\n\n\n\nlstmcell(xt, (_water,_water))\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=<SqueezeBackward1>),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=<SqueezeBackward1>))"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#똑같은-코드들-정리",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#똑같은-코드들-정리",
    "title": "기계학습 (1130) 12주차",
    "section": "똑같은 코드들 정리",
    "text": "똑같은 코드들 정리\n- 원래 1은 단순히 observation의 차원이 아니다. 즉 \\({\\bf X}_{n \\times p}\\)에서 \\(n\\)에 대응하는 차원으로 생각할 수 없다.\n- 그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은 순환망에 한정하여서는 observation 처럼 생각해도 무방하다. <– 엄밀하게는 이게 위험한 생각임. 하지만 정식으로 모두 따지려면 너무 헷갈림"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실제구현시-기억할-것",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실제구현시-기억할-것",
    "title": "기계학습 (1130) 12주차",
    "section": "실제구현시 기억할 것",
    "text": "실제구현시 기억할 것\n- 현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이 없다. (느리거든요) // 그냥 이해용으로 구현\n- torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 _water의 dim을 명시할 일도 없다.\n- 오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data",
    "title": "기계학습 (1130) 12주차",
    "section": "data",
    "text": "data\n\ntxt = list('hi!')*3 + list('hi?')*3"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각내지-않은-시계열",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각내지-않은-시계열",
    "title": "기계학습 (1130) 12주차",
    "section": "조각내지 않은 시계열",
    "text": "조각내지 않은 시계열\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.matshow(soft(output)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n# 이것도 밑 그래프랑 같은! \n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6b994a6f50>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각난-시계열",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각난-시계열",
    "title": "기계학습 (1130) 12주차",
    "section": "조각난 시계열",
    "text": "조각난 시계열\n\ntxt1= txt[:9]\ntxt2= txt[9:]\n\n\ntxt1,txt2\n\n(['h', 'i', '!', 'h', 'i', '!', 'h', 'i', '!'],\n ['h', 'i', '?', 'h', 'i', '?', 'h', 'i', '?'])\n\n\n\ntxt1_x = txt1[:-1] \ntxt1_y = txt1[1:] \ntxt2_x = txt2[:-1] \ntxt2_y = txt2[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\ny1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\nx2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\ny2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n\n\nx1.shape, y1.shape, x2.shape, y2.shape\n\n(torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]))\n\n\n\nxx = torch.stack([x1,x2],axis=1)   # x1과 x2를 합치자\nyy = torch.stack([y1,y2],axis=1)\nxx.shape, yy.shape\n\n(torch.Size([8, 2, 4]), torch.Size([8, 2, 4]))\n\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(xx) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n    # (8,4), (8,4)가 stack되어있는데 첫번째 스택 봅고. yy도 뽑고.. 그럼 로스가 한번 계산이 되는데 다시 로스를 더하면 \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig , ax = plt.subplots(1,2) \nax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\nax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6b70111650>\n\n\n\n\n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6b70111350>\n\n\n\n\n\n- 조각난 시계열로 학습한 경우는 hi!에서 hi?로 바뀔 수 없다. 왜냐햐면 그러한 연결정보가 끊어져 있으니까"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#재미있는-실험",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#재미있는-실험",
    "title": "기계학습 (1130) 12주차",
    "section": "재미있는 실험",
    "text": "재미있는 실험\n- x1만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x1) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y1)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x2)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6b701ba890>\n\n\n\n\n\n- x2만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x2) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y2)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x1)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f6b9809ef50>"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5-1",
    "title": "기계학습 (1130) 12주차",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn-1",
    "title": "기계학습 (1130) 12주차",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy \ndls = DataLoaders(dl1,dl2) \n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        torch.manual_seed(43052)\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      1.762846\n      1.502211\n      00:00\n    \n    \n      1\n      1.631212\n      1.620583\n      00:00\n    \n    \n      2\n      1.627597\n      1.443686\n      00:00\n    \n    \n      3\n      1.580216\n      1.368762\n      00:00\n    \n    \n      4\n      1.536200\n      1.307310\n      00:00\n    \n    \n      5\n      1.496099\n      1.216339\n      00:00\n    \n    \n      6\n      1.453670\n      1.113821\n      00:00\n    \n    \n      7\n      1.408125\n      1.019931\n      00:00\n    \n    \n      8\n      1.361426\n      0.941434\n      00:00\n    \n    \n      9\n      1.315507\n      0.884034\n      00:00\n    \n  \n\n\n\n\nsoft(lrnr.model(x)).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.144, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn-1",
    "href": "posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn-1",
    "title": "기계학습 (1130) 12주차",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(10):\n    ## 1 \n    hidden, _ = lstm(x)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nhidden, _ = lstm(x)\noutput = linr(hidden) \nsoft(output).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.145, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html",
    "href": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html",
    "title": "기계학습 (1201)",
    "section": "",
    "text": "IMDB자료의 분석 (텍스트생성과 감성분류), 잡담"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "href": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "title": "기계학습 (1201)",
    "section": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석",
    "text": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석\n- 순환신경망은 순서가 있는 (말이 좀 애매하지만 아무튼 이렇게 많이 표현해요) 자료를 분석할때 사용할 수 있다. 순서가 있는 자료는 대표적으로 시계열자료과 텍스트자료가 있다.\n- 그래서 언뜻 생각하면 텍스트마이닝이나 시계열분석과 내용이 비슷할 것 같지만 사실 그렇지 않다.\n\n텍스트마이닝의 토픽: 단어를 어떻게 숫자로 잘 만들지, 토픽모델 // 자잘하고 실용적인 느낌? 공학적임..\n\n시계열분석의 토픽: 예측(forecasting)과 신뢰구간, 변화점과 관련한 연구 (detection/test), 정상/비정상시계열모형 (ARIMA, GARCH), Cointegration Test, // 느낌이 좀 거창해.. 경제와 관련 많음.\n순환신경망의 토픽(재작년까지): 텍스트생성, 텍스트분류 + 시계열 자료의 예측, 단어의 숫자화 … 텍스트마이닝과 시계열분석의 거의 모든 토픽에 관여함\n순환신경망의 토픽(작년부터?): 딥러닝의 거의 모든 영역에 관여하기 시작함 (심지어 요즘 이미지 분석도 순환망으로 합니다)\n\n\nhttps://youtu.be/thsXGOkcGGg"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "href": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "title": "기계학습 (1201)",
    "section": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?",
    "text": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?\n- 과거기준(텍스트생성, 텍스트분류, 시계열자료예측 등에만 순환망이 이용되었을 때): 학부수준에서 순수 RNN만 알아도 충분했던 것 같음. LSTM이나 GRU는 석사수준?\n- 현재기준: 석사기준 LSTM 같은건 기본이고 어텐션, 트랜스포머등에 대한 개념도 잘 알고 있어야 함. (학부는 잘 모르겠네..)\n- 내 생각: 결국 아키텍처는 근데 유행이라 아키텍처는 한번 따라하면서 이해해보고 핵심 아이디어만 이해하면 된다고 생각함. 즉 LSTM 같은 특정모형의 아키텍처를 달달 외울필요는 없다, 수식써있는거 보고 이해하면 그만임. (수식정도를 이해할 능력은 필요한게.. 코드를 짤때 옵션을 이해할 수는 있어야하니까)\n- 망상: 나중에는 순환신경망이 거의 모든 딥러닝 방법의 base가 되지 않을까?"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담3-fastai-pytorch-lightning",
    "href": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담3-fastai-pytorch-lightning",
    "title": "기계학습 (1201)",
    "section": "잡담3: fastai, pytorch lightning",
    "text": "잡담3: fastai, pytorch lightning\n- 비 컴퓨터공학 출신이 쓰기에는 fastai가 좀 더 쓰기 편한건 사실\n- pytorch lightning은 fastai보다 쓰기 어렵지만 (진짜 약간의 클래스관련 지식이 필요함, 솔직히 별로 어렵진 않아요) 좀 더 순수 파이토치에 가깝고 따라서 코드를 뜯어보기 편리하다.\n- 과거의 생각\n\n전문가: pytorch + fastai // pytorch + pytorch lightning (컴공출신)\n비 전문가: 순수 fastai\n\n- 요즘 생각\n\n모두: pytorch + pytorch lightning\n특정한경우: 순수 fastai <– 모형이 구현되어 있다면 fastai가 좋긴 좋아.. 그런데 모형의 구현속도가 못따라감"
  },
  {
    "objectID": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "href": "posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "title": "기계학습 (1201)",
    "section": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)",
    "text": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)\n- 능력1: 코드이해력 (= 구현능력 = 코드 베끼는 능력)\n\n이미지분석? 해봤음. 텍스트자료? 해봤음. 시계열? 해봤음. 등등등등? 다 해본적 있음. 어떤 원리인지 정확하게 몰라도 다 해본적 있고 그래서 일할 수 있음!!\n돌아가는 코드 최대한 많이 모아놓으세요. torch, fastai, pytorch lightning, tensorflow, keras 등등\n\n- 능력2: 최신트렌드를 파악할 수 있는 힘 (= 논문이해력)\n\n공부, 공부, 공부… A to Z 까지 수식 다 뜯어보고 코드 다 뜯어보면서 집요하게 공부해야함. (LSTM에서 했던것 처럼!) 물론 차근차근 알려주면 수업이 있다면 좋겠지 그런데 보통은 적당히 두리뭉실하게 설명하지 detail 하게 설명하는 수업은 잘 없음. (지루하거든요)\n수식이나 코드중 하나라도 볼 줄 모르면 능력2를 얻는것 자체가 불가능."
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html",
    "title": "기계학습 (0914) 2주차",
    "section": "",
    "text": "#\nfrom fastai.vision.all import *  ## 이미지분석\nfrom fastai.collab import * ## 추천시스템\nfrom fastai.text.all import * ## 텍스트분석 \nfrom fastai.vision.gan import * ## GAN (이미지생성)\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#이미지-자료분석-실습-지난시간-복습",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#이미지-자료분석-실습-지난시간-복습",
    "title": "기계학습 (0914) 2주차",
    "section": "이미지 자료분석 실습 (지난시간 복습)",
    "text": "이미지 자료분석 실습 (지난시간 복습)\n\n1단계: 데이터의 정리\n\npath=untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:09<00:00]\n    \n    \n\n\n\npath\n\n#path뒤에 점찍으면 뒤에 함수 나옴. \n#path.ls 하면 뒤에 목록이 나온다!!\n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\n#path에서 이미지 파일만 가져오기\nfnames = get_image_files(path)\n\n\nfnames\n#이미지 파일이라는 것만 가져옴\n\n(#7390) [Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_52.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_73.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Siamese_75.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_170.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_172.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_37.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_186.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_152.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pug_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_156.jpg')...]\n\n\n\npath.ls()\n#위에랑 다른것=이미지파일이 아닌게 3개가 있겠지!\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_52.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_73.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Siamese_75.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_170.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_172.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_37.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_186.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_152.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pug_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_156.jpg')...]\n\n\n\n\n\n # f(x)=x+1이라는 함수가 있는데\n # lambda=x+1이라는 식으로 표현하고 싶어. 그럼 f:lamda x: x+1 하면 이 자체가 함수가 되는거임!\n\n f=lambda fname: 'cat' if fname[0].isupper() else 'dog'\n\n\n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    f, # f대신 (lambda fname: 'cat' if fname[0].isupper() else 'dog') 를 넣어도 가능\n    item_tfms=Resize(224))\n\n#함수잘 모르면 ? 물음표해서 성질 보기!!\n\n\ndls.show_batch()\n\n\n\n\n\n#object를 하나 만드는데, 학습을 하고 학습된 결과를 토대로 예측데이터를만드는거!\n\n\n\n2단계: lrnr 오브젝트 생성\n\n# 러너 오브젝트 만들기 위해서\n# cnn_learner?\ncnn_learner?\n\n#코드가 있는 곳에 들어가서 찾아보면.. file로 찾아가 봅시다!!\n#return이 비전러너,, \n\n#Signature: cnn_learner(*args, **kwargs)\n#Docstring: Deprecated name for `vision_learner` -- do not use\n#File:      /usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py\n#Type:      function\n\n\ncnn_learner??\n\n\n?cnn_learner\n\n\nlrnr = cnn_learner(dls,resnet34,metrics=error_rate)\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\nlrnr.dls.show_batch()\n\n\n\n\n\nid(dls)\n\n139724031921680\n\n\n\nid(lrnr.dls)\n\n# 위와 아래의 주소값이 같다! 등호(=)는 포스트잇?같은걸 붙여서 너는 부르면,, 나와야햄 \n# 숫자가 의미하는 것은 dls는 이름일 뿐이고 실제 오브젝트 메모리가 있는 장소\n# dls 에도 포스트잇 붙여놓고 lrnr.dls에도 포스트잇 붙여논당..\n\n139724031921680\n\n\n\n\n3단계: lrnr.학습()\n\nlrnr.fine_tune(1)\n\n#이거 너무 오래걸려.. 그래서 그때 GPU인가 뭐로 바꾸라고 했는데 바꿔도 너어어어어어무 느림..ㅠㅠ  그래서 뒤에 내용 다 놓쳤어 엉엉\n\n# 오! 다시 됬땅.\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.094556\n      0.028600\n      0.007442\n      32:59\n    \n  \n\n\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00<?]\n    \n    \n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n  \n\n\n    \n      \n      60.87% [56/92 27:03<17:23 0.0558]\n    \n    \n\n\n\n# 학습을 하는 방법은 fine_tune만 있는 것이 아니다. \n# fit, method... 등등 \n# mbti확인할때 장례식장이라는 특수한 상황에서 튜닝을 해야함->fine_tune   \n# 이미학습된 내 정보를 일부는 유지하고 미세한 영향을 주는 것만 조정하는 것. 기존 모델은 활용하고 새로운 모델을 조금 반영-> trnasfer model\n# CNN에서 투디아키펙처? 원..?아키펙처,,,가있고 원 어쩌고 아키펙처에서 튜닝...@@@@@ \n\n\nfine_tune()은 모든 가중치를 학습하는 것이 아니라 일부만 학습하는 것임.\nfine_tune()이외이 방법으로 학습할 수도 있음.\n\n\n\n4단계: lrnr.예측()\n(방법1) lrnr.predict() 함수를 이용\n\n#lrnr.predict('2022-09-06-hani03.jpg')\n\n\n# X,y=dis.one_batch()\n# X.shape\n# torch\n## 이쪽 잘 못들었어!! 다시들어야함!1\n# 왼쪼\n\n\n#type(_rtn)\n#튜플,, 대괄호면 튜플\n\n(방법2) lrnr.model(X) 를 이용: X의 shape이 (?,3,224,224)의 형태의 텐서이어야함"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#프로그래밍-과정",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#프로그래밍-과정",
    "title": "기계학습 (0914) 2주차",
    "section": "프로그래밍 과정",
    "text": "프로그래밍 과정\n\n프로그래밍 과정 overview\n- overview\n\ndls 오브젝트 생성\nlrnr 오브젝트 생성\nlrnr.학습()\nlrnr.예측()\n\n\n\n이미지분석, 추천시스템, 텍스트분석, GAN 분석과정 비교\n- 비교\n\n\n\n\n\n\n\n\n\n\n\n이미지분석(CNN)\n추천시스템\n텍스트분석\nGAN\n\n\n\n\n1단계\nImageDataLoaders\nCollabDataLoaders\nTextDataLoaders\nDataBlock -> dls\n\n\n2단계\ncnn_learner()\ncollab_learner()\nlanguage_model_learner()\nGANLearner.wgan()\n\n\n3단계\nlrnr.fine_tune(1)\nlrnr.fit()\nlrnr.fit()\nlrnr.fit()\n\n\n4단계\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\nlrnr.predict()"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#추천시스템-실습",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#추천시스템-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "추천시스템 실습",
    "text": "추천시스템 실습\n\n1단계\n\ndf_view=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv')\n#웹에 있는걸 바로 가져오기\ndf_view\n# !wget ~뒤에 링크 하면 옆에 파일로 떠서 볼수있다는듯\n# 빈칸이 있는 건 메모리를 많이 잡아 먹음,\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      커피1\n      커피2\n      커피3\n      커피4\n      커피5\n      커피6\n      커피7\n      커피8\n      커피9\n      커피10\n      홍차1\n      홍차2\n      홍차3\n      홍차4\n      홍차5\n      홍차6\n      홍차7\n      홍차8\n      홍차9\n      홍차10\n    \n  \n  \n    \n      0\n      4.149209\n      NaN\n      NaN\n      4.078139\n      4.033415\n      4.071871\n      NaN\n      NaN\n      NaN\n      NaN\n      1.142659\n      1.109452\n      NaN\n      0.603118\n      1.084308\n      NaN\n      0.906524\n      NaN\n      NaN\n      0.903826\n    \n    \n      1\n      4.031811\n      NaN\n      NaN\n      3.822704\n      NaN\n      NaN\n      NaN\n      4.071410\n      3.996206\n      NaN\n      NaN\n      0.839565\n      1.011315\n      NaN\n      1.120552\n      0.911340\n      NaN\n      0.860954\n      0.871482\n      NaN\n    \n    \n      2\n      4.082178\n      4.196436\n      NaN\n      3.956876\n      NaN\n      NaN\n      NaN\n      4.450931\n      3.972090\n      NaN\n      NaN\n      NaN\n      NaN\n      0.983838\n      NaN\n      0.918576\n      1.206796\n      0.913116\n      NaN\n      0.956194\n    \n    \n      3\n      NaN\n      4.000621\n      3.895570\n      NaN\n      3.838781\n      3.967183\n      NaN\n      NaN\n      NaN\n      4.105741\n      1.147554\n      NaN\n      1.346860\n      NaN\n      0.614099\n      1.297301\n      NaN\n      NaN\n      NaN\n      1.147545\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      3.888208\n      NaN\n      3.970330\n      3.979490\n      NaN\n      4.010982\n      NaN\n      0.920995\n      1.081111\n      0.999345\n      NaN\n      1.195183\n      NaN\n      0.818332\n      1.236331\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.511905\n      1.066144\n      NaN\n      1.315430\n      NaN\n      1.285778\n      NaN\n      0.678400\n      1.023020\n      0.886803\n      NaN\n      4.055996\n      NaN\n      NaN\n      4.156489\n      4.127622\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      96\n      NaN\n      1.035022\n      NaN\n      1.085834\n      NaN\n      0.812558\n      NaN\n      1.074543\n      NaN\n      0.852806\n      3.894772\n      NaN\n      4.071385\n      3.935935\n      NaN\n      NaN\n      3.989815\n      NaN\n      NaN\n      4.267142\n    \n    \n      97\n      NaN\n      1.115511\n      NaN\n      1.101395\n      0.878614\n      NaN\n      NaN\n      NaN\n      1.329319\n      NaN\n      4.125190\n      NaN\n      4.354638\n      3.811209\n      4.144648\n      NaN\n      NaN\n      4.116915\n      3.887823\n      NaN\n    \n    \n      98\n      NaN\n      0.850794\n      NaN\n      NaN\n      0.927884\n      0.669895\n      NaN\n      NaN\n      0.665429\n      1.387329\n      NaN\n      NaN\n      4.329404\n      4.111706\n      3.960197\n      NaN\n      NaN\n      NaN\n      3.725288\n      4.122072\n    \n    \n      99\n      NaN\n      NaN\n      1.413968\n      0.838720\n      NaN\n      NaN\n      1.094826\n      0.987888\n      NaN\n      1.177387\n      3.957383\n      4.136731\n      NaN\n      4.026915\n      NaN\n      NaN\n      4.164773\n      4.104276\n      NaN\n      NaN\n    \n  \n\n100 rows × 20 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#위에 링크: 교수님 깃허브-> DL2022/_notebooks/2022-09-08-rcmd_anal.csv\n#컴퓨터가 좋아하는 타입이 아님. 컴퓨터가 좋아하는 타입으로...\n\n\n#'-' 컴퓨터가 좋아하는 데이터 타입\n# https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n\n\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n\n--2022-09-14 11:32:06--  https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 31987 (31K) [text/plain]\nSaving to: ‘2022-09-08-rcmd_anal.csv’\n\n2022-09-08-rcmd_ana 100%[===================>]  31.24K  --.-KB/s    in 0.002s  \n\n2022-09-14 11:32:06 (13.2 MB/s) - ‘2022-09-08-rcmd_anal.csv’ saved [31987/31987]\n\n\n\n\ndf= pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\n\n\ndls = CollabDataLoaders.from_df(df)\n\n\nCollabDataLoaders.from_df?\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n    \n  \n  \n    \n      0\n      47\n      12\n      0.937742\n    \n    \n      1\n      29\n      12\n      0.964676\n    \n    \n      2\n      96\n      4\n      1.315430\n    \n    \n      3\n      9\n      13\n      0.967607\n    \n    \n      4\n      8\n      14\n      1.092273\n    \n    \n      5\n      91\n      10\n      1.453194\n    \n    \n      6\n      41\n      11\n      0.973238\n    \n    \n      7\n      26\n      10\n      3.794259\n    \n    \n      8\n      23\n      2\n      4.048529\n    \n    \n      9\n      45\n      17\n      0.608018\n    \n  \n\n\n\n\ndls.one_batch()\n#가로로시자하니까 타입이 튜플\n\n(tensor([[84, 10],\n         [55, 16],\n         [62, 10],\n         [91,  8],\n         [98,  2],\n         [60, 17],\n         [92,  4],\n         [58, 13],\n         [58,  8],\n         [99,  6],\n         [30,  5],\n         [96,  4],\n         [15, 20],\n         [59, 12],\n         [ 3, 20],\n         [ 9, 10],\n         [77,  1],\n         [67, 14],\n         [71, 15],\n         [ 4, 13],\n         [27, 16],\n         [67, 17],\n         [15,  1],\n         [36, 11],\n         [41,  2],\n         [76, 18],\n         [52,  8],\n         [10, 18],\n         [ 9,  7],\n         [22, 15],\n         [42,  1],\n         [33,  7],\n         [74, 13],\n         [67, 18],\n         [36,  6],\n         [83,  1],\n         [33, 16],\n         [24, 18],\n         [97, 20],\n         [51,  7],\n         [84,  2],\n         [76,  1],\n         [74,  5],\n         [44,  6],\n         [98, 15],\n         [75, 13],\n         [62, 18],\n         [53, 15],\n         [26, 10],\n         [25,  9],\n         [55,  9],\n         [52,  6],\n         [57, 17],\n         [37, 11],\n         [73,  4],\n         [86,  4],\n         [ 1,  6],\n         [26,  4],\n         [64, 16],\n         [33, 14],\n         [83, 18],\n         [70,  2],\n         [75,  1],\n         [33, 12]]), tensor([[1.2715],\n         [4.0267],\n         [0.7438],\n         [0.9987],\n         [1.1155],\n         [3.8992],\n         [1.0577],\n         [3.9485],\n         [0.8547],\n         [0.6699],\n         [4.0411],\n         [1.3154],\n         [0.8391],\n         [4.0661],\n         [0.9562],\n         [3.6942],\n         [1.2878],\n         [4.1035],\n         [4.1144],\n         [1.3469],\n         [1.1454],\n         [3.7744],\n         [4.2453],\n         [1.4332],\n         [3.8708],\n         [4.1442],\n         [0.9954],\n         [0.7891],\n         [4.1260],\n         [0.5774],\n         [4.3466],\n         [4.1756],\n         [4.2065],\n         [3.5310],\n         [4.0288],\n         [0.9260],\n         [0.8332],\n         [0.9404],\n         [4.2671],\n         [0.9587],\n         [1.0322],\n         [1.2164],\n         [1.0687],\n         [4.0421],\n         [4.1446],\n         [3.7454],\n         [4.2632],\n         [3.8596],\n         [3.7943],\n         [3.9132],\n         [0.7096],\n         [0.7217],\n         [4.0679],\n         [1.1996],\n         [1.1524],\n         [0.9177],\n         [4.0719],\n         [4.1183],\n         [3.7412],\n         [1.0213],\n         [3.7535],\n         [0.8947],\n         [0.8515],\n         [1.3081]]))\n\n\n\ntype(dls.one_batch())\n\ntuple\n\n\n\nX,y=dls.one_batch()\n\n\nX[:5]\n\ntensor([[29,  8],\n        [41, 15],\n        [27, 17],\n        [58, 19],\n        [87, 11]])\n\n\n\ny[:5]\n\n#y는 평점 x는 사람의 인덱스,아이템인덱스\n#파이썬은 인덱스가 0번으로 되어잇는지 1번으로 되어잇는지 헷갈료\n#dls를 만들때 제일작은게 0인지 1인지 궁금쓰\n\ntensor([[4.1002],\n        [0.7859],\n        [1.0369],\n        [4.0163],\n        [4.0558]])\n\n\n\ndf.user\n\n0        1\n1        1\n2        1\n3        1\n4        1\n      ... \n995    100\n996    100\n997    100\n998    100\n999    100\nName: user, Length: 1000, dtype: int64\n\n\n\ndf.user.unique(), df.item.unique()\n#중복제거하고 유니크한 숫자만 보고싶을때\n#유저는 1~100까지, 아이템은 1~20까지 있다는 걸 확인할 수 있음\n\n(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100]),\n array([15,  1, 11,  5,  4, 14,  6, 20, 12, 17,  8,  9, 13, 19, 18, 16,  2,\n         3, 10,  7]))\n\n\n\n\n2단계\n\n?collab_learner\n\n\nlrnr = collab_learner(dls, y_range=(0.5))\n\n\n\n3단계\n\nlrnr.fit(10) \n#이거왜안되지?ㅠㅠ 위에 파인튠학습안되서 그런가...흠 \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.564446\n      0.408502\n      0.408502\n      -0.763844\n      02:29\n    \n    \n      1\n      -0.580162\n      0.261919\n      0.261919\n      -0.767689\n      02:27\n    \n    \n      2\n      -0.573394\n      0.211019\n      0.211019\n      -0.748596\n      02:26\n    \n    \n      3\n      -0.565945\n      0.312586\n      0.312586\n      -0.731640\n      02:26\n    \n    \n      4\n      -0.533000\n      0.208635\n      0.208635\n      -0.709664\n      02:26\n    \n    \n      5\n      -0.563198\n      0.189235\n      0.189235\n      -0.736768\n      02:26\n    \n    \n      6\n      -0.565810\n      0.210935\n      0.210935\n      -0.741373\n      02:26\n    \n    \n      7\n      -0.565554\n      0.257288\n      0.257288\n      -0.737568\n      02:26\n    \n    \n      8\n      -0.562049\n      0.309152\n      0.309152\n      -0.743085\n      02:26\n    \n    \n      9\n      -0.565225\n      0.227808\n      0.227808\n      -0.726368\n      02:27\n    \n  \n\n\n\n\n\n4단계\n\n!nvidia-smi\n#GPU를 써야 학습이 빨리 된다... \n#CPU로 되어있어서?.. .?????? batch라는 개념을 알아야함..\n\nNVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n\n\n\n\n#lrnr.model(X.to(\"cuda:0\"))\n#y.reshpe(-1) 학습이 얼마 안된면 잘 몰라,, 그래서 위에 3단계에서 fit옆에 좀더 숫자를 키워,,\n#3단계안되서 4단계 다 안되는듯..\n\nRuntimeError: ignored"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#텍스트분석-실습",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#텍스트분석-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "텍스트분석 실습",
    "text": "텍스트분석 실습\n\n1단계\n\n# 텍스트 데이터는 순환신경망을 사용한다!!\n# 만약 hello라는 단어를 생각할때, \n# h -> e\n# e -> l\n# l -> l\n# l -> o\n# 근데 l이 애매하다!! 그래서 두개 시점으로 하는게 좋을 거 같아\n\n# he -> l\n# el -> l\n# ll -> o\n\n\n#순서가 중요한게 있음. 텍스트랑 시계열~~\n\n# 다음텍스트가 뭐가 나오는지 적용시키는것 중 하나가 챗봇!\n# 나는 학교에 갔다.\n# 나는 다음에 학교에 가 나와야함. 반복되는 단위가 단어... 또는 문장 단위로 반복될 수도 있음!!\n\n# 나는 학교에 갔다. => 공부를 했다. => 집에 왓당..\n\n# 텍스트는 문맥에 맞게 그럴듯한걸 결과값을 주면 된다. cf)주식은 그 뒤에 값을 정해야함!! ㅠ 내일의 주식장...\n\n'h e l l o . h e l l o ! h e l l o ? h e l l o !!'\n\n\n\n2단계\n\n\n3단계\n\n\n4단계"
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-intro",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-intro",
    "title": "기계학습 (0914) 2주차",
    "section": "GAN intro",
    "text": "GAN intro\n- 저자: 이안굿펠로우 (이름이 특이함. 좋은친구..) - 천재임 - 지도교수가 요수아 벤지오\n- 논문 NIPS, 저는 이 논문 읽고 소름돋았어요.. - https://arxiv.org/abs/1406.2661 (현재시점, 38751회 인용되었음 \\(\\to\\) 48978회 인용..)\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 무슨내용? 생성모형\n\n생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n\nGAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면? - https://www.lgsl.kr/sto/stories/60/ALMA2020070001\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요…..\n\n\n\n생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다.\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|x) = \\frac{p(x,y)}{p(x)} = \\frac{p(x,y)}{\\sum_{y}p(x,y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다.\n\n\nGAN의 원리\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –> 상사에게 혼남. 그것도 구분못하냐고\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-실습",
    "href": "posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "GAN 실습",
    "text": "GAN 실습\n\n1단계\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\n\n\n\n\n    \n      \n      100.14% [3219456/3214948 00:00<00:00]\n    \n    \n\n\n\ndblock = DataBlock(blocks=(TransformBlock,ImageBlock),\n          get_x = generate_noise,\n          get_items=get_image_files,\n          item_tfms=Resize(32))\ndls = dblock.dataloaders(path) \n\n\ndls.show_batch()\n\n\n\n\n\n\n2단계\n\ncounterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1)\npolice = basic_critic(32,n_channels=3,n_extra_layers=1)\n\n\nlrnr = GANLearner.wgan(dls,counterfeiter,police) \n\n\n\n3단계\n- lrnr.fit(10) 진행\n\nlrnr.fit(10)\n\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/10 00:00<?]\n    \n    \n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n  \n\n\n    \n      \n      51.67% [93/180 01:13<01:08 -0.4932]\n    \n    \n\n\nKeyboardInterrupt: ignored\n\n\n\nlrnr.show_results()\n\n- lrnr.fit(10) 추가로 진행 // 총20회\n\nlrnr.fit(10)\n\n\nlrnr.show_results()\n\n- lrnr.fit(10) 추가로 진행 // 총30회\n\nlrnr.fit(10)\n\n\nlrnr.show_results()\n\n\n\n4단계 (없음)"
  },
  {
    "objectID": "posts/Machine Learning/(202250926)기계학습특강_final (2).html",
    "href": "posts/Machine Learning/(202250926)기계학습특강_final (2).html",
    "title": "기계학습 final",
    "section": "",
    "text": "기계학습특강 기말고사\n\nimport torch \nfrom fastai.text.all import *\n\n\ndf = pd.read_csv('/content/Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      UserName\n      ScreenName\n      Location\n      TweetAt\n      OriginalTweet\n      Sentiment\n    \n  \n  \n    \n      0\n      3799\n      48751\n      London\n      16-03-2020\n      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\n      Neutral\n    \n    \n      1\n      3800\n      48752\n      UK\n      16-03-2020\n      advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\n      Positive\n    \n    \n      2\n      3801\n      48753\n      Vagabonds\n      16-03-2020\n      Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\n      Positive\n    \n    \n      3\n      3802\n      48754\n      NaN\n      16-03-2020\n      My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\n      Positive\n    \n    \n      4\n      3803\n      48755\n      NaN\n      16-03-2020\n      Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\n      Extremely Negative\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      41152\n      44951\n      89903\n      Wellington City, New Zealand\n      14-04-2020\n      Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\n      Neutral\n    \n    \n      41153\n      44952\n      89904\n      NaN\n      14-04-2020\n      Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\n      Extremely Negative\n    \n    \n      41154\n      44953\n      89905\n      NaN\n      14-04-2020\n      You know itÂs getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\n      Positive\n    \n    \n      41155\n      44954\n      89906\n      NaN\n      14-04-2020\n      Is it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\n      Neutral\n    \n    \n      41156\n      44955\n      89907\n      i love you so much || he/him\n      14-04-2020\n      @TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\n      Negative\n    \n  \n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n# 텍스트 분석\n# 1단계 : TextDataLoaders\n# 2단계 : language_model_learner()\n# 3단계 : lrnr.fit()\n# 4단계 : lrnr.predict()\n\ndf = pd.read_csv('Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      UserName\n      ScreenName\n      Location\n      TweetAt\n      OriginalTweet\n      Sentiment\n    \n  \n  \n    \n      0\n      3799\n      48751\n      London\n      16-03-2020\n      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\n      Neutral\n    \n    \n      1\n      3800\n      48752\n      UK\n      16-03-2020\n      advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\n      Positive\n    \n    \n      2\n      3801\n      48753\n      Vagabonds\n      16-03-2020\n      Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\n      Positive\n    \n    \n      3\n      3802\n      48754\n      NaN\n      16-03-2020\n      My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\n      Positive\n    \n    \n      4\n      3803\n      48755\n      NaN\n      16-03-2020\n      Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\n      Extremely Negative\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      41152\n      44951\n      89903\n      Wellington City, New Zealand\n      14-04-2020\n      Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\n      Neutral\n    \n    \n      41153\n      44952\n      89904\n      NaN\n      14-04-2020\n      Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\n      Extremely Negative\n    \n    \n      41154\n      44953\n      89905\n      NaN\n      14-04-2020\n      You know itÂs getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\n      Positive\n    \n    \n      41155\n      44954\n      89906\n      NaN\n      14-04-2020\n      Is it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\n      Neutral\n    \n    \n      41156\n      44955\n      89907\n      i love you so much || he/him\n      14-04-2020\n      @TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\n      Negative\n    \n  \n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nTextDataLoaders?\n\n\ndls = TextDataLoaders.from_df(df,text_col='OriginalTweet',is_lm=True, seq_len=64)\n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      text\n      text_\n    \n  \n  \n    \n      0\n      xxbos xxmaj japanese symbol for xxunk xxmaj germany at supermarket xxmaj edeka the will teach you how to appropriately social distance and give you shit when you don t xxbos xxup tp xxmaj shortages ? ? ! ? ! xxmaj not us we are fully stocked and you can help a great cause ? \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n .\n      xxmaj japanese symbol for xxunk xxmaj germany at supermarket xxmaj edeka the will teach you how to appropriately social distance and give you shit when you don t xxbos xxup tp xxmaj shortages ? ? ! ? ! xxmaj not us we are fully stocked and you can help a great cause ? \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n . \\r\\r\\n\n    \n    \n      1\n      , when there was shortage of food and # xxmaj corona at its peak ? xxbos xxmaj consider donating to a local shelter if you have the means … xxunk was today 's pick for me ! xxmaj they are also always looking for retailer gift cards if that suits you better . xxmaj they would love the extra support as they work to\n      when there was shortage of food and # xxmaj corona at its peak ? xxbos xxmaj consider donating to a local shelter if you have the means … xxunk was today 's pick for me ! xxmaj they are also always looking for retailer gift cards if that suits you better . xxmaj they would love the extra support as they work to combat\n    \n    \n      2\n      a little xxmaj wednesday humor for you . \\r\\r\\n\\r\\r\\n▁ # coronavirus # toiletpaper # xxunk # xxunk # xxmaj satire # humor # xxunk https : / / t.co / xxunk xxbos xxmaj so a friend of mine at a division of has to supply her own gloves and safety equipment xxmaj grocery store workers deserve hazard pay and the means to protect themselves\n      little xxmaj wednesday humor for you . \\r\\r\\n\\r\\r\\n▁ # coronavirus # toiletpaper # xxunk # xxunk # xxmaj satire # humor # xxunk https : / / t.co / xxunk xxbos xxmaj so a friend of mine at a division of has to supply her own gloves and safety equipment xxmaj grocery store workers deserve hazard pay and the means to protect themselves from\n    \n    \n      3\n      https : / / t.co / xxunk xxbos xxmaj as a former supermarket fairy , i think itâs about time all of the food shop workers get some credit . xxmaj theyâre always looked down on as xxunk working in a xxunk but theyâre working hard to put the stock on the shelves that everyone is panic buying every day ! ? ? #\n      : / / t.co / xxunk xxbos xxmaj as a former supermarket fairy , i think itâs about time all of the food shop workers get some credit . xxmaj theyâre always looked down on as xxunk working in a xxunk but theyâre working hard to put the stock on the shelves that everyone is panic buying every day ! ? ? # coronavirus\n    \n    \n      4\n      care home staff xxmaj care at home teams xxmaj volunteers xxmaj call help lines xxmaj supermarket workers xxmaj xxunk transport teams xxmaj social xxmaj xxunk xxmaj thank xxmaj you 19uk xxbos \" the real risk now is that the xxmaj government sets terms to pay so xxunk that it brings mass social unrest . \" \\r\\r\\n\\r\\r\\n xxmaj the xxmaj government has never spent more\n      home staff xxmaj care at home teams xxmaj volunteers xxmaj call help lines xxmaj supermarket workers xxmaj xxunk transport teams xxmaj social xxmaj xxunk xxmaj thank xxmaj you 19uk xxbos \" the real risk now is that the xxmaj government sets terms to pay so xxunk that it brings mass social unrest . \" \\r\\r\\n\\r\\r\\n xxmaj the xxmaj government has never spent more in\n    \n    \n      5\n      at third and last reading that allows the government to limit the prices of non - vital medicine and medical devices . xxmaj as a result , the state has more influence on price regulation . # xxup covid2019 # covid19russia ahk - liveticker https : / / t.co / xxunk https : / / t.co / xxunk xxbos a graduate from our xxmaj\n      third and last reading that allows the government to limit the prices of non - vital medicine and medical devices . xxmaj as a result , the state has more influence on price regulation . # xxup covid2019 # covid19russia ahk - liveticker https : / / t.co / xxunk https : / / t.co / xxunk xxbos a graduate from our xxmaj english\n    \n    \n      6\n      called racist . xxmaj on cue , he is called racist by globalists in denial . xxmaj pathetic ! https : / / t.co / xxunk xxbos @susannareid100 xxmaj but it 's ok for hundreds of people to be shopping in 300 argos stores across the country that are allowed to remain open even though they are nt essential retailers xxunk @bbcwatchdog @sainsburys @argos_online\n      racist . xxmaj on cue , he is called racist by globalists in denial . xxmaj pathetic ! https : / / t.co / xxunk xxbos @susannareid100 xxmaj but it 's ok for hundreds of people to be shopping in 300 argos stores across the country that are allowed to remain open even though they are nt essential retailers xxunk @bbcwatchdog @sainsburys @argos_online #\n    \n    \n      7\n      panicbuyinguk xxbos xxmaj did a supply run today . xxmaj walk all the way from my condo to the nearest supermarket ( still pretty far ! xxmaj walkthrough xxup xxunk ) and back in broad xxunk . 7 kg rice not included in the pic cuz its in my xxunk sucks . https : / / t.co / xxunk xxbos # xxup covid19 :\n      xxbos xxmaj did a supply run today . xxmaj walk all the way from my condo to the nearest supermarket ( still pretty far ! xxmaj walkthrough xxup xxunk ) and back in broad xxunk . 7 kg rice not included in the pic cuz its in my xxunk sucks . https : / / t.co / xxunk xxbos # xxup covid19 : xxmaj\n    \n    \n      8\n      the phone . # toiletpaper # xxmaj coronavirus xxbos xxmaj denver xxmaj news xxup ag warns xxmaj coloradans against coronavirus scams https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxmaj this bus driver said he felt violated when a passenger coughed and sneezed on the bus without covering her mouth . xxmaj he died of # coronavirus\n      phone . # toiletpaper # xxmaj coronavirus xxbos xxmaj denver xxmaj news xxup ag warns xxmaj coloradans against coronavirus scams https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxmaj this bus driver said he felt violated when a passenger coughed and sneezed on the bus without covering her mouth . xxmaj he died of # coronavirus 11\n    \n  \n\n\n\n\nlrnr = language_model_learner(dls,AWD_LSTM,metrics=[accuracy,Perplexity()])\n\n\nlrnr.fine_tune(3,1e-1) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      perplexity\n      time\n    \n  \n  \n    \n      0\n      4.812939\n      4.488820\n      0.288512\n      89.016312\n      02:03\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      perplexity\n      time\n    \n  \n  \n    \n      0\n      4.009799\n      3.902233\n      0.327761\n      49.512905\n      02:30\n    \n    \n      1\n      3.722594\n      3.662943\n      0.355355\n      38.975876\n      02:33\n    \n    \n      2\n      3.447793\n      3.590583\n      0.365500\n      36.255199\n      02:30\n    \n  \n\n\n\n\nlrnr.predict('the price of',20) \n\n\n\n\n\n\n\n\n'the price of milk and toilet roll havenâ\\x92t tripled surges by the end of the week but we have had a sense of'\n\n\n\n\n2. COVID10 tweets -> 분류\n\ndf = pd.read_csv('Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      UserName\n      ScreenName\n      Location\n      TweetAt\n      OriginalTweet\n      Sentiment\n    \n  \n  \n    \n      0\n      3799\n      48751\n      London\n      16-03-2020\n      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\n      Neutral\n    \n    \n      1\n      3800\n      48752\n      UK\n      16-03-2020\n      advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\n      Positive\n    \n    \n      2\n      3801\n      48753\n      Vagabonds\n      16-03-2020\n      Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\n      Positive\n    \n    \n      3\n      3802\n      48754\n      NaN\n      16-03-2020\n      My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\n      Positive\n    \n    \n      4\n      3803\n      48755\n      NaN\n      16-03-2020\n      Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\n      Extremely Negative\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      41152\n      44951\n      89903\n      Wellington City, New Zealand\n      14-04-2020\n      Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\n      Neutral\n    \n    \n      41153\n      44952\n      89904\n      NaN\n      14-04-2020\n      Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\n      Extremely Negative\n    \n    \n      41154\n      44953\n      89905\n      NaN\n      14-04-2020\n      You know itÂs getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\n      Positive\n    \n    \n      41155\n      44954\n      89906\n      NaN\n      14-04-2020\n      Is it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\n      Neutral\n    \n    \n      41156\n      44955\n      89907\n      i love you so much || he/him\n      14-04-2020\n      @TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\n      Negative\n    \n  \n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndls = TextDataLoaders.from_df(df,text_col='OriginalTweet', label_col='Sentiment', seq_len=64)\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      category\n    \n  \n  \n    \n      0\n      xxbos xxrep 5 ? ? ? xxrep 7 ? ? ? xxrep 7 ? xxrep 4 ? xxrep 4 ? xxrep 11 ? ? ? xxrep 6 ? xxrep 4 ? , xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 3 ? ? ? ? ? xxrep 4 ? ? ? xxrep 3 ? , xxrep 4 ? ? ? ? ? xxrep 6 ? xxrep 3 ? xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? \\r\\r\\n▁ xxrep 5 ? xxrep 6 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 4 ? ? ? xxrep 4 ? xxrep 6 ? xxrep 4 ? xxrep 8 ? ? ? xxrep 6 ? ? ? xxrep 5 ? ? ? xxrep 3 ? xxrep 4 ? ? ? xxrep 7 ? xxrep 5 ? - xxrep 8 ? xxrep 5\n      Neutral\n    \n    \n      1\n      xxbos xxup ask xxup your xxup self xxup what xxup do xxup you xxup think xxup is xxup going xxup to xxup happen xxup the xxup time xxup to xxup wake xxup up xxup is xxup now xxup do xxup you xxup think xxup food xxup going xxup to xxup be xxup xxunk xxup on xxup shop xxup shelfs .. no \\r\\r\\n xxup do xxup you xxup think xxup food xxup rise xxup in xxup price .. yes \\r\\r\\n xxup i m xxup going xxup to xxup stock xxup up xxup as xxup much i xxup can \\r\\r\\n xxup food xxup ladies xxup gentleman xxup is xxup most xxup valuable xxup asset \\r\\r\\n▁ # xxmaj coronavirus # xxup covid19 https : / / t.co / xxunk\n      Extremely Positive\n    \n    \n      2\n      xxbos xxup keep xxup your xxup home xxup safe & & xxup clean \\r\\r\\n xxmaj the xxmaj best xxmaj way to xxmaj avoid the # xxmaj coronavirus is in xxmaj clean xxmaj home \\r\\r\\n xxmaj absolutely xxmaj outstanding xxmaj cleaning @ xxmaj awesome xxmaj rates \\r\\r\\n xxmaj prices : 2 xxmaj hours 2 xxmaj maids $ 75 + \\r\\r\\n xxmaj serving xxmaj las # xxmaj vegas , # xxmaj summerlin , # xxmaj xxunk xxmaj city & & xxmaj more \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n ( xxunk - xxunk \\r\\r\\n▁ # xxup xxunk # xxup xxunk # xxup xxunk https : / / t.co / xxunk\n      Extremely Positive\n    \n    \n      3\n      xxbos # xxup xxunk : xxup xxunk ' xxup back & & xxup forth xxup in xxup my xxup chair , xxup wearin ' xxup my xxup xxunk , xxup wrapped xxup in xxup my xxup blanket , xxup xxunk ' xxup exhausted , xxup xxunk ' xxunk xxup xxunk ' xxup in xxup line xxup at xxup the xxup supermarket , xxup xxunk ' xxup like xxup i m xxup cool xxup wit ' # xxup socialdistancing xxup there … . xxup why i xxup have xxup to xxup wait xxup so xxup long xxup before xxup xxunk  https : / / t.co / xxunk\n      Positive\n    \n    \n      4\n      xxbos xxup sweet xxup baby xxup jesus & & xxup all xxup his xxup xxunk ! i swear 2 xxmaj god xxmaj i 'm going 2 throat punch these xxup covid-19 xxup food xxup hoarders . xxmaj the world xxmaj is n't going 2 end u selfish pricks . i went 2 get milk tonight & & they were out of stock . 4 the love of xxup xxunk xxup hoarding & & xxup save xxup some xxup products xxup for xxup the xxup rest xxup of xxup us xxrep 3 ! https : / / t.co / xxunk\n      Extremely Positive\n    \n    \n      5\n      xxbos xxmaj this # xxmaj afternoon : xxmaj at xxup bs i could n't buy scratchers b / c it was # closed b / c of # coronavirus . xxmaj after xxup bs i walked to # xxmaj water xxmaj store to buy $ 2 scratchers . i won $ 10 with xxup xxunk and $ 1 with xxup xxunk . xxmaj after xxup ws i walked to # xxmaj mexican # xxmaj grocery to buy $ 2 scratchers . i lost $ 1 with xxup xxunk and $ 1 with xxup xxunk .\n      Positive\n    \n    \n      6\n      xxbos xxmaj running xxmaj in xxmaj place , xxmaj working xxmaj out # 2k20 # xxmaj park # xxmaj workouts # xxmaj xxunk # xxmaj xxunk # xxmaj basketball # xxmaj court # xxmaj bored # xxmaj coronavirus # toiletpaper # xxmaj running # xxmaj lockdown # xxmaj home # xxmaj governor # xxmaj browns # xxup nfl # xxup nba # xxmaj cleveland # xxmaj art # xxmaj poetry # xxmaj peaceful # xxmaj beauty # xxmaj meditation # xxmaj ventilator \\r\\r\\n https : / / t.co / xxunk via @youtube\n      Neutral\n    \n    \n      7\n      xxbos xxup mbbs - xxup rmc xxmaj pakistan \\r\\r\\n msc xxmaj public xxmaj health - xxup lsh xxup uk \\r\\r\\n ex - global xxmaj coordinator xxup who \\r\\r\\n ex - regional xxmaj adviser xxup who \\r\\r\\n xxmaj founder & & xxmaj executive xxmaj coordinator - xxmaj the xxmaj network for xxmaj consumer xxmaj protection xxmaj pakistan \\r\\r\\n\\r\\r\\n xxup vs \\r\\r\\n\\r\\r\\n xxup ba - xxmaj national xxmaj college xxmaj karachi . \\r\\r\\n xxup llb - xxmaj sindh xxmaj muslim xxmaj law xxmaj college \\r\\r\\n\\r\\r\\n▁ # coronaviruspakistan # xxmaj coronavirus\n      Neutral\n    \n    \n      8\n      xxbos xxup stop xxup hoarding - u r xxup causing xxup problems 4 / xxup people xxup who xxup canât get around xxup easy & & quick ( the elderly & & those w / physical disabilities ) most r xxup over xxup buying products xxunk at higher prices xxup not 4 / xxup need & & treating toilet paper like xxup roll xxup gold - look at xxup what u r xxup doing . \\r\\r\\n▁ # stophoarding \\r\\r\\n▁ # coronavirus https : / / t.co / xxunk\n      Negative\n    \n  \n\n\n\n\nlrnr = text_classifier_learner(dls,AWD_LSTM,metrics=accuracy)\n\n\nlrnr.fine_tune(5, 1e-2)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.466701\n      1.372223\n      0.390597\n      00:46\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.171761\n      1.022376\n      0.572956\n      00:53\n    \n    \n      1\n      0.947488\n      0.843770\n      0.669056\n      00:51\n    \n    \n      2\n      0.802706\n      0.684167\n      0.740858\n      00:52\n    \n    \n      3\n      0.671411\n      0.648740\n      0.758110\n      00:52\n    \n    \n      4\n      0.605033\n      0.645920\n      0.759203\n      00:54\n    \n  \n\n\n\n\nlrnr.predict(\"the government’s approach to the pendemic has been a complete disaster\") \n\n\n\n\n\n\n\n\n('Extremely Negative',\n tensor(0),\n tensor([6.7275e-01, 5.5622e-06, 3.2659e-01, 2.4446e-05, 6.2955e-04]))\n\n\n\nlrnr.predict(\"the new vaccines hold the promise of a quick return to economic growth\") \n\n\n\n\n\n\n\n\n('Extremely Positive',\n tensor(1),\n tensor([1.6411e-06, 9.0713e-01, 1.5391e-04, 4.9677e-05, 9.2669e-02]))\n\n\n\n\n3. human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[:5], txt_y[:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\n #torch.nn.RNNCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\n\ntorch.manual_seed(202250926)\nrnncell = torch.nn.RNNCell(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.999, 0.   , 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.002, 0.998, 0.   , 0.   , 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.999, 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.001, 0.001, 0.998],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.999, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n# torch.nn.RNN()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\nrnn = torch.nn.RNN(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, hT = rnn(x) \n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n#  torch.nn.LSTMCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\ntorch.manual_seed(202250926) \nlstmcell = torch.nn.LSTMCell(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []\n    ht = torch.zeros(8).to(\"cuda:0\")\n    ct = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.997, 0.   , 0.002, 0.   , 0.001, 0.   ],\n       [0.   , 0.   , 0.991, 0.004, 0.005, 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.028, 0.003, 0.969, 0.   , 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.975, 0.021],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.019, 0.   , 0.   , 0.021, 0.961],\n       [0.998, 0.002, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.937, 0.   , 0.03 , 0.   , 0.032]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n# torch.nn.LSTM()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\nlstm = torch.nn.LSTM(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, (hT,cT) = lstm(x)\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html",
    "title": "기계학습 (1012) 6주차",
    "section": "",
    "text": "깊은신경망(2)– 시벤코정리, 신경망의표현, CPU vs GPU, 확률적경사하강법, 오버피팅"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#지난시간-논리전개",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#지난시간-논리전개",
    "title": "기계학습 (1012) 6주차",
    "section": "지난시간 논리전개",
    "text": "지난시간 논리전개\n- 아이디어: linear -> relu -> linear (-> sigmoid) 조합으로 꺽은선으로 표현되는 underlying 을 표현할 수 있었다.\n\n아이디어의 실용성: 실제자료에서 꺽은선으로 표현되는 underlying은 몇개 없을 것 같음. 그건 맞는데 꺽이는 점을 많이 설정하면 얼추 비슷하게는 “근사” 시킬 수 있음.\n아이디어의 확장성: 이러한 논리전개는 X:(n,2)인 경우도 가능했음. (이 경우 꺽인선은 꺽인평면이 된다)\n아이디어에 해당하는 용어정리: 이 구조가 x->y 로 바로 가는 것이 아니라 x->(u1->v1)->(u2->v2)=y 의 구조인데 이러한 네트워크를 하나의 은닉층을 포함하는 네트워크라고 표현한다. (이 용어는 이따가..)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#시벤코정리-1",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#시벤코정리-1",
    "title": "기계학습 (1012) 6주차",
    "section": "시벤코정리",
    "text": "시벤코정리\nuniversal approximation thm: (범용근사정리,보편근사정리,시벤코정리), 1989\n\n하나의 은닉층을 가지는 “linear -> sigmoid -> linear” 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다면)\n\n- 사실 엄청 이해안되는 정리임. 왜냐햐면,\n\n그렇게 잘 맞추면 1989년에 세상의 모든 문제를 다 풀어야 한거 아니야?\n요즘은 “linear -> sigmoid -> linear” 가 아니라 “linear -> relu -> linear” 조합으로 많이 쓰던데?\n요즘은 하나의 은닉층을 포함하는 네트워크는 잘 안쓰지 않나? 은닉층이 여러개일수록 좋다고 어디서 본 것 같은데?\n\n- 약간의 의구심이 있지만 아무튼 universal approximation thm에 따르면 우리는 아래와 같은 무기를 가진 꼴이 된다.\n\n우리의 무기: \\({\\bf X}: (n,p)\\) 꼴의 입력에서 \\({\\bf y}:(n,1)\\) 꼴의 출력으로 향하는 맵핑을 “linear -> relu -> linear”와 같은 네트워크를 이용해서 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#그림으로-보는-증명과정",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#그림으로-보는-증명과정",
    "title": "기계학습 (1012) 6주차",
    "section": "그림으로 보는 증명과정",
    "text": "그림으로 보는 증명과정\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자.\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,color='C2'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$') #모자의 시프팅(왼족아래쪽이동), 모자높이 이동 (1->2...)\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ \\\\l_1)(x)$')\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data,'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+0.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nax[0].plot(x,l1(x).data,'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nfig\n\n\n\n\n- 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data)\n\n\n\n\n- 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n- 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- \\(h(x)\\)를 활성화함수로 가지는 네트워크를 설계하여 보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input): #forward: x에서 y로가는거.. \n        return h(input) # activation 의 출력 \n\n\na1=MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n\nplt.plot(x,a1(x)) \n\n\n\n\n히든레이어가 1개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1),\n            MyActivation(),\n            torch.nn.Linear(1,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 2개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,2),\n            MyActivation(),\n            torch.nn.Linear(2,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 3개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,3),\n            MyActivation(),\n            torch.nn.Linear(3,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 1024개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1024),\n            MyActivation(),\n            torch.nn.Linear(1024,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-sin-exp",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-sin-exp",
    "title": "기계학습 (1012) 6주차",
    "section": "예제1 (sin, exp)",
    "text": "예제1 (sin, exp)\n\ntorch.manual_seed(43052)\nx = torch.linspace(-10,10,200).reshape(-1,1)\nunderlying = torch.sin(2*x) + torch.sin(0.5*x) + torch.exp(-0.2*x)\neps = torch.randn(200).reshape(-1,1)*0.1  #오차항\ny = underlying + eps \nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(x,underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(x,underlying,lw=3)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-스펙높아도-취업x",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-스펙높아도-취업x",
    "title": "기계학습 (1012) 6주차",
    "section": "예제2 (스펙높아도 취업X)",
    "text": "예제2 (스펙높아도 취업X)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      underlying\n      y\n    \n  \n  \n    \n      0\n      -1.000000\n      0.000045\n      0.0\n    \n    \n      1\n      -0.998999\n      0.000046\n      0.0\n    \n    \n      2\n      -0.997999\n      0.000047\n      0.0\n    \n    \n      3\n      -0.996998\n      0.000047\n      0.0\n    \n    \n      4\n      -0.995998\n      0.000048\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      0.995998\n      0.505002\n      0.0\n    \n    \n      1996\n      0.996998\n      0.503752\n      0.0\n    \n    \n      1997\n      0.997999\n      0.502501\n      0.0\n    \n    \n      1998\n      0.998999\n      0.501251\n      1.0\n    \n    \n      1999\n      1.000000\n      0.500000\n      1.0\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).reshape(-1,1).float()\ny = torch.tensor(df.y).reshape(-1,1).float()\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(df.x,df.underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(df.x,df.underlying,lw=3)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-mnist-data-with-dnn",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-mnist-data-with-dnn",
    "title": "기계학습 (1012) 6주차",
    "section": "예제3 (MNIST data with DNN)",
    "text": "예제3 (MNIST data with DNN)\n\n# 예비학습\n(예비학습1) Path\n\npath = untar_data(URLs.MNIST) \npath\n\nPath('/home/cgb4/.fastai/data/mnist_png')\n\n\n\npath 도 오브젝트임\npath 도 정보+기능이 있음\n\n- path의 정보\n\npath._str # 숨겨놓았네? #path도 object 동작을 정의하는 기능이 있을거야..\n#path 오브젝트에 저장된 정보(attribute, 기능은 method)\n\n'/home/cgb4/.fastai/data/mnist_png'\n\n\n- 기능1\n\npath.ls()  # path 오브젝트의 안에 있는 목록(폴더)를 보여줘!\n\n(#2) [Path('/home/cgb4/.fastai/data/mnist_png/training'),Path('/home/cgb4/.fastai/data/mnist_png/testing')]\n\n\n- 기능2\n\npath/'training'  #경로를 결합\n\nPath('/home/cgb4/.fastai/data/mnist_png/training')\n\n\n\npath/'testing'\n\nPath('/home/cgb4/.fastai/data/mnist_png/testing')\n\n\n- 기능1과 기능2의 결합\n\n(path/'training/3').ls()\n\n(#6131) [Path('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/12933.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/3576.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/59955.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/23144.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/40836.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/25536.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/42669.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/7046.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/47380.png')...]\n\n\n\n‘/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’ 이 파일을 더블클릭하면 이미지가 보인단 말임\n\n(예비학습2) plt.imshow\n\n# plt.imshow 값에 따라 밝게 어둡게 보여줌\n\n\nimgtsr = torch.tensor([[1.0,2],[2.0,4.0]])\nimgtsr\n\ntensor([[1., 2.],\n        [2., 4.]])\n\n\n\nplt.imshow(imgtsr,cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fceac108e50>\n\n\n\n\n\n(예비학습3) torchvision\n- ’/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’의 이미지파일을 torchvision.io.read_image 를 이용하여 텐서로 만듬\n\n#!s /home/cgb4/.fastai/data/mnist_png/training/3\n#ls아닌가? 뭐지\n\n\nimgtsr = torchvision.io.read_image('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png')\nimgtsr\n\ntensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66, 138,\n          149, 180, 138, 138,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  22, 162, 161, 228, 252, 252,\n          253, 252, 252, 252, 252,  74,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 253, 252, 252, 252, 189,\n          184, 110, 119, 252, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  74, 161, 160,  77,  45,   4,\n            0,   0,  70, 252, 210,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,  22, 205, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0, 162, 253, 245,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           36, 219, 252, 139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          222, 252, 202,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,\n          253, 252,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 240,\n          253, 157,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 160, 253,\n          231,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 252, 252,\n           42,  30,  78, 161,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          185, 228, 252, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          253, 252, 252, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 179, 252,\n          253, 252, 252, 210,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,\n          255, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,  89, 244,\n          253, 223,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 123, 142, 234, 252, 252,\n          184,  67,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 230, 253, 252, 252, 252, 168,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 126, 253, 252, 168,  43,   2,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n       dtype=torch.uint8)\n\n\n- 이 텐서는 (1,28,28)의 shape을 가짐\n\nimgtsr.shape\n\ntorch.Size([1, 28, 28])\n\n\n\n# 1: 채널의 숫자, 28*28은 픽셀의 숫자\n\n- imgtsr를 plt.imshow 로 시각화\n\nplt.imshow(imgtsr.reshape(28,28),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fceabd49a90>\n\n\n\n\n\n\n진짜 숫자3이 있음\n\n\n\n# 데이터정리\n- 데이터정리\n\nthrees = (path/'training/3').ls() #6131개, 1,28,28\nsevens = (path/'training/7').ls() #6265개, 1,28,28\nlen(threes),len(sevens)\n\n(6131, 6265)\n\n\n\nX3 = torch.stack([torchvision.io.read_image(str(threes[i])) for i in range(6131)]) #리스트 형태로 만들고.. \nX7 = torch.stack([torchvision.io.read_image(str(sevens[i])) for i in range(6265)])\n\n\n# X3 = torch.stack([torchvision.io.read_image(str(fn)])) for i in three_fnames]) \n# X7 = torch.stack([torchvision.io.read_image(str(fn)])) for i in seven_fnames])\n# 위와 같은 코드\n\n\nX3.shape,X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\nX=torch.concat([X3,X7]) #n * p 의 shape \n#float로 바꿔줘야함\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nXnp = X.reshape(-1,1*28*28).float()\nXnp.shape\n\ntorch.Size([12396, 784])\n\n\n\ny = torch.tensor([0.0]*6131 + [1.0]*6265).reshape(-1,1)  # 3을 0으로 7을 1로.. 나중에 sigmoin하기 편하게 하려고  6131대신에 len(X3)이렇게 써도 됨\ny.shape\n\ntorch.Size([12396, 1])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n“y=0”은 숫자3을 의미, “y=1”은 숫자7을 의미\n숫자3은 6131개, 숫자7은 6265개 있음\n\n\n\n# 학습\n- 네트워크의 설계\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(  #묶어주기..\n    torch.nn.Linear(in_features=1*28*28,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(200):\n    ## 1\n    yhat = net(Xnp) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o')\nplt.plot(net(Xnp).data,'.',alpha=0.2)\n\n\n\n\n\n대부분 잘 적합되었음"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xₙ\" -> \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xₙ*ŵ₁,    bias=False\" -> \"ŷₙ\"[label=\"sigmoid\"]\n\n    \".\" -> \"....................................\"[label=\"* ŵ₀\"]\n    \"..\" -> \"....................................\"[label=\"* ŵ₁\"]\n    \"....................................\" -> \"...\"[label=\" \"]\n\n    \"1 \" -> \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₂\" -> \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₂*ŵ₁,    bias=False\" -> \"ŷ₂\"[label=\"sigmoid\"]\n    \n    \"1  \" -> \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₁\" -> \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₁*ŵ₁,    bias=False\" -> \"ŷ₁\"[label=\"sigmoid\"]\n''')\n\n\n\n\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xᵢ\" -> \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xᵢ*ŵ₁,    bias=False\" -> \"ŷᵢ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x\" -> \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x*ŵ₁,    bias=False\" -> \"ŷ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n\nCode\ngv('''\n\"x\" -> \"x*ŵ₁,    bias=True\"[label=\"*ŵ₁\"] ;\n\"x*ŵ₁,    bias=True\" -> \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n\nCode\ngv('''\n\"x\" -> \"x*ŵ,    bias=True\"[label=\"*ŵ\"] ;\n\"x*ŵ,    bias=True\" -> \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\nCode\ngv('''\n\"x\" -> \"u\";\n\"u\" -> \"y\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 10월4일 강의노트에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n\nCode\ngv('''\n\"x\" -> \" -x\"[label=\"*(-1)\"];\n\"x\" -> \" x\"[label=\"*1\"]\n\" x\" -> \"rlu(x)\"[label=\"relu\"] \n\" -x\" -> \"rlu(-x)\"[label=\"relu\"] \n\"rlu(x)\" -> \"u\"[label=\"*(-4.5)\"] \n\"rlu(-x)\" -> \"u\"[label=\"*(-9.0)\"] \n\"u\" -> \"sig(u)=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n(좀 더 일반화된 표현) 10월4일 강의노트 상황을 일반화하면 아래와 같다.\n\n\nCode\ngv('''\n\"x\" -> \"u1[:,0]\"[label=\"*(-1)\"];\n\"x\" -> \"u1[:,1]\"[label=\"*1\"]\n\"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"] \n\"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"] \n\"v1[:,0]\" -> \"u2\"[label=\"*(-9.0)\"] \n\"v1[:,1]\" -> \"u2\"[label=\"*(-4.5)\"] \n\"u2\" -> \"v2=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"u1[:,0]\"\n    \"X\" -> \"u1[:,1]\"\n    \"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -> \"u2\"\n    \"v1[:,1]\" -> \"u2\"\n    \"u2\" -> \"v2=yhat\"[label=\"sigmoid\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\nLayer를 세는 방법\n\n정석: 학습가능한 파라메터가 몇층으로 있는지…\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음.\n위의 예제의 경우 number of layer = 2 이다.\n\n\n사실 input layer, activation layer 등의 표현을 자주 사용해서 layer를 세는 방법이 처음에는 헷갈립니다..\n\nHidden Layer의 수를 세는 방법\n\nLayer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat \"\n    \"node2\" -> \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"feature1\"\n    \"X\" -> \"feature2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"feature1\" -> \"yhat \"\n    \"feature2\" -> \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Input Layer\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n    \n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node32\"\n    \"x2\" -> \"node32\"\n    \"..\" -> \"node32\"\n    \"x784\" -> \"node32\"\n\n\n    label = \"Hidden Layer: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    \"...\" -> \"yhat\"\n    \"node32\" -> \"yhat\"\n    \n    label = \"Outplut Layer: sigmoid\"\n}\n''')\n\n\n\n\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-사용방법",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-사용방법",
    "title": "기계학습 (1012) 6주차",
    "section": "GPU 사용방법",
    "text": "GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) #net에 넣어야니까 shape을 바꿔주기\ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\")  #net_cpu.to(\"cuda:0\") 하게 되면 net_cpu도 gpu로 넘어가게 되므로 그대로 써주면 안뎀 \n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=<AddmmBackward0>)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=<MeanBackward0>)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#시간측정-예비학습",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#시간측정-예비학습",
    "title": "기계학습 (1012) 6주차",
    "section": "시간측정 (예비학습)",
    "text": "시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()  #현재시각\n\n\nt2 = time.time()\n\n\nt2-t1  # 현재시간 - 현재시간 : 위아래 실행하는 만큼의 초 나옴 \n\n4.9920783042907715"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-512",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-512",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU (512)",
    "text": "CPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\n- for문 준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.28586554527282715"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-512",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-512",
    "title": "기계학습 (1012) 6주차",
    "section": "GPU (512)",
    "text": "GPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\n- for문돌릴준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5355696678161621\n\n\n\n!! CPU가 더 빠르다?"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-20480",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-20480",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU vs GPU (20480)",
    "text": "CPU vs GPU (20480)\n- CPU (20480)\n\n#은닉충의 노드수: 20480\n\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.380666494369507\n\n\n- GPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5442469120025635\n\n\n- 왜 이런 차이가 나는가? 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-204800",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-204800",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU vs GPU (204800)",
    "text": "CPU vs GPU (204800)\n- CPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n51.95550894737244\n\n\n- GPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3824031352996826"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#좀-이상하지-않아요",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#좀-이상하지-않아요",
    "title": "기계학습 (1012) 6주차",
    "section": "좀 이상하지 않아요?",
    "text": "좀 이상하지 않아요?\n- 우리가 쓰는 GPU: 다나와 PC견적 - GPU 메모리 끽해봐야 24GB\n- 우리가 분석하는 데이터: 빅데이터..?\n- 데이터의 크기가 커지는순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "기계학습 (1012) 6주차",
    "section": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "기계학습 (1012) 6주차",
    "section": "경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n- ver1: 모든 샘플을 이용하여 slope 계산\n(epoch1) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n(epoch2) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n…\n- ver2: 하나의 샘플만을 이용하여 slope 계산\n(epoch1) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…\n- ver3: \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch1) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#용어의-정리",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#용어의-정리",
    "title": "기계학습 (1012) 6주차",
    "section": "용어의 정리",
    "text": "용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n\n# gpu메모리가 떨어져서 ver1은 못쓴당.. ver2는 불안한 느낌 for문이 너무 많이 돌ㄹ아가->느림..\n\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl",
    "title": "기계학습 (1012) 6주차",
    "section": "ds, dl",
    "text": "ds, dl\n\n# 데이터셋\n\n- ds\n\nx=torch.tensor(range(10)).float()#.reshape(-1,1) reshape원래는 해야는데 보여주기 위해서 생략쓰,,\ny=torch.tensor([1.0]*5+[0.0]*5)#.reshape(-1,1)\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n<torch.utils.data.dataset.TensorDataset at 0x7f62db294710>\n\n\n\nds.tensors # 그냥 (x,y)의 튜플\n\n(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))\n\n\n\n# 데이터로더\n\n- dl\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3) #batch_size: 3개씩 묶어서 배치를 해줌\n#set(dir(dl)) & {'__iter__'}\n\n#dir(dl):숨겨진 습성 \n#dl.__ : 숨겨진 습성\n# iter 오브젝트: for문에 돌릴수 있다는 특성..!\n\n\nfor xx,yy in dl:  #in 뒤에 iter오브젝트는 다 쓸수 있음\n    print(xx,yy)\n\ntensor([0., 1., 2.]) tensor([1., 1., 1.])\ntensor([3., 4., 5.]) tensor([1., 1., 0.])\ntensor([6., 7., 8.]) tensor([0., 0., 0.])\ntensor([9.]) tensor([0.])"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl을-이용한-mnist-구현",
    "href": "posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl을-이용한-mnist-구현",
    "title": "기계학습 (1012) 6주차",
    "section": "ds, dl을 이용한 MNIST 구현",
    "text": "ds, dl을 이용한 MNIST 구현\n- 데이터정리\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255  #255로나누는 이유 숙제\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n- ds \\(\\to\\) dl\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048) \n\n\n12665/2048\n\n6.18408203125\n\n\n\ni = 0 \nfor xx,yy in dl: # 총 7번 돌아가는 for문 \n    print(i)\n    i=i+1\n\n0\n1\n2\n3\n4\n5\n6\n\n\n- 미니배치 안쓰는 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(70): \n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss= loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ntorch.sum((yhat>0.5) == y) / len(y) \n# 분자: 전체 데이터 중 잘 맞춘게 몇개인지.\n# 분모: y의 갯수???\n# torch.mean((yhat>0.5) == y)*1.0) 계산하면 위와 같음\n\ntensor(0.9981)\n\n\n- 미니배치 쓰는 학습 (GPU 올리고 내리는 과정은 생략)\n\n# len(y)/2048 = 6.18408203125 \n# 1~2048, 2049~ 하면 6번 조금넘게나옴 (7번)\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10):\n    for xx,yy in dl: ## 7번\n        ## 1\n        #yhat = net(xx)\n        ## 2 \n        loss = loss_fn(net(xx),yy) \n        ## 3 \n        loss.backward() \n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\ntorch.mean(((net(X)>0.5) == y)*1.0)\n\ntensor(0.9950)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html",
    "title": "기계학습 (0928) 4주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#numpy-torch-선택학습",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#numpy-torch-선택학습",
    "title": "기계학습 (0928) 4주차",
    "section": "numpy, torch (선택학습)",
    "text": "numpy, torch (선택학습)\n\nnumpy, torch는 엄청 비슷해요\n- torch.tensor() = np.array() 처럼 생각해도 무방\n\nnp.array([1,2,3]), torch.tensor([1,2,3])\n\n(array([1, 2, 3]), tensor([1, 2, 3]))\n\n\n- 소수점의 정밀도에서 차이가 있음 (torch가 좀 더 쪼잔함)\n\nnp.array([3.123456789])\n\narray([3.12345679])\n\n\n\ntorch.tensor([3.123456789]) #GPU메모리에 저장해서 \n\ntensor([3.1235])\n\n\n- 기본적인 numpy 문법은 np 대신에 torch를 써도 무방 // 완전 같지는 않음\n\nnp.arange(10), torch.arange(10)\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n\n\nnp.linspace(0,1,10), torch.linspace(0,1,10)\n\n(array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n         1.0000]))\n\n\n\nnp.random.randn(10)\n\narray([ 0.68732684, -0.53367188,  0.27916096,  0.28236708,  0.03800702,\n       -0.66236923,  1.32472364, -0.11671166, -0.77019834, -1.14755872])\n\n\n\ntorch.randn(10)\n\ntensor([ 0.8525,  0.2257,  0.3406, -0.4713,  1.5393, -2.0060, -0.4257,  3.0482,\n        -0.7659,  0.3265])\n\n\n\n\nlength \\(n\\) vector, \\(n \\times 1\\) col-vector, \\(1 \\times n\\) row-vector\n- 길이가 3인 벡터 선언방법\n\na = torch.tensor([1,2,3])\na.shape\n\ntorch.Size([3])\n\n\n- 3x1 col-vec 선언방법\n(방법1)\n\na = torch.tensor([[1],[2],[3]])\na.shape\n\ntorch.Size([3, 1])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(3,1)\na.shape\n\ntorch.Size([3, 1])\n\n\n- 1x3 row-vec 선언방법\n(방법1)\n\na = torch.tensor([[1,2,3]])\na.shape\n\ntorch.Size([1, 3])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(1,3)\na.shape\n\ntorch.Size([1, 3])\n\n\n- 3x1 col-vec 선언방법, 1x3 row-vec 선언방법에서 [[1],[2],[3]] 혹은 [[1,2,3]] 와 같은 표현이 이해안되면 아래링크로 가셔서\nhttps://guebin.github.io/STBDA2022/2022/03/14/(2주차)-3월14일.html\n첫번째 동영상 12:15 - 22:45 에 해당하는 분량을 학습하시길 바랍니다.\n\n\ntorch의 dtype\n- 기본적으로 torch는 소수점으로 저장되면 dtype=torch.float32 가 된다. (이걸로 맞추는게 편리함)\n\ntsr = torch.tensor([1.23,2.34])\ntsr\n\ntensor([1.2300, 2.3400])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n\n#float64보다 데이터를 적게 쓴다는 뜻-> float32\n\n- 정수로 선언하더라도 dtype를 torch.float32로 바꾸는게 유리함\n(안 좋은 선언예시)\n\ntsr = torch.tensor([1,2])\ntsr \n\ntensor([1, 2])\n\n\n\ntsr.dtype\n\ntorch.int64\n\n\n(좋은 선언예시1)\n\ntsr = torch.tensor([1,2],dtype=torch.float32)\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(좋은 선언예시2)\n\ntsr = torch.tensor([1,2.0])\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(사실 int로 선언해도 나중에 float으로 바꾸면 큰 문제없음)\n\ntsr = torch.tensor([1,2]).float()\ntsr\n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 왜 정수만으로 torch.tensor를 만들때에도 torch.float32로 바꾸는게 유리할까? \\(\\to\\) torch.tensor끼리의 연산에서 문제가 될 수 있음\n별 문제 없을수도 있지만\n\ntorch.tensor([1,2])-torch.tensor([1.0,2.0]) \n\ntensor([0., 0.])\n\n\n아래와 같이 에러가 날수도 있다\n(에러1)\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1],[2]]) \n\nRuntimeError: expected scalar type Float but found Long\n\n\n(에러2)\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1.0],[2.0]])\n\nRuntimeError: expected scalar type Long but found Float\n\n\n(해결1) 둘다 정수로 통일\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1],[2]])\n\ntensor([[1],\n        [2]])\n\n\n(해결2) 둘다 소수로 통일 <– 더 좋은 방법임\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1.0],[2.0]])\n\ntensor([[1.],\n        [2.]])\n\n\n\n\nshape of vector\n- 행렬곱셈에 대한 shape 조심\n\nA = torch.tensor([[2.00,0.00],[0.00,3.00]]) \nb1 = torch.tensor([[-1.0,-5.0]])\nb2 = torch.tensor([[-1.0],[-5.0]])\nb3 = torch.tensor([-1.0,-5.0])\n\n\nA.shape,b1.shape,b2.shape,b3.shape\n\n(torch.Size([2, 2]), torch.Size([1, 2]), torch.Size([2, 1]), torch.Size([2]))\n\n\n- A@b1: 계산불가, b1@A: 계산가능\n\nA@b1 #행렬계산이라고 생각\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2 and 1x2)\n\n\n\nb1@A\n\ntensor([[ -2., -15.]])\n\n\n- A@b2: 계산가능, b2@A: 계산불가\n\nA@b2\n\ntensor([[ -2.],\n        [-15.]])\n\n\n\nb2@A\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)\n\n\n- A@b3: 계산가능, b3@A: 계산가능\n\n(A@b3).shape ## b3를 마치 col-vec 처럼 해석\n\ntorch.Size([2])\n\n\n\n(b3@A).shape ## b3를 마지 row-vec 처럼 해석\n\ntorch.Size([2])\n\n\n- 브로드캐스팅\n\na = torch.tensor([1,2,3]) #a는 길이가 3인 벡터지만... 연산이 된다.\na - 1\n\ntensor([0, 1, 2])\n\n\n\nb = torch.tensor([[1],[2],[3]]) #b는 컬럼 벡터\nb - 1\n\ntensor([[0],\n        [1],\n        [2]])\n\n\n\na - b # a를 row-vec 로 해석 \n#불필요한 오류를 막기 위해서 dimension잘 써놓기\n\ntensor([[ 0,  1,  2],\n        [-1,  0,  1],\n        [-2, -1,  0]])"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#review-step14",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#review-step14",
    "title": "기계학습 (0928) 4주차",
    "section": "Review: step1~4",
    "text": "Review: step1~4\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -2.482113\n      -8.542024\n    \n    \n      1\n      -2.362146\n      -6.576713\n    \n    \n      2\n      -1.997295\n      -5.949576\n    \n    \n      3\n      -1.623936\n      -4.479364\n    \n    \n      4\n      -1.479192\n      -4.251570\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      2.244400\n      10.325987\n    \n    \n      96\n      2.393501\n      12.266493\n    \n    \n      97\n      2.605604\n      13.098280\n    \n    \n      98\n      2.605658\n      12.546793\n    \n    \n      99\n      2.663240\n      13.834002\n    \n  \n\n100 rows × 2 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ntorch.tensor(df.x)\n#dtype=float32로 지정하면 밑에 dtype=torch.float64가 안붙는다. 메모리를 아끼기위해서 데이터타입을 float32로바꾼다리\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632], dtype=torch.float64)\n\n\n\nx= torch.tensor(df.x,dtype=torch.float32).reshape(100,1)   \ny= torch.tensor(df.y,dtype=torch.float32).reshape(100,1)\n\n# _1 = torch.ones([100,1])\n# X = torch.concat([_1,x]),axis=1\n\nX= torch.tensor([[1]*100,x]).T    #torch.ones([100,1])로 써도 됨\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 아무 점이나 주어보자! (-5,10)\n\n\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\n#plt.plot(x,-5+10*x,'--')\nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nver1: loss = sum of squares error\n\nalpha = 1/1000    #학습하는과정에 대한 분류 4가지\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n  #  What.data = What.data - 1/000 * What.grad   # alpha = 1/000\n  #  What.grad = None #              # gradient청소...\n\n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nnote: 왜 What = What - alpha*What.grad 는 안되는지?\n\n\n\nver2: loss = mean squared error = MSE\n\nalpha = 1/10\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.mean((y-yhat)**2)   # 위랑 다른거 여기 mean!!!! \n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n    # mean으로 하면 좋은거: 100개읟 ㅔ이터 1/1000 학습률 \n    # sample size가 달라질때마다 학습률 설정이 힘든데, mean으로 하면 데이터set이 계속 할수잇어서!!\n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-net-설계만",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-net-설계만",
    "title": "기계학습 (0928) 4주차",
    "section": "step1의 다른버전 – net 설계만",
    "text": "step1의 다른버전 – net 설계만\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True)  # 함수를 만들어준다. x가들어가면 y가 나오는 것 가틍ㄴ..\n\n# x.shape 했을때 torch.size(100,1) 이 나온다. 100은 observation이고 뒤쪽에 있는 1이 in_features!!\n# out_features는 y.shape의 뒤쪽,,\n\n# net.bias, net.weight 하면 tensor 0.2366 -> w0역할... tensor -0.8791 -> w1역할 \n# 위 숫자는 최초의 숫자라 아무거나 찍은거 실행할때마다 달라질수 있음.\n# 맨 위에 seed를 주면 나중에 교수님 강의할때 편하게` 하려고 \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- net에서 \\(\\hat{w}_0, \\hat{w}_1\\) 의 값은?\n\nnet.weight # w1 \n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nnet.bias # w0 \n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\n_yhat = -0.8470 + -0.3467*x \n\n\nplt.plot(x,y,'o')\nplt.plot(x, _yhat,'--')\nplt.plot(x,net(x).data,'-.')\n\n\n\n\n- 수식표현: \\(\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1 x_i = \\hat{b} + \\hat{w}x_i = -0.8470 + -0.3467 x_i\\) for all \\(i=1,2,\\dots,100\\).\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 입력이 x가 아닌 X를 넣고 싶다면? (보통 잘 안하긴 해요, 왜? bias=False로 주는게 귀찮거든요) - X는 바이어스가 고려된 상황\n\nnet(X) ## 그대로 쓰면 당연히 에러\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2, out_features=1, bias=False) #bias=false:뒤쪽에 더해지는 값인거 같으니까....\n\n# out_features=3으로 쓰면 shape이 [100,3] 된다,,,,,,,,,,, 1이 되야해,,\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias # false로 설정해서 아무것도 안뜸\n\n\nplt.plot(x,y,'o') \nplt.plot(x,net(X).data, '--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]), '-.')\n\n\n\n\n- 수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix}\\)\n\n\n잘못된사용1\n\n_x = x.reshape(-1)\n\n\n_x\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1,out_features=1) \n\n\nnet(_x) #이렇게 하면 에러메시지뜬다리 \n# net(_x.reshape(100,1))로 바궈줘야 한다.\n\nRuntimeError: size mismatch, got 1, 1x1,100\n\n\n\n\n잘못된사용2\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2,out_features=1) # bias=False를 깜빡.. bias=true로 설정됨 기본으로 \n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.2549], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]])+0.2549,'-.')\n# b hat = 0.2549 의도와는 다르게 모델링 된것..\n\n\n# plt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]),'-.')\n# bias=f일때\n\n\n\n\n\n수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} + \\hat{b}= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix} + 0.2549\\)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-끝까지",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-끝까지",
    "title": "기계학습 (0928) 4주차",
    "section": "step1의 다른버전 – 끝까지",
    "text": "step1의 다른버전 – 끝까지\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1,bias=True) # in_features=1 에서 1만 써도 뎀, bias 생략해도 뎀\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\nnet.weight,net.bias\n\n(Parameter containing:\n tensor([[10.]], requires_grad=True),\n Parameter containing:\n tensor([-5.], requires_grad=True))\n\n\n- step1\n\nyhat = net(x)  # -5 + 10x 가 첫 값으로 나올것,,,\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad   #grad값이 없는데.... \n\n(None, None)\n\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad,net.weight.grad    # 미분후에 값 자체는 변화가 없지만 grad값이 \n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n- step4\n(업데이트전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n(업데이트)\n\nnet.bias.data = net.bias.data - 0.1*net.bias.grad   # 기울기 0.1\nnet.weight.data = net.weight.data - 0.1*net.weight.grad \n\n\nnet.bias.grad = None  # 바뀌기만 하고 청소가 안된상태ㅣ니까 none값으로 지정해주기...\nnet.weight.grad = None \n\n(업데이트후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-3.6577], requires_grad=True),\n Parameter containing:\n tensor([[8.8111]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n- 반복\n\nfor epoc in range(30):\n    # step1\n    yhat = net(x) \n    # step2\n    loss = torch.mean((y-yhat)**2)\n    # step3\n    loss.backward()\n    # step4\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.bias.data = net.bias.data - 0.1*net.bias.grad\n    net.weight.grad = None\n    net.bias.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 준비\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n- step1\n\nyhat = net(X)\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n- step4\n(업데이트전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n(업데이트)\n\nnet.weight.data = net.weight.data - 0.1*net.weight.grad\n\n\nnet.weight.grad = None\n\n(업데이트후)\n\nnet.weight\n\nParameter containing:\ntensor([[-3.6577,  8.8111]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n- 반복\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    # step1\n    yhat = net(X)\n    # step2 \n    loss = torch.mean((y-yhat)**2)\n    # step3\n    loss.backward()\n    # step4\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step4의-다른버전-옵티마이저",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step4의-다른버전-옵티마이저",
    "title": "기계학습 (0928) 4주차",
    "section": "step4의 다른버전: 옵티마이저!",
    "text": "step4의 다른버전: 옵티마이저!\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]]) \nnet.bias.data = torch.tensor([[-5.0]]) \n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) # step4가 너무 귀찮기 때문에 net파라미터를 받아서 업데이트하고 청소해주는 오브젝트를 하나 만들기\n# optim.SGD(parameter, lr(alpha)=0.1)\n# net.parameters() = generator 어쩌고 튀어나오는데 이거 넣어주기 \n\n- step1~3\n\nyhat = net(x)     \n\n\nloss = torch.mean((y-yhat)**2) \n\n\nloss.backward() \n\n- step4\n(update 전)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 전\n\n(tensor([[10.]]), tensor([[-5.]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 청소전 \n\n(tensor([[11.8893]]), tensor([[-13.4225]]))\n\n\n(update)\n\noptimizr.step()  # update 진행해줌\noptimizr.zero_grad() # grad값 청소\n\n(update 후)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 되었음 \n\n(tensor([[8.8111]]), tensor([[-3.6577]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 0으로 초기화하였음 \n\n(tensor([[0.]]), tensor([[0.]]))\n\n\n- 반복\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\nfor epoc in range(30): \n    # step1\n    yhat = net(x)\n    # step2\n    loss = torch.mean((y-yhat)**2) \n    # step3\n    loss.backward()\n    # step4 \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 바로 반복하겠습니다..\n\nnet = torch.nn.Linear(2,1,bias=False) \nnet.weight.data = torch.tensor([[-5.0, 10.0]])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nfor epoc in range(30): \n    yhat = net(X)              # ver1에서는 스몰x였는데 여기서는 라지X\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#appendix-net.parameters의-의미-선택학습",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#appendix-net.parameters의-의미-선택학습",
    "title": "기계학습 (0928) 4주차",
    "section": "Appendix: net.parameters()의 의미? (선택학습)",
    "text": "Appendix: net.parameters()의 의미? (선택학습)\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters)) & {'__iter__'}\n\nset()\n\n\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n- 무슨의미?\n\n_generator = net.parameters()\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n\n_generator.__next__()\n\nStopIteration: \n\n\n- 이건 이런느낌인데?\n\n_generator2 = iter([net.weight,net.bias])\n\n\n_generator2\n\n<list_iterator at 0x7efce86d5dd0>\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nStopIteration: \n\n\n- 즉 아래는 같은코드이다.\n### 코드1\n_generator = net.parameters() \ntorch.optim.SGD(_generator,lr=1/10) \n### 코드2\n_generator = iter([net.weight,net.bias])\ntorch.optim.SGD(_generator,lr=1/10) \n### 코드3 (이렇게 써도 코드2가 실행된다고 이해할 수 있음)\n_iterator = [net.weight,net.bias]\ntorch.optim.SGD(_iterator,lr=1/10) \n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트(iterable object)로 만드는 함수라 이해할 수 있다.\n- 응용예제1\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step();optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n- 응용예제2\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10)\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = b+ w*x \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step(); optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#logistic-regression",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#logistic-regression",
    "title": "기계학습 (0928) 4주차",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 증가함.\n\n# EX) x는 학점이고.. y는 취업할 확률\n\n- (X,y)는 어떤모양?\n\n_df = pd.DataFrame({'x':range(-6,7),'y':[0,0,0,0,0,0,1,0,1,1,1,1,1]})\n_df \n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -6\n      0\n    \n    \n      1\n      -5\n      0\n    \n    \n      2\n      -4\n      0\n    \n    \n      3\n      -3\n      0\n    \n    \n      4\n      -2\n      0\n    \n    \n      5\n      -1\n      0\n    \n    \n      6\n      0\n      1\n    \n    \n      7\n      1\n      0\n    \n    \n      8\n      2\n      1\n    \n    \n      9\n      3\n      1\n    \n    \n      10\n      4\n      1\n    \n    \n      11\n      5\n      1\n    \n    \n      12\n      6\n      1\n    \n  \n\n\n\n\n\nplt.plot(_df.x,_df.y,'o')\n\n\n\n\n- (예비학습) 시그모이드라는 함수가 있음\n\nxx = torch.linspace(-6,6,100)   # -6에서 6까지 100개..\ndef f(x):\n    return torch.exp(x)/(1+torch.exp(x))  \n\n\nplt.plot(_df.x,_df.y,'o')\nplt.plot(xx,f(xx))   # f(xx) = f(1*xx) 얌.. 근데 만약 f(5*xx)하면 기울기가 더 급해져.. 애매한 부분이 더 적어지고 스펙에 대한 영향을 ... f(2.5*xx)-1.2 (우측으로 1.2 이동) 이렇게 튜닝이 가능\n\n\n\n\n\n\nmodel\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 <— 외우세요!!!\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) <— 외우세요!!\n\n\n# 베르누이.. pi i 라는 건.. 왜 p가 아니고 pi냐? 사람마다 합격할 확률이 다르기 때문에.\n# x가 무한대로 가면 pi i 는 1에 가까워지고 마이너스 무한대로 가면 0에가까워진다\n\n# loss는 MSE로 하긴 어렵고,, 라이클리우드?????????? 설명이기니까 위에 그냥 외우기\n# y i = 0 일대랑 1 일때 저식에 넣어서 그래프 그려서 생각해보기... loss는 yi랑 y값이 비슷하면 loss 값이 작아짐\n\n\n\ntoy example\n- 예제시작\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함,  v는 성공할확률\ny = torch.bernoulli(v) \n\n# torch.bernoulli(toch.tensor([0.5]*100))   0,1 반복해서 뽑힘. 0.5는 확률!!!!!\n\n\nplt.scatter(x,y,alpha=0.05)   # 여기서 알파가 투명도인듯??????????? \nplt.plot(x,v,'--r')\n\n\n\n\n\n우리의 목적: \\(x\\)가 들어가면 빨간선 \\(\\hat{y}\\)의 값을 만들어주는 mapping을 학습해보자.\n\n\n# 최초의 곡선\n# w0hat = -1\n# w1hat = 3\n\n\n# yhat = f(w0hat+x*w1hat)\n# plt.plot(x,y, 'o', alpha=0.05)   \n# plt.plot(x,v,'--')\n# plt.plot(x,yhat,'--r')\n\nSyntaxError: ignored\n\n\n\n# sigmoid함수만들엇던걸..............."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#숙제",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#숙제",
    "title": "기계학습 (0928) 4주차",
    "section": "숙제",
    "text": "숙제"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html",
    "title": "기계학습 (0921) 3주차",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#로드맵",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#로드맵",
    "title": "기계학습 (0921) 3주차",
    "section": "로드맵",
    "text": "로드맵\n- 회귀분석 \\(\\to\\) 로지스틱 \\(\\to\\) 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN)\n- 강의계획서"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#ref",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#ref",
    "title": "기계학습 (0921) 3주차",
    "section": "ref",
    "text": "ref\n- 넘파이 문법이 약하다면? (reshape, concatenate, stack)\n\nreshape: 아래 링크의 넘파이공부 2단계 reshape 참고\n\nhttps://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html\n\nconcatenate, stack: 아래 링크의 넘파이공부 4단계 참고\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형-소개",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형-소개",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형 소개",
    "text": "회귀모형 소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-데이터-생성",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-데이터-생성",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형에서 데이터 생성",
    "text": "회귀모형에서 데이터 생성\n\n_rnt=torch.randn(100).sort() #100개의 난수 생성 .sort()는 정렬된 값 표현\n\n\ntype(_rnt) #type해보니까 모르는 거네? lengh를 보면 2니까 리스트를 해볼수 있음!\n\ntorch.return_types.sort\n\n\n\na,_ = _rnt[0], _rnt[1] #첫번쨰 원소가 a에 들어가고 두번째 원소가 언더바에 들어가게 된다.\n\n\nx,_ = torch.randn(100).sort()\nx     # X벡터 안에 들어가는 x1, x2, x3 ... \n\ntensor([-2.6694e+00, -2.6132e+00, -2.2525e+00, -2.0763e+00, -1.9791e+00,\n        -1.8444e+00, -1.7486e+00, -1.7284e+00, -1.6991e+00, -1.6634e+00,\n        -1.6364e+00, -1.5948e+00, -1.5710e+00, -1.5043e+00, -1.5002e+00,\n        -1.4035e+00, -1.3328e+00, -1.3239e+00, -1.2964e+00, -1.2064e+00,\n        -1.1857e+00, -1.1184e+00, -1.0559e+00, -1.0148e+00, -1.0105e+00,\n        -9.7771e-01, -9.2156e-01, -8.9929e-01, -8.8333e-01, -7.6213e-01,\n        -6.8896e-01, -6.2386e-01, -6.0660e-01, -5.9161e-01, -5.7884e-01,\n        -4.4417e-01, -4.3631e-01, -3.8129e-01, -3.5062e-01, -3.4311e-01,\n        -3.1632e-01, -2.7753e-01, -2.7065e-01, -2.7020e-01, -2.6189e-01,\n        -2.2925e-01, -1.4359e-01, -1.2405e-01, -6.8853e-02, -5.1603e-02,\n        -4.9887e-02, -2.3798e-02, -1.6275e-03,  7.4200e-02,  1.6760e-01,\n         1.7279e-01,  2.3754e-01,  2.5730e-01,  2.6886e-01,  2.8250e-01,\n         2.9296e-01,  3.0017e-01,  3.1466e-01,  3.2627e-01,  3.5380e-01,\n         3.5664e-01,  3.6345e-01,  3.6429e-01,  4.3469e-01,  4.3551e-01,\n         4.6556e-01,  4.9491e-01,  4.9940e-01,  5.4481e-01,  6.4859e-01,\n         6.7236e-01,  6.8683e-01,  7.2763e-01,  7.3832e-01,  7.8508e-01,\n         8.0376e-01,  8.1716e-01,  8.2234e-01,  8.8814e-01,  9.1453e-01,\n         9.8436e-01,  1.0107e+00,  1.0332e+00,  1.0441e+00,  1.0577e+00,\n         1.1333e+00,  1.1406e+00,  1.2557e+00,  1.3057e+00,  1.3221e+00,\n         1.3361e+00,  1.6109e+00,  1.7063e+00,  1.8415e+00,  2.0672e+00])\n\n\n\nones= torch.ones(100)   #torch.ones(100) 1이 100개 들어간거. X벡터만들기 위해서 \n\n\ntorch.stack([ones, x]) #stack 쌓는다!!!   근데 우리가 원하는 건 이거의 T (트랜스)를 가지고 싶으니까 벡터T 해주기!\n\ntensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n        [-2.6694e+00, -2.6132e+00, -2.2525e+00, -2.0763e+00, -1.9791e+00,\n         -1.8444e+00, -1.7486e+00, -1.7284e+00, -1.6991e+00, -1.6634e+00,\n         -1.6364e+00, -1.5948e+00, -1.5710e+00, -1.5043e+00, -1.5002e+00,\n         -1.4035e+00, -1.3328e+00, -1.3239e+00, -1.2964e+00, -1.2064e+00,\n         -1.1857e+00, -1.1184e+00, -1.0559e+00, -1.0148e+00, -1.0105e+00,\n         -9.7771e-01, -9.2156e-01, -8.9929e-01, -8.8333e-01, -7.6213e-01,\n         -6.8896e-01, -6.2386e-01, -6.0660e-01, -5.9161e-01, -5.7884e-01,\n         -4.4417e-01, -4.3631e-01, -3.8129e-01, -3.5062e-01, -3.4311e-01,\n         -3.1632e-01, -2.7753e-01, -2.7065e-01, -2.7020e-01, -2.6189e-01,\n         -2.2925e-01, -1.4359e-01, -1.2405e-01, -6.8853e-02, -5.1603e-02,\n         -4.9887e-02, -2.3798e-02, -1.6275e-03,  7.4200e-02,  1.6760e-01,\n          1.7279e-01,  2.3754e-01,  2.5730e-01,  2.6886e-01,  2.8250e-01,\n          2.9296e-01,  3.0017e-01,  3.1466e-01,  3.2627e-01,  3.5380e-01,\n          3.5664e-01,  3.6345e-01,  3.6429e-01,  4.3469e-01,  4.3551e-01,\n          4.6556e-01,  4.9491e-01,  4.9940e-01,  5.4481e-01,  6.4859e-01,\n          6.7236e-01,  6.8683e-01,  7.2763e-01,  7.3832e-01,  7.8508e-01,\n          8.0376e-01,  8.1716e-01,  8.2234e-01,  8.8814e-01,  9.1453e-01,\n          9.8436e-01,  1.0107e+00,  1.0332e+00,  1.0441e+00,  1.0577e+00,\n          1.1333e+00,  1.1406e+00,  1.2557e+00,  1.3057e+00,  1.3221e+00,\n          1.3361e+00,  1.6109e+00,  1.7063e+00,  1.8415e+00,  2.0672e+00]])\n\n\n\ntype(torch.stack([ones, x]))\n\ntorch.Tensor\n\n\n\n# 역슬래시 하고 입실론 쓰고 탭 누르면 입실론 수학기호생김 신기하군\n\n\nW = torch.tensor([2.5,4])\nW\nW.shape #원래 shape이 매트릭스여야 하는데 벡터네? 그럼 X@W하면 매트릭스가 아닌 벡터가 된다. ~~~~~~~~~~ 2차원 1차원,,, 훔 \n\ntorch.Size([2])\n\n\n\ntorch.manual_seed(43052) #이건 원래 난수가 봅히는건뎅 교수님이 설명하기 편하게 ,, 숫자 정해논고\nones= torch.ones(100) #torch.ones(100) 1이 100개 들어간거. X벡터만들기 위해서 \nx,_ = torch.randn(100).sort()\nX = torch.stack([ones,x]).T # torch.stack([ones,x],axis=1)    T:트랜스포 해주는거. 근데 그렇게 안하고 axis=1해도 된당!\nW = torch.tensor([2.5,4])\nϵ = torch.randn(100)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--') #트루펑션 점선으로 찍어보기\n\n#언더라인펑션~= Y=4x+2.5 \n# w0, w1를 추정하면 언더라인 펑션을 잘 추정했다고 확인 할 수 잇어염 \n\n\n\n\n\n# 파란점은 기본 데이터. 입실론을 뺀거(오차항 뺸거)=TRUU FUNCTION을 찾고 싶어!"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-학습이란",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-학습이란",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형에서 학습이란?",
    "text": "회귀모형에서 학습이란?\n\n# x에서 y로가는 맵핑 \n# 리니어 맵핑,, 2.5랑 4에 가깝게 맞추는거!!\n\n- 파란점만 주어졌을때, 주황색 점선을 추정하는것. 좀 더 정확하게 말하면 given data로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 더 쉽게 말하면 아래의 그림을 보고 적당한 추세선을 찾는것이다.\n\n# \"적당한\" 추세선이 뭐냐? 하면 웱,,\n# 숫자로 만드는게 제일 편하다!!\n# 적당한게 정도가 있어서 일단 안적당한 거 먼저 해볼게용\n\n\nplt.plot(x,y,'o')\nplt.plot(x, -5+10*x, '--')\n\n# 원데이터가 y1, y2 되고.. 언더바에 잇는게 y1 hat, y2 hat ..... \n\n\n\n\n- 시도: \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단.\n\n\\(\\hat{y}_i=-5 +10 x_i\\) 와 같이 \\(y_i\\)의 값을 적합시키겠다는 의미\n\n- 벡터표현으로 주황색점선을 계산\n\nWhat= torch.tensor([-5.0, 10.0])\nWhat\n\ntensor([-5., 10.])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'--')\n\n# 모델링: 데이터를 보고 아키텍처 설정,,"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "title": "기계학습 (0921) 3주차",
    "section": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)",
    "text": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)\n- 이론적으로 추론 <- 회귀분석시간에 배운것\n- 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법) <- 우리가 오늘 파이토치로 실습해볼 내용.\n- 전략: 아래와 같은 3단계 전략을 취한다.\n\nstage1: 아무 점선이나 그어본다..\nstage2: stage1에서 그은 점선보다 더 좋은 점선으로 바꾼다.\nstage3: stage1 - 2 를 반복한다.\n\n\nStage1: 첫번째 점선 – 임의의 선을 일단 그어보자\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\nWhat= torch.tensor([-5.0, 10.0], requires_grad=True)\nWhat # 나중에 미분하기 위해서 requires_grad 필요한 옵션\n\n# 뒤에 꼬리표가 붙어있음! 따라다녀,, \n\n#텐서플로우 패키지에서 tf.variable이랑 tf. 어ㅓㅉ고 랑 선언하는데 tf.variable로 설정한거\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\nWhat + 1\n# 뒤에 grad_fn 어쩌고가 따라오지만 신경쓰지 않아도 된당 ,, 벡터처럼 계산도 가능해!!\n# 꼬리표를 빼고싶을땐...... \nWhat.detach()\nWhat.data\n\ntensor([-5., 10.])\n\n\n\n처음에는 ${}=\n\\[\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n$ 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것\n\n그려보자!\n\n\nStage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n# y와 yhat의 값이 비슷하면 loss값이 0에 가까워진다.\n\n\nloss=torch.sum((y-X@What)**2) #이 값이 주황색 점선에 대한 loss!!!\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터를 학습 하라 = 손실함수를 최소화 하라”\n\n# 그 function을 minimize하는 정의역의 세트를 찾으면 된다. = 적당한 선으로 업데이트 하라= ...=\n\n- 우리의 무기: 경사하강법, 벡터미분\n\n\nStage2를 위한 경사하강법 복습\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) <– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n\n# 접선의 기울기가 만약 -4 라는 음수가 나오면 양수값으로 가면 된다.. \n# 미분계수의 절대값이 작아지는 정도로.. 보폭 조절!!\n\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) <– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\n\n# 왼쪽으로 갈래? 오른쪽으로 갈래?\n# 위로 갈래? 아래로 갈래? ->점에서 한쪽방향을 고정되어있다 생각하고 왼오, 또는 위아래로만 -> 편미분으로 가넝!!\n# 2차원, 3차원,, 원리는 결국 1차원과 똑같당!\n\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- $수정값 원래값 - 기울어진크기(=미분계수) $\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n\n# 반대방향으로 가야하니까 - 를 붙인다. \n# a 알파값은 .. 만약 미분계수가 -8이 나왔엉. 근데 그렇다고 8곱해버리면 너무 크니까 0.8 이든 0.08이든.. 그런 알파값을 곱해줘야해!!\n\n# a 값은 양수여야함!!! 음수면 방향이 바꾸기 때문에 a는 정답이 없어. 0.0001 이렇게 걍 맞춰가면 뎀..\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nWhat.grad\n\n\nloss.backward()\n\n# 자기 혼자 미분하고 결과값을 안보여죵  \n# 뭘로 미분하라는거야? ->꼬리표 추적... What까지 가서 얘를 미분하라는 거구나 하고 미분해줌\n\n\nX@What #꼬리표가 있어!!!\n\ntensor([-29.8211, -28.6215, -24.9730, -21.2394, -19.7919, -19.6354, -19.5093,\n        -19.4352, -18.7223, -18.0793, -16.9040, -16.0918, -16.0536, -15.8746,\n        -14.4690, -14.3193, -13.6426, -12.8578, -12.5486, -12.4213, -11.9484,\n        -11.1034, -10.8296, -10.6210, -10.5064, -10.0578,  -9.8063,  -9.7380,\n         -9.7097,  -9.6756,  -8.8736,  -8.7195,  -8.6880,  -8.1592,  -7.7752,\n         -7.7716,  -7.7339,  -7.7208,  -7.6677,  -7.1551,  -7.0004,  -6.8163,\n         -6.7081,  -6.5655,  -6.4480,  -6.3612,  -6.0566,  -5.6031,  -5.5589,\n         -5.2137,  -4.3446,  -4.3165,  -3.8047,  -3.5801,  -3.4793,  -3.4325,\n         -2.3545,  -2.3440,  -1.8434,  -1.7799,  -1.5386,  -1.0161,  -0.8103,\n          0.4426,   0.5794,   0.9125,   1.1483,   1.4687,   1.4690,   1.5234,\n          1.6738,   2.0592,   2.1414,   2.8221,   3.1536,   3.6682,   4.2907,\n          4.8037,   4.8531,   4.9414,   5.3757,   5.3926,   5.6973,   6.0239,\n          6.1261,   6.5317,   7.2891,   8.4032,   8.4936,   9.2794,   9.9943,\n         10.0310,  10.4369,  11.7886,  15.8323,  17.4440,  18.9350,  21.0560,\n         21.0566,  21.6324], grad_fn=<MvBackward0>)\n\n\n\ny-X@What #꼬리표가 있는 걸로 파생된 모든 것들은 다 꼬리표가 있땅\n\ntensor([21.2791, 22.0448, 19.0234, 16.7600, 15.5403, 16.5028, 15.4853, 15.2491,\n        15.3820, 15.8766, 14.8778, 13.5299, 14.7183, 13.8280, 14.0026, 12.9680,\n        11.9954, 12.7489, 12.2415, 11.7914, 11.9046, 11.5198, 11.2462, 10.5267,\n        10.7726, 10.5168, 10.6967, 10.6377, 10.3411, 11.0601,  9.6820,  9.9789,\n         9.8090, 10.0825,  8.8370,  9.1268,  9.8500,  8.8644,  9.2922,  8.9190,\n         8.6027,  8.5628,  7.6912,  8.3478,  8.5596,  9.2232,  8.1731,  7.1257,\n         8.1160,  8.0498,  7.7402,  6.3844,  6.6187,  7.0653,  7.0851,  6.0290,\n         5.2399,  6.2613,  5.4961,  5.8827,  5.8510,  4.4186,  4.0283,  4.1260,\n         3.7978,  3.3949,  3.3412,  3.0141,  3.8481,  3.9753,  3.7895,  3.9736,\n         3.1428,  2.2318,  2.3002,  2.3654,  1.4343,  0.9550,  1.3489,  1.6579,\n         1.0864,  1.1214,  0.9873,  1.3258,  1.9648,  0.5476, -0.4224, -0.9803,\n        -1.2392, -2.0827, -0.4937, -0.9971, -2.9482, -2.7127, -4.7377, -7.1180,\n        -6.6685, -7.9578, -8.5098, -7.7984], grad_fn=<SubBackward0>)\n\n\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n\nWhat.grad\n\ntensor([-1342.2522,  1188.9305])\n\n\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2523,  1188.9305], grad_fn=<AddBackward0>)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nWhat.data\n\ntensor([-5., 10.])\n\n\n\nstr(What.data) #문자열이 됨! \n\n'tensor([-5., 10.])'\n\n\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad)) #1341*0.001, 1190*0.001\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')  #주황색\nplt.plot(x,X@Wafter,'--')  #초록색\n\n\n\n\n\n\n\nStage3: Learn (=estimate \\(\\bf\\hat{W})\\)\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) \nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() #미분.. what.grad로 미분이 된 것을 볼 수 있따->편미분계수값\n    What.data = What.data-alpha * What.grad #경사하강법~~\n    What.grad=None  # 파이토치 특징.. 미분된 grad값에 새 미분값이 안들어가있고.. 이전미분값에 그다음미분값이 더해져서 들어가기 때문에->defalut기 대문에 초기상태로 바꿔줘야햄....\n\n\nWhat\n\ntensor([2.4290, 4.0144], requires_grad=True)\n\n\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--') #그림을 그리기위해서 꼬리표를 떼준당.."
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "title": "기계학습 (0921) 3주차",
    "section": "파라메터의 학습과정 음미 (학습과정 모니터링)",
    "text": "파라메터의 학습과정 음미 (학습과정 모니터링)\n\n학습과정의 기록\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  .\nyhat_history = [] # 기록하고 싶은것 2  yhat이 어떻게 변하는지\nWhat_history = [] # 기록하고 싶은것 3 \n\n\n#loss_history #처음엔 비어있지만.. 값을 점점 넣고 싶어!!!\n\n\n#loss_history.append(loss)\n#loss_history\n\n\n#loss.item()\n\n\n#loss_history.append(loss.item())\n#loss_history # 텐서를 리스트로 바꿔줘서 넣어주기..\n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())  #세미콜론만 주석처리하면.. 위랑 똑같은 코드..\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nloss_history\n\n[8587.6875,\n 5675.2109375,\n 3755.637451171875,\n 2489.581787109375,\n 1654.0390625,\n 1102.3206787109375,\n 737.8441162109375,\n 496.96514892578125,\n 337.7142028808594,\n 232.39694213867188,\n 162.72906494140625,\n 116.63263702392578,\n 86.1263656616211,\n 65.93397521972656,\n 52.566444396972656,\n 43.71583557128906,\n 37.855220794677734,\n 33.974090576171875,\n 31.403636932373047,\n 29.701112747192383,\n 28.57339096069336,\n 27.826366424560547,\n 27.331483840942383,\n 27.003639221191406,\n 26.78643798828125,\n 26.642536163330078,\n 26.547197341918945,\n 26.48402976989746,\n 26.442174911499023,\n 26.414440155029297]\n\n\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\nyhat_history\n\n[[-29.821128845214844,\n  -28.621461868286133,\n  -24.97295379638672,\n  -21.239360809326172,\n  -19.791915893554688,\n  -19.635364532470703,\n  -19.50925064086914,\n  -19.435216903686523,\n  -18.722301483154297,\n  -18.079282760620117,\n  -16.903972625732422,\n  -16.09178924560547,\n  -16.053556442260742,\n  -15.874590873718262,\n  -14.468965530395508,\n  -14.31933879852295,\n  -13.642648696899414,\n  -12.857781410217285,\n  -12.548619270324707,\n  -12.421306610107422,\n  -11.94838809967041,\n  -11.103449821472168,\n  -10.829590797424316,\n  -10.621047973632812,\n  -10.506429672241211,\n  -10.05777359008789,\n  -9.80626392364502,\n  -9.737953186035156,\n  -9.709654808044434,\n  -9.67557144165039,\n  -8.873588562011719,\n  -8.719473838806152,\n  -8.687962532043457,\n  -8.159214973449707,\n  -7.775153636932373,\n  -7.771570682525635,\n  -7.733872890472412,\n  -7.7207512855529785,\n  -7.667671203613281,\n  -7.155084609985352,\n  -7.000405311584473,\n  -6.816307067871094,\n  -6.708141326904297,\n  -6.565457820892334,\n  -6.4479804039001465,\n  -6.361170768737793,\n  -6.056612968444824,\n  -5.603134632110596,\n  -5.558872222900391,\n  -5.213672637939453,\n  -4.34455680847168,\n  -4.3164825439453125,\n  -3.8046953678131104,\n  -3.5801002979278564,\n  -3.479255437850952,\n  -3.4324843883514404,\n  -2.3544726371765137,\n  -2.3440215587615967,\n  -1.843425989151001,\n  -1.7798891067504883,\n  -1.5385699272155762,\n  -1.016080617904663,\n  -0.8102789521217346,\n  0.44257819652557373,\n  0.5793601274490356,\n  0.9125399589538574,\n  1.1482644081115723,\n  1.468665599822998,\n  1.468990445137024,\n  1.5233922004699707,\n  1.673753261566162,\n  2.059195041656494,\n  2.141373634338379,\n  2.8221492767333984,\n  3.1536107063293457,\n  3.6682331562042236,\n  4.290748119354248,\n  4.803698539733887,\n  4.853081226348877,\n  4.9413557052612305,\n  5.375688076019287,\n  5.392560005187988,\n  5.697267055511475,\n  6.023870468139648,\n  6.126120090484619,\n  6.531744956970215,\n  7.289087772369385,\n  8.403202056884766,\n  8.493597030639648,\n  9.279403686523438,\n  9.994264602661133,\n  10.030980110168457,\n  10.436870574951172,\n  11.788615226745605,\n  15.832330703735352,\n  17.444000244140625,\n  18.93501091003418,\n  21.05604362487793,\n  21.05657958984375,\n  21.632400512695312],\n [-25.527816772460938,\n  -24.470781326293945,\n  -21.25605583190918,\n  -17.96636199951172,\n  -16.691007614135742,\n  -16.553070068359375,\n  -16.44194793701172,\n  -16.37671661376953,\n  -15.748562812805176,\n  -15.181994438171387,\n  -14.1464204788208,\n  -13.430801391601562,\n  -13.397112846374512,\n  -13.239425659179688,\n  -12.000919342041016,\n  -11.869081497192383,\n  -11.272846221923828,\n  -10.581294059753418,\n  -10.30888843536377,\n  -10.196712493896484,\n  -9.780020713806152,\n  -9.035539627075195,\n  -8.794240951538086,\n  -8.610491752624512,\n  -8.509501457214355,\n  -8.114187240600586,\n  -7.892580509185791,\n  -7.832390785217285,\n  -7.807457447052002,\n  -7.777426242828369,\n  -7.070793151855469,\n  -6.935001850128174,\n  -6.907237529754639,\n  -6.441354274749756,\n  -6.102954864501953,\n  -6.09979772567749,\n  -6.066582202911377,\n  -6.055020809173584,\n  -6.008251190185547,\n  -5.556607723236084,\n  -5.420318603515625,\n  -5.258108615875244,\n  -5.1628031730651855,\n  -5.037083625793457,\n  -4.933573246002197,\n  -4.85708475112915,\n  -4.588736534118652,\n  -4.189174175262451,\n  -4.150174140930176,\n  -3.8460164070129395,\n  -3.0802321434020996,\n  -3.0554959774017334,\n  -2.6045565605163574,\n  -2.4066641330718994,\n  -2.3178091049194336,\n  -2.2765989303588867,\n  -1.326755166053772,\n  -1.3175466060638428,\n  -0.8764684200286865,\n  -0.8204857110977173,\n  -0.6078576445579529,\n  -0.14748874306678772,\n  0.03384458273649216,\n  1.13774573802948,\n  1.2582652568817139,\n  1.5518323183059692,\n  1.759530782699585,\n  2.0418384075164795,\n  2.0421247482299805,\n  2.0900585651397705,\n  2.2225425243377686,\n  2.5621581077575684,\n  2.634566307067871,\n  3.2344024181365967,\n  3.5264554023742676,\n  3.9798927307128906,\n  4.528395175933838,\n  4.980359077453613,\n  5.023870468139648,\n  5.101649761199951,\n  5.4843430519104,\n  5.499208927154541,\n  5.767688751220703,\n  6.055461406707764,\n  6.145554065704346,\n  6.502953052520752,\n  7.170252799987793,\n  8.151906967163086,\n  8.231554985046387,\n  8.923933982849121,\n  9.553803443908691,\n  9.586153030395508,\n  9.94378662109375,\n  11.134817123413086,\n  14.69776439666748,\n  16.117816925048828,\n  17.431556701660156,\n  19.300413131713867,\n  19.300886154174805,\n  19.808244705200195],\n [-22.067176818847656,\n  -21.124095916748047,\n  -18.25593376159668,\n  -15.320884704589844,\n  -14.183019638061523,\n  -14.059952735900879,\n  -13.960810661315918,\n  -13.90261173248291,\n  -13.34217643737793,\n  -12.836686134338379,\n  -11.912752151489258,\n  -11.274280548095703,\n  -11.244223594665527,\n  -11.103535652160645,\n  -9.998546600341797,\n  -9.880922317504883,\n  -9.348963737487793,\n  -8.731964111328125,\n  -8.48892593383789,\n  -8.388842582702637,\n  -8.017072677612305,\n  -7.352850437164307,\n  -7.137564659118652,\n  -6.9736247062683105,\n  -6.883521556854248,\n  -6.530824184417725,\n  -6.333107948303223,\n  -6.279407024383545,\n  -6.257161617279053,\n  -6.230367660522461,\n  -5.599913597106934,\n  -5.478761196136475,\n  -5.4539899826049805,\n  -5.038331031799316,\n  -4.73641300201416,\n  -4.733596324920654,\n  -4.703961372375488,\n  -4.693646430969238,\n  -4.651918888092041,\n  -4.248964786529541,\n  -4.127368450164795,\n  -3.982645273208618,\n  -3.8976142406463623,\n  -3.7854480743408203,\n  -3.69309663772583,\n  -3.6248538494110107,\n  -3.385435104370117,\n  -3.028947353363037,\n  -2.9941515922546387,\n  -2.7227838039398193,\n  -2.039555072784424,\n  -2.0174853801727295,\n  -1.6151596307754517,\n  -1.438601016998291,\n  -1.3593250513076782,\n  -1.3225574493408203,\n  -0.47511163353919983,\n  -0.46689584851264954,\n  -0.07336807250976562,\n  -0.023420605808496475,\n  0.16628508269786835,\n  0.5770238637924194,\n  0.7388085722923279,\n  1.7237036228179932,\n  1.8312305212020874,\n  2.0931496620178223,\n  2.2784571647644043,\n  2.5303306579589844,\n  2.530586004257202,\n  2.573352098464966,\n  2.691553831100464,\n  2.9945571422576904,\n  3.059159278869629,\n  3.594330072402954,\n  3.854898452758789,\n  4.259452819824219,\n  4.748823642730713,\n  5.152063846588135,\n  5.190884590148926,\n  5.260278701782227,\n  5.601716041564941,\n  5.614979267120361,\n  5.854515075683594,\n  6.111264705657959,\n  6.191644668579102,\n  6.510514736175537,\n  7.1058759689331055,\n  7.98170280456543,\n  8.052763938903809,\n  8.670501708984375,\n  9.232467651367188,\n  9.261330604553223,\n  9.580409049987793,\n  10.643040657043457,\n  13.821883201599121,\n  15.088847160339355,\n  16.26095962524414,\n  17.9283447265625,\n  17.92876625061035,\n  18.381427764892578],\n [-19.276042938232422,\n  -18.424091339111328,\n  -15.833085060119629,\n  -13.181654930114746,\n  -12.153742790222168,\n  -12.04256820678711,\n  -11.953006744384766,\n  -11.900431632995605,\n  -11.39415168762207,\n  -10.937507629394531,\n  -10.102855682373047,\n  -9.526080131530762,\n  -9.49892807006836,\n  -9.371834754943848,\n  -8.373621940612793,\n  -8.267363548278809,\n  -7.786808967590332,\n  -7.22943115234375,\n  -7.009877681732178,\n  -6.919466018676758,\n  -6.583621025085449,\n  -5.983583450317383,\n  -5.7891011238098145,\n  -5.641002655029297,\n  -5.559606552124023,\n  -5.24099063873291,\n  -5.062380313873291,\n  -5.01386833190918,\n  -4.993772506713867,\n  -4.969567775726318,\n  -4.400035381317139,\n  -4.290590286254883,\n  -4.26821231842041,\n  -3.8927195072174072,\n  -3.619976043701172,\n  -3.617431640625,\n  -3.590660333633423,\n  -3.5813422203063965,\n  -3.543646812438965,\n  -3.179630756378174,\n  -3.069784641265869,\n  -2.9390463829040527,\n  -2.862231731414795,\n  -2.760904550552368,\n  -2.6774771213531494,\n  -2.615828514099121,\n  -2.399545431137085,\n  -2.077505588531494,\n  -2.046072244644165,\n  -1.8009270429611206,\n  -1.1837197542190552,\n  -1.1637827157974243,\n  -0.8003342151641846,\n  -0.640836775302887,\n  -0.5692213177680969,\n  -0.5360066294670105,\n  0.22954916954040527,\n  0.23697106540203094,\n  0.5924716591835022,\n  0.637592613697052,\n  0.8089667558670044,\n  1.1800153255462646,\n  1.3261665105819702,\n  2.2158896923065186,\n  2.313025951385498,\n  2.549635410308838,\n  2.717036485671997,\n  2.944571018218994,\n  2.9448018074035645,\n  2.9834353923797607,\n  3.0902152061462402,\n  3.363938570022583,\n  3.4222981929779053,\n  3.905754804611206,\n  4.141143798828125,\n  4.506605625152588,\n  4.94868803024292,\n  5.312962532043457,\n  5.348031520843506,\n  5.410720348358154,\n  5.71916389465332,\n  5.73114538192749,\n  5.947534561157227,\n  6.179473876953125,\n  6.252087116241455,\n  6.540143966674805,\n  7.077974796295166,\n  7.869168758392334,\n  7.933363437652588,\n  8.491408348083496,\n  8.999070167541504,\n  9.02514362335205,\n  9.313389778137207,\n  10.273337364196777,\n  13.145004272460938,\n  14.289539337158203,\n  15.348388671875,\n  16.854652404785156,\n  16.855031967163086,\n  17.263954162597656],\n [-17.02360725402832,\n  -16.244606018066406,\n  -13.875457763671875,\n  -11.451059341430664,\n  -10.511163711547852,\n  -10.409507751464844,\n  -10.327615737915039,\n  -10.279541969299316,\n  -9.81661319732666,\n  -9.399069786071777,\n  -8.635885238647461,\n  -8.10849666595459,\n  -8.083669662475586,\n  -7.967459201812744,\n  -7.054719924926758,\n  -6.957560062408447,\n  -6.518153190612793,\n  -6.0085015296936035,\n  -5.807747840881348,\n  -5.7250776290893555,\n  -5.417989253997803,\n  -4.869330883026123,\n  -4.691501617431641,\n  -4.556084156036377,\n  -4.4816575050354,\n  -4.190323829650879,\n  -4.02700662612915,\n  -3.9826488494873047,\n  -3.964273452758789,\n  -3.942141532897949,\n  -3.4213757514953613,\n  -3.3213019371032715,\n  -3.3008406162261963,\n  -2.9574995040893555,\n  -2.7081100940704346,\n  -2.7057836055755615,\n  -2.681304693222046,\n  -2.6727843284606934,\n  -2.6383166313171387,\n  -2.3054697513580322,\n  -2.205029249191284,\n  -2.0854856967926025,\n  -2.0152485370635986,\n  -1.9225974082946777,\n  -1.846313714981079,\n  -1.7899439334869385,\n  -1.5921801328659058,\n  -1.2977153062820435,\n  -1.268973469734192,\n  -1.0448191165924072,\n  -0.48046091198921204,\n  -0.4622310400009155,\n  -0.12990324199199677,\n  0.015937041491270065,\n  0.08142035454511642,\n  0.11179099977016449,\n  0.8117952346801758,\n  0.8185816407203674,\n  1.1436420679092407,\n  1.1848994493484497,\n  1.3415995836257935,\n  1.680876612663269,\n  1.8145134449005127,\n  2.6280529499053955,\n  2.716871976852417,\n  2.9332215785980225,\n  3.0862884521484375,\n  3.2943403720855713,\n  3.294551134109497,\n  3.3298768997192383,\n  3.427513360977173,\n  3.6777989864349365,\n  3.731161594390869,\n  4.173221588134766,\n  4.388454914093018,\n  4.722623825073242,\n  5.126852512359619,\n  5.459935665130615,\n  5.492002010345459,\n  5.549322605133057,\n  5.831355094909668,\n  5.842310905456543,\n  6.0401716232299805,\n  6.252251148223877,\n  6.318646430969238,\n  6.582037925720215,\n  7.073816776275635,\n  7.797264099121094,\n  7.855961799621582,\n  8.366223335266113,\n  8.830416679382324,\n  8.854257583618164,\n  9.11782169342041,\n  9.995573043823242,\n  12.621350288391113,\n  13.667882919311523,\n  14.636066436767578,\n  16.013355255126953,\n  16.013702392578125,\n  16.387609481811523],\n [-15.204924583435059,\n  -14.484371185302734,\n  -12.292978286743164,\n  -10.050481796264648,\n  -9.181105613708496,\n  -9.087077140808105,\n  -9.01132869720459,\n  -8.966862678527832,\n  -8.538666725158691,\n  -8.152451515197754,\n  -7.446528434753418,\n  -6.958709716796875,\n  -6.9357452392578125,\n  -6.828253746032715,\n  -5.983996868133545,\n  -5.894127368927002,\n  -5.487689018249512,\n  -5.0162763595581055,\n  -4.830584526062012,\n  -4.754117012023926,\n  -4.470069885253906,\n  -3.9625768661499023,\n  -3.7980897426605225,\n  -3.672832727432251,\n  -3.603990077972412,\n  -3.33451509475708,\n  -3.1834518909454346,\n  -3.1424221992492676,\n  -3.125425338745117,\n  -3.1049540042877197,\n  -2.623260974884033,\n  -2.530695676803589,\n  -2.5117695331573486,\n  -2.1941893100738525,\n  -1.963511347770691,\n  -1.9613593816757202,\n  -1.938717007637024,\n  -1.9308359622955322,\n  -1.8989545106887817,\n  -1.591080904006958,\n  -1.4981764554977417,\n  -1.3876020908355713,\n  -1.3226348161697388,\n  -1.2369352579116821,\n  -1.1663750410079956,\n  -1.1142346858978271,\n  -0.9313089847564697,\n  -0.6589377522468567,\n  -0.6323524117469788,\n  -0.42501628398895264,\n  0.09699846059083939,\n  0.11386056244373322,\n  0.4212539494037628,\n  0.5561519265174866,\n  0.616722047328949,\n  0.6448140144348145,\n  1.2922972440719604,\n  1.298574447631836,\n  1.5992457866668701,\n  1.637407660484314,\n  1.7823506593704224,\n  2.0961718559265137,\n  2.2197821140289307,\n  2.9722821712493896,\n  3.0544371604919434,\n  3.254554033279419,\n  3.396136522293091,\n  3.588578224182129,\n  3.588773250579834,\n  3.621448516845703,\n  3.711759328842163,\n  3.9432661533355713,\n  3.9926249980926514,\n  4.401517391204834,\n  4.600602149963379,\n  4.909698486328125,\n  5.283597946166992,\n  5.5916900634765625,\n  5.621350288391113,\n  5.674370288848877,\n  5.935242176055908,\n  5.945375919342041,\n  6.128391265869141,\n  6.324558258056641,\n  6.385972023010254,\n  6.62960147857666,\n  7.084482192993164,\n  7.753649711608887,\n  7.807943344116211,\n  8.27992057800293,\n  8.709284782409668,\n  8.731337547302246,\n  8.975126266479492,\n  9.787020683288574,\n  12.215786933898926,\n  13.183798789978027,\n  14.079340934753418,\n  15.353291511535645,\n  15.353612899780273,\n  15.69946575164795],\n [-13.7357177734375,\n  -13.06203556060791,\n  -11.013188362121582,\n  -8.916561126708984,\n  -8.103736877441406,\n  -8.015825271606445,\n  -7.945003986358643,\n  -7.903429985046387,\n  -7.503087520599365,\n  -7.141994953155518,\n  -6.481991291046143,\n  -6.025904178619385,\n  -6.0044331550598145,\n  -5.903934001922607,\n  -5.114594459533691,\n  -5.0305705070495605,\n  -4.650570392608643,\n  -4.209822177886963,\n  -4.036209583282471,\n  -3.9647161960601807,\n  -3.6991453170776367,\n  -3.2246639728546143,\n  -3.070876359939575,\n  -2.9537672996520996,\n  -2.8894026279449463,\n  -2.6374564170837402,\n  -2.4962196350097656,\n  -2.4578588008880615,\n  -2.441967725753784,\n  -2.422827959060669,\n  -1.9724682569503784,\n  -1.885924220085144,\n  -1.8682290315628052,\n  -1.5713067054748535,\n  -1.3556339740753174,\n  -1.3536220788955688,\n  -1.3324525356292725,\n  -1.3250840902328491,\n  -1.2952765226364136,\n  -1.007429599761963,\n  -0.9205683469772339,\n  -0.8171865940093994,\n  -0.7564453482627869,\n  -0.6763203740119934,\n  -0.6103500127792358,\n  -0.5616012215614319,\n  -0.39057457447052,\n  -0.13592055439949036,\n  -0.11106456071138382,\n  0.0827847421169281,\n  0.5708433985710144,\n  0.5866086483001709,\n  0.8740066289901733,\n  1.0001296997070312,\n  1.0567599534988403,\n  1.083024501800537,\n  1.6883901357650757,\n  1.6942590475082397,\n  1.975372314453125,\n  2.011051893234253,\n  2.146566390991211,\n  2.439974308013916,\n  2.5555436611175537,\n  3.2590951919555664,\n  3.3359060287475586,\n  3.523005723953247,\n  3.655378580093384,\n  3.8353021144866943,\n  3.835484743118286,\n  3.8660342693328857,\n  3.9504706859588623,\n  4.1669182777404785,\n  4.213066577911377,\n  4.595361232757568,\n  4.781496047973633,\n  5.070486068725586,\n  5.4200639724731445,\n  5.708115100860596,\n  5.735846042633057,\n  5.785417556762695,\n  6.029320240020752,\n  6.03879451751709,\n  6.20990514755249,\n  6.393311977386475,\n  6.450730800628662,\n  6.6785125732421875,\n  7.103804111480713,\n  7.729443550109863,\n  7.780205726623535,\n  8.221481323242188,\n  8.622916221618652,\n  8.643534660339355,\n  8.871465682983398,\n  9.630547523498535,\n  11.901327133178711,\n  12.806371688842773,\n  13.643659591674805,\n  14.834742546081543,\n  14.835042953491211,\n  15.158398628234863],\n [-12.548260688781738,\n  -11.912196159362793,\n  -9.97775650024414,\n  -7.998204708099365,\n  -7.230768203735352,\n  -7.147764682769775,\n  -7.080898761749268,\n  -7.0416460037231445,\n  -6.663658618927002,\n  -6.322729110717773,\n  -5.69957971572876,\n  -5.268960475921631,\n  -5.248688697814941,\n  -5.153800964355469,\n  -4.408538341522217,\n  -4.3292059898376465,\n  -3.9704248905181885,\n  -3.554287910461426,\n  -3.3903696537017822,\n  -3.322868585586548,\n  -3.072127103805542,\n  -2.624140739440918,\n  -2.478940725326538,\n  -2.368370771408081,\n  -2.307600259780884,\n  -2.0697226524353027,\n  -1.9363723993301392,\n  -1.900153636932373,\n  -1.8851499557495117,\n  -1.8670789003372192,\n  -1.4418671131134033,\n  -1.360155701637268,\n  -1.3434486389160156,\n  -1.0631064176559448,\n  -0.8594767451286316,\n  -0.8575771450996399,\n  -0.8375897407531738,\n  -0.830632746219635,\n  -0.8024895787239075,\n  -0.5307159423828125,\n  -0.4487050175666809,\n  -0.35109609365463257,\n  -0.29374656081199646,\n  -0.2180957943201065,\n  -0.1558091938495636,\n  -0.10978250950574875,\n  0.051694076508283615,\n  0.2921282947063446,\n  0.315596342086792,\n  0.4986211657524109,\n  0.959426760673523,\n  0.9743117094039917,\n  1.2456614971160889,\n  1.3647419214248657,\n  1.4182099103927612,\n  1.4430078268051147,\n  2.0145699977874756,\n  2.020111322402954,\n  2.285527229309082,\n  2.319214344024658,\n  2.447161912918091,\n  2.7241859436035156,\n  2.8333020210266113,\n  3.4975674152374268,\n  3.570089101791382,\n  3.74674129486084,\n  3.871722459793091,\n  4.041599273681641,\n  4.041771411895752,\n  4.070615291595459,\n  4.150336742401123,\n  4.354698181152344,\n  4.398269176483154,\n  4.759216785430908,\n  4.934957981109619,\n  5.207810878753662,\n  5.537868499755859,\n  5.809834957122803,\n  5.836017608642578,\n  5.8828206062316895,\n  6.113103866577148,\n  6.122049331665039,\n  6.283605098724365,\n  6.456770420074463,\n  6.510982990264893,\n  6.726045608520508,\n  7.127589225769043,\n  7.718293190002441,\n  7.766220569610596,\n  8.182855606079102,\n  8.561875343322754,\n  8.581341743469238,\n  8.796545028686523,\n  9.513239860534668,\n  11.657219886779785,\n  12.511727333068848,\n  13.302261352539062,\n  14.426834106445312,\n  14.427118301391602,\n  14.732418060302734],\n [-11.588088035583496,\n  -10.982240676879883,\n  -9.139697074890137,\n  -7.254184246063232,\n  -6.523205280303955,\n  -6.444145202636719,\n  -6.380455493927002,\n  -6.343067646026611,\n  -5.983036518096924,\n  -5.658303260803223,\n  -5.064756870269775,\n  -4.6545939445495605,\n  -4.635285377502441,\n  -4.544905662536621,\n  -3.8350467681884766,\n  -3.7594833374023438,\n  -3.417746067047119,\n  -3.0213780403137207,\n  -2.8652467727661133,\n  -2.800952196121216,\n  -2.5621225833892822,\n  -2.1354176998138428,\n  -1.9971154928207397,\n  -1.8917983770370483,\n  -1.8339147567749023,\n  -1.6073375940322876,\n  -1.480322241783142,\n  -1.445824146270752,\n  -1.4315330982208252,\n  -1.4143205881118774,\n  -1.0093086957931519,\n  -0.9314789175987244,\n  -0.9155654907226562,\n  -0.6485410928726196,\n  -0.4545849859714508,\n  -0.45277559757232666,\n  -0.43373769521713257,\n  -0.4271112382411957,\n  -0.40030497312545776,\n  -0.14144207537174225,\n  -0.0633271187543869,\n  0.02964484691619873,\n  0.0842699483036995,\n  0.15632690489292145,\n  0.21565455198287964,\n  0.25949472188949585,\n  0.4133002758026123,\n  0.6423125863075256,\n  0.6646657586097717,\n  0.8389959335327148,\n  1.2779107093811035,\n  1.292088508605957,\n  1.55054771900177,\n  1.663971185684204,\n  1.7148991823196411,\n  1.7385190725326538,\n  2.282928943634033,\n  2.2882070541381836,\n  2.5410141944885254,\n  2.573101043701172,\n  2.6949703693389893,\n  2.958834171295166,\n  3.0627667903900146,\n  3.6954758167266846,\n  3.764552593231201,\n  3.9328126907348633,\n  4.051856517791748,\n  4.213663101196289,\n  4.213827133178711,\n  4.2413010597229,\n  4.317235469818115,\n  4.51188850402832,\n  4.553389549255371,\n  4.897190093994141,\n  5.064582347869873,\n  5.3244733810424805,\n  5.638851642608643,\n  5.897898197174072,\n  5.922836780548096,\n  5.967416763305664,\n  6.186760425567627,\n  6.1952805519104,\n  6.349161624908447,\n  6.514101028442383,\n  6.565738201141357,\n  6.7705841064453125,\n  7.153051853179932,\n  7.715693950653076,\n  7.761344909667969,\n  8.158186912536621,\n  8.519201278686523,\n  8.537742614746094,\n  8.74272346496582,\n  9.425371170043945,\n  11.467500686645508,\n  12.281414031982422,\n  13.034393310546875,\n  14.10554313659668,\n  14.105813980102539,\n  14.396610260009766],\n [-10.811363220214844,\n  -10.229805946350098,\n  -8.46113395690918,\n  -6.651216983795166,\n  -5.949544429779053,\n  -5.873653888702393,\n  -5.8125176429748535,\n  -5.776628494262695,\n  -5.431032180786133,\n  -5.11931848526001,\n  -4.5495686531066895,\n  -4.155850410461426,\n  -4.13731575012207,\n  -4.0505595207214355,\n  -3.3691604137420654,\n  -3.296626567840576,\n  -2.968590497970581,\n  -2.58811354637146,\n  -2.438242197036743,\n  -2.376525402069092,\n  -2.147270917892456,\n  -1.7376737594604492,\n  -1.6049163341522217,\n  -1.5038214921951294,\n  -1.448258638381958,\n  -1.2307655811309814,\n  -1.1088424921035767,\n  -1.0757274627685547,\n  -1.0620094537734985,\n  -1.0454870462417603,\n  -0.6567130088806152,\n  -0.582003653049469,\n  -0.5667282342910767,\n  -0.31040942668914795,\n  -0.12422949820756912,\n  -0.12249265611171722,\n  -0.104218028485775,\n  -0.09785724431276321,\n  -0.07212571799755096,\n  0.17635875940322876,\n  0.25134190917015076,\n  0.340586394071579,\n  0.39302143454551697,\n  0.4621894657611847,\n  0.519138514995575,\n  0.5612210631370544,\n  0.7088601589202881,\n  0.9286907911300659,\n  0.950147807598114,\n  1.1174886226654053,\n  1.5388063192367554,\n  1.5524157285690308,\n  1.800512671470642,\n  1.909388780593872,\n  1.9582748413085938,\n  1.9809478521347046,\n  2.503530979156494,\n  2.5085973739624023,\n  2.7512691020965576,\n  2.782069444656372,\n  2.899052858352661,\n  3.1523375511169434,\n  3.252103328704834,\n  3.859445571899414,\n  3.925752639770508,\n  4.08726692199707,\n  4.2015380859375,\n  4.356857776641846,\n  4.357015132904053,\n  4.383387088775635,\n  4.456276893615723,\n  4.643126010894775,\n  4.6829633712768555,\n  5.012979984283447,\n  5.173661231994629,\n  5.423132419586182,\n  5.7249064445495605,\n  5.973567485809326,\n  5.997506141662598,\n  6.040298938751221,\n  6.250848293304443,\n  6.259027004241943,\n  6.406738758087158,\n  6.565064907073975,\n  6.6146321296691895,\n  6.811265468597412,\n  7.178399085998535,\n  7.7184834480285645,\n  7.762304306030273,\n  8.14323616027832,\n  8.489776611328125,\n  8.507574081420898,\n  8.704336166381836,\n  9.359615325927734,\n  11.319870948791504,\n  12.101153373718262,\n  12.823944091796875,\n  13.852148056030273,\n  13.852408409118652,\n  14.131546020507812],\n [-10.182785987854004,\n  -9.620768547058105,\n  -7.911523342132568,\n  -6.162417888641357,\n  -5.484321117401123,\n  -5.410980701446533,\n  -5.351898670196533,\n  -5.317215442657471,\n  -4.9832305908203125,\n  -4.681990146636963,\n  -4.131383895874023,\n  -3.750894069671631,\n  -3.7329823970794678,\n  -3.6491410732269287,\n  -2.9906365871429443,\n  -2.9205398559570312,\n  -2.6035256385803223,\n  -2.235832691192627,\n  -2.090996742248535,\n  -2.03135347366333,\n  -1.8098018169403076,\n  -1.4139670133590698,\n  -1.2856701612472534,\n  -1.187972068786621,\n  -1.1342761516571045,\n  -0.9240906238555908,\n  -0.8062641024589539,\n  -0.7742617130279541,\n  -0.761004626750946,\n  -0.745037317276001,\n  -0.3693259060382843,\n  -0.29712674021720886,\n  -0.2823645770549774,\n  -0.03465794026851654,\n  0.14526645839214325,\n  0.14694494009017944,\n  0.1646055430173874,\n  0.170752614736557,\n  0.19561956822872162,\n  0.4357551038265228,\n  0.5082188844680786,\n  0.5944647789001465,\n  0.6451380848884583,\n  0.7119820713996887,\n  0.767017662525177,\n  0.8076862692832947,\n  0.9503647685050964,\n  1.1628092527389526,\n  1.1835453510284424,\n  1.3452636003494263,\n  1.752425193786621,\n  1.7655773162841797,\n  2.005338430404663,\n  2.1105563640594482,\n  2.15779972076416,\n  2.179711103439331,\n  2.6847357749938965,\n  2.689631938934326,\n  2.924149751663208,\n  2.9539153575897217,\n  3.0669682025909424,\n  3.3117427825927734,\n  3.408156394958496,\n  3.9950923919677734,\n  4.059171676635742,\n  4.215259075164795,\n  4.325690746307373,\n  4.4757914543151855,\n  4.475943565368652,\n  4.501429557800293,\n  4.571870803833008,\n  4.75244140625,\n  4.790940284729004,\n  5.109869003295898,\n  5.265151023864746,\n  5.506240367889404,\n  5.797874927520752,\n  6.038180828094482,\n  6.061315536499023,\n  6.102670192718506,\n  6.306145191192627,\n  6.314049243927002,\n  6.456798076629639,\n  6.609804630279541,\n  6.657706260681152,\n  6.8477325439453125,\n  7.202530860900879,\n  7.72446870803833,\n  7.766817092895508,\n  8.134949684143066,\n  8.469846725463867,\n  8.48704719543457,\n  8.677197456359863,\n  9.310460090637207,\n  11.204852104187012,\n  11.959882736206055,\n  12.658388137817383,\n  13.652046203613281,\n  13.652297019958496,\n  13.9220552444458],\n [-9.673905372619629,\n  -9.127617835998535,\n  -7.466211318969727,\n  -5.766060829162598,\n  -5.106943130493164,\n  -5.0356550216674805,\n  -4.978226661682129,\n  -4.944514274597168,\n  -4.619877338409424,\n  -4.327067852020264,\n  -3.791872262954712,\n  -3.422031879425049,\n  -3.4046216011047363,\n  -3.323126792907715,\n  -2.6830527782440186,\n  -2.6149179935455322,\n  -2.306776523590088,\n  -1.9493745565414429,\n  -1.808592438697815,\n  -1.750618577003479,\n  -1.5352678298950195,\n  -1.1505117416381836,\n  -1.0258057117462158,\n  -0.9308421015739441,\n  -0.8786489963531494,\n  -0.6743462681770325,\n  -0.5598175525665283,\n  -0.5287108421325684,\n  -0.5158247947692871,\n  -0.5003044009208679,\n  -0.13510854542255402,\n  -0.06493011862039566,\n  -0.050581131130456924,\n  0.1901925802230835,\n  0.36508116126060486,\n  0.36671265959739685,\n  0.3838789761066437,\n  0.3898540139198303,\n  0.4140249788761139,\n  0.6474394798278809,\n  0.7178751230239868,\n  0.8017071485519409,\n  0.8509621620178223,\n  0.9159352779388428,\n  0.9694305658340454,\n  1.0089608430862427,\n  1.1476460695266724,\n  1.35414457321167,\n  1.374300241470337,\n  1.5314922332763672,\n  1.927258014678955,\n  1.9400420188903809,\n  2.1730926036834717,\n  2.2753655910491943,\n  2.321286916732788,\n  2.3425848484039307,\n  2.833474636077881,\n  2.838233709335327,\n  3.066187858581543,\n  3.095120429992676,\n  3.2050089836120605,\n  3.4429328441619873,\n  3.5366477966308594,\n  4.107156276702881,\n  4.169442176818848,\n  4.321160793304443,\n  4.428501605987549,\n  4.574401378631592,\n  4.574549674987793,\n  4.599322319030762,\n  4.667791366577148,\n  4.843308448791504,\n  4.880730152130127,\n  5.190732002258301,\n  5.341668128967285,\n  5.576009750366211,\n  5.8594818115234375,\n  6.093061923980713,\n  6.115549087524414,\n  6.1557464599609375,\n  6.353526592254639,\n  6.361209392547607,\n  6.49996280670166,\n  6.64868688583374,\n  6.695247650146484,\n  6.879955768585205,\n  7.224823474884033,\n  7.732153415679932,\n  7.773316383361816,\n  8.131145477294922,\n  8.456668853759766,\n  8.473387718200684,\n  8.65821647644043,\n  9.273755073547363,\n  11.11512565612793,\n  11.849024772644043,\n  12.527979850769043,\n  13.493826866149902,\n  13.494071006774902,\n  13.756278991699219],\n [-9.261781692504883,\n  -8.728165626525879,\n  -7.105295658111572,\n  -5.444580554962158,\n  -4.800751209259033,\n  -4.731117248535156,\n  -4.675020694732666,\n  -4.642090320587158,\n  -4.3249831199646,\n  -4.038965702056885,\n  -3.516183853149414,\n  -3.1549222469329834,\n  -3.13791561126709,\n  -3.0583112239837646,\n  -2.433084011077881,\n  -2.3665294647216797,\n  -2.065535306930542,\n  -1.716423511505127,\n  -1.578906774520874,\n  -1.5222777128219604,\n  -1.3119219541549683,\n  -0.9360904097557068,\n  -0.8142769932746887,\n  -0.7215160727500916,\n  -0.6705335974693298,\n  -0.4709697663784027,\n  -0.35909754037857056,\n  -0.3287123739719391,\n  -0.3161252439022064,\n  -0.3009648025035858,\n  0.0557602196931839,\n  0.12431085109710693,\n  0.1383270025253296,\n  0.37351590394973755,\n  0.5443479418754578,\n  0.5459415912628174,\n  0.5627096891403198,\n  0.5685461759567261,\n  0.5921564698219299,\n  0.8201568722724915,\n  0.8889586925506592,\n  0.9708462357521057,\n  1.0189588069915771,\n  1.0824248790740967,\n  1.1346791982650757,\n  1.173292636871338,\n  1.3087610006332397,\n  1.510469675064087,\n  1.5301578044891357,\n  1.6837037801742554,\n  2.0702898502349854,\n  2.082777261734009,\n  2.31042218208313,\n  2.410322904586792,\n  2.45517897605896,\n  2.475982904434204,\n  2.955486536026001,\n  2.960134983062744,\n  3.1828017234802246,\n  3.2110631465911865,\n  3.3184027671813965,\n  3.5508079528808594,\n  3.6423492431640625,\n  4.199624538421631,\n  4.260465621948242,\n  4.408665657043457,\n  4.513516426086426,\n  4.656032085418701,\n  4.656176567077637,\n  4.680374622344971,\n  4.747255802154541,\n  4.918701648712158,\n  4.955255031585693,\n  5.258066654205322,\n  5.405501842498779,\n  5.6344075202941895,\n  5.911304473876953,\n  6.139466762542725,\n  6.161432266235352,\n  6.200697422027588,\n  6.393889904022217,\n  6.401394367218018,\n  6.536929130554199,\n  6.682203769683838,\n  6.727684497833252,\n  6.908108234405518,\n  7.244976997375488,\n  7.740539073944092,\n  7.780747413635254,\n  8.130276679992676,\n  8.448249816894531,\n  8.464580535888672,\n  8.645122528076172,\n  9.246382713317871,\n  11.045042991638184,\n  11.761919021606445,\n  12.425125122070312,\n  13.368569374084473,\n  13.368807792663574,\n  13.624934196472168],\n [-8.927906036376953,\n  -8.404502868652344,\n  -6.81269645690918,\n  -5.1837687492370605,\n  -4.552262783050537,\n  -4.483961582183838,\n  -4.428938865661621,\n  -4.3966383934021,\n  -4.085601329803467,\n  -3.805058479309082,\n  -3.292283058166504,\n  -2.9379360675811768,\n  -2.921255111694336,\n  -2.8431742191314697,\n  -2.229914426803589,\n  -2.1646337509155273,\n  -1.869400978088379,\n  -1.5269713401794434,\n  -1.3920868635177612,\n  -1.3365416526794434,\n  -1.1302123069763184,\n  -0.7615744471549988,\n  -0.6420926451683044,\n  -0.5511072278022766,\n  -0.5011005997657776,\n  -0.30535656213760376,\n  -0.1956256479024887,\n  -0.1658220887184143,\n  -0.15347588062286377,\n  -0.13860562443733215,\n  0.21129140257835388,\n  0.27852991223335266,\n  0.2922777831554413,\n  0.5229650139808655,\n  0.6905271410942078,\n  0.6920903325080872,\n  0.7085375189781189,\n  0.7142622470855713,\n  0.7374206185340881,\n  0.9610569477081299,\n  1.0285418033599854,\n  1.108862042427063,\n  1.1560535430908203,\n  1.2183048725128174,\n  1.2695591449737549,\n  1.3074333667755127,\n  1.4403088092803955,\n  1.6381566524505615,\n  1.6574679613113403,\n  1.8080748319625854,\n  2.1872613430023193,\n  2.199509859085083,\n  2.422797203063965,\n  2.5207858085632324,\n  2.5647833347320557,\n  2.5851891040802,\n  3.0555145740509033,\n  3.0600743293762207,\n  3.2784790992736816,\n  3.306199550628662,\n  3.411484479904175,\n  3.6394412517547607,\n  3.7292304039001465,\n  4.275839328765869,\n  4.335515975952148,\n  4.480878829956055,\n  4.583723068237305,\n  4.7235107421875,\n  4.723652362823486,\n  4.747387409210205,\n  4.81298828125,\n  4.981152534484863,\n  5.0170063972473145,\n  5.314021587371826,\n  5.458634853363037,\n  5.683159351348877,\n  5.954756259918213,\n  6.178551197052002,\n  6.200096130371094,\n  6.238609790802002,\n  6.428104400634766,\n  6.435465335845947,\n  6.568406105041504,\n  6.710899829864502,\n  6.755510330200195,\n  6.932480335235596,\n  7.262901306152344,\n  7.7489776611328125,\n  7.788416385650635,\n  8.131255149841309,\n  8.44314193725586,\n  8.459160804748535,\n  8.636246681213379,\n  9.225998878479004,\n  10.990230560302734,\n  11.693385124206543,\n  12.343897819519043,\n  13.269283294677734,\n  13.269516944885254,\n  13.520740509033203],\n [-8.657336235046387,\n  -8.142171859741211,\n  -6.575418949127197,\n  -4.972128868103027,\n  -4.35056209564209,\n  -4.2833356857299805,\n  -4.2291789054870605,\n  -4.197387218475342,\n  -3.8912453651428223,\n  -3.6151180267333984,\n  -3.110413074493408,\n  -2.761643409729004,\n  -2.745224714279175,\n  -2.668372869491577,\n  -2.064765214920044,\n  -2.000511884689331,\n  -1.709925889968872,\n  -1.372885823249817,\n  -1.240124225616455,\n  -1.1854532957077026,\n  -0.9823713898658752,\n  -0.6195355653762817,\n  -0.5019342303276062,\n  -0.4123808741569519,\n  -0.3631612956523895,\n  -0.1704980731010437,\n  -0.06249423325061798,\n  -0.033159755170345306,\n  -0.021007858216762543,\n  -0.006371652241796255,\n  0.3380183279514313,\n  0.4041985869407654,\n  0.41773006319999695,\n  0.6447864770889282,\n  0.8097113966941833,\n  0.8112499117851257,\n  0.827438235282898,\n  0.83307284116745,\n  0.8558667898178101,\n  1.0759832859039307,\n  1.1424059867858887,\n  1.2214620113372803,\n  1.2679108381271362,\n  1.3291823863983154,\n  1.3796298503875732,\n  1.4169081449508667,\n  1.5476921796798706,\n  1.7424260377883911,\n  1.7614333629608154,\n  1.9096699953079224,\n  2.282888412475586,\n  2.2949440479278564,\n  2.5147171020507812,\n  2.61116361618042,\n  2.654468536376953,\n  2.674553155899048,\n  3.1374762058258057,\n  3.1419641971588135,\n  3.356931447982788,\n  3.3842155933380127,\n  3.4878435134887695,\n  3.712212324142456,\n  3.800588369369507,\n  4.33859395980835,\n  4.397331237792969,\n  4.540406227111816,\n  4.641631603240967,\n  4.779219627380371,\n  4.779358863830566,\n  4.802720546722412,\n  4.867288589477539,\n  5.032806396484375,\n  5.068095684051514,\n  5.36043643951416,\n  5.502773761749268,\n  5.723764419555664,\n  5.991086483001709,\n  6.211359024047852,\n  6.232564926147461,\n  6.270472049713135,\n  6.456984519958496,\n  6.464229583740234,\n  6.595077991485596,\n  6.7353291511535645,\n  6.779237270355225,\n  6.9534220695495605,\n  7.278642177581787,\n  7.757068634033203,\n  7.795886516571045,\n  8.133329391479492,\n  8.4403076171875,\n  8.456073760986328,\n  8.630373001098633,\n  9.21084213256836,\n  10.947306632995605,\n  11.639394760131836,\n  12.279668807983398,\n  13.190489768981934,\n  13.190719604492188,\n  13.437989234924316],\n [-8.438004493713379,\n  -7.929488182067871,\n  -6.38295316696167,\n  -4.800353050231934,\n  -4.186807155609131,\n  -4.120448589324951,\n  -4.066990852355957,\n  -4.035609245300293,\n  -3.7334179878234863,\n  -3.4608538150787354,\n  -2.9626619815826416,\n  -2.6183929443359375,\n  -2.602186441421509,\n  -2.5263261795043945,\n  -1.930507779121399,\n  -1.8670837879180908,\n  -1.5802475214004517,\n  -1.2475568056106567,\n  -1.1165084838867188,\n  -1.0625430345535278,\n  -0.8620818257331848,\n  -0.5039282441139221,\n  -0.3878445327281952,\n  -0.29944679141044617,\n  -0.25086236000061035,\n  -0.06068538501858711,\n  0.04592471569776535,\n  0.07488065212965012,\n  0.08687572926282883,\n  0.10132306069135666,\n  0.44126883149147034,\n  0.5065950751304626,\n  0.5199519395828247,\n  0.7440782785415649,\n  0.9068748950958252,\n  0.9083935618400574,\n  0.9243730306625366,\n  0.9299349188804626,\n  0.9524346590042114,\n  1.169710636138916,\n  1.235276222229004,\n  1.31331205368042,\n  1.3591614961624146,\n  1.4196423292160034,\n  1.469438910484314,\n  1.506235957145691,\n  1.6353323459625244,\n  1.8275532722473145,\n  1.8463153839111328,\n  1.9926389455795288,\n  2.3610410690307617,\n  2.372941255569458,\n  2.5898783206939697,\n  2.685080051422119,\n  2.7278263568878174,\n  2.7476518154144287,\n  3.2046008110046387,\n  3.209030866622925,\n  3.4212241172790527,\n  3.4481561183929443,\n  3.5504469871520996,\n  3.7719204425811768,\n  3.8591558933258057,\n  4.390218734741211,\n  4.448198318481445,\n  4.5894269943237305,\n  4.6893463134765625,\n  4.82515811920166,\n  4.825295925140381,\n  4.848355770111084,\n  4.912091255187988,\n  5.075472831726074,\n  5.110306739807129,\n  5.398874759674072,\n  5.539375305175781,\n  5.757513999938965,\n  6.021386623382568,\n  6.238816738128662,\n  6.259748935699463,\n  6.29716682434082,\n  6.4812726974487305,\n  6.488424301147461,\n  6.617583751678467,\n  6.756025314331055,\n  6.799366474151611,\n  6.971303462982178,\n  7.292326927185059,\n  7.764579772949219,\n  7.802896499633789,\n  8.135985374450684,\n  8.439001083374023,\n  8.454564094543457,\n  8.62661361694336,\n  9.199593544006348,\n  10.913649559020996,\n  11.596805572509766,\n  12.2288179397583,\n  13.127883911132812,\n  13.128111839294434,\n  13.372190475463867],\n [-8.260159492492676,\n  -7.757010459899902,\n  -6.226800441741943,\n  -4.660905838012695,\n  -4.053836822509766,\n  -3.988178253173828,\n  -3.9352846145629883,\n  -3.9042344093322754,\n  -3.6052331924438477,\n  -3.3355460166931152,\n  -2.8426129817962646,\n  -2.5019781589508057,\n  -2.4859423637390137,\n  -2.4108831882476807,\n  -1.8213540315628052,\n  -1.7585995197296143,\n  -1.4747910499572754,\n  -1.145612120628357,\n  -1.0159471035003662,\n  -0.9625513553619385,\n  -0.7642061114311218,\n  -0.4098331332206726,\n  -0.29497477412223816,\n  -0.20751014351844788,\n  -0.1594385802745819,\n  0.028730938211083412,\n  0.13421568274497986,\n  0.16286596655845642,\n  0.174734428524971,\n  0.189029261469841,\n  0.5253866314888,\n  0.5900232791900635,\n  0.6032391786575317,\n  0.8249996900558472,\n  0.9860778450965881,\n  0.9875805377960205,\n  1.0033912658691406,\n  1.008894443511963,\n  1.0311566591262817,\n  1.2461391687393188,\n  1.3110127449035645,\n  1.388224720954895,\n  1.4335901737213135,\n  1.493432641029358,\n  1.5427035093307495,\n  1.5791122913360596,\n  1.7068458795547485,\n  1.8970377445220947,\n  1.9156018495559692,\n  2.0603809356689453,\n  2.424894332885742,\n  2.436668634414673,\n  2.651315927505493,\n  2.7455127239227295,\n  2.7878077030181885,\n  2.8074238300323486,\n  3.259549617767334,\n  3.263932704925537,\n  3.473886013031006,\n  3.5005338191986084,\n  3.6017448902130127,\n  3.820880651473999,\n  3.9071953296661377,\n  4.432652473449707,\n  4.490019798278809,\n  4.629757404327393,\n  4.728621959686279,\n  4.863000392913818,\n  4.8631367683410645,\n  4.885953426361084,\n  4.9490156173706055,\n  5.110672950744629,\n  5.145139217376709,\n  5.430661201477051,\n  5.56967830657959,\n  5.785514831542969,\n  6.04660177230835,\n  6.261736869812012,\n  6.2824482917785645,\n  6.31947135925293,\n  6.501633167266846,\n  6.50870943069458,\n  6.636505603790283,\n  6.7734856605529785,\n  6.816370010375977,\n  6.986491680145264,\n  7.304126739501953,\n  7.7713942527771,\n  7.809306621551514,\n  8.13887882232666,\n  8.43869686126709,\n  8.454095840454102,\n  8.62432861328125,\n  9.19126033782959,\n  10.887223243713379,\n  11.5631685256958,\n  12.188508033752441,\n  13.078084945678711,\n  13.078310012817383,\n  13.319812774658203],\n [-8.115914344787598,\n  -7.617101669311523,\n  -6.1000800132751465,\n  -4.547680854797363,\n  -3.9458436965942383,\n  -3.880751132965088,\n  -3.8283135890960693,\n  -3.7975308895111084,\n  -3.5011065006256104,\n  -3.233743667602539,\n  -2.745059013366699,\n  -2.4073598384857178,\n  -2.3914623260498047,\n  -2.317049980163574,\n  -1.7326017618179321,\n  -1.670388102531433,\n  -1.3890256881713867,\n  -1.0626837015151978,\n  -0.9341362714767456,\n  -0.8812006711959839,\n  -0.6845648884773254,\n  -0.3332460820674896,\n  -0.21937762200832367,\n  -0.13266681134700775,\n  -0.08500954508781433,\n  0.10153822600841522,\n  0.20611386001110077,\n  0.23451721668243408,\n  0.2462833821773529,\n  0.26045501232147217,\n  0.5939134955406189,\n  0.6579930782318115,\n  0.671095073223114,\n  0.8909443616867065,\n  1.0506342649459839,\n  1.0521239042282104,\n  1.067798376083374,\n  1.0732542276382446,\n  1.0953246355056763,\n  1.3084542751312256,\n  1.3727686405181885,\n  1.4493151903152466,\n  1.494289755821228,\n  1.5536164045333862,\n  1.602462649345398,\n  1.6385575532913208,\n  1.7651903629302979,\n  1.9537429809570312,\n  1.9721471071243286,\n  2.115678310394287,\n  2.4770500659942627,\n  2.4887232780456543,\n  2.7015204429626465,\n  2.794905424118042,\n  2.8368358612060547,\n  2.856282949447632,\n  3.3045120239257812,\n  3.3088574409484863,\n  3.5170013904571533,\n  3.543419361114502,\n  3.6437580585479736,\n  3.8610050678253174,\n  3.946575880050659,\n  4.467504501342773,\n  4.524377346038818,\n  4.6629109382629395,\n  4.760923385620117,\n  4.894143581390381,\n  4.894278526306152,\n  4.916898727416992,\n  4.97941780090332,\n  5.139681339263916,\n  5.1738505363464355,\n  5.456912040710449,\n  5.594730854034424,\n  5.808707237243652,\n  6.067543983459473,\n  6.280825138092041,\n  6.301357746124268,\n  6.338061809539795,\n  6.518653869628906,\n  6.525669097900391,\n  6.6523637771606445,\n  6.788163185119629,\n  6.830677509307861,\n  6.999333381652832,\n  7.314230918884277,\n  7.77747106552124,\n  7.815056800842285,\n  8.141789436340332,\n  8.4390230178833,\n  8.454288482666016,\n  8.623055458068848,\n  9.185099601745605,\n  10.866446495056152,\n  11.536565780639648,\n  12.156517028808594,\n  13.038426399230957,\n  13.038649559020996,\n  13.278070449829102],\n [-7.998893737792969,\n  -7.5035858154296875,\n  -5.997223377227783,\n  -4.4557318687438965,\n  -3.858123540878296,\n  -3.7934882640838623,\n  -3.7414190769195557,\n  -3.71085262298584,\n  -3.416511058807373,\n  -3.151026964187622,\n  -2.665776014328003,\n  -2.3304495811462402,\n  -2.314663887023926,\n  -2.240774154663086,\n  -1.6604324579238892,\n  -1.5986559391021729,\n  -1.319270372390747,\n  -0.9952215552330017,\n  -0.8675772547721863,\n  -0.815013587474823,\n  -0.6197594404220581,\n  -0.2709091007709503,\n  -0.15784072875976562,\n  -0.07173916697502136,\n  -0.024416757747530937,\n  0.16082027554512024,\n  0.26466113328933716,\n  0.29286491870880127,\n  0.3045484125614166,\n  0.3186204731464386,\n  0.6497359871864319,\n  0.7133653163909912,\n  0.7263752222061157,\n  0.9446797966957092,\n  1.1032476425170898,\n  1.1047269105911255,\n  1.1202912330627441,\n  1.1257086992263794,\n  1.1476240158081055,\n  1.3592561483383179,\n  1.4231185913085938,\n  1.4991273880004883,\n  1.5437859296798706,\n  1.6026957035064697,\n  1.6511987447738647,\n  1.687040090560913,\n  1.8127830028533936,\n  2.0000109672546387,\n  2.0182857513427734,\n  2.1608083248138428,\n  2.519641160964966,\n  2.5312321186065674,\n  2.7425341606140137,\n  2.8352630138397217,\n  2.876898765563965,\n  2.896209239959717,\n  3.3412890434265137,\n  3.3456039428710938,\n  3.5522851943969727,\n  3.5785176753997803,\n  3.6781513690948486,\n  3.893872022628784,\n  3.978841543197632,\n  4.496109962463379,\n  4.55258321762085,\n  4.69014310836792,\n  4.787467002868652,\n  4.9197516441345215,\n  4.919885635375977,\n  4.942346572875977,\n  5.004426002502441,\n  5.1635637283325195,\n  5.197493076324463,\n  5.478565692901611,\n  5.615416049957275,\n  5.8278889656066895,\n  6.084907054901123,\n  6.296689510345459,\n  6.317078113555908,\n  6.353524208068848,\n  6.5328474044799805,\n  6.539813041687012,\n  6.665617942810059,\n  6.8004631996154785,\n  6.842678546905518,\n  7.0101494789123535,\n  7.322834491729736,\n  7.782819747924805,\n  7.820141315460205,\n  8.144577980041504,\n  8.439723014831543,\n  8.45488166809082,\n  8.622462272644043,\n  9.180558204650879,\n  10.850090980529785,\n  11.515501976013184,\n  12.131096839904785,\n  13.00680923461914,\n  13.007031440734863,\n  13.244770050048828],\n [-7.903938293457031,\n  -7.411464214324951,\n  -5.913720607757568,\n  -4.381049156188965,\n  -3.7868597507476807,\n  -3.7225944995880127,\n  -3.670823335647583,\n  -3.6404316425323486,\n  -3.3477742671966553,\n  -3.0838091373443604,\n  -2.601334571838379,\n  -2.2679266929626465,\n  -2.2522313594818115,\n  -2.178764581680298,\n  -1.601743221282959,\n  -1.5403201580047607,\n  -1.262533187866211,\n  -0.9403384327888489,\n  -0.8134244680404663,\n  -0.7611615657806396,\n  -0.5670245885848999,\n  -0.22017022967338562,\n  -0.10774879902601242,\n  -0.022139888256788254,\n  0.02491176314651966,\n  0.20908893644809723,\n  0.31233564019203186,\n  0.3403780460357666,\n  0.35199472308158875,\n  0.36598625779151917,\n  0.6952072381973267,\n  0.7584725022315979,\n  0.771407961845398,\n  0.9884634613990784,\n  1.1461241245269775,\n  1.1475948095321655,\n  1.1630702018737793,\n  1.1684565544128418,\n  1.1902464628219604,\n  1.4006677865982056,\n  1.4641648530960083,\n  1.5397387742996216,\n  1.584141731262207,\n  1.642714500427246,\n  1.690940022468567,\n  1.7265762090682983,\n  1.8515998125076294,\n  2.0377564430236816,\n  2.055926561355591,\n  2.197633981704712,\n  2.5544135570526123,\n  2.5659382343292236,\n  2.776031255722046,\n  2.868229389190674,\n  2.9096271991729736,\n  2.9288270473480225,\n  3.3713600635528564,\n  3.375650405883789,\n  3.581149101257324,\n  3.607231616973877,\n  3.7062952518463135,\n  3.9207816123962402,\n  4.005264759063721,\n  4.51957368850708,\n  4.575723648071289,\n  4.712496757507324,\n  4.809263706207275,\n  4.940791130065918,\n  4.940924644470215,\n  4.9632568359375,\n  5.024981498718262,\n  5.183208465576172,\n  5.216943740844727,\n  5.496407985687256,\n  5.632475852966309,\n  5.8437323570251465,\n  6.09928035736084,\n  6.309850692749023,\n  6.330122947692871,\n  6.366360187530518,\n  6.544657230377197,\n  6.551583290100098,\n  6.676668167114258,\n  6.810741901397705,\n  6.852716445922852,\n  7.019228935241699,\n  7.330124378204346,\n  7.787477970123291,\n  7.824585914611816,\n  8.14716625213623,\n  8.44062328338623,\n  8.455695152282715,\n  8.622316360473633,\n  9.17721939086914,\n  10.837199211120605,\n  11.49880313873291,\n  12.110876083374023,\n  12.98157787322998,\n  12.98179817199707,\n  13.21817684173584],\n [-7.826869964599609,\n  -7.336688995361328,\n  -5.845917224884033,\n  -4.320380687713623,\n  -3.728957414627075,\n  -3.6649913787841797,\n  -3.6134610176086426,\n  -3.5832109451293945,\n  -3.2919158935546875,\n  -3.029179573059082,\n  -2.5489509105682373,\n  -2.217095136642456,\n  -2.201472759246826,\n  -2.1283481121063232,\n  -1.5540128946304321,\n  -1.4928756952285767,\n  -1.2163819074630737,\n  -0.8956869840621948,\n  -0.7693638205528259,\n  -0.7173442244529724,\n  -0.5241109728813171,\n  -0.1788712739944458,\n  -0.06697317957878113,\n  0.01823720894753933,\n  0.06506982445716858,\n  0.24838963150978088,\n  0.35115569829940796,\n  0.3790675699710846,\n  0.39063015580177307,\n  0.4045565724372864,\n  0.7322449684143066,\n  0.7952157258987427,\n  0.8080909848213196,\n  1.0241360664367676,\n  1.1810626983642578,\n  1.182526707649231,\n  1.1979299783706665,\n  1.2032912969589233,\n  1.2249797582626343,\n  1.434421420097351,\n  1.4976229667663574,\n  1.5728451013565063,\n  1.6170413494110107,\n  1.6753414869308472,\n  1.7233424186706543,\n  1.7588127851486206,\n  1.8832542896270752,\n  2.068544387817383,\n  2.08663010597229,\n  2.227677583694458,\n  2.582796335220337,\n  2.5942673683166504,\n  2.803382396697998,\n  2.8951516151428223,\n  2.936356544494629,\n  2.9554669857025146,\n  3.395940065383911,\n  3.400210380554199,\n  3.604752540588379,\n  3.63071346282959,\n  3.729315996170044,\n  3.9428038597106934,\n  4.0268940925598145,\n  4.538808345794678,\n  4.594696998596191,\n  4.730833530426025,\n  4.827149868011475,\n  4.958065032958984,\n  4.958198070526123,\n  4.98042631149292,\n  5.041863441467285,\n  5.19935417175293,\n  5.232932090759277,\n  5.5110955238342285,\n  5.646529674530029,\n  5.8568034172058105,\n  6.111161231994629,\n  6.320751667022705,\n  6.34092903137207,\n  6.376997947692871,\n  6.554465293884277,\n  6.56135892868042,\n  6.685861587524414,\n  6.819311141967773,\n  6.861090183258057,\n  7.026827335357666,\n  7.336275577545166,\n  7.791500091552734,\n  7.82843542098999,\n  8.149514198303223,\n  8.441604614257812,\n  8.4566068649292,\n  8.622452735900879,\n  9.174772262573242,\n  10.827024459838867,\n  11.485548973083496,\n  12.094772338867188,\n  12.961421012878418,\n  12.961640357971191,\n  13.196918487548828],\n [-7.764307975769043,\n  -7.27598237991333,\n  -5.790853023529053,\n  -4.271090030670166,\n  -3.681905508041382,\n  -3.6181814670562744,\n  -3.5668461322784424,\n  -3.536710739135742,\n  -3.246518135070801,\n  -2.984776258468628,\n  -2.5063650608062744,\n  -2.1757652759552,\n  -2.1602022647857666,\n  -2.0873541831970215,\n  -1.5151927471160889,\n  -1.4542869329452515,\n  -1.1788396835327148,\n  -0.8593584895133972,\n  -0.7335134744644165,\n  -0.6816907525062561,\n  -0.4891888499259949,\n  -0.14525583386421204,\n  -0.033781249076128006,\n  0.051106635481119156,\n  0.09776199609041214,\n  0.2803879678249359,\n  0.3827650845050812,\n  0.41057130694389343,\n  0.4220901429653168,\n  0.43596383929252625,\n  0.7624120116233826,\n  0.8251444101333618,\n  0.8379709720611572,\n  1.0531983375549316,\n  1.2095310688018799,\n  1.2109894752502441,\n  1.2263344526290894,\n  1.2316755056381226,\n  1.253281831741333,\n  1.4619308710098267,\n  1.5248931646347046,\n  1.5998305082321167,\n  1.6438595056533813,\n  1.7019389867782593,\n  1.7497583627700806,\n  1.7850943803787231,\n  1.9090650081634521,\n  2.093653678894043,\n  2.111670970916748,\n  2.2521846294403076,\n  2.605959415435791,\n  2.617387056350708,\n  2.8257105350494385,\n  2.9171321392059326,\n  2.958181142807007,\n  2.977219343185425,\n  3.416025400161743,\n  3.4202795028686523,\n  3.6240475177764893,\n  3.6499102115631104,\n  3.7481393814086914,\n  3.9608192443847656,\n  4.044590950012207,\n  4.554568290710449,\n  4.610245227813721,\n  4.745866775512695,\n  4.841818332672119,\n  4.972238063812256,\n  4.972370147705078,\n  4.994514465332031,\n  5.055719375610352,\n  5.212613582611084,\n  5.24606466293335,\n  5.523175239562988,\n  5.658096790313721,\n  5.867574691772461,\n  6.120970249176025,\n  6.329767227172852,\n  6.349868297576904,\n  6.385800361633301,\n  6.562595844268799,\n  6.569463729858398,\n  6.693495273590088,\n  6.826439380645752,\n  6.868060111999512,\n  7.033170223236084,\n  7.341447353363037,\n  7.794949054718018,\n  7.83174467086792,\n  8.151607513427734,\n  8.44259262084961,\n  8.457537651062012,\n  8.622756004333496,\n  9.172985076904297,\n  10.818984031677246,\n  11.475016593933105,\n  12.081933975219727,\n  12.945302963256836,\n  12.945521354675293,\n  13.179908752441406],\n [-7.713510990142822,\n  -7.226686954498291,\n  -5.746126174926758,\n  -4.231037616729736,\n  -3.643665313720703,\n  -3.580137252807617,\n  -3.5289597511291504,\n  -3.4989171028137207,\n  -3.2096168994903564,\n  -2.9486801624298096,\n  -2.47174072265625,\n  -2.142157793045044,\n  -2.1266424655914307,\n  -2.054018497467041,\n  -1.4836169481277466,\n  -1.422898530960083,\n  -1.1482985019683838,\n  -0.829800009727478,\n  -0.7043420076370239,\n  -0.6526787281036377,\n  -0.4607689380645752,\n  -0.11789380013942719,\n  -0.006762102246284485,\n  0.07786467671394348,\n  0.12437653541564941,\n  0.3064407706260681,\n  0.408502995967865,\n  0.43622371554374695,\n  0.44770708680152893,\n  0.4615381062030792,\n  0.7869821786880493,\n  0.8495216369628906,\n  0.8623087406158447,\n  1.0768741369247437,\n  1.232725977897644,\n  1.2341798543930054,\n  1.2494776248931885,\n  1.2548022270202637,\n  1.2763421535491943,\n  1.4843493700027466,\n  1.547118067741394,\n  1.6218249797821045,\n  1.6657185554504395,\n  1.7236193418502808,\n  1.7712914943695068,\n  1.8065189123153687,\n  1.9301081895828247,\n  2.1141293048858643,\n  2.1320908069610596,\n  2.272172451019287,\n  2.624859094619751,\n  2.636251449584961,\n  2.8439342975616455,\n  2.935074806213379,\n  2.9759974479675293,\n  2.9949772357940674,\n  3.4324333667755127,\n  3.4366743564605713,\n  3.63981556892395,\n  3.6655988693237305,\n  3.76352596282959,\n  3.9755516052246094,\n  4.059065818786621,\n  4.567473888397217,\n  4.622980117797852,\n  4.75818395614624,\n  4.8538408279418945,\n  4.983859539031982,\n  4.9839911460876465,\n  5.006067276000977,\n  5.067083835601807,\n  5.223495960235596,\n  5.2568440437316895,\n  5.533102035522461,\n  5.667608737945557,\n  5.876441955566406,\n  6.129057884216309,\n  6.337213039398193,\n  6.35725212097168,\n  6.393074035644531,\n  6.5693254470825195,\n  6.576172351837158,\n  6.699821949005127,\n  6.832357406616211,\n  6.873850345611572,\n  7.038452625274658,\n  7.345781326293945,\n  7.797888278961182,\n  7.834570407867432,\n  8.153450012207031,\n  8.4435396194458,\n  8.458438873291016,\n  8.623148918151855,\n  9.171685218811035,\n  10.8126220703125,\n  11.466635704040527,\n  12.071686744689941,\n  12.93239974975586,\n  12.932618141174316,\n  13.166284561157227],\n [-7.672260761260986,\n  -7.186653137207031,\n  -5.709791660308838,\n  -4.198488712310791,\n  -3.612584114074707,\n  -3.5492148399353027,\n  -3.4981651306152344,\n  -3.4681975841522217,\n  -3.1796202659606934,\n  -2.91933536529541,\n  -2.4435875415802,\n  -2.11482834815979,\n  -2.099351644515991,\n  -2.026909112930298,\n  -1.457932949066162,\n  -1.3973662853240967,\n  -1.1234523057937622,\n  -0.8057495951652527,\n  -0.6806051135063171,\n  -0.6290708780288696,\n  -0.43764063715934753,\n  -0.0956222265958786,\n  0.015231793746352196,\n  0.09964711964130402,\n  0.14604276418685913,\n  0.32765209674835205,\n  0.4294593036174774,\n  0.457110732793808,\n  0.468565434217453,\n  0.48236188292503357,\n  0.806992769241333,\n  0.869376003742218,\n  0.8821310997009277,\n  1.0961604118347168,\n  1.2516227960586548,\n  1.2530730962753296,\n  1.268332600593567,\n  1.273643970489502,\n  1.2951301336288452,\n  1.502617597579956,\n  1.5652294158935547,\n  1.639749526977539,\n  1.6835334300994873,\n  1.7412896156311035,\n  1.7888426780700684,\n  1.8239821195602417,\n  1.9472625255584717,\n  2.130823850631714,\n  2.148740530014038,\n  2.2884721755981445,\n  2.64027738571167,\n  2.651641368865967,\n  2.8588054180145264,\n  2.9497179985046387,\n  2.9905385971069336,\n  3.0094707012176514,\n  3.445833921432495,\n  3.4500644207000732,\n  3.652698040008545,\n  3.6784167289733887,\n  3.77609920501709,\n  3.9875950813293457,\n  4.0709004402160645,\n  4.578038692474365,\n  4.633405685424805,\n  4.768272399902344,\n  4.86368989944458,\n  4.993383407592773,\n  4.9935150146484375,\n  5.015536308288574,\n  5.076399803161621,\n  5.232420921325684,\n  5.26568603515625,\n  5.541253566741943,\n  5.675424575805664,\n  5.883735656738281,\n  6.135720729827881,\n  6.343355655670166,\n  6.363344669342041,\n  6.39907693862915,\n  6.574888229370117,\n  6.581717491149902,\n  6.705058574676514,\n  6.837263107299805,\n  6.878652095794678,\n  7.042842864990234,\n  7.3494038581848145,\n  7.800381183624268,\n  7.836971759796143,\n  8.155054092407227,\n  8.444419860839844,\n  8.459280967712402,\n  8.623579978942871,\n  9.170745849609375,\n  10.807581901550293,\n  11.459961891174316,\n  12.06350040435791,\n  12.922063827514648,\n  12.922280311584473,\n  13.155364036560059],\n [-7.63875675201416,\n  -7.154134273529053,\n  -5.680269718170166,\n  -4.17203426361084,\n  -3.5873184204101562,\n  -3.5240776538848877,\n  -3.4731316566467285,\n  -3.4432246685028076,\n  -3.155233144760132,\n  -2.8954765796661377,\n  -2.420694351196289,\n  -2.092602014541626,\n  -2.0771567821502686,\n  -2.004861354827881,\n  -1.4370397329330444,\n  -1.3765959739685059,\n  -1.1032378673553467,\n  -0.7861799001693726,\n  -0.661289393901825,\n  -0.6098597645759583,\n  -0.41881799697875977,\n  -0.07749363034963608,\n  0.03313542529940605,\n  0.11737944930791855,\n  0.16368094086647034,\n  0.34492170810699463,\n  0.4465223252773285,\n  0.474117636680603,\n  0.48554909229278564,\n  0.49931755661964417,\n  0.8232896327972412,\n  0.8855462670326233,\n  0.8982754945755005,\n  1.1118704080581665,\n  1.2670173645019531,\n  1.2684646844863892,\n  1.2836933135986328,\n  1.2889938354492188,\n  1.3104363679885864,\n  1.517502784729004,\n  1.5799875259399414,\n  1.6543564796447754,\n  1.6980515718460083,\n  1.7556904554367065,\n  1.8031470775604248,\n  1.8382152318954468,\n  1.9612454175949097,\n  2.1444342136383057,\n  2.1623146533966064,\n  2.301762580871582,\n  2.6528539657592773,\n  2.6641948223114014,\n  2.870938301086426,\n  2.9616665840148926,\n  3.00240421295166,\n  3.0212981700897217,\n  3.456775665283203,\n  3.4609975814819336,\n  3.663220167160034,\n  3.6888866424560547,\n  3.7863707542419434,\n  3.9974374771118164,\n  4.080574035644531,\n  4.5866827964782715,\n  4.641937732696533,\n  4.7765302658081055,\n  4.871754169464111,\n  5.001184940338135,\n  5.001316070556641,\n  5.023292541503906,\n  5.084033012390137,\n  5.239737510681152,\n  5.272934436798096,\n  5.547943115234375,\n  5.6818413734436035,\n  5.889730453491211,\n  6.141203880310059,\n  6.348417282104492,\n  6.36836576461792,\n  6.404025554656982,\n  6.579480171203613,\n  6.5862956047058105,\n  6.709386348724365,\n  6.841322422027588,\n  6.882627487182617,\n  7.046485424041748,\n  7.352424144744873,\n  7.802485942840576,\n  7.83900260925293,\n  8.156439781188965,\n  8.44521713256836,\n  8.460049629211426,\n  8.624013900756836,\n  9.170069694519043,\n  10.803584098815918,\n  11.45464038848877,\n  12.056954383850098,\n  12.913774490356445,\n  12.913991928100586,\n  13.146601676940918],\n [-7.611539840698242,\n  -7.127716064453125,\n  -5.656280517578125,\n  -4.1505303382873535,\n  -3.5667781829833984,\n  -3.5036416053771973,\n  -3.452779769897461,\n  -3.422921895980835,\n  -3.1354050636291504,\n  -2.8760764598846436,\n  -2.402076482772827,\n  -2.0745251178741455,\n  -2.059105396270752,\n  -1.986928939819336,\n  -1.4200431108474731,\n  -1.3596988916397095,\n  -1.0867912769317627,\n  -0.7702558040618896,\n  -0.6455711126327515,\n  -0.5942262411117554,\n  -0.4034992754459381,\n  -0.06273742020130157,\n  0.047709330916404724,\n  0.13181452453136444,\n  0.17803971469402313,\n  0.35898181796073914,\n  0.46041497588157654,\n  0.48796483874320984,\n  0.49937742948532104,\n  0.5131232142448425,\n  0.8365614414215088,\n  0.8987154364585876,\n  0.9114237427711487,\n  1.1246665716171265,\n  1.2795579433441162,\n  1.2810028791427612,\n  1.2962063550949097,\n  1.3014981746673584,\n  1.3229053020477295,\n  1.5296305418014526,\n  1.5920122861862183,\n  1.666258692741394,\n  1.7098817825317383,\n  1.7674256563186646,\n  1.8148040771484375,\n  1.8498144149780273,\n  1.972641944885254,\n  2.1555287837982178,\n  2.17337965965271,\n  2.3125979900360107,\n  2.6631107330322266,\n  2.6744329929351807,\n  2.880835771560669,\n  2.971414566040039,\n  3.0120849609375,\n  3.030947685241699,\n  3.465707778930664,\n  3.4699225425720215,\n  3.671811819076538,\n  3.6974360942840576,\n  3.794759511947632,\n  4.005478382110596,\n  4.088478088378906,\n  4.593752861022949,\n  4.648916721343994,\n  4.783287048339844,\n  4.878354549407959,\n  5.007571697235107,\n  5.007702827453613,\n  5.029642581939697,\n  5.090282917022705,\n  5.245730876922607,\n  5.278873443603516,\n  5.553429126739502,\n  5.687106609344482,\n  5.894652843475342,\n  6.145711898803711,\n  6.352583885192871,\n  6.372499465942383,\n  6.408100605010986,\n  6.583265781402588,\n  6.5900702476501465,\n  6.712958335876465,\n  6.844676494598389,\n  6.885913848876953,\n  7.049501419067383,\n  7.354936122894287,\n  7.804256439208984,\n  7.840712547302246,\n  8.15762710571289,\n  8.445928573608398,\n  8.460736274719238,\n  8.624430656433105,\n  9.169586181640625,\n  10.800409317016602,\n  11.45039176940918,\n  12.051713943481445,\n  12.907122611999512,\n  12.90733814239502,\n  13.139565467834473],\n [-7.589427947998047,\n  -7.1062517166137695,\n  -5.63678503036499,\n  -4.133049488067627,\n  -3.5500783920288086,\n  -3.4870262145996094,\n  -3.436232328414917,\n  -3.406414747238159,\n  -3.1192824840545654,\n  -2.8603007793426514,\n  -2.386935234069824,\n  -2.059821844100952,\n  -2.0444228649139404,\n  -1.97234308719635,\n  -1.4062156677246094,\n  -1.3459522724151611,\n  -1.073409914970398,\n  -0.757297933101654,\n  -0.6327800750732422,\n  -0.5815038681030273,\n  -0.3910321295261383,\n  -0.050726234912872314,\n  0.0595727264881134,\n  0.14356538653373718,\n  0.1897287219762802,\n  0.3704287111759186,\n  0.4717261493206024,\n  0.49923914670944214,\n  0.5106364488601685,\n  0.5243638753890991,\n  0.8473693132400513,\n  0.9094401597976685,\n  0.9221314191818237,\n  1.1350890398025513,\n  1.2897729873657227,\n  1.2912160158157349,\n  1.3063991069793701,\n  1.3116838932037354,\n  1.3330624103546143,\n  1.53951096534729,\n  1.6018093824386597,\n  1.67595636844635,\n  1.7195210456848145,\n  1.7769880294799805,\n  1.8243030309677124,\n  1.8592665195465088,\n  1.9819296598434448,\n  2.164571762084961,\n  2.182398796081543,\n  2.3214306831359863,\n  2.6714744567871094,\n  2.68278169631958,\n  2.8889081478118896,\n  2.979365825653076,\n  3.019981861114502,\n  3.0388193130493164,\n  3.4729976654052734,\n  3.4772069454193115,\n  3.678825855255127,\n  3.704415798187256,\n  3.8016092777252197,\n  4.0120463371276855,\n  4.094934463500977,\n  4.5995330810546875,\n  4.654623031616211,\n  4.788814067840576,\n  4.883754253387451,\n  5.012798309326172,\n  5.012929439544678,\n  5.034840106964111,\n  5.095399379730225,\n  5.250638961791992,\n  5.2837371826171875,\n  5.557925224304199,\n  5.691424369812012,\n  5.898692607879639,\n  6.149415969848633,\n  6.356010913848877,\n  6.3759002685546875,\n  6.4114532470703125,\n  6.586384296417236,\n  6.593179702758789,\n  6.715902805328369,\n  6.847445487976074,\n  6.888627052307129,\n  7.051996231079102,\n  7.357022285461426,\n  7.805741310119629,\n  7.842148303985596,\n  8.158638954162598,\n  8.446555137634277,\n  8.461341857910156,\n  8.624817848205566,\n  9.169244766235352,\n  10.797884941101074,\n  11.44699764251709,\n  12.047514915466309,\n  12.901779174804688,\n  12.901994705200195,\n  13.1339111328125],\n [-7.571461200714111,\n  -7.088809967041016,\n  -5.620939254760742,\n  -4.118837833404541,\n  -3.5364997386932373,\n  -3.4735164642333984,\n  -3.4227776527404785,\n  -3.3929922580718994,\n  -3.1061720848083496,\n  -2.8474717140197754,\n  -2.3746204376220703,\n  -2.0478625297546387,\n  -2.032480239868164,\n  -1.960478663444519,\n  -1.3949663639068604,\n  -1.3347684144973755,\n  -1.062522053718567,\n  -0.7467535138130188,\n  -0.6223708987236023,\n  -0.5711504220962524,\n  -0.38088560104370117,\n  -0.040949393063783646,\n  0.06922974437475204,\n  0.1531311571598053,\n  0.19924433529376984,\n  0.37974801659584045,\n  0.4809354245662689,\n  0.5084185004234314,\n  0.5198034644126892,\n  0.5335159301757812,\n  0.8561704754829407,\n  0.9181739091873169,\n  0.930851399898529,\n  1.1435775756835938,\n  1.298093557357788,\n  1.2995350360870361,\n  1.3147016763687134,\n  1.3199806213378906,\n  1.3413360118865967,\n  1.547560214996338,\n  1.6097909212112427,\n  1.6838574409484863,\n  1.727374792098999,\n  1.7847793102264404,\n  1.832042932510376,\n  1.8669683933258057,\n  1.989498257637024,\n  2.1719419956207275,\n  2.1897497177124023,\n  2.3286306858062744,\n  2.6782939434051514,\n  2.689588785171509,\n  2.895491600036621,\n  2.9858508110046387,\n  3.0264227390289307,\n  3.0452396869659424,\n  3.4789464473724365,\n  3.4831509590148926,\n  3.6845510005950928,\n  3.710113286972046,\n  3.8072009086608887,\n  4.017409324645996,\n  4.100207805633545,\n  4.604258060455322,\n  4.65928840637207,\n  4.793333530426025,\n  4.88817024230957,\n  5.0170745849609375,\n  5.017205238342285,\n  5.039092063903809,\n  5.09958553314209,\n  5.254656791687012,\n  5.287718772888184,\n  5.561609268188477,\n  5.694962978363037,\n  5.902006149291992,\n  6.152457237243652,\n  6.358827590942383,\n  6.378695011138916,\n  6.414209842681885,\n  6.588951110839844,\n  6.595738887786865,\n  6.718328952789307,\n  6.849728107452393,\n  6.890865325927734,\n  7.054056644439697,\n  7.35875129699707,\n  7.80698299407959,\n  7.843350887298584,\n  8.159497261047363,\n  8.447100639343262,\n  8.461872100830078,\n  8.62516975402832,\n  9.169004440307617,\n  10.795876502990723,\n  11.444284439086914,\n  12.044148445129395,\n  12.89748477935791,\n  12.897700309753418,\n  13.129364013671875],\n [-7.556859493255615,\n  -7.074634075164795,\n  -5.608058452606201,\n  -4.107281684875488,\n  -3.5254576206207275,\n  -3.4625296592712402,\n  -3.4118356704711914,\n  -3.3820767402648926,\n  -3.0955095291137695,\n  -2.8370375633239746,\n  -2.364603042602539,\n  -2.038133382797241,\n  -2.0227646827697754,\n  -1.9508267641067505,\n  -1.3858133554458618,\n  -1.325668454170227,\n  -1.0536623001098633,\n  -0.7381722927093506,\n  -0.6138994693756104,\n  -0.5627241134643555,\n  -0.3726271688938141,\n  -0.03299083933234215,\n  0.07709110528230667,\n  0.1609184890985489,\n  0.20699100196361542,\n  0.3873354494571686,\n  0.4884335994720459,\n  0.5158924460411072,\n  0.527267336845398,\n  0.5409677028656006,\n  0.8633376359939575,\n  0.9252863526344299,\n  0.9379526376724243,\n  1.1504912376403809,\n  1.304870843887329,\n  1.306311011314392,\n  1.3214643001556396,\n  1.326738715171814,\n  1.3480751514434814,\n  1.5541175603866577,\n  1.61629319190979,\n  1.6902943849563599,\n  1.7337733507156372,\n  1.7911272048950195,\n  1.8383492231369019,\n  1.873243808746338,\n  1.9956656694412231,\n  2.177948236465454,\n  2.1957404613494873,\n  2.334498882293701,\n  2.6838538646698,\n  2.695138692855835,\n  2.9008595943450928,\n  2.9911391735076904,\n  3.031675338745117,\n  3.050475835800171,\n  3.483799695968628,\n  3.4880008697509766,\n  3.689223051071167,\n  3.7147626876831055,\n  3.81176495552063,\n  4.021787643432617,\n  4.104513168334961,\n  4.608119010925293,\n  4.663100719451904,\n  4.797027587890625,\n  4.891780853271484,\n  5.020571231842041,\n  5.0207014083862305,\n  5.042569160461426,\n  5.103009223937988,\n  5.257943630218506,\n  5.290976524353027,\n  5.564625263214111,\n  5.697861671447754,\n  5.904722213745117,\n  6.154952049255371,\n  6.361140727996826,\n  6.380990505218506,\n  6.416473865509033,\n  6.591060638427734,\n  6.597842693328857,\n  6.720324516296387,\n  6.8516082763671875,\n  6.892708778381348,\n  7.055756568908691,\n  7.360182285308838,\n  7.808018207550049,\n  7.844354152679443,\n  8.160221099853516,\n  8.44757080078125,\n  8.462329864501953,\n  8.625483512878418,\n  9.168838500976562,\n  10.794275283813477,\n  11.442111015319824,\n  12.0414457321167,\n  12.89402961730957,\n  12.894245147705078,\n  13.125704765319824],\n [-7.544992446899414,\n  -7.063112258911133,\n  -5.5975871086120605,\n  -4.0978851318359375,\n  -3.5164780616760254,\n  -3.4535951614379883,\n  -3.402937412261963,\n  -3.373199701309204,\n  -3.0868377685546875,\n  -2.8285508155822754,\n  -2.356454849243164,\n  -2.030219078063965,\n  -2.0148613452911377,\n  -1.9429749250411987,\n  -1.3783661127090454,\n  -1.318264365196228,\n  -1.0464529991149902,\n  -0.7311890125274658,\n  -0.6070051789283752,\n  -0.555866539478302,\n  -0.3659057021141052,\n  -0.026512641459703445,\n  0.08349045366048813,\n  0.16725780069828033,\n  0.2132973074913025,\n  0.3935125768184662,\n  0.4945383071899414,\n  0.5219774842262268,\n  0.5333442687988281,\n  0.5470348000526428,\n  0.8691738247871399,\n  0.9310781359672546,\n  0.9437353610992432,\n  1.1561217308044434,\n  1.310390830039978,\n  1.311829924583435,\n  1.3269723653793335,\n  1.3322429656982422,\n  1.3535641431808472,\n  1.5594589710235596,\n  1.6215901374816895,\n  1.6955382823944092,\n  1.7389861345291138,\n  1.796298861503601,\n  1.843487024307251,\n  1.878356695175171,\n  2.0006906986236572,\n  2.182842969894409,\n  2.200622320175171,\n  2.3392813205718994,\n  2.6883859634399414,\n  2.699662685394287,\n  2.9052364826202393,\n  2.9954514503479004,\n  3.0359585285186768,\n  3.0547454357147217,\n  3.4877591133117676,\n  3.491956949234009,\n  3.693035125732422,\n  3.7185566425323486,\n  3.8154892921447754,\n  4.02536153793335,\n  4.108027458190918,\n  4.611272811889648,\n  4.666214942932129,\n  4.800045967102051,\n  4.894731521606445,\n  5.0234293937683105,\n  5.023560047149658,\n  5.045412063598633,\n  5.105808734893799,\n  5.260632038116455,\n  5.293641567230225,\n  5.567094326019287,\n  5.700234889984131,\n  5.906947612762451,\n  6.156998157501221,\n  6.363039016723633,\n  6.382874488830566,\n  6.418332576751709,\n  6.592794418334961,\n  6.599571228027344,\n  6.721965789794922,\n  6.853155136108398,\n  6.894226551055908,\n  7.057157039642334,\n  7.361364841461182,\n  7.80888032913208,\n  7.845190048217773,\n  8.160831451416016,\n  8.447975158691406,\n  8.462722778320312,\n  8.625760078430176,\n  9.168725967407227,\n  10.792997360229492,\n  11.440369606018066,\n  12.039276123046875,\n  12.89124870300293,\n  12.891464233398438,\n  13.122757911682129]]\n\n\n\nlen(yhat_history)\n\n30\n\n\n\nlen(yhat_history[0]) #0에 100개... [1]에 100개.. \n\n100\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811477661133, 7.861191749572754],\n [-1.649186134338379, 7.101552963256836],\n [-0.9060712456703186, 6.49347448348999],\n [-0.2966785430908203, 6.006272315979004],\n [0.20277434587478638, 5.615575313568115],\n [0.6119105815887451, 5.302003383636475],\n [0.9469034671783447, 5.050129413604736],\n [1.2210699319839478, 4.847657680511475],\n [1.4453645944595337, 4.684779167175293],\n [1.6287915706634521, 4.553659439086914],\n [1.778746247291565, 4.448036193847656],\n [1.90129816532135, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nloss_history\n\n[8587.6875,\n 5675.2109375,\n 3755.637451171875,\n 2489.581787109375,\n 1654.0390625,\n 1102.3206787109375,\n 737.8441162109375,\n 496.96514892578125,\n 337.7142028808594,\n 232.39694213867188,\n 162.72906494140625,\n 116.63263702392578,\n 86.1263656616211,\n 65.93397521972656,\n 52.566444396972656,\n 43.71583557128906,\n 37.855220794677734,\n 33.974090576171875,\n 31.403636932373047,\n 29.701112747192383,\n 28.57339096069336,\n 27.826366424560547,\n 27.331483840942383,\n 27.003639221191406,\n 26.78643798828125,\n 26.642536163330078,\n 26.547197341918945,\n 26.48402976989746,\n 26.442174911499023,\n 26.414440155029297]\n\n\n\nplt.plot(loss_history)\n\n\n\n\n\n\n학습과정을 animation으로 시각화\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n\n# 왼쪽 2d 오른쪽 3d 축만 생긴다\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 <- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fac8c960610>\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n#처음 값!! 오른쪽 그림에서 저 동그라미 회색점이 별표로 가야해~~ 경사하강법생각하자!\n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fac8c7e5710>\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#alpha에-대하여-alpha는-학습률",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#alpha에-대하여-alpha는-학습률",
    "title": "기계학습 (0921) 3주차",
    "section": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)",
    "text": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)\n\n#머신러닝에서 a는 학습률...\n\n\n(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(3) \\(\\alpha=0.0085\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(4) \\(\\alpha=0.01\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#숙제",
    "href": "posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#숙제",
    "title": "기계학습 (0921) 3주차",
    "section": "숙제",
    "text": "숙제\n- 학습률(\\(\\alpha\\))를 조정하며 실습해보고 스크린샷 제출\n\n# α=0.00912\nloss_history = [] \nyhat_history = [] \nWhat_history = [] \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.00912\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html",
    "title": "기계학습 (1005) 5주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n\n준비1 loss_fn을 plot하는 함수\n\ndef plot_loss(loss_fn,ax=None):\n    if ax==None:\n        fig = plt.figure()\n        ax=fig.add_subplot(1,1,1,projection='3d')\n        ax.elev=15;ax.azim=75\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.15),torch.arange(-1,10,0.15),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    ax.scatter(w0hat,w1hat,loss,s=0.1,alpha=0.2) \n    ax.scatter(-1,5,l(-1,5),s=200,marker='*') # 실제로 -1,5에서 최소값을 가지는건 아님.. \n\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\) 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음.\n\n준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    what_history = [] \n\n    for epoc in range(1000): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad() \n\n        ## record \n        if epoc % 20 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            what_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    return yhat_history, loss_history, what_history\n\n\n20에폭마다 yhat, loss, what을 기록\n\n준비3: 애니메이션을 만들어주는 함수\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\ndef show_lrpr2(net,loss_fn,optimizr,suptitle=''):\n    yhat_history,loss_history,what_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7,2.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ax1.set_xticks([]);ax1.set_yticks([])\n    ax2.set_xticks([]);ax2.set_yticks([]);ax2.set_zticks([])\n    ax2.elev = 15; ax2.azim = 75\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,v,'--')\n    ax1.scatter(x,y,alpha=0.05)\n    line, = ax1.plot(x,yhat_history[0],'--') \n    plot_loss(loss_fn,ax2)\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(what_history)[epoc,0],np.array(what_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#logistic-intro-review-alpha",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#logistic-intro-review-alpha",
    "title": "기계학습 (1005) 5주차",
    "section": "Logistic intro (review + \\(\\alpha\\))",
    "text": "Logistic intro (review + \\(\\alpha\\))\n- 모델: \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 <— 외우세요!!!\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) <— 외우세요!!\n\n- toy example\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nnote: \\((w_0,w_1)\\)의 true는 \\((-1,5)\\)이다. -> \\((\\hat{w}_0, \\hat{w}_1)\\)을 적당히 \\((-1,5)\\)근처로 추정하면 된다는 의미\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\n\n\n\n\n- step1: yhat을 만들기\n(방법1)\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)  #x의 shape보면(2000,1)인데 뒤에 1이 중요..\na1 = torch.nn.Sigmoid() \nyhat = a1(l1(x))\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=<SigmoidBackward0>)\n\n\n(방법2)\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid() \nnet = torch.nn.Sequential(l1,a1) #net는 l1과 a1의 합성함수\nyhat = net(x)\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=<SigmoidBackward0>)\n\n\n(방법3)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\nyhat\n\n# 단점: a1과 l1 각 통과하는게 궁금한데 이건 중간과정 보기가힘들다.\n# len(net) = 2 : 2가 나오네.. 우너소에 접근을 해보자\n#net[0], net[1]\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=<SigmoidBackward0>)\n\n\n\nnet[0]\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet[0](x)\n\ntensor([[-0.5003],\n        [-0.5007],\n        [-0.5010],\n        ...,\n        [-1.1930],\n        [-1.1934],\n        [-1.1937]], grad_fn=<AddmmBackward0>)\n\n\n\nnet[1] #a1의 기능\n\nSigmoid()\n\n\n\nnet[1](net[0](x))\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=<SigmoidBackward0>)\n\n\n- step2: loss (일단 MSE로..)\n(방법1)\n\ntorch.mean((y-yhat)**2) #mse는 교수님들이 싫어한데.. 왜? 몰라 일단 걍 해보쟈\n\ntensor(0.2846, grad_fn=<MeanBackward0>)\n\n\n\nloss=torch.mean((y-yhat)**2)\nloss\n\ntensor(0.2846, grad_fn=<MeanBackward0>)\n\n\n(방법2)\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(yhat,y) # yhat을 먼저쓰자!\n\ntensor(0.2846, grad_fn=<MseLossBackward0>)\n\n\n- step3~4는 동일\n- 반복 (준비+for문)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss() #MSELoss로 하면.. .. 별로? BCE이거로바꾸기\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nplt.plot(x,y,'o',alpha=0.01)\n\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() #청소\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱bceloss",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱bceloss",
    "title": "기계학습 (1005) 5주차",
    "section": "로지스틱–BCEloss",
    "text": "로지스틱–BCEloss\n- BCEloss로 바꾸어서 적합하여 보자.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) # loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 왜 잘맞지? -> “linear -> sigmoid” 와 같은 net에 BCEloss를 이용하면 손실함수의 모양이 convex 하기 때문에\n\n#convex:볼록한... convex가 학습하기 좋은!!\n\n\nplot_loss 함수소개 = 이 예제에 한정하여 \\(\\hat{w}_0,\\hat{w}_1,loss(\\hat{w}_0,\\hat{w}_1)\\)를 각각 \\(x,y,z\\) 축에 그려줍니다.\n\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n시각화1: MSE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) #학습률\n\n\nl1,a1 = net #초기값 세팅\nl1.bias.data = torch.tensor([-3.0]) #세팅값\nl1.weight.data = torch.tensor([[-1.0]]) #세팅값\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱adam-국민옵티마이저",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱adam-국민옵티마이저",
    "title": "기계학습 (1005) 5주차",
    "section": "로지스틱–Adam (국민옵티마이저)",
    "text": "로지스틱–Adam (국민옵티마이저)\n\n# Adam은 SGD에 비하여 2가지 면에서 개선점이 있음\n# 1. 어려워서 몰라도 뎀\n# 2. 가속도의 개념\n\n\n시각화1: MSE, 좋은초기값 –> 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05)  ## <-- 여기를 수정!\n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값 –> 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값 –> 이걸 아담으로! (혼자해봐요..)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값 –> 이걸 아담으로! (혼자해봐요..)\n(참고) Adam이 우수한 이유? SGD보다 두 가지 측면에서 개선이 있었음. 1. 그런게 있음.. 2. 가속도의 개념을 적용!!"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망로지스틱-회귀의-한계",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망로지스틱-회귀의-한계",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–로지스틱 회귀의 한계",
    "text": "깊은신경망–로지스틱 회귀의 한계\n\n신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다.\n\n\n가짜데이터\n- 위의 기사를 모티브로 한 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      x\n      underlying\n      y\n    \n  \n  \n    \n      0\n      -1.000000\n      0.000045\n      0.0\n    \n    \n      1\n      -0.998999\n      0.000046\n      0.0\n    \n    \n      2\n      -0.997999\n      0.000047\n      0.0\n    \n    \n      3\n      -0.996998\n      0.000047\n      0.0\n    \n    \n      4\n      -0.995998\n      0.000048\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      0.995998\n      0.505002\n      0.0\n    \n    \n      1996\n      0.996998\n      0.503752\n      0.0\n    \n    \n      1997\n      0.997999\n      0.502501\n      0.0\n    \n    \n      1998\n      0.998999\n      0.501251\n      1.0\n    \n    \n      1999\n      1.000000\n      0.500000\n      1.0\n    \n  \n\n2000 rows × 3 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nplt.plot(df.x,df.y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n\n로지스틱 회귀로 적합\n\n#nn: netral network?의 약자\n\n\nx= torch.tensor(df.x).float().reshape(-1,1)   #float(): 뒤에 거슬리는거 빼주기\ny= torch.tensor(df.y).float().reshape(-1,1)\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat=net(x)\n\n\nloss_fn = torch.nn.BCELoss() \nloss = loss_fn(yhat,y) # loss = -torch.mean((y)*torch.log(yhat)+(1-y)*torch.log(1-yhat))\nloss\n\ntensor(0.9367, grad_fn=<BinaryCrossEntropyBackward0>)\n\n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--') # 학습전\n\n\n\n\n\nfor epoc in range(6000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 이건 epoc=6억번으로 설정해도 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) \\(\\to\\) 모형의 표현력이 너무 낮다.\n\n\n해결책\n- sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다.\n\nsig = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0');ax[0,1].plot(sig(u1),'--o',color='C0')\nax[1,0].plot(u2,'--o',color='C1');ax[1,1].plot(sig(u2),'--o',color='C1')\nax[2,0].plot(u3,'--o',color='C2');ax[2,1].plot(sig(u3),'--o',color='C2')\nax[3,0].plot(u4,'--o',color='C3');ax[3,1].plot(sig(u4),'--o',color='C3')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn을-이용한-해결",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn을-이용한-해결",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–DNN을 이용한 해결",
    "text": "깊은신경망–DNN을 이용한 해결\n- 목표: 아래와 같은 벡터 \\({\\boldsymbol u}\\)를 만들어보자.\n\\({\\boldsymbol u} = [u_1,u_2,\\dots,u_{2000}], \\quad u_i = \\begin{cases} 9x_i +4.5& x_i <0 \\\\ -4.5x_i + 4.5& x_i >0 \\end{cases}\\)\n\n꺽인 그래프를 만드는 방법1\n\nu = [9*xi+4.5 if xi <0 else -4.5*xi+4.5 for xi in x.reshape(-1).tolist()]  #tolist하면 list화 \nplt.plot(u,'--')\n\n\n\n\n\n\n꺽인 그래프를 만드는 방법2\n- 전략: 선형변환 \\(\\to\\) ReLU \\(\\to\\) 선형변환\n(예비학습) ReLU 함수란?\n\\(ReLU(x) = \\max(0,x)\\)\n\nrelu=torch.nn.ReLU()\nplt.plot(x,'--r')\nplt.plot(relu(x),'--b')\n\n\n\n\n\n빨간색: x, 파란색: relu(x)\n\n예비학습끝\n우리 전략 다시 확인: 선형변환1 -> 렐루 -> 선형변환2\n(선형변환1)\n\nplt.plot(x);plt.plot(-x)\n\n\n\n\n(렐루)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.5)\nplt.plot(relu(x),'--',color='C0');plt.plot(relu(-x),'--',color='C1')\n\n#out feature을 2로 잡는당->선을 두개로\n\n\n\n\n(선형변환2)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.2)\nplt.plot(relu(x),'--',color='C0',alpha=0.2);plt.plot(relu(-x),'--',color='C1',alpha=0.2)\nplt.plot(-4.5*relu(x)-9.0*relu(-x)+4.5,'--',color='C2')\n\n#하늘색 점선과 노란색 점섬을 더해보자..\n\n\n\n\n이제 초록색선에 sig를 취하기만 하면?\n\nplt.plot(sig(-4.5*relu(x)-9.0*relu(-x)+4.5),'--',color='C2')\n\n\n\n\n정리하면!\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title('x'); ax1.plot(x,'--',color='C0')\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title('-x'); ax2.plot(-x,'--',color='C1')\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title('relu(x)'); ax3.plot(relu(x),'--',color='C0')\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title('relu(-x)'); ax4.plot(relu(-x),'--',color='C1')\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title('u'); ax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('yhat'); ax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n이런느낌으로 \\(\\hat{\\boldsymbol y}\\)을 만들면 된다.\n\n\n\ntorch.nn.Linear()를 이용한 꺽인 그래프 구현\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=1,out_features=2,bias=True) \na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(in_features=2,out_features=1,bias=True) \na2 = torch.nn.Sigmoid() \n\n\nnet = torch.nn.Sequential(l1,a1,l2,a2) \n\n\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[-0.3467],\n         [-0.8470]], requires_grad=True), Parameter containing:\n tensor([0.3604, 0.9336], requires_grad=True), Parameter containing:\n tensor([[ 0.2880, -0.6282]], requires_grad=True), Parameter containing:\n tensor([0.2304], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0, 0.0])\nl2.weight.data = torch.tensor([[ -4.5, -9.0]])\nl2.bias.data= torch.tensor([4.5])\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[ 1.],\n         [-1.]], requires_grad=True), Parameter containing:\n tensor([0., 0.], requires_grad=True), Parameter containing:\n tensor([[-4.5000, -9.0000]], requires_grad=True), Parameter containing:\n tensor([4.5000], requires_grad=True))\n\n\n\nplt.plot(l1(x).data)\n\n\n\n\n\nplt.plot(a1(l1(x)).data)\n\n\n\n\n\nplt.plot(l2(a1(l1(x))).data,color='C2')\n\n\n\n\n\nplt.plot(a2(l2(a1(l1(x)))).data,color='C2')\n#plt.plot(net(x).data,color='C2')\n\n\n\n\n- 수식표현\n\n\\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n\\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n\\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n\\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\\\ =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n\\(net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\\\=\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}\\)\n\n- 차원만 따지자\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nStep1 ~ Step4\n- 준비\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2), #u1=l1(x), x:(n,1) --> u1:(n,2) \n    torch.nn.ReLU(), # v1=a1(u1), u1:(n,2) --> v1:(n,2) \n    torch.nn.Linear(in_features=2,out_features=1), # u2=l2(v1), v1:(n,2) --> u2:(n,1) \n    torch.nn.Sigmoid() # v2=a2(u2), u2:(n,1) --> v2:(n,1) \n) \n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters()) # lr은 디폴트값으로..\n\n- 반복\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\nplt.title(\"before\")\n\nText(0.5, 1.0, 'before')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 3000 epochs\")\n\nText(0.5, 1.0, 'after 3000 epochs')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 6000 epochs\")\n\nText(0.5, 1.0, 'after 6000 epochs')"
  },
  {
    "objectID": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "href": "posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–DNN으로 해결가능한 다양한 예제",
    "text": "깊은신경망–DNN으로 해결가능한 다양한 예제\n\n예제1\n- 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. \\(\\to\\) 그래서 이 역시 표현력이 부족할 듯 하다. \\(\\to\\) 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex1.csv')\n\n\n# 데이터정리\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n이거 시그모이드 취하기 직전은 step이 포함된 듯 \\(\\to\\) 그래서 꺽은선으로는 표현할 수 없는 구조임 \\(\\to\\) 그런데 사실 대충은 표현가능\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=16), # x:(n,1) --> u1:(n,16) #최대 16번 꺾일 수 있음..\n    torch.nn.ReLU(), # u1:(n,16) --> v1:(n,16)\n    torch.nn.Linear(in_features=16,out_features=1), # v1:(n,16) --> u2:(n,1) \n    torch.nn.Sigmoid() # u2:(n,1) --> v2:(n,1) \n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(6000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b') #실제로는 관츷ㄱ 못하는거\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n예제2\n- 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? \\(\\to\\) 심지어 곡선도 대충 맞게 적합된다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex2.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\nx=torch.tensor(df.x).float().reshape(-1,1)\ny=torch.tensor(df.y).float().reshape(-1,1)\n\n(풀이1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --> u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --> v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --> u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() #mseloss:마지막에 sigmoid형태가 아니니까!\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4) #lw:두겁게\n\n\n\n\n(풀이2) – 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운)\n\ntorch.manual_seed(5)  # seed값을 43052->5로바꿔주기...\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --> u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --> v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --> u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n\n풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? –> 안나옴!! (local min에 빠졌다)\n\n\n\n예제3\n\nimport seaborn as sns\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex3.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      x1\n      x2\n      y\n    \n  \n  \n    \n      0\n      -0.874139\n      0.210035\n      0.0\n    \n    \n      1\n      -1.143622\n      -0.835728\n      1.0\n    \n    \n      2\n      -0.383906\n      -0.027954\n      0.0\n    \n    \n      3\n      2.131652\n      0.748879\n      1.0\n    \n    \n      4\n      2.411805\n      0.925588\n      1.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      -0.002797\n      -0.040410\n      0.0\n    \n    \n      1996\n      -1.003506\n      1.182736\n      0.0\n    \n    \n      1997\n      1.388121\n      0.079317\n      0.0\n    \n    \n      1998\n      0.080463\n      0.816024\n      1.0\n    \n    \n      1999\n      -0.416859\n      0.067907\n      0.0\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)})\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n\n# 데이터준비\nx1 = torch.tensor(df.x1).float().reshape(-1,1) \nx2 = torch.tensor(df.x2).float().reshape(-1,1) \nX = torch.concat([x1,x2],axis=1) \ny = torch.tensor(df.y).float().reshape(-1,1) \n\n\nX.shape\n\ntorch.Size([2000, 2])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=32),#X의 shape이 2니까 in_features=2\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(3000):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ndf2 = df.assign(yhat=yhat.reshape(-1).detach().tolist()) #seaborn을 그리려먼 dataframe형식으로 되어잇어야해\ndf2\n\n\n\n\n\n  \n    \n      \n      x1\n      x2\n      y\n      yhat\n    \n  \n  \n    \n      0\n      -0.874139\n      0.210035\n      0.0\n      0.345833\n    \n    \n      1\n      -1.143622\n      -0.835728\n      1.0\n      0.605130\n    \n    \n      2\n      -0.383906\n      -0.027954\n      0.0\n      0.111915\n    \n    \n      3\n      2.131652\n      0.748879\n      1.0\n      0.918491\n    \n    \n      4\n      2.411805\n      0.925588\n      1.0\n      0.912608\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      -0.002797\n      -0.040410\n      0.0\n      0.254190\n    \n    \n      1996\n      -1.003506\n      1.182736\n      0.0\n      0.508002\n    \n    \n      1997\n      1.388121\n      0.079317\n      0.0\n      0.410099\n    \n    \n      1998\n      0.080463\n      0.816024\n      1.0\n      0.262315\n    \n    \n      1999\n      -0.416859\n      0.067907\n      0.0\n      0.107903\n    \n  \n\n2000 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow')\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n- 결과시각화\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)},ax=ax[0])\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow',ax=ax[1])\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n- 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html",
    "href": "posts/Data Visualization/DV_3(0919).html",
    "title": "DV 3주차(1)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#line-plot",
    "href": "posts/Data Visualization/DV_3(0919).html#line-plot",
    "title": "DV 3주차(1)",
    "section": "Line plot",
    "text": "Line plot\n\n기본플랏\n- 예시\n\nx=[1,2,3,4]\ny=[1,2,4,3]\n\n\nplt.plot(x,y)\n\n\n\n\n\n\n모양변경\n- 예시1\n\nplt.plot(x,y,'--') #점선\n\n\n\n\n- 예시2\n\nplt.plot(x,y,':')\n\n\n\n\n- 예시3\n\nplt.plot(x,y,'-.')\n\n\n\n\n\n\n색상변경\n- 예시1\n\nplt.plot(x,y,'r')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'k') #블랙\n\n\n\n\n\n\n모양 + 색상변경\n- 예시1\n\nplt.plot(x,y,'--r')  # r을 앞에 쓰든 뒤에 쓰든 나온다\n\n\n\n\n\n\n원리?\n- r-- 등의 옵션은 Markers + Line Styles + Colors의 조합으로 표현 가능\nref : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n--r: 점선(dashed)스타일 + 빨간색\nr--: 빨간색 + 점선(dashed)스타일\n:k: 점선(dotted)스타일 + 검은색\nk:: 검은색 + 점선(dotted)스타일\n\n- 우선 Marker를 무시하면 Line Styles + Color로 표현가능한 조합은 4*8 = 32개\n(Line Styles) 모두 4개\n\n\n\ncharacter\ndescription\n\n\n\n\n‘-’\nsolid line style\n\n\n‘–’\ndashed line style\n\n\n‘-.’\ndash-dot line style\n\n\n‘:’\ndotted line style\n\n\n\n(Color) 모두 8개\n\n\n\ncharacter\ncolor\n\n\n\n\n‘b’\nblue\n\n\n‘g’\ngreen\n\n\n‘r’\nred\n\n\n‘c’\ncyan\n\n\n‘m’\nmagenta\n\n\n‘y’\nyellow\n\n\n‘k’\nblack\n\n\n‘w’\nwhite\n\n\n\n- 예시1\n\nplt.plot(x,y,'--m')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'-.c')\n\n\n\n\n- 예시3: line style + color 조합으로 사용하든 color + line style 조합으로 사용하든 상관없음\n\nplt.plot(x,y,'c-.')\n\n\n\n\n- 예시4: line style을 중복으로 사용하거나 color를 중복으로 쓸 수 는 없다.\n\nplt.plot(x,y,'--:')\n\nValueError: Illegal format string \"--:\"; two linestyle symbols\n\n\n\n\n\n\nplt.plot(x,y,'rb')\n\nValueError: Illegal format string \"rb\"; two color symbols\n\n\n\n\n\n- 예시5: 색이 사실 8개만 있는 것은 아니다.\nref: https://matplotlib.org/2.0.2/examples/color/named_colors.html\n\nplt.plot(x,y,'--',color='aqua') # 8가지 색 외의 다른 것은 color= 옵션으로 줘야함\n\n\n\n\n- 예시6: 색을 바꾸려면 Hex코드를 밖아 넣는 방법이 젤 깔끔함\nref: https://htmlcolorcodes.com/\n\nplt.plot(x,y,color='#277E41')   \n\n\n\n\n- 예시7: 라인스타일도 4개만 있지 않다\nref: https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html\n\nplt.plot(x,y,linestyle='dashed')\n\n\n\n\n\nplt.plot(x,y,linestyle=(0, (20, 5)))\n\n\n\n\n\nplt.plot(x,y,linestyle=(0, (20, 1)))"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#scatter-plot",
    "href": "posts/Data Visualization/DV_3(0919).html#scatter-plot",
    "title": "DV 3주차(1)",
    "section": "Scatter plot",
    "text": "Scatter plot\n\n원리\n- 그냥 마커를 설정하면 끝\nref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n\n\ncharacter\ndescription\n\n\n\n\n‘.’\npoint marker\n\n\n‘,’\npixel marker\n\n\n‘o’\ncircle marker\n\n\n‘v’\ntriangle_down marker\n\n\n‘^’\ntriangle_up marker\n\n\n‘<’\ntriangle_left marker\n\n\n‘>’\ntriangle_right marker\n\n\n‘1’\ntri_down marker\n\n\n‘2’\ntri_up marker\n\n\n‘3’\ntri_left marker\n\n\n‘4’\ntri_right marker\n\n\n‘8’\noctagon marker\n\n\n‘s’\nsquare marker\n\n\n‘p’\npentagon marker\n\n\n‘P’\nplus (filled) marker\n\n\n’*’\nstar marker\n\n\n‘h’\nhexagon1 marker\n\n\n‘H’\nhexagon2 marker\n\n\n‘+’\nplus marker\n\n\n‘x’\nx marker\n\n\n‘X’\nx (filled) marker\n\n\n‘D’\ndiamond marker\n\n\n‘d’\nthin_diamond marker\n\n\n‘|’\nvline marker\n\n\n’_’\nhline marker\n\n\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n기본플랏\n\nplt.plot(x,y,'.')\n\n\n\n\n\nplt.plot(x,y,'x')\n\n\n\n\n\n\n색깔변경\n\nplt.plot(x,y,'or')\n\n\n\n\n\nplt.plot(x,y,'db')\n\n\n\n\n\nplt.plot(x,y,'bx')"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#dot-connected-plot",
    "href": "posts/Data Visualization/DV_3(0919).html#dot-connected-plot",
    "title": "DV 3주차(1)",
    "section": "dot-connected plot",
    "text": "dot-connected plot\n- 예시1: 마커와 라인스타일을 동시에 사용하면 dot-connected plot이 된다.\n\nplt.plot(x,y,'o-')\n\n\n\n\n- 예시2: 당연히 색도 적용가능\n\nplt.plot(x,y,'o--r')\n\n\n\n\n- 예시3: 서로 순서를 바꿔도 상관없다.\n\nplt.plot(x,y,'r--o')\n\n\n\n\n\nplt.plot(x,y,'ro--')"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#여러-그림-그리기",
    "href": "posts/Data Visualization/DV_3(0919).html#여러-그림-그리기",
    "title": "DV 3주차(1)",
    "section": "여러 그림 그리기",
    "text": "여러 그림 그리기\n\n겹쳐그리기\n- 예시1\n\nx = np.arange(-5,5,0.1)\nϵ = np.random.randn(100)\ny = 2*x + ϵ\n\n\nplt.plot(x,y,'.b')\nplt.plot(x,2*x,'r')\n\n\n\n\n\n\n따로그리기(subplot) // 외우기\n- 예시1\n\nfig, axs = plt.subplots(2)\naxs[0].plot(x,y,'.b')\naxs[1].plot(x,2*x,'r')\n\n\n\n\n- 예시2\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot(x,2*x,'--b')\naxs[0,1].plot(x,ϵ,'.r')\naxs[1,0].plot(x,y,'.r')\naxs[1,1].plot(x,y,'.r')\naxs[1,1].plot(x,2*x,'-b')"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#fig와-axes의-이해-matplotlib으로-어렵게-그림을-기리는-방법",
    "href": "posts/Data Visualization/DV_3(0919).html#fig와-axes의-이해-matplotlib으로-어렵게-그림을-기리는-방법",
    "title": "DV 3주차(1)",
    "section": "fig와 axes의 이해: matplotlib으로 어렵게 그림을 기리는 방법",
    "text": "fig와 axes의 이해: matplotlib으로 어렵게 그림을 기리는 방법\n\n예제1\n- 목표: plt.plot()을 이용하지 않고 아래의 그림을 그려보자.\n\nplt.plot([1,2,3,4],[1,2,4,3],'or--')\n\n\n\n\n- 구조: axis \\(\\subset\\) axes \\(\\subset\\) figure\nref: https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py\n\n- 전략: Fig을 만들고 (도화지를 준비) \\(\\to\\) axes를 만들고 (네모틀) \\(\\to\\) axes에 그림을 그린다.\n- 그림객체를 생성한다.\n\nfig = plt.figure()\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig # 지금은 아무것도 없다\n\n<Figure size 432x288 with 0 Axes>\n\n\n- 그림객체에는 여러 인스턴스+함수가 있는데 그중에서 axes도 있다. (그런데 그 와중에 plot method는 없다.)\n\nfig.axes   # 비어있는 리스트\n\n[]\n\n\n- axes추가\n\nfig.add_axes([0,0,1,1])  # (0,0) 위치에 (1,1)인 액시즈(=네모틀)을 만들어라.\n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig  # 아까는 아무것도 없었는데 지금 도화지안에 네모틀이 들어가 있다.\n\n\n\n\n- 첫번째 액시즈를 ax1으로 받음 (원래 axes1이어야하는데 그냥 편의상)\n\nax1 = fig.axes[0]\n\n\nid(fig.axes[0]), id(ax1)\n\n(140307253185296, 140307253185296)\n\n\n- 잠깐만! (fig오브젝트와 ax1 오브젝트는 포함관계에 있다.)\n\nid(fig.axes[0]), id(ax1)\n\n(140307253185296, 140307253185296)\n\n\n- 또 잠깐만! (fig오브젝트에는 plot이 없지만 ax1에서는 plot가 있다.)\n\nset(dir(fig)) & {'plot'}\n\nset()\n\n\n\nset(dir(ax1)) & {'plot'}\n\n{'plot'}\n\n\n- ax1.plot()을 사용하여 그림을 그려보자.\n\nax1.plot([1,2,3,4],[1,2,4,3],'--or') # 안되누?\n\n\nfig\n\n\n\n\n\n\n예제2: 예제1의 응용\n- 위에서 축을 하나 더 추가\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig.add_axes([1,1,1,1,])  # (1,1) 위치에 (1,1)크기의 액자틀 추가\n\n<Axes:>\n\n\n\nfig.axes  #추가해서 두개\n\n[<Axes:>, <Axes:>]\n\n\n\nfig\n\n\n\n\n\nax1, ax2 = fig.axes\n\n- ax2에 파란선으로 그림을 그리자\n\nax2.plot([1,2,3,4],[1,2,4,3],'--ob')\n\n\nfig\n\n\n\n\n\n\n예제3: 응용(미니맵)\n- 위의 상황에서 액시지를 하나 더 추가\n\nfig.add_axes([0.65,0.1,0.3,0.3])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nfig.axes[-1].plot([1,2,3,4],[1,2,4,3],'xr')\n\n\nfig\n\n\n\n\n\n\n예제4: 재해석1\n(ver1)\n\nplt.plot([1,2,3,4],[1,2,4,3])\n\n\n\n\n(ver2)\nver1은 사실 아래가 연속적으로 실행된 축약구문임\nfig = plt.figure() \nfig.add_axes([?,?,?,?])\nax1 = fig.axes[0]\nax1.plot([1,2,3,4],[1,2,4,3])\nfig\n\n\n예제5: 재해석2\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot([1,2,3,4],[1,2,4,3],'.')\naxs[0,1].plot([1,2,3,4],[1,2,4,3],'--r')\naxs[1,0].plot([1,2,3,4],[1,2,4,3],'o--')\naxs[1,1].plot([1,2,3,4],[1,2,4,3],'o--',color='lime')\n\n\n\n\n- fig, axs = plt.subplots(2,2)의 축약버전을 이해하면된다.\n(ver1)\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n(ver2)\nver1은 사실 아래가 연속적으로 실행된 축약구문임\nfig = plt.figure()\nfig.add_axes([?,?,?,?]) \nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nax1,ax2,ax3,ax4 = fig.axes\naxs = np.array(((ax1,ax2),(ax3,ax4)))\n(ver3)\nver1은 아래와 같이 표현할 수도 있다.\n\nfig = plt.figure()\naxs = fig.subplots(2,2)"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0919).html#숙제",
    "href": "posts/Data Visualization/DV_3(0919).html#숙제",
    "title": "DV 3주차(1)",
    "section": "숙제",
    "text": "숙제\n\n숙제1\n\nfig, axs = plt.subplots(2,3)\naxs[0,0].plot([1,2,3,4],[1,2,4,3],'or')\naxs[0,1].plot([1,2,3,4],[1,2,4,3],'og')\naxs[0,2].plot([1,2,3,4],[1,2,4,3],'ob')\naxs[1,0].plot([1,2,3,4],[1,2,4,3],'or--')\naxs[1,1].plot([1,2,3,4],[1,2,4,3],'og--')\naxs[1,2].plot([1,2,3,4],[1,2,4,3],'ob--')\n\n\n\n\n\n\n숙제2\n\nx,y = [1,2,3,4], [1,2,1,1]\n\n\nfig = plt.figure()\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig.axes\n\n[]\n\n\n\nfig.add_axes([0,0,1,1]) \n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig\n\n\n\n\n\nax1 = fig.axes[0]\n\n\nax1.plot(x,y,'or')\n\n\nfig\n\n\n\n\n\nfig.add_axes([0.5,0.5,1,1,])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nfig.add_axes([1,1,1,1,])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nax1, ax2, ax3 = fig.axes\n\n\nax2.plot(x,y,'og')\nax3.plot(x,y,'ob')\n\n\nfig\n\n\n\n\n\n\n숙제3\n\nx = np.arange(-5,5,0.1)\ny1 = np.sin(x)\ny2 = np.sin(2*x) + 2\ny3 = np.sin(4*x) + 4 \ny4 = np.sin(8*x) + 6\n\n\nplt.plot(x, y1, '--r')\nplt.plot(x, y2, '--b')\nplt.plot(x, y3, '--g')\nplt.plot(x, y4, '--m')"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html",
    "href": "posts/Data Visualization/DV_5(1006).html",
    "title": "DV 5주차(2)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#애드워드-터프티",
    "href": "posts/Data Visualization/DV_5(1006).html#애드워드-터프티",
    "title": "DV 5주차(2)",
    "section": "애드워드 터프티",
    "text": "애드워드 터프티\n- 데이터 시각화계의 거장\n- 터프티의 이론중 백미: 엄격한 미니멀리즘\n\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다.\n\n- 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량\n- 차트정크 (나이젤홈즈의 그래프)\n\n\n“Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (…) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (…) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.”\n\n\n차트정크 = 대중을 멸시 + 데이터에 대한 모독\n차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다..\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 제 생각: 글쎄…"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#찰스미나드의-도표",
    "href": "posts/Data Visualization/DV_5(1006).html#찰스미나드의-도표",
    "title": "DV 5주차(2)",
    "section": "찰스미나드의 도표",
    "text": "찰스미나드의 도표\n\n인류역사상 가장 훌륭한 시각화\n\n\n- 터프티의 평\n\n지금까지 그려진 최고의 통계 그래픽일지도 모른다.\n여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 \\(\\to\\) 6차원의 변수\n백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. \\(\\to\\) 미니멀리즘..\n\n- 왜 우수한 그래프일까?\n\n자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존\n이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임\n미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#미나드처럼-그리는게-왜-어려운가",
    "href": "posts/Data Visualization/DV_5(1006).html#미나드처럼-그리는게-왜-어려운가",
    "title": "DV 5주차(2)",
    "section": "미나드처럼 그리는게 왜 어려운가?",
    "text": "미나드처럼 그리는게 왜 어려운가?\n- 몸무게, 키, 성별, 국적\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')  \ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv') \ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv')\n\n- 미나드의 접근방법\n\n_df = pd.concat([pd.concat([df1,df2],axis=1).assign(g='m'),df3.assign(g='f')]) # df1과 df2는 옆으로 붙여야 하므로 axis=0, df3와 구분을 주기위한 g추가\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')]).reset_index(drop=True) # 인덱스를 0~부터 다시 정리해논거\ndf\n\n\n\n\n\n  \n    \n      \n      w\n      h\n      g\n      g2\n    \n  \n  \n    \n      0\n      72.788217\n      183.486773\n      m\n      korea\n    \n    \n      1\n      66.606430\n      173.599877\n      m\n      korea\n    \n    \n      2\n      69.806324\n      173.237903\n      m\n      korea\n    \n    \n      3\n      67.449439\n      173.223805\n      m\n      korea\n    \n    \n      4\n      70.463183\n      174.931946\n      m\n      korea\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1525\n      78.154632\n      188.324350\n      m\n      foreign\n    \n    \n      1526\n      74.754308\n      183.017979\n      f\n      foreign\n    \n    \n      1527\n      91.196208\n      190.100456\n      m\n      foreign\n    \n    \n      1528\n      87.770394\n      187.987255\n      m\n      foreign\n    \n    \n      1529\n      88.021995\n      193.456798\n      m\n      foreign\n    \n  \n\n1530 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df,x='w',y='h',hue='g',style='g2')\n\n# 4차원 그림, style을 통해 외국인 구분하기\n\n<AxesSubplot:xlabel='w', ylabel='h'>\n\n\n\n\n\n- 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름\n\n\n기획력부족 -> 훌륭한 시각화를 많이 볼 것\n\n\n데이터프레임에 대한 이해부족 -> tidydata에 대한 개념\n\n\n프로그래밍 능력 -> 코딩공부열심히 (pandas를 엄청 잘해야함)"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#방법1-rpy2-코랩-아닌경우-실습금지",
    "href": "posts/Data Visualization/DV_5(1006).html#방법1-rpy2-코랩-아닌경우-실습금지",
    "title": "DV 5주차(2)",
    "section": "방법1: rpy2 (코랩 아닌경우 실습금지)",
    "text": "방법1: rpy2 (코랩 아닌경우 실습금지)\n\nimport rpy2\n%load_ext rpy2.ipython\n\n\n%%R \n### 여기는 R처럼 쓸 수 있다. \na <- c(1,2,3) \na+1\n\n[1] 2 3 4\n\n\n\na\n\nNameError: name 'a' is not defined\n\n\n\nR과 파이썬은 독립적이므로 R을 나가서 a를 입력하면 아무것도 안나옴\n\n\n%%R \nlibrary(tidyverse)\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nmpg\n\nNameError: name 'mpg' is not defined\n\n\n\n%R -o mpg # R에 있는 자료가 파이썬으로 넘어옴\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      5\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      234\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "href": "posts/Data Visualization/DV_5(1006).html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "title": "DV 5주차(2)",
    "section": "방법2: 저장된 csv파일을 통하여 데이터를 확보",
    "text": "방법2: 저장된 csv파일을 통하여 데이터를 확보\n\nmpg.to_csv(\"mpg.csv\",index=False)\n\n\npd.read_csv(\"mpg.csv\")\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#방법3-github등에-공개된-csv를-읽어오기",
    "href": "posts/Data Visualization/DV_5(1006).html#방법3-github등에-공개된-csv를-읽어오기",
    "title": "DV 5주차(2)",
    "section": "방법3: github등에 공개된 csv를 읽어오기",
    "text": "방법3: github등에 공개된 csv를 읽어오기\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\n- 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#data-설명",
    "href": "posts/Data Visualization/DV_5(1006).html#data-설명",
    "title": "DV 5주차(2)",
    "section": "data 설명",
    "text": "data 설명\n- displ: 자동차의 엔진크기\n- hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐?\n- 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#python에서-plotnine을-이용한-산점도",
    "href": "posts/Data Visualization/DV_5(1006).html#python에서-plotnine을-이용한-산점도",
    "title": "DV 5주차(2)",
    "section": "python에서: plotnine을 이용한 산점도",
    "text": "python에서: plotnine을 이용한 산점도\n\nggplot(data=mpg) + geom_point(aes(x='displ', y='hyw')) \n\n\nggplot(data=mpg) + geom_point(mapping=aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726736046009)>\n\n\n\n산점도 해석: 엔진크기가 클수록 효율이 낮음.\n\n- 빠르게 그리기: data=와 mapping=은 생략가능함\n\nggplot(mpg) + geom_point(aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726735544581)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#r에서-ggplot2를-이용한-산점도",
    "href": "posts/Data Visualization/DV_5(1006).html#r에서-ggplot2를-이용한-산점도",
    "title": "DV 5주차(2)",
    "section": "R에서: ggplot2를 이용한 산점도",
    "text": "R에서: ggplot2를 이용한 산점도\n- R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!)\n\nw 800은 그림의 폭 조정\n\n\n%%R -w 800\nggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "href": "posts/Data Visualization/DV_5(1006).html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "title": "DV 5주차(2)",
    "section": "python에서: 객체지향적인 느낌으로 산점도 그리기",
    "text": "python에서: 객체지향적인 느낌으로 산점도 그리기\nstep1: 도화지를 준비한다.\n\nfig = ggplot(data=mpg)\nfig\n\n\n\n\n<ggplot: (8726735085529)>\n\n\nstep2 변수와 에스테틱사이의 맵핑을 설정한다.\n\na1= aes(x='displ',y='hwy')\na1\n\n{'x': 'displ', 'y': 'hwy'}\n\n\nstep3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다.\n\npoint1=geom_point(mapping=a1)\n\n\ngeom_point(): 점들을 그려! 어떻게?\na1에서 설정된 표를 보고\n\nstep4 도화지와 지옴을 합친다.\n\nfig+point1\n\n\n\n\n<ggplot: (8726775447877)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경",
    "text": "산점도 + 점크기변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734563561)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-투명도변경",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-투명도변경",
    "title": "DV 5주차(2)",
    "section": "산점도 + 투명도변경",
    "text": "산점도 + 투명도변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734989121)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-투명도점크기를-동시에-적용",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-투명도점크기를-동시에-적용",
    "title": "DV 5주차(2)",
    "section": "산점도 + 투명도/점크기를 동시에 적용",
    "text": "산점도 + 투명도/점크기를 동시에 적용\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734522405)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-형태",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-형태",
    "title": "DV 5주차(2)",
    "section": "산점도 + 형태",
    "text": "산점도 + 형태\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',shape='class'))\n\n\n\n\n<ggplot: (8726734265229)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-색깔",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-색깔",
    "title": "DV 5주차(2)",
    "section": "산점도 + 색깔",
    "text": "산점도 + 색깔\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',color='class'))\n\n\n\n\n<ggplot: (8726734017473)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#객체지향적-느낌으로",
    "href": "posts/Data Visualization/DV_5(1006).html#객체지향적-느낌으로",
    "title": "DV 5주차(2)",
    "section": "객체지향적 느낌으로?",
    "text": "객체지향적 느낌으로?\n\na2 = aes(x='displ', y='hwy', color='class') \n\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\npoint2=geom_point(a2)\n\n\nfig+point2\n\n\n\n\n<ggplot: (8726733712885)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-색깔-적합선",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-색깔-적합선",
    "title": "DV 5주차(2)",
    "section": "산점도 + 색깔 + 적합선",
    "text": "산점도 + 색깔 + 적합선\n- 일단 색깔이 없는 포인트 지옴부터 연습\n\nfig+point1\n\n\n\n\n<ggplot: (8726733452617)>\n\n\n\nline1 = geom_smooth(a1)\n\n\nfig+point1+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732994973)>\n\n\n- point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능!\n\nfig+point2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732661565)>\n\n\n- 명령어로 한번에 그리기\n\n줄 넘어 가는 연산자 표현 : \\\n\n\nggplot(data=mpg) + \\\ngeom_point(mapping=aes(x='displ',y='hwy',color='class')) + \\\ngeom_smooth(mapping=aes(x='displ',y='hwy'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732727485)>\n\n\n- 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함)\n\nggplot(data=mpg,mapping=aes(x='displ',y='hwy')) + \\\ngeom_point(mapping=aes(color='class')) + \\\ngeom_smooth()\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733489953)>\n\n\n- R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다.\n\n%%R -w 800\nggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth()\n\nR[write to console]: `geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔",
    "text": "산점도 + 점크기변경 + 색깔\n- drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다.\n\nggplot(data=mpg, mapping=aes(x='displ',y='hwy')) + geom_point(mapping=aes(size='class',color='drv'),alpha=0.3)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731152845)>\n\n\n\n모든 \\(x\\)에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 \\(\\to\\) 4륜구동방식이 연비가 좋지 않음"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-객체지향버전",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-객체지향버전",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 (객체지향버전)",
    "text": "산점도 + 점크기변경 + 색깔 (객체지향버전)\n- 맵핑규칙\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\na3 = a2.copy() \n\n\na3['color'] = 'drv'\na3['size'] = 'class'\na3\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'}\n\n\n\n아래와 같이 선언해도 괜찮음\n\na3= aes(x='displ',y='hwy',color='drv',size='class')\n\npoint3=geom_point(a3)\n\n\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731065581)>\n\n\n\n그림의 전체적인 투명도를 조절하면 좋겠음\n\n\npoint3=geom_point(a3,alpha=0.2)\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726730819657)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-선추가",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-선추가",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 + 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + 선추가\n\nfig+point3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726730575253)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-drv별로-선추가",
    "href": "posts/Data Visualization/DV_5(1006).html#산점도-점크기변경-색깔-drv별로-선추가",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 + drv별로 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + drv별로 선추가\n- 맵핑규칙\n\na1,a2,a3\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'})\n\n\n\na4 = a2.copy() \na4['color']='drv'\na4\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv'}\n\n\n\nline2 = geom_smooth(a4)\n\n\nfig + point3 +line2\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726729919385)>\n\n\n- 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면?\n\na1,a2,a3,a4\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv'})\n\n\n\na5=a1.copy()\na5['linetype']='drv' \na5\n\n{'x': 'displ', 'y': 'hwy', 'linetype': 'drv'}\n\n\n\nline3 = geom_smooth(a5,size=0.5,color='gray')\n\n\nfig+point3+line3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732637457)>\n\n\n- 전체적인 추세선도 추가하고 싶다면?\n\nfig+point3+line3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732939513)>\n\n\n- 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음.\n\nline2 = geom_smooth(a4,size=0.5,linetype='dashed')\nfig+point3+line2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733678229)>\n\n\n- 고차원을 변수를 표현할 수 있는 무기는 다양하다.\n\n산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도\n라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기"
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html",
    "href": "posts/Data Visualization/DV_09(1102).html",
    "title": "DV 9주차",
    "section": "",
    "text": "Cairo, A. Functional Art, The: An Introduction to Information Graphics and Visualization, New Riders, 2012. San Francisco, US."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#presentation",
    "href": "posts/Data Visualization/DV_09(1102).html#presentation",
    "title": "DV 9주차",
    "section": "Presentation",
    "text": "Presentation\n\n- 프리젠테이션방식의 시각화는 화자가 다듬은 이야기를 전달하기에 좋은 시각화이다. 즉 잘 정리된 메시지를 전달하기에 좋다."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#exploration",
    "href": "posts/Data Visualization/DV_09(1102).html#exploration",
    "title": "DV 9주차",
    "section": "Exploration",
    "text": "Exploration\n\n\n문학적유기체라는 작품이다.(https://www.stefanieposavec.com/).\n어떤 소설책을 시각화.\n수형도 + 칼라\n수형도의 의미: 단원, 문단, 문장, 단어 (수형도 계층적 구조를 시각화 하기에 뛰어남. ex: 리그레션트리!)\n색깔: 여행, 음악, 파티 등 소설에서 자주 등장하는 소재 (색은 범주형 변수를 표현하기에 뛰어남)\n\n- 익스플로래이션 방식은 독자가 스스로 그림에서 메시지를 찾아낸다.\n- 소설을 읽어보지 않은 사람: 이 그래픽으로 소설책의 전체 주제를 미리 파악가능\n- 소설을 이미 읽어본 사람: 분석 & 탐구를 할 수 있음. ex: 파티와 음악이 동시에 등장하는 경우가 많다."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#절충",
    "href": "posts/Data Visualization/DV_09(1102).html#절충",
    "title": "DV 9주차",
    "section": "절충",
    "text": "절충\n- 카이로: 사실 프리젠테이션과 익스플로레이션은 절충가능함\n\n\naes(x=‘GDP’,y=‘불평등’,text=‘년도’,color=‘정부’)\n초록색정부: 소득이 증가 & 불평등이 훨씬 더 증가\n갈색정부: 매우 빠른 경제 성장\n포인트간의 간격이 조밀하다 = 변화가 더디다 // 포인트간의 간격이 넓다 = 변화가 빠르다.\n\n- 언뜻보기에는 우리에게 익숙한 라인플랏인듯 보이지만 의외로 정보를 해석할만한 요소가 있다.\n\n익스플로레이션형의 그래프는 그릴줄도 알아야 하지만 남이 그린 그래프를 해석할 수도 있어야함."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#인구문제에-대한-편견",
    "href": "posts/Data Visualization/DV_09(1102).html#인구문제에-대한-편견",
    "title": "DV 9주차",
    "section": "인구문제에 대한 편견",
    "text": "인구문제에 대한 편견\n- 주장1 (맬서스주의자): 가난한 나라들의 출산율이 너무 높음 \\(\\to\\) 세계인구가 90억까지 증가할 것이다. (현재 70억)\n- 주장2: 잘사는 나라에서는 애를 적게 낳음 \\(\\to\\) 고령화 문제"
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#에서-제기된-리들리의-메시지",
    "href": "posts/Data Visualization/DV_09(1102).html#에서-제기된-리들리의-메시지",
    "title": "DV 9주차",
    "section": "<이성적 낙관주의자>에서 제기된 리들리의 메시지",
    "text": "<이성적 낙관주의자>에서 제기된 리들리의 메시지\n- 둘다 틀렸다.\n- 주장1의 반박: 가난한 나라의 출산율은 점점 감소하고 있음. (특히 가난하다가 막 부유해진 나라는 이러한 감소폭이 드라마틱함, ex: 브라질)\n- 주장2의 반박: 평균적으로 잘사는 국가들의 출산률이 매우 낮은것은 사실이나 최근들어 약간 증가하는 경향을 보임. (ex: 스웨덴, 영국, 노르웨이, 스페인)\n- 리들리의 주장: 결국 세계의 인구는 안정화 될 것 (증가하지도 감소하지도 않는다)\n- 리들리의 주장을 뒷받침하기 위해 그린 그림\n\n\n이 그림은 간단명료해 보이지만 리들리의 주장을 뒷받침하기에는 부족하다.\n그림에서 얻을 수 있는 정보: 인구변화를 연도별로 나열했더니 성장속도가 둔화된다는 사실\n리들리가 주장한 다양한 패턴은 이 그림에 보이지 않는다. (출산률이 회복되고 있다는 선진국이라든가, 브라질/인도와 같은 나라의 인구안정화에 대한 주장)\n\n\n카이로\n- 리들러의 메시지는 아래의 그림들이 더 잘 전달한다.\n\n\n스웨덴, 노르웨이 -> 출산률 증가\n브라질, 인도 -> 출산률 대폭감소\n\n\n\n소감\n- 어떠한 통계량 혹은 현상을 살펴볼때 그것의 부분집합들이 역시 그러한지 살펴보는것은 기본임 (그룹별로 파악하면 정반대의 결과가 나올 수 있음)\n- 중요한 선을 제외한 나머지는 회색처리(일러스트레이터 사용) 한 것이 시각적으로 우수하며, 인상적이었음\n- 과학적인 논문작업에 들어갈 그림이라면 임의로 회색처리한 것이 다소 비판을 받을 수 있음."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#사례1-남미국가의-국방력",
    "href": "posts/Data Visualization/DV_09(1102).html#사례1-남미국가의-국방력",
    "title": "DV 9주차",
    "section": "사례1: 남미국가의 국방력",
    "text": "사례1: 남미국가의 국방력\n- 아래는 남미국가들의 국방력을 시각화한 그림\n\n\n쓸모없는 그래픽\n뭐 기억나는 것이 있나요?\n\n- 아래가 더 우수한 그림이다. 더 정확한 비교를 할 수 있어요.\n\n- 그리고 위의 그림보다 아래의 그림이 더 우수한 시각화이다.\n\n\n브라질이 국방력도 우수하고 예산도 많이 투자하는 것 같지만 인구가 흑막인것 같다.\n\n- 흑막을 제거\n\n- 최종적으로 제안하는 그래프\n\n\n좌측하단: aes(x=‘인구’, y=‘군인수’, size=‘예산’)\n우측하단: 관심있는 그래프가 아님\n\n사실 저는 좌측하단의 그래프가 좋은 시각화라고 생각안해요\n- 1사분면의 의미: 인구도 높고 군인수도 많은 나라 (똑같은 정보임 의미가 없다. 마치 x축이 토익점수, y축이 텝스점수 같은느낌임)\n\n모든 점들이 직선에 몰려있다면? \\(\\to\\) 왜 2차원으로 표현함?\n\n- 저같으면 aes(x=‘예산(인구효과제거)’, y=‘군인수(인구효과제거)’,size=‘인구’)로 할것 같아요.\n\n1사분면의 의미: 예산도 많이 쓰고 군인수도 많은나라 = 콜롬비아.\n4사분면의 의미: 예산은 많이 쓰는데 군인수가 적은나라 = 브라질\n\n- 산점도에서 데이터를 한눈에 파악하고 특징을 요약하기 위해서는 X,Y를 너무 비슷한 성질의 변수로 설정하지마라.\n아래중 어떤것이 더 바람직한 그래프인가?\n\naes(x=‘토익’, y=‘텝스’, color=‘합/불’, shape=‘회사의종류’)\naes(x=‘토익’, y=‘GPA’, color=‘합/불’, shape=‘회사의종류’)"
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#사례2-스페인의-실업률",
    "href": "posts/Data Visualization/DV_09(1102).html#사례2-스페인의-실업률",
    "title": "DV 9주차",
    "section": "사례2: 스페인의 실업률",
    "text": "사례2: 스페인의 실업률\n\n\n명암으로 왜 크기비교를 하는것인가?\n\n- 비교를 위해서는 바플랏이 더 우수하다."
  },
  {
    "objectID": "posts/Data Visualization/DV_09(1102).html#사례3-버블의-남용",
    "href": "posts/Data Visualization/DV_09(1102).html#사례3-버블의-남용",
    "title": "DV 9주차",
    "section": "사례3: 버블의 남용",
    "text": "사례3: 버블의 남용\n- 카이로교수님의 강의자료에 등장하는 그림\n- 회색이 befor, 검은색이 after\n\n\n크기비교는 바플랏으로 하는것이 아니다.\n\n- 우리눈은 작은원이 큰원의 절반정도 차지한다고 느껴진다.\n\n- 그렇지만 실제로는 아래와 같음\n\n- 버블차트는 크기를 왜곡시킨다.\n\n- 하지만 아래의 버블차트는 우수하다.\n\n- 선거지도는 수치비교에 별로 관심이 없다.\n- 대신에 민주당표와 공화당표가 어떤 지역에 몰렸는지 파악하는 것이중요\n- 따라서 aes중 가장 중요한 x,y를 모두 지역에 투자함"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html",
    "href": "posts/Data Visualization/DV_07(1019).html",
    "title": "DV 7주차(2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#자료생성",
    "href": "posts/Data Visualization/DV_07(1019).html#자료생성",
    "title": "DV 7주차(2)",
    "section": "자료생성",
    "text": "자료생성\n기상자료개방포털: https://data.kma.go.kr/cmmn/main.do\n\n_df=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/temp.csv')\n_df\n\n\n\n\n\n  \n    \n      \n      지점번호\n      지점명\n      일시\n      평균기온(℃)\n      최고기온(℃)\n      최고기온시각\n      최저기온(℃)\n    \n  \n  \n    \n      0\n      146\n      전주\n      2020-01-01\n      -0.5\n      4.3\n      15:09\n      -6.4\n    \n    \n      1\n      146\n      전주\n      2020-01-02\n      1.4\n      6.5\n      14:12\n      -3.0\n    \n    \n      2\n      146\n      전주\n      2020-01-03\n      2.6\n      7.6\n      13:32\n      -0.5\n    \n    \n      3\n      146\n      전주\n      2020-01-04\n      2.0\n      7.7\n      13:51\n      -2.6\n    \n    \n      4\n      146\n      전주\n      2020-01-05\n      2.5\n      8.6\n      14:05\n      -3.2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      146\n      전주\n      2021-10-13\n      19.9\n      25.5\n      14:29\n      15.6\n    \n    \n      652\n      146\n      전주\n      2021-10-14\n      20.4\n      25.5\n      13:36\n      17.0\n    \n    \n      653\n      146\n      전주\n      2021-10-15\n      18.3\n      22.0\n      13:47\n      15.7\n    \n    \n      654\n      146\n      전주\n      2021-10-16\n      12.8\n      17.4\n      0:01\n      6.5\n    \n    \n      655\n      146\n      전주\n      2021-10-17\n      6.7\n      12.4\n      15:18\n      2.2\n    \n  \n\n656 rows × 7 columns\n\n\n\n- 평균기온만 선택\n\npd.Series(_df.columns)\n\n0       지점번호\n1        지점명\n2         일시\n3    평균기온(℃)\n4    최고기온(℃)\n5     최고기온시각\n6    최저기온(℃)\ndtype: object\n\n\n\ntemp=np.array(_df.iloc[:,3])"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#숨은-진짜-상황1-온도-to-아이스크림-판매량",
    "href": "posts/Data Visualization/DV_07(1019).html#숨은-진짜-상황1-온도-to-아이스크림-판매량",
    "title": "DV 7주차(2)",
    "section": "숨은 진짜 상황1: 온도 \\(\\to\\) 아이스크림 판매량",
    "text": "숨은 진짜 상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자\n아이스크림 판매량 = 20 + 2 x 온도 + ϵ\n\nnp.random.seed(1)\neps = np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2*temp + eps\n\n\nplt.plot(temp, icecream, 'o', alpha=0.2)\nplt.xlabel(\"temp\", size=15)\nplt.ylabel(\"icecream\", size=15)\n\nText(0, 0.5, 'icecream')"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#숨은-진짜-상황2-온도-to-소아마비-반응수치",
    "href": "posts/Data Visualization/DV_07(1019).html#숨은-진짜-상황2-온도-to-소아마비-반응수치",
    "title": "DV 7주차(2)",
    "section": "숨은 진짜 상황2: 온도 \\(\\to\\) 소아마비 반응수치",
    "text": "숨은 진짜 상황2: 온도 \\(\\to\\) 소아마비 반응수치\n- 아래와 같은 관계가 있다고 하자\n소아마비 반응수치 = 30 + 0.5 x 온도 + ϵ\n\nnp.random.seed(2) \neps=np.random.normal(size=len(temp),scale=1)\ndisease= 30 + 0.5 * temp + eps\n\n\nplt.plot(temp, disease, 'o', alpha=0.2)\nplt.xlabel(\"temp\", size=15)\nplt.ylabel(\"disease\", size=15)\n\nText(0, 0.5, 'disease')"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#우리가-관측한-상황-온도는-은닉되어-있음",
    "href": "posts/Data Visualization/DV_07(1019).html#우리가-관측한-상황-온도는-은닉되어-있음",
    "title": "DV 7주차(2)",
    "section": "우리가 관측한 상황 (온도는 은닉되어 있음)",
    "text": "우리가 관측한 상황 (온도는 은닉되어 있음)\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.xlabel(\"icecream\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\ncorr이 높아서 얼핏 생각하면 인과성이 있어보인다.\n\nnp.corrcoef(icecream, disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\ncorr = 0.86"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#직관-여름만-뽑아서-plot해보자",
    "href": "posts/Data Visualization/DV_07(1019).html#직관-여름만-뽑아서-plot해보자",
    "title": "DV 7주차(2)",
    "section": "직관: 여름만 뽑아서 plot해보자",
    "text": "직관: 여름만 뽑아서 plot해보자\n- temp>25 (여름으로 간주) 인 관측치만 plot\n\nplt.plot(icecream[temp>25], disease[temp>25], 'o', alpha=0.2)\n\n\n\n\n상관관계가 없어보인다?\n\nnp.corrcoef(icecream[temp>25], disease[temp>25])\n\narray([[1.        , 0.26612659],\n       [0.26612659, 1.        ]])\n\n\n- 전체적인 산점도\n\nfig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) \nax1.plot(temp,icecream,'o',alpha=0.2); ax1.set_xlabel('temp'); ax1.set_ylabel('icecream'); ax1.set_title(\"hidden1\")\nax2.plot(temp,disease,'o',alpha=0.2); ax2.set_xlabel('temp'); ax2.set_ylabel('disease'); ax2.set_title(\"hidden2\")\nax3.plot(icecream,disease,'o',alpha=0.2); ax3.set_xlabel('icecream'); ax3.set_ylabel('disease'); ax3.set_title(\"observed\")\nax4.plot(icecream,disease,'o',alpha=0.2); ax4.set_xlabel('icecream'); ax4.set_ylabel('disease'); ax4.set_title(\"observed\")\nax4.plot(icecream[temp>25],disease[temp>25],'o',label='temp>25')\nax4.legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#ggplot-온도구간을-세분화-하여-시각화",
    "href": "posts/Data Visualization/DV_07(1019).html#ggplot-온도구간을-세분화-하여-시각화",
    "title": "DV 7주차(2)",
    "section": "ggplot: 온도구간을 세분화 하여 시각화",
    "text": "ggplot: 온도구간을 세분화 하여 시각화\n- 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자.\n\n사실 지금 변수는 온도, 아이스크림판매량, 소아마비\n온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#df로-자료정리",
    "href": "posts/Data Visualization/DV_07(1019).html#df로-자료정리",
    "title": "DV 7주차(2)",
    "section": "df로 자료정리",
    "text": "df로 자료정리\n\ndf=pd.DataFrame({'temp':temp, 'icecream':icecream, 'disease' : disease})\ndf\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n    \n  \n\n656 rows × 3 columns\n\n\n\n\n구간세분화\n온도를 봄 여름 가을 경루.. 확인하기 위해 구간을 확인하자\n\nplt.hist(df.temp)\n\n(array([  3.,   9.,  29.,  60.,  92.,  86.,  65.,  93., 139.,  80.]),\n array([-12.4 ,  -8.16,  -3.92,   0.32,   4.56,   8.8 ,  13.04,  17.28,\n         21.52,  25.76,  30.  ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\ndf.temp.hist() # 위에도 되고 이거도 되고\n\n<AxesSubplot:>\n\n\n\n\n\n- 구간을 5정도로 하면 적당\n\ndef cut(x): #\n    if x<0: \n        y='Temp: <0'\n    elif x<5: \n        y='Temp: 0~5'\n    elif x<10: \n        y='Temp: 5~10'\n    elif x<15: \n        y='Temp: 10~15'\n    elif x<20:\n        y='Temp: 15~20'\n    elif x<25: \n        y='Temp: 20~25'\n    else: \n        y='Temp: >30'\n    return y \n\n\ndf.temp\n\n0      -0.5\n1       1.4\n2       2.6\n3       2.0\n4       2.5\n       ... \n651    19.9\n652    20.4\n653    18.3\n654    12.8\n655     6.7\nName: temp, Length: 656, dtype: float64\n\n\n\ncut(-0.5)\n\n'Temp: <0'\n\n\n\ncut(4)\n\n'Temp: 0~5'\n\n\n\ndf.assign(temp2=list(map(cut,df.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\n\nggplot\n\nfig = ggplot(data=df.assign(temp2=list(map(cut,df.temp))))\np1 = geom_point(aes(x='icecream', y='disease', color='temp2'))\nl1 = geom_smooth(aes(x='icecream', y='disease', color='temp2')) # color별 추체선\nfig+p1+l1\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8764688308729)>\n\n\n\n각 온도별로 추세선 기울기가 거의 0이다. \\(\\to\\) 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 것!\n아이스크림 판매량과 소아마비의 corr은 유의미해 보였지만, 온도를 통제하였을 경우 아이스크림의 판매량과 소아마비 반응수치의 corr은 유의미해보이지 않다.\n\n\n\n해석\n- 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. \\(\\to\\) 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 “온도->아이스크림판매량,소아마비” 이라는 합리적인 진리를 얻을 수 있었다.\n\n온도와 같은 변수를 은닉변수라고 한다.\n\n- 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지?\n\n이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능.\n그런데 이론적으로는 “세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)” 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 “상관성=인과성”이다.\n\n- 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능\n\n피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가)\n인과추론: 실험계획이 사실상 불가능한 경우가 있음 \\(\\to\\) 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 “매칭”을 시킨다!\n\n실험계획법 - 내가 데이터를 모아야함/ 잘 생각해서 계획적으로\n인과추론 - 모인데이터를 활용 / 데이터의 양이 많아야하는 다넘이 있지만 실험은 하지 않아도 된다는 장점"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1019).html#만약-아이스크림과-소아마비가-관련있는-경우라면",
    "href": "posts/Data Visualization/DV_07(1019).html#만약-아이스크림과-소아마비가-관련있는-경우라면",
    "title": "DV 7주차(2)",
    "section": "만약 아이스크림과 소아마비가 관련있는 경우라면?",
    "text": "만약 아이스크림과 소아마비가 관련있는 경우라면?\n- 온도는 아이스크림 판매에 여전히 영향을 주지만\n아이스크림 판매량 = 20 + 2 x 온도 + ϵ\n\nnp.random.seed(1)\neps=np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2 * temp + eps \n\n- 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면?\n소아마비 반응수치 = 30 + 0 x 온도 + 0.15 x 아이스크림판매랑 + ϵ\n\nnp.random.seed(2) \neps = np.random.normal(size=len(temp),scale=2)\ndisease= 30+ 0*temp + 0.15*icecream + eps\n\n\ndf2=pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf2.assign(temp2=list(map(cut,df2.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      34.453002\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      32.389832\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      28.715350\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      35.271089\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      31.461240\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.693811\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.924088\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      41.765212\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.842022\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      37.715537\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\nggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+\\\ngeom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.2)+\\\ngeom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8764688192609)>\n\n\n\ndf.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.975609\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.862990\n    \n    \n      disease\n      0.975609\n      0.862990\n      1.000000\n    \n  \n\n\n\n\n\ndf2.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.725505\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.830539\n    \n    \n      disease\n      0.725505\n      0.830539\n      1.000000\n    \n  \n\n\n\n\n단순 corr을 봐서는 “온도->아이스크림,소아마비” 인지, “온도->아이스크림->소아마비” 인지 알기 어렵다."
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html",
    "href": "posts/Data Visualization/DV_4(0926).html",
    "title": "DV 4주차(1)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#예시자료",
    "href": "posts/Data Visualization/DV_4(0926).html#예시자료",
    "title": "DV 4주차(1)",
    "section": "예시자료",
    "text": "예시자료\n- 예시1\n\nx1 = np.random.uniform(low=0, high=1, size=10000)  # 0~1사이의 10000개\ny1 = np.random.uniform(low=0, high=1, size=10000) \n\n\nplt.plot(x1,y1,',')\nplt.plot(x1[0], y1[0],'or')\n\n\n\n\n- 예시2 (원)\n\n_r2 = x1**2 + y1**2 # 반지름\n_r2\n\narray([0.32841936, 0.65211343, 0.8620744 , ..., 0.99310561, 0.35628571,\n       0.32995271])\n\n\n\nlen(_r2)\n\n10000\n\n\n\nx2=x1[_r2<1]\ny2=y1[_r2<1]\n\n\nplt.plot(x2,y2,',')\n\n\n\n\n- 예시3 (이변량정규분포)\n\nx3 = np.random.randn(10000)\ny3 = np.random.randn(10000)\n\n\nplt.plot(x3,y3,',')"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#상관계수",
    "href": "posts/Data Visualization/DV_4(0926).html#상관계수",
    "title": "DV 4주차(1)",
    "section": "상관계수",
    "text": "상관계수\n예시1, 예시2, 예시3의 산점도를 보고 상관계수가 얼마인지 예상해보라. 실제 계산결과와 확인하라.\n\nnp.corrcoef([x1,y1])\n\narray([[1.        , 0.01268214],\n       [0.01268214, 1.        ]])\n\n\n\nnp.corrcoef([x2,y2])\n\narray([[ 1.        , -0.28666195],\n       [-0.28666195,  1.        ]])\n\n\n\nnp.corrcoef([x3,y3])\n\narray([[1.        , 0.00827362],\n       [0.00827362, 1.        ]])\n\n\n독립을 따져보자.\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(x1,y1,',')\nax[1].plot(x2,y2,',')\n\n\n\n\n\ndef g(intval, data, ax, col = 'r'):\n    a,b = intval\n    x,y = data\n    idx = (a<x) & (x<b)\n    ax.plot(x[idx], y[idx],',',color=col)\n\n\nfig\n\n\n\n\n\ng([-0.1,0.1],[x1,y1],ax[0])\ng([-0.1,0.1],[x2,y2],ax[1])\nfig\n\n\n\n\n\ng([0.79,0.99],[x1,y1],ax[0],col='m')\ng([0.79,0.99],[x2,y2],ax[1],col='m')\nfig\n\n\n\n\n- 예시3\n\nplt.plot(x3,y3,',')\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(x3,y3,',',color='gray')     # g함수 사용하기 위해 이렇게 해보자\n\n\n\n\n\ng([-2.5,-1.5],[x3,y3],ax,col='r')\nfig\n\n\n\n\n\ng([-2.5,-1.5],[x3,y3],ax,col='r')\ng([-0.5,+0.5],[x3,y3],ax,col='b')\ng([+1.5,+2.5],[x3,y3],ax,col='g')\nfig\n\n\n\n\n\nidx = (-0.5<x3) & (x3<0.5)\nplt.hist(y3[idx])  # 위의 파란색을 뽑아보자\n\n(array([   5.,   32.,  188.,  512.,  938., 1054.,  722.,  303.,   79.,\n          16.]),\n array([-3.81904376, -3.09056613, -2.36208849, -1.63361085, -0.90513321,\n        -0.17665557,  0.55182207,  1.28029971,  2.00877735,  2.73725499,\n         3.46573263]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nidx = (-0.5<x3) & (x3<0.5)\nplt.hist(y3[idx]);  # 맨 뒤 세미콜론 붙이면 위의 글씨 안나옴\n\n\n\n\n\ndef h(intval, data, ax, col):\n    a,b = intval\n    x,y = data\n    idx = (a<x) &  (x<b)\n    ax.hist(y[idx], color=col)\n\n\nfig,ax = plt.subplots(5,2,figsize=(8,16))\nax[0,0].plot(x3,y3,',',color='gray'); g([-2.5,-1.5],[x3,y3],ax[0,0],col='r')\nax[1,0].plot(x3,y3,',',color='gray'); g([-1.5,-0.5],[x3,y3],ax[1,0],col='g')\nax[2,0].plot(x3,y3,',',color='gray'); g([-0.5,+0.5],[x3,y3],ax[2,0],col='b')\nax[3,0].plot(x3,y3,',',color='gray'); g([+0.5,+1.5],[x3,y3],ax[3,0],col='m')\nax[4,0].plot(x3,y3,',',color='gray'); g([+1.5,+2.5],[x3,y3],ax[4,0],col='lime')\n\nh([-2.5,-1.5],[x3,y3],ax[0,1],col='r')\nh([-1.5,-0.5],[x3,y3],ax[1,1],col='g')\nh([-0.5,+0.5],[x3,y3],ax[2,1],col='b')\nh([+0.5,+1.5],[x3,y3],ax[3,1],col='m')\nh([+1.5,+2.5],[x3,y3],ax[4,1],col='lime')"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#그림만-보고-싶을때",
    "href": "posts/Data Visualization/DV_4(0926).html#그림만-보고-싶을때",
    "title": "DV 4주차(1)",
    "section": "그림만 보고 싶을때",
    "text": "그림만 보고 싶을때\n\nplt.plot([0,1,2,3],[2,3,4,1])\n\n\n\n\n\nplt.plot([2,3,4,1])    # [0,1,2,3] 이 기본 default 값이므로 생략 가능\n\n\n\n\n\nplt.plot([2,3,4,1]);   # 그림 위에 올라가는거 없어짐"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#marker-size-line-width",
    "href": "posts/Data Visualization/DV_4(0926).html#marker-size-line-width",
    "title": "DV 4주차(1)",
    "section": "marker size, line width",
    "text": "marker size, line width\n\nplt.plot([2,3,4,1],'o',markersize=13)   # markersize = ms 라고 써도 됨\n\n\n\n\n\nplt.plot([2,3,4,1],'--',lw=12)"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#label-legend",
    "href": "posts/Data Visualization/DV_4(0926).html#label-legend",
    "title": "DV 4주차(1)",
    "section": "label, legend",
    "text": "label, legend\n\nplt.plot([2,3,4,1],'--o', label='A')\nplt.plot([4,3.2,1,3],'--o', label='B')\nplt.legend()  # 범례.. 위의 label\n\n<matplotlib.legend.Legend at 0x7fbc8767d050>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#색깔조정-c0-c1",
    "href": "posts/Data Visualization/DV_4(0926).html#색깔조정-c0-c1",
    "title": "DV 4주차(1)",
    "section": "색깔조정 (C0, C1,…)",
    "text": "색깔조정 (C0, C1,…)\n\nplt.plot([2,3,4,1],'--o', label='A', color='C1')\nplt.plot([4,3.2,1,3],'--o', label='B', color='C0')  # 그래프 위아래의 선 색 변경시 color='C0'\nplt.legend() \n\n<matplotlib.legend.Legend at 0x7fbc86d99750>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#title",
    "href": "posts/Data Visualization/DV_4(0926).html#title",
    "title": "DV 4주차(1)",
    "section": "title",
    "text": "title\n- 방법1\n\nplt.plot([1,2,3,2])\nplt.title('title')\n\nText(0.5, 1.0, 'title')\n\n\n\n\n\n- 방법2\n\nfig, ax = plt.subplots()\nax.set_title('asdf')\n\nText(0.5, 1.0, 'asdf')"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#suptitle",
    "href": "posts/Data Visualization/DV_4(0926).html#suptitle",
    "title": "DV 4주차(1)",
    "section": "suptitle",
    "text": "suptitle\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\n#plt.suptitle('suptitle') 둘다된다\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#tight_layout",
    "href": "posts/Data Visualization/DV_4(0926).html#tight_layout",
    "title": "DV 4주차(1)",
    "section": "tight_layout()",
    "text": "tight_layout()\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\nfig.suptitle('suptitle')\nfig.tight_layout()   # 컴퓨터에서 알아서 이쁘게 레이아웃 설정"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#fig-ax-plt-소속",
    "href": "posts/Data Visualization/DV_4(0926).html#fig-ax-plt-소속",
    "title": "DV 4주차(1)",
    "section": "fig, ax, plt 소속",
    "text": "fig, ax, plt 소속\n예시\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,1])\n\n\n\n\n- fig에는 있고 ax에는 없는 것\nadd_axes, tight_layout, suptitle, …\n\nset(dir(fig)) - set(dir(ax))    # fig에만 있는 함수\n\n{'_add_axes_internal',\n '_align_label_groups',\n '_axobservers',\n '_axstack',\n '_button_pick_id',\n '_cachedRenderer',\n '_canvas_callbacks',\n '_constrained',\n '_constrained_layout_pads',\n '_dpi',\n '_get_dpi',\n '_get_draw_artists',\n '_gridspecs',\n '_localaxes',\n '_normalize_grid_string',\n '_original_dpi',\n '_process_projection_requirements',\n '_repr_html_',\n '_scroll_pick_id',\n '_set_dpi',\n '_suplabels',\n '_suptitle',\n '_supxlabel',\n '_supylabel',\n '_tight_parameters',\n 'add_axes',\n 'add_axobserver',\n 'add_gridspec',\n 'add_subfigure',\n 'add_subplot',\n 'align_labels',\n 'align_xlabels',\n 'align_ylabels',\n 'autofmt_xdate',\n 'bbox_inches',\n 'canvas',\n 'clf',\n 'colorbar',\n 'delaxes',\n 'dpi',\n 'dpi_scale_trans',\n 'draw_without_rendering',\n 'execute_constrained_layout',\n 'figbbox',\n 'figimage',\n 'frameon',\n 'gca',\n 'get_axes',\n 'get_constrained_layout',\n 'get_constrained_layout_pads',\n 'get_dpi',\n 'get_edgecolor',\n 'get_figheight',\n 'get_figwidth',\n 'get_frameon',\n 'get_linewidth',\n 'get_size_inches',\n 'get_tight_layout',\n 'ginput',\n 'legends',\n 'number',\n 'savefig',\n 'sca',\n 'set_canvas',\n 'set_constrained_layout',\n 'set_constrained_layout_pads',\n 'set_dpi',\n 'set_edgecolor',\n 'set_figheight',\n 'set_figwidth',\n 'set_frameon',\n 'set_linewidth',\n 'set_size_inches',\n 'set_tight_layout',\n 'show',\n 'subfigs',\n 'subfigures',\n 'subplot_mosaic',\n 'subplotpars',\n 'subplots',\n 'subplots_adjust',\n 'suppressComposite',\n 'suptitle',\n 'supxlabel',\n 'supylabel',\n 'tight_layout',\n 'transFigure',\n 'transSubfigure',\n 'waitforbuttonpress'}\n\n\n- ax에는 있고 fig에는 없는 것\nboxplot, hist, plot, set_title, …\n\nset(dir(ax)) - set(dir(fig))   # ax만 있는 함수\n\n{'ArtistList',\n '_add_text',\n '_adjustable',\n '_alias_map',\n '_anchor',\n '_aspect',\n '_autoscaleXon',\n '_autoscaleYon',\n '_autotitlepos',\n '_axes',\n '_axes_class',\n '_axes_locator',\n '_axis_names',\n '_axisbelow',\n '_box_aspect',\n '_check_no_units',\n '_children',\n '_colorbars',\n '_convert_dx',\n '_current_image',\n '_deprecate_noninstance',\n '_facecolor',\n '_fill_between_x_or_y',\n '_frameon',\n '_gen_axes_patch',\n '_gen_axes_spines',\n '_get_axis_list',\n '_get_axis_map',\n '_get_lines',\n '_get_pan_points',\n '_get_patches_for_fill',\n '_get_view',\n '_gridOn',\n '_init_axis',\n '_label_outer_xaxis',\n '_label_outer_yaxis',\n '_left_title',\n '_make_twin_axes',\n '_mouseover_set',\n '_navigate',\n '_navigate_mode',\n '_originalPosition',\n '_parse_scatter_color_args',\n '_pcolor_grid_deprecation_helper',\n '_pcolorargs',\n '_position',\n '_prepare_view_from_bbox',\n '_process_unit_info',\n '_projection_init',\n '_quiver_units',\n '_rasterization_zorder',\n '_remove_legend',\n '_request_autoscale_view',\n '_right_title',\n '_sci',\n '_set_lim_and_transforms',\n '_set_position',\n '_set_title_offset_trans',\n '_set_view',\n '_set_view_from_bbox',\n '_shared_axes',\n '_sharex',\n '_sharey',\n '_stale_viewlims',\n '_subplotspec',\n '_twinned_axes',\n '_unit_change_handler',\n '_unstale_viewLim',\n '_update_image_limits',\n '_update_line_limits',\n '_update_patch_limits',\n '_update_title_position',\n '_update_transScale',\n '_use_sticky_edges',\n '_validate_converted_limits',\n '_viewLim',\n '_xaxis_transform',\n '_xmargin',\n '_yaxis_transform',\n '_ymargin',\n 'acorr',\n 'add_child_axes',\n 'add_collection',\n 'add_container',\n 'add_image',\n 'add_line',\n 'add_patch',\n 'add_table',\n 'angle_spectrum',\n 'annotate',\n 'apply_aspect',\n 'arrow',\n 'autoscale',\n 'autoscale_view',\n 'axhline',\n 'axhspan',\n 'axis',\n 'axison',\n 'axline',\n 'axvline',\n 'axvspan',\n 'bar',\n 'bar_label',\n 'barbs',\n 'barh',\n 'boxplot',\n 'broken_barh',\n 'bxp',\n 'can_pan',\n 'can_zoom',\n 'change_geometry',\n 'child_axes',\n 'cla',\n 'clabel',\n 'cohere',\n 'collections',\n 'containers',\n 'contains_point',\n 'contour',\n 'contourf',\n 'csd',\n 'dataLim',\n 'drag_pan',\n 'end_pan',\n 'errorbar',\n 'eventplot',\n 'figbox',\n 'fill',\n 'fill_between',\n 'fill_betweenx',\n 'fmt_xdata',\n 'fmt_ydata',\n 'format_coord',\n 'format_xdata',\n 'format_ydata',\n 'get_adjustable',\n 'get_anchor',\n 'get_aspect',\n 'get_autoscale_on',\n 'get_autoscalex_on',\n 'get_autoscaley_on',\n 'get_axes_locator',\n 'get_axisbelow',\n 'get_box_aspect',\n 'get_data_ratio',\n 'get_fc',\n 'get_frame_on',\n 'get_geometry',\n 'get_gridspec',\n 'get_images',\n 'get_legend',\n 'get_legend_handles_labels',\n 'get_lines',\n 'get_navigate',\n 'get_navigate_mode',\n 'get_position',\n 'get_rasterization_zorder',\n 'get_renderer_cache',\n 'get_shared_x_axes',\n 'get_shared_y_axes',\n 'get_subplotspec',\n 'get_title',\n 'get_xaxis',\n 'get_xaxis_text1_transform',\n 'get_xaxis_text2_transform',\n 'get_xaxis_transform',\n 'get_xbound',\n 'get_xgridlines',\n 'get_xlabel',\n 'get_xlim',\n 'get_xmajorticklabels',\n 'get_xminorticklabels',\n 'get_xscale',\n 'get_xticklabels',\n 'get_xticklines',\n 'get_xticks',\n 'get_yaxis',\n 'get_yaxis_text1_transform',\n 'get_yaxis_text2_transform',\n 'get_yaxis_transform',\n 'get_ybound',\n 'get_ygridlines',\n 'get_ylabel',\n 'get_ylim',\n 'get_ymajorticklabels',\n 'get_yminorticklabels',\n 'get_yscale',\n 'get_yticklabels',\n 'get_yticklines',\n 'get_yticks',\n 'grid',\n 'has_data',\n 'hexbin',\n 'hist',\n 'hist2d',\n 'hlines',\n 'ignore_existing_data_limits',\n 'imshow',\n 'in_axes',\n 'indicate_inset',\n 'indicate_inset_zoom',\n 'inset_axes',\n 'invert_xaxis',\n 'invert_yaxis',\n 'is_first_col',\n 'is_first_row',\n 'is_last_col',\n 'is_last_row',\n 'label_outer',\n 'legend_',\n 'locator_params',\n 'loglog',\n 'magnitude_spectrum',\n 'margins',\n 'matshow',\n 'minorticks_off',\n 'minorticks_on',\n 'name',\n 'numCols',\n 'numRows',\n 'pcolor',\n 'pcolorfast',\n 'pcolormesh',\n 'phase_spectrum',\n 'pie',\n 'plot',\n 'plot_date',\n 'psd',\n 'quiver',\n 'quiverkey',\n 'redraw_in_frame',\n 'relim',\n 'reset_position',\n 'scatter',\n 'secondary_xaxis',\n 'secondary_yaxis',\n 'semilogx',\n 'semilogy',\n 'set_adjustable',\n 'set_anchor',\n 'set_aspect',\n 'set_autoscale_on',\n 'set_autoscalex_on',\n 'set_autoscaley_on',\n 'set_axes_locator',\n 'set_axis_off',\n 'set_axis_on',\n 'set_axisbelow',\n 'set_box_aspect',\n 'set_fc',\n 'set_frame_on',\n 'set_navigate',\n 'set_navigate_mode',\n 'set_position',\n 'set_prop_cycle',\n 'set_rasterization_zorder',\n 'set_subplotspec',\n 'set_title',\n 'set_xbound',\n 'set_xlabel',\n 'set_xlim',\n 'set_xmargin',\n 'set_xscale',\n 'set_xticklabels',\n 'set_xticks',\n 'set_ybound',\n 'set_ylabel',\n 'set_ylim',\n 'set_ymargin',\n 'set_yscale',\n 'set_yticklabels',\n 'set_yticks',\n 'sharex',\n 'sharey',\n 'specgram',\n 'spines',\n 'spy',\n 'stackplot',\n 'stairs',\n 'start_pan',\n 'stem',\n 'step',\n 'streamplot',\n 'table',\n 'tables',\n 'tick_params',\n 'ticklabel_format',\n 'title',\n 'titleOffsetTrans',\n 'transAxes',\n 'transData',\n 'transLimits',\n 'transScale',\n 'tricontour',\n 'tricontourf',\n 'tripcolor',\n 'triplot',\n 'twinx',\n 'twiny',\n 'update_datalim',\n 'update_params',\n 'use_sticky_edges',\n 'viewLim',\n 'violin',\n 'violinplot',\n 'vlines',\n 'xaxis',\n 'xaxis_date',\n 'xaxis_inverted',\n 'xcorr',\n 'yaxis',\n 'yaxis_date',\n 'yaxis_inverted'}\n\n\n\nset(dir(ax)) & set(dir(fig))   # 교집합\n\n{'_PROPERTIES_EXCLUDED_FROM_SET',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_agg_filter',\n '_alpha',\n '_animated',\n '_callbacks',\n '_clipon',\n '_clippath',\n '_cm_set',\n '_default_contains',\n '_gci',\n '_get_clipping_extent_bbox',\n '_gid',\n '_in_layout',\n '_label',\n '_mouseover',\n '_path_effects',\n '_picker',\n '_rasterized',\n '_remove_method',\n '_set_alpha_for_array',\n '_set_artist_props',\n '_set_gc_clip',\n '_sketch',\n '_snap',\n '_stale',\n '_sticky_edges',\n '_tight',\n '_transform',\n '_transformSet',\n '_update_set_signature_and_docstring',\n '_url',\n '_visible',\n 'add_artist',\n 'add_callback',\n 'artists',\n 'axes',\n 'bbox',\n 'callbacks',\n 'clear',\n 'clipbox',\n 'contains',\n 'convert_xunits',\n 'convert_yunits',\n 'draw',\n 'draw_artist',\n 'figure',\n 'findobj',\n 'format_cursor_data',\n 'get_agg_filter',\n 'get_alpha',\n 'get_animated',\n 'get_children',\n 'get_clip_box',\n 'get_clip_on',\n 'get_clip_path',\n 'get_cursor_data',\n 'get_default_bbox_extra_artists',\n 'get_facecolor',\n 'get_figure',\n 'get_gid',\n 'get_in_layout',\n 'get_label',\n 'get_path_effects',\n 'get_picker',\n 'get_rasterized',\n 'get_sketch_params',\n 'get_snap',\n 'get_tightbbox',\n 'get_transform',\n 'get_transformed_clip_path_and_affine',\n 'get_url',\n 'get_visible',\n 'get_window_extent',\n 'get_zorder',\n 'have_units',\n 'images',\n 'is_transform_set',\n 'legend',\n 'lines',\n 'mouseover',\n 'patch',\n 'patches',\n 'pchanged',\n 'pick',\n 'pickable',\n 'properties',\n 'remove',\n 'remove_callback',\n 'set',\n 'set_agg_filter',\n 'set_alpha',\n 'set_animated',\n 'set_clip_box',\n 'set_clip_on',\n 'set_clip_path',\n 'set_facecolor',\n 'set_figure',\n 'set_gid',\n 'set_in_layout',\n 'set_label',\n 'set_path_effects',\n 'set_picker',\n 'set_rasterized',\n 'set_sketch_params',\n 'set_snap',\n 'set_transform',\n 'set_url',\n 'set_visible',\n 'set_zorder',\n 'stale',\n 'stale_callback',\n 'sticky_edges',\n 'text',\n 'texts',\n 'update',\n 'update_from',\n 'zorder'}\n\n\n- plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다)\n\nplt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot\nplt.set_title 은 없지만 plt.title 은 있음\nplt.add_axes 는 없음..\n\n\nset(dir(plt)) & {'add_axes'}\n\nset()"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0926).html#x축-y축-label-설정",
    "href": "posts/Data Visualization/DV_4(0926).html#x축-y축-label-설정",
    "title": "DV 4주차(1)",
    "section": "x축, y축 label 설정",
    "text": "x축, y축 label 설정\n\nfig,ax = plt.subplots()\nax.plot([1,2,3,2])\n#ax.set_xlabel('x',size=36, style='italic')\n_dct = {'size':36, 'family':'serif', 'style':'italic'}  #family:글꼴\nax.set_xlabel('x',_dct)  #옵션을 딕셔너리 형태로 해서 이렇게 표현도 가능\n\nText(0.5, 0, 'x')\n\n\n\n\n\n\nax.xaxis.set_label_text('xlabel',size=16,family='serif',weight=1000,style='italic')\n#_fontsettings={'size':16,'family':'serif','weight'=1000,'style':'italic'}\n#ax.xaxis.set_label_text('xlabel',_fontsettings)\nfig\n\n# weight 굵음\n# xaxis 도 가능.. (x축)\n\n\n\n\n폰트ref : https://matplotlib.org/stable/api/font_manager_api.html#matplotlib.font_manager.FontProperties\n\nsize:\nfontweight: 0~1000\nfamily: ‘serif’, ‘sans-serif’, ‘monospace’\nstyle: ‘normal’, ‘italic’\n\n\nax.set_xlabel??\n\n\nSignature: ax.set_xlabel(xlabel, fontdict=None, labelpad=None, *, loc=None, **kwargs)\nSource:   \n    def set_xlabel(self, xlabel, fontdict=None, labelpad=None, *,\n                   loc=None, **kwargs):\n        \"\"\"\n        Set the label for the x-axis.\n        Parameters\n        ----------\n        xlabel : str\n            The label text.\n        labelpad : float, default: :rc:`axes.labelpad`\n            Spacing in points from the Axes bounding box including ticks\n            and tick labels.  If None, the previous value is left as is.\n        loc : {'left', 'center', 'right'}, default: :rc:`xaxis.labellocation`\n            The label position. This is a high-level alternative for passing\n            parameters *x* and *horizontalalignment*.\n        Other Parameters\n        ----------------\n        **kwargs : `.Text` properties\n            `.Text` properties control the appearance of the label.\n        See Also\n        --------\n        text : Documents the properties supported by `.Text`.\n        \"\"\"\n        if labelpad is not None:\n            self.xaxis.labelpad = labelpad\n        protected_kw = ['x', 'horizontalalignment', 'ha']\n        if {*kwargs} & {*protected_kw}:\n            if loc is not None:\n                raise TypeError(f\"Specifying 'loc' is disallowed when any of \"\n                                f\"its corresponding low level keyword \"\n                                f\"arguments ({protected_kw}) are also \"\n                                f\"supplied\")\n        else:\n            loc = (loc if loc is not None\n                   else mpl.rcParams['xaxis.labellocation'])\n            _api.check_in_list(('left', 'center', 'right'), loc=loc)\n            if loc == 'left':\n                kwargs.update(x=0, horizontalalignment='left')\n            elif loc == 'center':\n                kwargs.update(x=0.5, horizontalalignment='center')\n            elif loc == 'right':\n                kwargs.update(x=1, horizontalalignment='right')\n        return self.xaxis.set_label_text(xlabel, fontdict, **kwargs)\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py\nType:      method"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html",
    "href": "posts/Data Visualization/DV_6(1012).html",
    "title": "DV 6주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#lambda",
    "href": "posts/Data Visualization/DV_6(1012).html#lambda",
    "title": "DV 6주차",
    "section": "lambda",
    "text": "lambda\n- 예제1: 람다표현식 (lambda expression) 자체가 하나의 오브젝트임\n\n(lambda x: (x-2)**2)  # lambda가 실행되는 순간 메모리상에 함수 오브젝트가 저장됨\n\n<function __main__.<lambda>(x)>\n\n\n\nlambda x: (x-2)**2 는 \\(lambda(x)=(x-2)^2\\) 의 느낌으로 기억하면 쉬움\n\n(사용방법)\n\n(lambda x: (x-2)**2)(2)  # 입력 2-> 출력 (2-2)^2 = 0\n\n0\n\n\n\n(lambda x: (x-2)**2)(4)  # 입력 4-> 출력 (4-2)^2 = 4\n\n4\n\n\n- 예제2: 람다표현식에 이름을 줄 수 있음\n\nf = lambda x: (x-2)**2\n\n\nf(2),f(4)\n\n(0, 4)\n\n\n위의 코드는 아래와 같다\n\ndef f(x):\n    return (x-2)**2\nf(2), f(4)\n\n(0, 4)\n\n\n- 예제3: 조건부 출력\n\nf = lambda x,y: x if x>y else y  # 큰 값 리턴\n\n\nf(1,2),  f(-4,3)\n\n(2, 3)\n\n\n- 예제4: 람다표현식들의 리스트\n\nfl = [lambda x: x, lambda x: x**2, lambda x: x**3]\n\n\ntype(fl)\n\nlist\n\n\n\nfl[0](10), fl[1](10), fl[2](10)\n\n(10, 100, 1000)\n\n\n\nfor f in fl:\n    print(f(2))\n\n2\n4\n8\n\n\n\nfor s in ['a','b','c']:\n    print(s)\n\na\nb\nc\n\n\n\nfor s in ['a', lambda x:x, 'c']:\n    print(s)\n\na\n<function <lambda> at 0x7f3ddff33c20>\nc\n\n\n\nx = np.linspace(-1,1,100)\nfor f in fl:\n    plt.plot(x,f(x),'--')\n\n\n\n\n- 예제5: 람다표현식들의 딕셔너리\n\nfd = {'f1': lambda x:x, 'f2': lambda x: x**2, 'f3':lambda x:x**3}\nfd\n\n{'f1': <function __main__.<lambda>(x)>,\n 'f2': <function __main__.<lambda>(x)>,\n 'f3': <function __main__.<lambda>(x)>}\n\n\n\nfor k in fd:\n    plt.plot(x,fd[k](x),'--')\n\n\n\n\n- 예제6: 람다표현식을 리턴하는 함수(함수를 리턴하는 함수)\n(예비학습) 함수 \\(g(x)\\)가 정의되어 있을때 \\(\\frac{d}{dx}g(x)\\)의 값을 계산\n\ng = lambda x : x**2\n\n\ng(3)\n\n9\n\n\n\\(f'(x)\\approx \\frac{f(x+h)-f(x)}{h}\\)\n\ngg =  lambda x: (g(x+0.001)-g(x))/0.001\n\n\ngg(3)\n\n6.000999999999479\n\n\n(예비학습끝)\n(목표) 도함수를 구해주는 derivate 함수를 정의. 임의의 함수 g를 입력으로 받으면, g의 도함수 (gg)가 리턴되는 기능을 가진다.\n\ndef derivate(g):\n    gg = lambda x: (g(x+0.001)-g(x))/0.001\n    return gg\n\n(사용)\n\ng = lambda x: np.sin(x)\n\n\ngg = derivate(g)\n\n\nx = np.linspace(0,6.28,1000)\n\n\nplt.plot(x,g(x))\nplt.plot(x,gg(x))\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2\ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\n\n\nplt.plot(x,g0(x))\nplt.plot(x,g1(x))\nplt.plot(x,g2(x))\n\n\n\n\n- 예제7: 예제6의 다른표현\n\nderivate = lambda g : lambda x: (g(x+0.001)-g(x))/0.001\n# 위와 같은 코드\n\n\ng = lambda x: np.sin(x)\n\n\ngg = derivate(g)\n\n\nx = np.linspace(0,6.28,1000)\n\n\nplt.plot(x,g(x))\nplt.plot(x,gg(x))\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2\ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\n\n\nplt.plot(x,g0(x))\nplt.plot(x,g1(x))\nplt.plot(x,g2(x))"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#map",
    "href": "posts/Data Visualization/DV_6(1012).html#map",
    "title": "DV 6주차",
    "section": "map",
    "text": "map\n- 개념: \\(\\text{map}\\left(f,[x_1,x_2,\\dots,x_n] \\right) = \\left[f(x_1),f(x_2),\\dots,f(x_n)\\right]\\)\n- 예제1\n\nx=[1,2,3]\nf = lambda x: x+1\ny= list(map(f,x))\n\n\nlist(map(f,x))\n\n[2, 3, 4]\n\n\n\nf(x) # 리스트라 오류남\n\nTypeError: can only concatenate list (not \"int\") to list\n\n\n\nf(x[0])\n\n2\n\n\n(다른구현1)\n\nlist(map(lambda x:x+1, x))\n\n[2, 3, 4]\n\n\n\nlist(map(lambda x:x+1, [1,2,3]))\n\n[2, 3, 4]\n\n\n(다른구현2)\n\nf = lambda x: x+1\n[xi for xi in [1,2,3]]\n\n[1, 2, 3]\n\n\n\nf = lambda x: x+1\n[f(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현3)\n\n[(lambda x:x+1)(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현4)-최악\n\ny = []\nx = [1,2,3]\nf = lambda x: x+1\nfor xi in x:\n    y.append(f(xi))\n\n\ny\n\n[2, 3, 4]\n\n\n(다른구현5)-더 최악\n\ny = []\nx = [1,2,3]\nf = lambda x: x+1\nfor i in range(len(x)):\n    y.append(f(x[i]))\n\n\ny\n\n[2, 3, 4]\n\n\n- 예제2: 문자열을 입력으로 받고 대문자이면 True, 소문자이면 False\n입력: A,B,C,a,b,c\n출력: T,T,T,F,F,F\n\nf(np.array(x))\n\narray([2, 3, 4])\n\n\n\n'A'.isupper()\n\nTrue\n\n\n\n#x = ['A', 'B', 'C', 'a', 'b', 'c']\nx = list('ABCabc')\nf = lambda s : s.isupper()\ny = list(map(f,x))\n\n\nx,y\n\n(['A', 'B', 'C', 'a', 'b', 'c'], [True, True, True, False, False, False])\n\n\n- 예제3: 두 개의 입력을 받는 함수\n\n(lambda x,y : x+y)(-1,3)\n\n2\n\n\n\nlist(map(lambda x,y: x+y, [1,2,3],[-1,-2,-3]))\n\n[0, 0, 0]\n\n\n(다른 구현) - 리스트컴프리헨션\n\nf = lambda x,y: x+y\n[f(x,y) for x,y in zip([1,2,3],[-1,-2,-3])]\n\n[0, 0, 0]\n\n\n- 예제4: map은 “하나의 함수에 다양한 입력”을 적용하는 경우에만 사용가능, 리스트 컴프리헨션은 “다양한 함수에 다양한 입력”을 지원한다.\n\nflst = [lambda x: x+1, lambda x: x+2, lambda x: x+3]\n\n(map으로 구현 시도) -> 실패\n\nlist(map(flst,[-1,-2,-3])) # 결과가 0,0,0 나오길 시도\n\nTypeError: 'list' object is not callable\n\n\n리스트컴프리헨션으로 구현시도 -> 성공\n\n[f(x) for f,x in zip(flst, [-1,-2,-3])]\n\n[0, 0, 0]\n\n\n- 종합: map과 리스트컴프리헨션과 비교 - map은 반복인덱스를 쓰지 않지만 리스트컴프리헨션은 반복인덱스가 필요함 - map은 좀더 리스트컴프리헨션보다 제약적으로 사용할 수 밖에 없음"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#데이터프레임-준비",
    "href": "posts/Data Visualization/DV_6(1012).html#데이터프레임-준비",
    "title": "DV 6주차",
    "section": "데이터프레임 준비",
    "text": "데이터프레임 준비\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n- 앞으로는 위와 같은 df형태를 가정할 것이다. 즉 column의 이름은 문자열, row의 이름은 0부터 시작하는 정수로 가정한다.\n\nnp.array([[1,2,3],[1,2,5]])\n\narray([[1, 2, 3],\n       [1, 2, 5]])\n\n\n- 아래와 같은 형태는 일단 생각 안함\n\npd.DataFrame({'att':[60,65,80,90],'rep':[50,100,90,100]},index=['A','B','C','D'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      A\n      60\n      50\n    \n    \n      B\n      65\n      100\n    \n    \n      C\n      80\n      90\n    \n    \n      D\n      90\n      100"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#df의-4가지-컨셉",
    "href": "posts/Data Visualization/DV_6(1012).html#df의-4가지-컨셉",
    "title": "DV 6주차",
    "section": "df의 4가지 컨셉",
    "text": "df의 4가지 컨셉\n- 원소에 접근하는 4가지 방법: ., [], iloc[], .loc[]\n\n컨셉1: 클래스느낌\n- 컨셉1: df는 인스턴스이다. 그리고 df.att, df.rep, df.mid, df.fin과 같이 col이름에 대응하는 속성이 있다.\n\ndf.head(6)\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n  \n\n\n\n\n\ndf.att\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndf.fin\n\n0      10\n1      10\n2      20\n3       5\n4      70\n       ..\n195    95\n196    85\n197    10\n198    60\n199    85\nName: fin, Length: 200, dtype: int64\n\n\n- 언제유용? col의 이름을 대충 알고 있을 경우 자동완성으로 쉽게 선택가능\n\n\n컨셉2: 딕셔너리 + \\(\\alpha\\) 느낌\n- 컨셉2: df는 컬럼이름이 key, 컬럼의 데이터가 value가 되는 dictionary로 이해가능. 즉 아래의 dct와 같은 딕셔너리로 이해할 수 있다.\n\ncol indexing\n- 예시1: dct가 가능하면 df도 가능하다.\n\ndct = dict(df)\n\n\ndct['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndf['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: dct가 가능하면 df도 가능하다.(2)\n\ndf.get('att')\n#dct.get('att')\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시3: dct에서는 불가능하지만 df에서 가능한 것도 잇다.\n\ndct.get('att')\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndct.get(['att','rep']) #이건 안됨\n\nTypeError: unhashable type: 'list'\n\n\n\ndf.get(['att','rep'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시4: dct에서는 불가능하지만 df에서 가능한 것도 잇다.(2)\n\ndct['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndct[['att','rep']]\n\nTypeError: unhashable type: 'list'\n\n\n\ndf[['att','rep']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n\n\nlow indexing\n- 예시5: dct에서는 불가능하지만 df에서 가능한 것도 잇다.(3)\n\ndct[:5]\n\nTypeError: unhashable type: 'slice'\n\n\n\ndf[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n  \n\n\n\n\n\n\n\n컨셉3: 넘파이느낌\n- 컨셉3: df.iloc은 넘파이어레이처럼 생각 가능하다. 즉 아래와 같은 넘파이 어레이로 생각 가능\n\narr=np.array(df)\narr\n\narray([[ 65,  45,   0,  10],\n       [ 95,  30,  60,  10],\n       [ 65,  85,  15,  20],\n       [ 55,  35,  35,   5],\n       [ 80,  60,  55,  70],\n       [ 75,  40,  75,  85],\n       [ 65,  70,  60,  75],\n       [ 60,  25,  20,  35],\n       [ 95,  55,  65,  90],\n       [ 90,  25,  95,  50],\n       [ 55,  45,  75,  30],\n       [ 95,  60,  25,  55],\n       [ 95,  35,   0,  25],\n       [ 50,  55,  90,  45],\n       [ 50,  65,  50,  70],\n       [ 95, 100,  25,  40],\n       [ 50,  65,  35,  85],\n       [ 65,  85,  10,   5],\n       [ 70,  65,  65,  80],\n       [ 90,  70, 100,  30],\n       [ 80,  45,  80,  85],\n       [ 55,  45,  85,  70],\n       [ 65,  35,  45,  20],\n       [ 70,  25,  50,  70],\n       [ 85,  55,  30,  80],\n       [ 90,  30,  30,   0],\n       [100,  65,  50,  70],\n       [ 80,  70,  50, 100],\n       [ 80,  35,  25,  65],\n       [ 55,  75,  20,  25],\n       [ 75,  75,  85,  95],\n       [ 80,  95,   5,   5],\n       [ 95,  60,  65,  10],\n       [ 95,  60,  90,  75],\n       [100,  75,  70,  25],\n       [100,  55,  35,  85],\n       [ 80,  60,  65,  55],\n       [ 70,  80,   0,  10],\n       [ 85,  65,  60,  60],\n       [100,  95,   0,  25],\n       [ 95,  60,  15,  45],\n       [ 75,  40,  30,  10],\n       [ 70,  80,  50,  25],\n       [ 50,  45,  10,  10],\n       [100, 100, 100,  50],\n       [ 75,  50,  60,   5],\n       [ 85,  50,  35, 100],\n       [ 80,  35,  75,  80],\n       [ 95,  45,  35,  80],\n       [ 65,  85,  85,  15],\n       [ 90,  30,  25,   5],\n       [ 65,  65,  35,  70],\n       [ 80,  65,  30,  90],\n       [ 95,  80,  45,  35],\n       [ 65,  75,  50,  35],\n       [ 90,  55, 100,  30],\n       [ 95,  25,  95,  90],\n       [100,  50,  80,  10],\n       [ 50,  55,  35,  60],\n       [ 90,  70,  35,  25],\n       [ 50,  55,  15,  75],\n       [ 80,  50,  55,  90],\n       [ 50,  75,  65,  90],\n       [ 70,  40,  90,   5],\n       [ 65,  85,  20,  90],\n       [ 60,  30,   0,  50],\n       [ 50,  65,  15,   0],\n       [ 60,  95,  30,  70],\n       [ 70,  70,   5,   0],\n       [ 75,  45,  15,  75],\n       [ 50,  60,  15,  50],\n       [ 85,  90,  90,  90],\n       [ 80,  25,  85,  20],\n       [ 55,  75,  95,  90],\n       [ 85,  30,  45,  15],\n       [ 65,  30,  45,  15],\n       [ 85,  95,  35,  25],\n       [ 60,  25,  10,  50],\n       [ 95,  45,  90,  35],\n       [ 85,  50,  60,  45],\n       [ 60,  50, 100,  70],\n       [100,  75,  60,   0],\n       [100,  90,  85,  75],\n       [ 55, 100, 100,  60],\n       [ 70,  60,  30,  40],\n       [ 70,  90,  95,  40],\n       [ 55,  50,   0,   5],\n       [100, 100,  45,  90],\n       [ 85,  70,  90,  80],\n       [100,  85,  65,  85],\n       [ 60,  65,  35,  15],\n       [ 65,  75,  75,  85],\n       [ 65,  25,  40,   0],\n       [ 75,  75,  50,  40],\n       [ 50,  55,  80,  55],\n       [ 75,  30,  20,  50],\n       [100,  50,  25,  65],\n       [ 90,  30,  95,  35],\n       [ 55, 100,  80,   0],\n       [ 75,  60,  15,  40],\n       [ 60,  25,  25,  50],\n       [ 85,  35,  10,  60],\n       [ 60, 100,  55,  40],\n       [ 70,  55,  50,  75],\n       [ 80,  65,  95,  85],\n       [ 65,  35,  15,  65],\n       [ 85,  70, 100,   0],\n       [100,  30,  60,  65],\n       [ 65,  70,  55,  70],\n       [ 85,  55,  85,  90],\n       [ 85,  95,  80,  10],\n       [ 85,  70,  75,   5],\n       [100,  35,  70,   0],\n       [ 95,  45,  55,  65],\n       [ 95,  85,  40,  65],\n       [ 55,  50,  30,  85],\n       [ 85,  50,   5,  65],\n       [ 75,  90,  85,  85],\n       [ 95,  70,  10,   5],\n       [ 85,  35,  80,  95],\n       [ 95,  50,  80,  90],\n       [100,  65,  75,  40],\n       [ 95,  70,  70,   0],\n       [ 95,  70,  20,  25],\n       [100,  60,  10,   5],\n       [ 55,  35,  25,  10],\n       [ 60,  90,  40,   5],\n       [ 85,  90,  85,  75],\n       [ 75,  85,  25,  35],\n       [ 55,  30,  50,  45],\n       [ 70,  60,  75,  75],\n       [ 80,  30,  95,   5],\n       [ 90,  85,  80,  15],\n       [ 90,  25,  95,   5],\n       [ 60,  85,  50,  20],\n       [ 90,  50,  95,  95],\n       [ 75,  95,  65,  40],\n       [ 60,  40,  35,   0],\n       [ 55, 100,  15,  80],\n       [ 70,  75,  80,   0],\n       [ 75,  65,  25,  20],\n       [ 90,  75,  80,  25],\n       [ 50,  75,  75,  20],\n       [ 55,  45,  35,  45],\n       [ 90,  70,  90,   0],\n       [ 75,  30, 100,  60],\n       [ 90,  85,   0,  40],\n       [ 85,  70,  35,   0],\n       [100,  75, 100,  85],\n       [ 55,  35,  20,  10],\n       [ 70,  75,  90,  90],\n       [ 90,  90,  55,  55],\n       [ 55,  60,  40,   0],\n       [100,  90,   5,  30],\n       [ 50,  55,  25,  80],\n       [100, 100,  90,  55],\n       [ 70,  45,  70,  75],\n       [ 85,  95,  85,  90],\n       [ 55,  25,  95,  45],\n       [ 75,  30,  10,  95],\n       [ 65,  85,  15,  60],\n       [ 70,  90,  70,   0],\n       [ 60,  85,  70,  85],\n       [100,  25,  10,  20],\n       [ 75,  25,  80,  25],\n       [ 90,  95,  40,  80],\n       [ 95,  90,  50,  50],\n       [ 90,  90,  65,  85],\n       [ 95,  75,  50,  40],\n       [ 55,  60,  70,   5],\n       [ 95,  85,   0,  15],\n       [ 65,  60,  35,  20],\n       [ 65,  50,   5,   5],\n       [ 90,  25,  60,  25],\n       [100,  40,  40,  15],\n       [ 70,  25, 100,  75],\n       [100,  30,  70,  70],\n       [ 50,  55,  55,   5],\n       [ 70,  35,  70, 100],\n       [ 70,  60,  60,  80],\n       [ 55,  45,  90,   5],\n       [ 55,  55,  10,  95],\n       [ 65,  80,  10,  30],\n       [ 90,  25,  35,  55],\n       [100,  30,  30,  85],\n       [ 70,  85,  70,  65],\n       [ 60, 100,  45, 100],\n       [ 70,  25, 100,  15],\n       [ 70,  35,  80,  25],\n       [ 65,  60,  30,  35],\n       [ 95,  35,  40,  95],\n       [ 50,  80,  65,  90],\n       [100,  40,  80,  80],\n       [ 55,  30,  95, 100],\n       [ 65,  40,  65,  70],\n       [ 55,  70,  40,  95],\n       [ 65,  85,  25,  85],\n       [ 85,  85, 100,  10],\n       [ 80,  65,  35,  60],\n       [ 50,  95,  45,  85]])\n\n\n\nrow indexing\n- 예시1: 단일레이블\n\narr[0,:] # first row\n\narray([65, 45,  0, 10])\n\n\n\narr[0]\n\narray([65, 45,  0, 10])\n\n\n\narr[0,] # R\n\narray([65, 45,  0, 10])\n\n\n\ndf.iloc[0,:]\n# df.iloc[0,]\n# df.iloc[0]\n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\narr[[0,1,2],:]  # 처음 3개의 row 선택\narr[[0,1,2],]\narr[[0,1,2]]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[[0,1,2],:]  # 처음 3개의 row 선택\ndf.iloc[[0,1,2],]\ndf.iloc[[0,1,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬라이싱\n\narr[0:3,:]  # 처음 3개의 row 선택, 끝점포함x\narr[0:3,]\narr[0:3]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[0:3,:]  # 처음 3개의 row 선택\ndf.iloc[0:3,]\ndf.iloc[0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n\n\ncol indexing\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n  \n\n\n\n\n- 예시1: 단일레이블\n\n#df.iloc[:,0] # first column \narr[:,0] # first column \n\narray([ 65,  95,  65,  55,  80,  75,  65,  60,  95,  90,  55,  95,  95,\n        50,  50,  95,  50,  65,  70,  90,  80,  55,  65,  70,  85,  90,\n       100,  80,  80,  55,  75,  80,  95,  95, 100, 100,  80,  70,  85,\n       100,  95,  75,  70,  50, 100,  75,  85,  80,  95,  65,  90,  65,\n        80,  95,  65,  90,  95, 100,  50,  90,  50,  80,  50,  70,  65,\n        60,  50,  60,  70,  75,  50,  85,  80,  55,  85,  65,  85,  60,\n        95,  85,  60, 100, 100,  55,  70,  70,  55, 100,  85, 100,  60,\n        65,  65,  75,  50,  75, 100,  90,  55,  75,  60,  85,  60,  70,\n        80,  65,  85, 100,  65,  85,  85,  85, 100,  95,  95,  55,  85,\n        75,  95,  85,  95, 100,  95,  95, 100,  55,  60,  85,  75,  55,\n        70,  80,  90,  90,  60,  90,  75,  60,  55,  70,  75,  90,  50,\n        55,  90,  75,  90,  85, 100,  55,  70,  90,  55, 100,  50, 100,\n        70,  85,  55,  75,  65,  70,  60, 100,  75,  90,  95,  90,  95,\n        55,  95,  65,  65,  90, 100,  70, 100,  50,  70,  70,  55,  55,\n        65,  90, 100,  70,  60,  70,  70,  65,  95,  50, 100,  55,  65,\n        55,  65,  85,  80,  50])\n\n\n\ndf.iloc[:,0] # first column\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\n#arr[:,[0,2]] # col1, col3 선택\n\n\ndf.iloc[:,[0,2]] # 처음 3개의 row선택\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬라이싱\n\ndf.iloc[:,0:3] # 처음 3개의 col선택, 끝점포함X\n#arr[:,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\nrow+col indexing\n\ndf.iloc[:2,0:3] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n  \n\n\n\n\n\ndf.iloc[::2,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      6\n      65\n      70\n      60\n    \n    \n      8\n      95\n      55\n      65\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      190\n      95\n      35\n      40\n    \n    \n      192\n      100\n      40\n      80\n    \n    \n      194\n      65\n      40\n      65\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      198\n      80\n      65\n      35\n    \n  \n\n100 rows × 3 columns\n\n\n\n\n\n\n컨셉4: 데이터프레임 느낌\n- 컨셉4: df.loc새로운 느낌 (R에 익숙하면 dataframe 혹은 티블느낌이라고 보면 된다.)\n\nR에서.. 교수님꺼 강의노트 참고\n\n\nrow indexing\n- 예시1: 단일레이블\n\ndf.loc[0,:]   # 첫번째 row를 선택\ndf.loc[0,]\ndf.loc[0]\n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[[0,1,2],:]   # 처음 3개의 row를 선택\ndf.loc[[0,1,2],]\ndf.loc[[0,1,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬라이싱(끝점포함 O!!)\n\ndf.loc[0:3,:]   # 처음 4개의 row를 선택\ndf.loc[0:3,]\ndf.loc[0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n  \n\n\n\n\n\n\ncol indexing\n- 예시1: 단일레이블\n\ndf.loc[:,'att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[:,['att','mid']]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬라이싱 (끝점 포함 O)\n\ndf.loc[:,'att':'mid']   # R에서는 안됬었고 끝점 포함\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\nrow+col indexing\n\ndf.loc[::-1,'att':'mid']   \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      199\n      50\n      95\n      45\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      0\n      65\n      45\n      0\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\n\n컨셉 1~4 정리\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\n\n- col 이름을 알아야하는 부담감\n\n. : 앞글자만 대충 알아도 자동완성 가능\n[]: 정확한 col 이름을 알아야 함\n.loc: 보통 정확한 col 이름을 알아야 하지만 슬라이싱 이용시 양 끝의 컬럼이름만 알면 무방\n.iloc: 정확한 col 이름을 몰라도 번호로 인덱싱 가능\n\n- 자주하는 실수\n\n# df['att'] # 가능\n# df.loc['att'] # 불가능\ndf.loc[:,'att'] # 가능\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#요약",
    "href": "posts/Data Visualization/DV_6(1012).html#요약",
    "title": "DV 6주차",
    "section": "요약",
    "text": "요약\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\nrow/bool,list\nX\nO\nO\nO\n\n\nrow/bool,ser\nX\nO\nX\nO\n\n\nrow/bool,map\nX\nX\nO\nO"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#숙제1",
    "href": "posts/Data Visualization/DV_6(1012).html#숙제1",
    "title": "DV 6주차",
    "section": "숙제1",
    "text": "숙제1\n아래와 같이 0~9까지 포함된 리스트를 만들어라\n\nx=list(range(10))\nx\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n아래와 동일한 기능을 수행하는 함수를 lambda expression으로 정의하라.\n\ndef f(xi):\n    return '짝' if (xi % 2)==0 else '홀'\n\n\nff = lambda x: \"짝\" if (x % 2)==0 else \" 홀\" \n\n\nff(2)\n\n'짝'\n\n\n\nf(2)\n\n'짝'\n\n\nmap과 lambda expression 을 이용하여 아래와 같은 결과를 만들어라. (리스트컴프리헨션, for문 사용금지)\n\nx=list(range(10))\nff = lambda x: \"짝\" if (x % 2)==0 else \" 홀\" \ny=list(map(ff,x))\ny\n\n['짝', ' 홀', '짝', ' 홀', '짝', ' 홀', '짝', ' 홀', '짝', ' 홀']"
  },
  {
    "objectID": "posts/Data Visualization/DV_6(1012).html#숙제2",
    "href": "posts/Data Visualization/DV_6(1012).html#숙제2",
    "title": "DV 6주차",
    "section": "숙제2",
    "text": "숙제2\n다음과 같은 데이터프레임을 불러온 뒤 물음에 답하라\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n(1) 기말고사 성적이 중간고사 성적보다 향상된 학생들을 출력하라. 즉 mid < fin 인 학생들을 출력하라. (다양한 방법으로 연습할 것, 제출은 한 가지 방법으로 구현해도 감점없음)\n\ndf.query('mid<fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf.loc[(df.mid<df.fin)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf.iloc[list((df.mid<df.fin))]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf[list(map(lambda x,y: x<y, df.mid, df.fin))]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n(2) 기말고사 성적이 중간고사 성적보다 향상된 학생들의 출석과 레포트 점수를 출력하라.\n\ndf2 = df.query('mid<fin').copy()\n\n\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n  \n\n\n\n\n\ndf2.loc[:,['att','rep']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      2\n      65\n      85\n    \n    \n      4\n      80\n      60\n    \n    \n      5\n      75\n      40\n    \n    \n      6\n      65\n      70\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n93 rows × 2 columns\n\n\n\n\ndf2로 받는 방법 말고 다른 방법이 또 있을 거 같은뎀,,"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html",
    "href": "posts/Data Visualization/DV_13(1128).html",
    "title": "DV 13주차(1)",
    "section": "",
    "text": "import folium \nimport pandas as pd \nimport json \nimport requests"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#folium.polygon",
    "href": "posts/Data Visualization/DV_13(1128).html#folium.polygon",
    "title": "DV 13주차(1)",
    "section": "folium.Polygon",
    "text": "folium.Polygon\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Marker(\n    location = [35.8471, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.1289]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1297]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.12995]\n).add_to(m)\nfolium.Marker(\n    location = [35.8474, 127.1300]\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[35.8471, 127.1291],  # location's'라고 해야함\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[[35.8471, 127.1291],\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n                 \n                 [[ 35.8471 , 127.1302],\n                 [ 35.8468 , 127.1300],\n                 [ 35.84635, 127.1302],\n                 [ 35.84635, 127.1308],\n                 [ 35.8468 , 127.13105],\n                 [ 35.8474 , 127.1311]]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#dict-view-vs-copy",
    "href": "posts/Data Visualization/DV_13(1128).html#dict-view-vs-copy",
    "title": "DV 13주차(1)",
    "section": "dict: view vs copy",
    "text": "dict: view vs copy\n- 원하지 않는 코드\n\ndct1 = {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1 \ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 9999}, {'a': 1, 'b': 2, 'c': 9999})\n\n\n- 원하는 코드\n\ndct1 = {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1.copy()\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 9999})"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#json-파일-다운로드",
    "href": "posts/Data Visualization/DV_13(1128).html#json-파일-다운로드",
    "title": "DV 13주차(1)",
    "section": "json 파일 다운로드",
    "text": "json 파일 다운로드\n\nglobal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json').text)\nlocal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-municipalities-2018-geo.json').text)\n\n\nlocal_dict.keys()\n\ndict_keys(['type', 'features', 'name', 'crs'])"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#json-파일의-구조",
    "href": "posts/Data Visualization/DV_13(1128).html#json-파일의-구조",
    "title": "DV 13주차(1)",
    "section": "json 파일의 구조",
    "text": "json 파일의 구조\n- global_dict의 구조\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘Polygon’\n\n\n\n\n\ncoordinates\n(1,??,2) list\n\n\n\n\nproperties\nname\n‘서울특별시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seoul’\n\n\n\n\n\ncode\n‘11’\n\n\n\n…\n…\n…\n…\n\n\n\n[16]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(6,1,??,2) list\n\n\n\n\nproperties\nname\n‘’제주특별자치도’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jeju-do’\n\n\n\n\n\ncode\n‘39’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’\n\n\n\n\n- local_dict의 구조\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(1,1,??,2) list\n\n\n\n\nproperties\nname\n‘종로구’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jongno-gu’\n\n\n\n\n\ncode\n‘11010’\n\n\n\n…\n…\n…\n…\n\n\n\n[249]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(10,1,??,2) list\n\n\n\n\nproperties\nname\n‘서귀포시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seogwipo-si’\n\n\n\n\n\ncode\n‘39020’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제1-global-scale",
    "href": "posts/Data Visualization/DV_13(1128).html#예제1-global-scale",
    "title": "DV 13주차(1)",
    "section": "예제1: global scale",
    "text": "예제1: global scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start = 8,\n    scroolWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data = global_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제2-local-scale",
    "href": "posts/Data Visualization/DV_13(1128).html#예제2-local-scale",
    "title": "DV 13주차(1)",
    "section": "예제2: local scale",
    "text": "예제2: local scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start = 7,\n    scroolWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data = local_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제3-덕진구-완산구-시각화",
    "href": "posts/Data Visualization/DV_13(1128).html#예제3-덕진구-완산구-시각화",
    "title": "DV 13주차(1)",
    "section": "예제3: 덕진구, 완산구 시각화",
    "text": "예제3: 덕진구, 완산구 시각화\n\nlocal_dict2 = local_dict.copy()\n\n\n_features = [local_dict['features'][i] for i in range(250) if local_dict['features'][i]['properties']['name'] == '전주시덕진구' or local_dict['features'][i]['properties']['name'] == '전주시완산구']\nlocal_dict2['features'] = _features\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n_name_lst = [local_dict['features'][i]['properties']['name'] for i in range(250)]\n\n\n[name for name in _name_lst if '완산' in name or '덕진' in name]\n\n['전주시완산구', '전주시덕진구']"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제1-덕진구-vs-완산구",
    "href": "posts/Data Visualization/DV_13(1128).html#예제1-덕진구-vs-완산구",
    "title": "DV 13주차(1)",
    "section": "예제1: 덕진구 vs 완산구",
    "text": "예제1: 덕진구 vs 완산구\n\n선실습\n\ndf = pd.DataFrame({'key':['전주시덕진구', '전주시완산구'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      전주시완산구\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n    # 연결의 매개체가 되는 것이 무엇인가? 'key'랑 'properties.name'\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n후실습\n이해를 위해 필요한 약간의 직관\n\n예비생각1: 코로플레스맵을 그리기 위해서는 항상 2개의 데이터를 연결해야하는 구조이다. 하나는 json에서 나온 dict (local_dict2), 다른하나는 df이다.\n예비생각2: 두개의 데이터를 연결하기 위해서는 공유가능한 연결의 매개체가 필요하다. (cbind: row-index를 공유, rbind: colnames공유, merge: 양쪽 데이터프레임에서 같은 이름을 가진 특정 col이 있었음)\n예비생각3: 코로플레스맵의 연결매개체는 ‘완산구’, ’덕진구’와 같은 지역명이다.\n\nfolium.Choropleth() 에 사용될 변수들 상상해보기\n\n재료: 두개의 데이터 (json과 df)를 명시해야 한다.\n연결매개체: 두개의 데이터프레임을 연결하는 변수이름을 명시해야 한다.\n색깔표시: (지역명,value)와 같은 쌍을 전달해야 한다."
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#key_on-에-대한-이해",
    "href": "posts/Data Visualization/DV_13(1128).html#key_on-에-대한-이해",
    "title": "DV 13주차(1)",
    "section": "key_on 에 대한 이해",
    "text": "key_on 에 대한 이해\n\n사용예시1: 한글이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n20에 대응하는 것들만 표시되고 미싱되는 것은 검정색 표현\n\n\n\n사용예시2: 영어이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name_eng',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n사용예시3: 코드로 key_on\n\nlocal_dict2['features'][0]['properties'], local_dict2['features'][1]['properties']\n\n({'name': '전주시완산구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusiwansangu',\n  'code': '35011'},\n {'name': '전주시덕진구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusideokjingu',\n  'code': '35012'})\n\n\n\ndf = pd.DataFrame({'code':['35012', '35011'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      code\n      value\n    \n  \n  \n    \n      0\n      35012\n      20\n    \n    \n      1\n      35011\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['code','value'],\n    key_on='properties.code',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제2-대한민국-인구수-시각화-global-scale",
    "href": "posts/Data Visualization/DV_13(1128).html#예제2-대한민국-인구수-시각화-global-scale",
    "title": "DV 13주차(1)",
    "section": "예제2: 대한민국 인구수 시각화 (global scale)",
    "text": "예제2: 대한민국 인구수 시각화 (global scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      서울특별시\n      9532428\n    \n    \n      1\n      부산광역시\n      3356311\n    \n    \n      2\n      대구광역시\n      2390721\n    \n    \n      3\n      인천광역시\n      2945009\n    \n    \n      4\n      광주광역시\n      1442454\n    \n    \n      5\n      대전광역시\n      1454228\n    \n    \n      6\n      울산광역시\n      1122566\n    \n    \n      7\n      세종특별자치시\n      368276\n    \n    \n      8\n      경기도\n      13549577\n    \n    \n      9\n      강원도\n      1537717\n    \n    \n      10\n      충청북도\n      1596948\n    \n    \n      11\n      충청남도\n      2118977\n    \n    \n      12\n      전라북도\n      1789770\n    \n    \n      13\n      전라남도\n      1834653\n    \n    \n      14\n      경상북도\n      2627925\n    \n    \n      15\n      경상남도\n      3318161\n    \n    \n      16\n      제주특별자치도\n      676569\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=global_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1128).html#예제3-대한민국-인구수-시각화-local-scale",
    "href": "posts/Data Visualization/DV_13(1128).html#예제3-대한민국-인구수-시각화-local-scale",
    "title": "DV 13주차(1)",
    "section": "예제3: 대한민국 인구수 시각화 (local scale)",
    "text": "예제3: 대한민국 인구수 시각화 (local scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-muni.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      종로구\n      145346\n    \n    \n      1\n      중구\n      122781\n    \n    \n      2\n      용산구\n      223713\n    \n    \n      3\n      성동구\n      287174\n    \n    \n      4\n      광진구\n      340814\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      269\n      함양군\n      38475\n    \n    \n      270\n      거창군\n      61242\n    \n    \n      271\n      합천군\n      43029\n    \n    \n      272\n      제주시\n      493225\n    \n    \n      273\n      서귀포시\n      183344\n    \n  \n\n274 rows × 2 columns\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html",
    "href": "posts/Data Visualization/DV_8(1024).html",
    "title": "DV 8주차",
    "section": "",
    "text": "!pip install pandas_profiling\n\nCollecting pandas_profiling\n  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 324.4/324.4 kB 13.2 MB/s eta 0:00:00\nCollecting ydata-profiling\n  Downloading ydata_profiling-4.0.0-py2.py3-none-any.whl (344 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 344.5/344.5 kB 43.0 MB/s eta 0:00:00\nCollecting typeguard<2.14,>=2.13.2\n  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: statsmodels<0.14,>=0.13.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.13.5)\nRequirement already satisfied: scipy<1.10,>=1.4.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.7.3)\nRequirement already satisfied: jinja2<3.2,>=2.11.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.1.2)\nCollecting PyYAML<6.1,>=5.0.0\n  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 596.3/596.3 kB 68.7 MB/s eta 0:00:00\nCollecting phik<0.13,>=0.11.1\n  Downloading phik-0.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (680 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 680.0/680.0 kB 36.1 MB/s eta 0:00:00\nCollecting multimethod<1.10,>=1.4\n  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\nCollecting pydantic<1.11,>=1.8.1\n  Downloading pydantic-1.10.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 78.6 MB/s eta 0:00:00:00:01\nRequirement already satisfied: matplotlib<3.7,>=3.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.5.3)\nRequirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.3.5)\nCollecting htmlmin==0.1.12\n  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... done\nRequirement already satisfied: numpy<1.24,>=1.16.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.21.6)\nRequirement already satisfied: seaborn<0.13,>=0.10.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.12.2)\nCollecting tqdm<4.65,>=4.48.2\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 15.4 MB/s eta 0:00:00\nRequirement already satisfied: requests<2.29,>=2.24.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (2.28.2)\nCollecting visions[type_image_path]==0.7.5\n  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.7/102.7 kB 20.6 MB/s eta 0:00:00\nRequirement already satisfied: attrs>=19.3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (22.2.0)\nCollecting networkx>=2.4\n  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 90.1 MB/s eta 0:00:00\nCollecting tangled-up-in-unicode>=0.0.4\n  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 93.1 MB/s eta 0:00:00ta 0:00:01\nRequirement already satisfied: Pillow in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (9.4.0)\nCollecting imagehash\n  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 296.5/296.5 kB 56.5 MB/s eta 0:00:00\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.1)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (23.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (4.38.0)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\nCollecting joblib>=0.14.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 52.3 MB/s eta 0:00:00\nRequirement already satisfied: typing-extensions>=4.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas_profiling) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\nRequirement already satisfied: patsy>=0.5.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\nRequirement already satisfied: six in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\nCollecting PyWavelets\n  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.4/6.4 MB 85.2 MB/s eta 0:00:00:00:0100:01\nBuilding wheels for collected packages: htmlmin\n  Building wheel for htmlmin (setup.py) ... done\n  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=7bcfaa4b7942dcfb19895abe1a49d1c43c9f2d12c73d8bc74499ddcb933893c8\n  Stored in directory: /home/koinup4/.cache/pip/wheels/56/18/c1/6b3058b1db1f804221515aac5ecf2513d5ba971f33b8560c7a\nSuccessfully built htmlmin\nInstalling collected packages: htmlmin, typeguard, tqdm, tangled-up-in-unicode, PyYAML, PyWavelets, pydantic, networkx, multimethod, joblib, imagehash, visions, phik, ydata-profiling, pandas_profiling\nSuccessfully installed PyWavelets-1.3.0 PyYAML-6.0 htmlmin-0.1.12 imagehash-4.3.1 joblib-1.2.0 multimethod-1.9.1 networkx-2.6.3 pandas_profiling-3.6.6 phik-0.12.3 pydantic-1.10.5 tangled-up-in-unicode-0.2.0 tqdm-4.64.1 typeguard-2.13.3 visions-0.7.5 ydata-profiling-4.0.0"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#모티브",
    "href": "posts/Data Visualization/DV_8(1024).html#모티브",
    "title": "DV 8주차",
    "section": "모티브",
    "text": "모티브\n- 원본데이터를 가급적 손상시키지 않으면서 데이터를 변형하고 싶음\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n복사본 생성\n\ndf2 = df\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n\ndf2['C'] = (df2.A+df2.B)/2\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf2['D'] = (df2.C - np.mean(df2.C))/np.std(df2.C)\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf  # 왜 C랑 D 값이 들어가있노?\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\nshallow copy\ndeep copy"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#해결책1",
    "href": "posts/Data Visualization/DV_8(1024).html#해결책1",
    "title": "DV 8주차",
    "section": "해결책1",
    "text": "해결책1\n- 올바른코드1\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf2 = df.copy() \ndf2['C'] = (df2.A+ df2.B)/2\ndf2['D']= (df2.C - np.mean(df2.C))/np.std(df2.C) \n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n- 올바른 코드2 (eval)\n\ndf.eval('C=(A+B)/2').eval('D=C-mean(c))/std(C)')\n\nTokenError: ('EOF in multi-line statement', (2, 0))\n\n\n\nmean([1,2,3]) # 정의가 안되있으무로\n\nNameError: name 'mean' is not defined\n\n\n\nmean = np.mean\n\n\nmean([1,2,3])\n\n2.0\n\n\n\nmean = np.mean\nstd = np.std\ndf.eval('C=(A+B)/2').eval('D=(C-@mean(C))/@std(C)')\n# 외부에서 온 거란 걸 표시해주기 위해서 mean앞에 @ 붙인다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\n어디까지 eval expression 안에서 지원되는지 명확하지 않고\n외부에 함수를 선언하고 eval expression 안에 @를 붙이는게 가독성이 없다.\n\n- 올바른 코드3 (assign) —-> 실패\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf.assign(C=(df.A+df.B)/2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf.assign(C=(df.A+df.B)/2).assign(D=(df.C-np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n\n# df.C 하면 나오는 오류와 동일한 오류가 위처럼 나타난다.\n\n\ndf.assign(C=(df.A+df.B)/2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n아래와 같이 고쳐야함\n\n_df = df.assign(C=(df.A+df.B)/2)\n_df.assign(D=(_df.C-np.mean(_df.C))/np.std(_df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#해결책2-assign",
    "href": "posts/Data Visualization/DV_8(1024).html#해결책2-assign",
    "title": "DV 8주차",
    "section": "해결책2 (assign)",
    "text": "해결책2 (assign)\n실패한 코드\n\ndf.assign(C=(df.A+df.B)/2).assign(D=(df.C-np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n두번째 assign에서 표현된 df.C에서 df current df ( = df.assign(C=(df.A+df.B)/2) 까지 연산된 상태) 를 의미하도록 만들고 싶다. \\(\\to\\) 아래와 같이 lambda df: 를 추가하면 된다.\n\ndf.assign(C=(df.A+df.B)/2).assign(D= lambda df: (df.C-np.mean(df.C))/np.std(df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n- 연쇄할당\n\ndf.assign(C= (df.A+df.B)/2).assign(D= lambda df:df.C+2).assign(E = lambda df: df.D - 2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      2.5\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n      3.5\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n      4.5\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n      5.5\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n      6.5\n      4.5"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#fifa23-data",
    "href": "posts/Data Visualization/DV_8(1024).html#fifa23-data",
    "title": "DV 8주차",
    "section": "FIFA23 DATA",
    "text": "FIFA23 DATA\n- FIFA23 라는 축구게임이 있음\n- 선수들의 능력치에 대한 데이터셋은 캐글에 공개 되어 있다.\nhttps://www.kaggle.com/datasets/bryanb/fifa-player-stats-database?select=FIFA23_official_data.csv"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#데이터-살펴보기",
    "href": "posts/Data Visualization/DV_8(1024).html#데이터-살펴보기",
    "title": "DV 8주차",
    "section": "데이터 살펴보기",
    "text": "데이터 살펴보기\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/FIFA23_official_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n  \n\n5 rows × 29 columns\n\n\n\n트랜스포즈하여 보는 것이 편할 때도 있다\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      17650\n      17651\n      17652\n      17653\n      17654\n      17655\n      17656\n      17657\n      17658\n      17659\n    \n  \n  \n    \n      ID\n      209658\n      212198\n      224334\n      192985\n      224232\n      212622\n      197445\n      187961\n      208333\n      210514\n      ...\n      256879\n      269546\n      267647\n      253186\n      267461\n      269526\n      267946\n      270567\n      256624\n      256376\n    \n    \n      Name\n      L. Goretzka\n      Bruno Fernandes\n      M. Acuña\n      K. De Bruyne\n      N. Barella\n      J. Kimmich\n      D. Alaba\n      22 Paulinho\n      E. Can\n      João Cancelo\n      ...\n      22 G. Leijon\n      Wu Fei\n      22 E. Grosz\n      22 S. Booth\n      22 L. Grimpe\n      Deng Xiongtao\n      22 Lim Jun Sub\n      A. Demir\n      21 S. Czajor\n      21 F. Jakobsson\n    \n    \n      Age\n      27\n      27\n      30\n      31\n      25\n      27\n      30\n      32\n      28\n      28\n      ...\n      19\n      32\n      18\n      20\n      17\n      19\n      17\n      25\n      18\n      20\n    \n    \n      Photo\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      https://cdn.sofifa.net/players/212/622/23_60.png\n      https://cdn.sofifa.net/players/197/445/23_60.png\n      https://cdn.sofifa.net/players/187/961/22_60.png\n      https://cdn.sofifa.net/players/208/333/23_60.png\n      https://cdn.sofifa.net/players/210/514/23_60.png\n      ...\n      https://cdn.sofifa.net/players/256/879/22_60.png\n      https://cdn.sofifa.net/players/269/546/23_60.png\n      https://cdn.sofifa.net/players/267/647/22_60.png\n      https://cdn.sofifa.net/players/253/186/22_60.png\n      https://cdn.sofifa.net/players/267/461/22_60.png\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      https://cdn.sofifa.net/players/256/376/21_60.png\n    \n    \n      Nationality\n      Germany\n      Portugal\n      Argentina\n      Belgium\n      Italy\n      Germany\n      Austria\n      Brazil\n      Germany\n      Portugal\n      ...\n      Sweden\n      China PR\n      Romania\n      England\n      Germany\n      China PR\n      Korea Republic\n      Turkey\n      Poland\n      Sweden\n    \n    \n      Flag\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      https://cdn.sofifa.net/flags/ar.png\n      https://cdn.sofifa.net/flags/be.png\n      https://cdn.sofifa.net/flags/it.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/at.png\n      https://cdn.sofifa.net/flags/br.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      ...\n      https://cdn.sofifa.net/flags/se.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/ro.png\n      https://cdn.sofifa.net/flags/gb-eng.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/kr.png\n      https://cdn.sofifa.net/flags/tr.png\n      https://cdn.sofifa.net/flags/pl.png\n      https://cdn.sofifa.net/flags/se.png\n    \n    \n      Overall\n      87\n      86\n      85\n      91\n      86\n      89\n      86\n      83\n      82\n      88\n      ...\n      52\n      51\n      52\n      51\n      54\n      48\n      48\n      51\n      50\n      50\n    \n    \n      Potential\n      88\n      87\n      85\n      91\n      89\n      90\n      86\n      83\n      82\n      88\n      ...\n      62\n      51\n      70\n      60\n      68\n      61\n      64\n      56\n      65\n      61\n    \n    \n      Club\n      FC Bayern München\n      Manchester United\n      Sevilla FC\n      Manchester City\n      Inter\n      FC Bayern München\n      Real Madrid CF\n      Al Ahli\n      Borussia Dortmund\n      Manchester City\n      ...\n      Örebro SK\n      Wuhan Three Towns\n      Gaz Metan Mediaş\n      Crewe Alexandra\n      RB Leipzig\n      Meizhou Hakka\n      Jeju United FC\n      Ümraniyespor\n      Fleetwood Town\n      IFK Norrköping\n    \n    \n      Club Logo\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/11/30.png\n      https://cdn.sofifa.net/teams/481/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      https://cdn.sofifa.net/teams/44/30.png\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/243/30.png\n      https://cdn.sofifa.net/teams/112387/30.png\n      https://cdn.sofifa.net/teams/22/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      https://cdn.sofifa.net/teams/705/30.png\n      https://cdn.sofifa.net/teams/116361/30.png\n      https://cdn.sofifa.net/teams/112637/30.png\n      https://cdn.sofifa.net/teams/121/30.png\n      https://cdn.sofifa.net/teams/112172/30.png\n      https://cdn.sofifa.net/teams/114628/30.png\n      https://cdn.sofifa.net/teams/1478/30.png\n      https://cdn.sofifa.net/teams/113796/30.png\n      https://cdn.sofifa.net/teams/112260/30.png\n      https://cdn.sofifa.net/teams/702/30.png\n    \n    \n      Value\n      €91M\n      €78.5M\n      €46.5M\n      €107.5M\n      €89.5M\n      €105.5M\n      €55.5M\n      €28.5M\n      €30.5M\n      €82.5M\n      ...\n      €150K\n      €30K\n      €180K\n      €110K\n      €210K\n      €100K\n      €100K\n      €70K\n      €90K\n      €90K\n    \n    \n      Wage\n      €115K\n      €190K\n      €46K\n      €350K\n      €110K\n      €130K\n      €220K\n      €61K\n      €63K\n      €250K\n      ...\n      €500\n      €2K\n      €500\n      €850\n      €500\n      €500\n      €500\n      €2K\n      €500\n      €500\n    \n    \n      Special\n      2312\n      2305\n      2303\n      2303\n      2296\n      2283\n      2277\n      2273\n      2271\n      2262\n      ...\n      779\n      777\n      775\n      768\n      767\n      762\n      761\n      759\n      758\n      749\n    \n    \n      Preferred Foot\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      ...\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Left\n    \n    \n      International Reputation\n      4.0\n      3.0\n      2.0\n      4.0\n      3.0\n      4.0\n      4.0\n      3.0\n      3.0\n      3.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Weak Foot\n      4.0\n      3.0\n      3.0\n      5.0\n      3.0\n      4.0\n      4.0\n      4.0\n      4.0\n      4.0\n      ...\n      3.0\n      2.0\n      2.0\n      2.0\n      3.0\n      3.0\n      2.0\n      2.0\n      2.0\n      2.0\n    \n    \n      Skill Moves\n      3.0\n      4.0\n      3.0\n      4.0\n      3.0\n      3.0\n      3.0\n      4.0\n      3.0\n      4.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Work Rate\n      High/ Medium\n      High/ High\n      High/ High\n      High/ High\n      High/ High\n      High/ Medium\n      Medium/ Medium\n      High/ High\n      Medium/ High\n      High/ Medium\n      ...\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n    \n    \n      Body Type\n      Unique\n      Unique\n      Stocky (170-185)\n      Unique\n      Normal (170-)\n      Normal (170-185)\n      Normal (170-185)\n      Normal (170-185)\n      Stocky (185+)\n      Unique\n      ...\n      Normal (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Normal (185+)\n    \n    \n      Real Face\n      Yes\n      Yes\n      No\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      ...\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n    \n    \n      Position\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos7\">LB\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos9\">RDM\n      <span class=\"pos pos6\">LCB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos7\">LB\n      ...\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n    \n    \n      Joined\n      Jul 1, 2018\n      Jan 30, 2020\n      Sep 14, 2020\n      Aug 30, 2015\n      Sep 1, 2020\n      Jul 1, 2015\n      Jul 1, 2021\n      Jul 22, 2021\n      Feb 18, 2020\n      Aug 7, 2019\n      ...\n      Jun 14, 2020\n      Feb 15, 2019\n      Jul 1, 2020\n      Jul 1, 2019\n      Feb 7, 2022\n      Apr 11, 2022\n      Jan 1, 2022\n      Jun 6, 2021\n      Jan 1, 2020\n      Jan 8, 2020\n    \n    \n      Loaned From\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      Contract Valid Until\n      2026\n      2026\n      2024\n      2025\n      2026\n      2025\n      2026\n      2024\n      2024\n      2027\n      ...\n      2022\n      2022\n      2022\n      2022\n      2023\n      2027\n      2026\n      2023\n      2021\n      2021\n    \n    \n      Height\n      189cm\n      179cm\n      172cm\n      181cm\n      172cm\n      177cm\n      180cm\n      183cm\n      186cm\n      182cm\n      ...\n      188cm\n      186cm\n      190cm\n      195cm\n      186cm\n      190cm\n      195cm\n      190cm\n      187cm\n      186cm\n    \n    \n      Weight\n      82kg\n      69kg\n      69kg\n      70kg\n      68kg\n      75kg\n      78kg\n      80kg\n      86kg\n      74kg\n      ...\n      81kg\n      78kg\n      70kg\n      80kg\n      78kg\n      78kg\n      84kg\n      82kg\n      79kg\n      78kg\n    \n    \n      Release Clause\n      €157M\n      €155M\n      €97.7M\n      €198.9M\n      €154.4M\n      €182M\n      €113.8M\n      €48.5M\n      €51.9M\n      €152.6M\n      ...\n      €218K\n      €47K\n      €356K\n      €215K\n      €488K\n      €218K\n      €188K\n      €142K\n      €214K\n      €131K\n    \n    \n      Kit Number\n      8.0\n      8.0\n      19.0\n      17.0\n      23.0\n      6.0\n      4.0\n      15.0\n      23.0\n      7.0\n      ...\n      33.0\n      1.0\n      99.0\n      27.0\n      43.0\n      35.0\n      21.0\n      12.0\n      40.0\n      30.0\n    \n    \n      Best Overall Rating\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n29 rows × 17660 columns\n\n\n\n\ncolumns 조사\n\ndf.keys()\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\ndf.Body Type\n\nSyntaxError: invalid syntax (<ipython-input-29-8965601661e6>, line 1)\n\n\n띄어쓰기가 되어있어서 흠..\n\n\n각 column별로 자료형 조사\n\ndf['ID'].dtype\n\n\nfor key in df.keys():\n    print(df[key].dtype)\n\n\ndtypes = [df[key].dtype for key in df.keys()]\npd.DataFrame({'colname':df.keys(), 'dtype':dtypes})\n\n\n\n결측치 조사\n\n[df[key].isna().sum() for key in df.keys()]\n\n\npd.DataFrame({'colname':df.keys(), \n              'dtype':[df[key].dtype for key in df.keys()], \n              'na':[df[key].isna().sum() for key in df.keys()]})\n\n\n\n\n\n  \n    \n      \n      colname\n      dtype\n      na\n    \n  \n  \n    \n      0\n      ID\n      int64\n      0\n    \n    \n      1\n      Name\n      object\n      0\n    \n    \n      2\n      Age\n      int64\n      0\n    \n    \n      3\n      Photo\n      object\n      0\n    \n    \n      4\n      Nationality\n      object\n      0\n    \n    \n      5\n      Flag\n      object\n      0\n    \n    \n      6\n      Overall\n      int64\n      0\n    \n    \n      7\n      Potential\n      int64\n      0\n    \n    \n      8\n      Club\n      object\n      211\n    \n    \n      9\n      Club Logo\n      object\n      0\n    \n    \n      10\n      Value\n      object\n      0\n    \n    \n      11\n      Wage\n      object\n      0\n    \n    \n      12\n      Special\n      int64\n      0\n    \n    \n      13\n      Preferred Foot\n      object\n      0\n    \n    \n      14\n      International Reputation\n      float64\n      0\n    \n    \n      15\n      Weak Foot\n      float64\n      0\n    \n    \n      16\n      Skill Moves\n      float64\n      0\n    \n    \n      17\n      Work Rate\n      object\n      0\n    \n    \n      18\n      Body Type\n      object\n      38\n    \n    \n      19\n      Real Face\n      object\n      38\n    \n    \n      20\n      Position\n      object\n      35\n    \n    \n      21\n      Joined\n      object\n      1098\n    \n    \n      22\n      Loaned From\n      object\n      16966\n    \n    \n      23\n      Contract Valid Until\n      object\n      361\n    \n    \n      24\n      Height\n      object\n      0\n    \n    \n      25\n      Weight\n      object\n      0\n    \n    \n      26\n      Release Clause\n      object\n      1151\n    \n    \n      27\n      Kit Number\n      float64\n      35\n    \n    \n      28\n      Best Overall Rating\n      object\n      17639\n    \n  \n\n\n\n\n\n열의선택: 결측치가 10000개 이상인 열을 보고싶다면?\n\n\ndf.loc[:,[df[key].isna().sum()>10000 for key in df.keys()]]\n\n\n\n\n\n  \n    \n      \n      Loaned From\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      17655\n      NaN\n      NaN\n    \n    \n      17656\n      NaN\n      NaN\n    \n    \n      17657\n      NaN\n      NaN\n    \n    \n      17658\n      NaN\n      NaN\n    \n    \n      17659\n      NaN\n      NaN\n    \n  \n\n17660 rows × 2 columns\n\n\n\n\n\n.info()\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n### .describe()\n숫자들이 저장된 column에 대하여 기본통계량 조사\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      ID\n      Age\n      Overall\n      Potential\n      Special\n      International Reputation\n      Weak Foot\n      Skill Moves\n      Kit Number\n    \n  \n  \n    \n      count\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17625.000000\n    \n    \n      mean\n      246319.424462\n      23.127746\n      63.369592\n      70.981200\n      1537.915855\n      1.106285\n      2.900340\n      2.297169\n      25.037957\n    \n    \n      std\n      31487.892861\n      4.639821\n      8.036268\n      6.529836\n      285.893809\n      0.407021\n      0.663523\n      0.754264\n      19.154116\n    \n    \n      min\n      16.000000\n      15.000000\n      43.000000\n      42.000000\n      749.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n    \n    \n      25%\n      240732.500000\n      20.000000\n      58.000000\n      67.000000\n      1387.000000\n      1.000000\n      3.000000\n      2.000000\n      11.000000\n    \n    \n      50%\n      257041.000000\n      22.000000\n      63.000000\n      71.000000\n      1548.000000\n      1.000000\n      3.000000\n      2.000000\n      22.000000\n    \n    \n      75%\n      263027.500000\n      26.000000\n      69.000000\n      75.000000\n      1727.000000\n      1.000000\n      3.000000\n      3.000000\n      32.000000\n    \n    \n      max\n      271340.000000\n      54.000000\n      91.000000\n      95.000000\n      2312.000000\n      5.000000\n      5.000000\n      5.000000\n      99.000000\n    \n  \n\n\n\n\n- pandas_profiling.ProfileReport()를 이용한 전체적인 조사\n\npandas_profiling.ProfileReport(df).to_file('fifa2023_reprot.html')\n\n\n\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/pandas_profiling/model/correlations.py:73: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\nTo hide this warning, disable the calculation\n(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\nIf this is problematic for your use case, please report this as an issue:\nhttps://github.com/ydataai/pandas-profiling/issues\n(include the error message: 'No data; `observed` has size 0.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n특정열을 중심으로 정렬하여 보기\n\ndf.sort_values(by='Overall', ascending=False) \n# ascending=False  # 내림차순\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      41\n      188545\n      R. Lewandowski\n      33\n      https://cdn.sofifa.net/players/188/545/23_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      91\n      91\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 18, 2022\n      NaN\n      2025\n      185cm\n      81kg\n      €172.2M\n      9.0\n      NaN\n    \n    \n      124\n      165153\n      K. Benzema\n      34\n      https://cdn.sofifa.net/players/165/153/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      91\n      Real Madrid CF\n      https://cdn.sofifa.net/teams/243/30.png\n      ...\n      Yes\n      <span class=\"pos pos21\">CF\n      Jul 9, 2009\n      NaN\n      2023\n      185cm\n      81kg\n      €131.2M\n      9.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      56\n      158023\n      L. Messi\n      35\n      https://cdn.sofifa.net/players/158/023/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      91\n      91\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos23\">RW\n      Aug 10, 2021\n      NaN\n      2023\n      169cm\n      67kg\n      €99.9M\n      30.0\n      NaN\n    \n    \n      75\n      231747\n      K. Mbappé\n      23\n      https://cdn.sofifa.net/players/231/747/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      95\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 1, 2018\n      NaN\n      2025\n      182cm\n      73kg\n      €366.7M\n      7.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      15513\n      266751\n      22 Jung Ho Yeon\n      20\n      https://cdn.sofifa.net/players/266/751/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      45\n      53\n      GwangJu FC\n      https://cdn.sofifa.net/teams/112258/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 20, 2022\n      NaN\n      2026\n      180cm\n      73kg\n      €145K\n      23.0\n      NaN\n    \n    \n      16215\n      268279\n      22 J. Looschen\n      24\n      https://cdn.sofifa.net/players/268/279/22_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      44\n      47\n      SV Meppen\n      https://cdn.sofifa.net/teams/110597/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Mar 19, 2022\n      NaN\n      2026\n      178cm\n      78kg\n      €92K\n      42.0\n      NaN\n    \n    \n      16042\n      255283\n      20 Kim Yeong Geun\n      22\n      https://cdn.sofifa.net/players/255/283/20_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      44\n      49\n      Gyeongnam FC\n      https://cdn.sofifa.net/teams/111588/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 9, 2020\n      NaN\n      2020\n      174cm\n      71kg\n      €53K\n      43.0\n      NaN\n    \n    \n      14634\n      269038\n      22 Zhang Wenxuan\n      16\n      https://cdn.sofifa.net/players/269/038/22_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      44\n      59\n      Guangzhou FC\n      https://cdn.sofifa.net/teams/111839/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      May 1, 2022\n      NaN\n      2022\n      175cm\n      70kg\n      €239K\n      29.0\n      NaN\n    \n    \n      17618\n      168933\n      07 I. Paskov\n      33\n      https://cdn.sofifa.net/players/168/933/07_60.png\n      Bulgaria\n      https://cdn.sofifa.net/flags/bg.png\n      43\n      42\n      NaN\n      https://cdn.sofifa.net/flags/bg.png\n      ...\n      NaN\n      <span class=\"pos pos28\">SUB\n      NaN\n      NaN\n      NaN\n      184cm\n      79kg\n      NaN\n      24.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.sort_values(by='Overall', ascending=False,ignore_index=True)\n# df.sort_values(by='Overall', ascending=False).reset_index() 와 같음\n# 맨 왼쪽 인덱스 순서 정렬\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      188545\n      R. Lewandowski\n      33\n      https://cdn.sofifa.net/players/188/545/23_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      91\n      91\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 18, 2022\n      NaN\n      2025\n      185cm\n      81kg\n      €172.2M\n      9.0\n      NaN\n    \n    \n      1\n      165153\n      K. Benzema\n      34\n      https://cdn.sofifa.net/players/165/153/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      91\n      Real Madrid CF\n      https://cdn.sofifa.net/teams/243/30.png\n      ...\n      Yes\n      <span class=\"pos pos21\">CF\n      Jul 9, 2009\n      NaN\n      2023\n      185cm\n      81kg\n      €131.2M\n      9.0\n      NaN\n    \n    \n      2\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      3\n      158023\n      L. Messi\n      35\n      https://cdn.sofifa.net/players/158/023/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      91\n      91\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos23\">RW\n      Aug 10, 2021\n      NaN\n      2023\n      169cm\n      67kg\n      €99.9M\n      30.0\n      NaN\n    \n    \n      4\n      231747\n      K. Mbappé\n      23\n      https://cdn.sofifa.net/players/231/747/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      95\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 1, 2018\n      NaN\n      2025\n      182cm\n      73kg\n      €366.7M\n      7.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      266751\n      22 Jung Ho Yeon\n      20\n      https://cdn.sofifa.net/players/266/751/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      45\n      53\n      GwangJu FC\n      https://cdn.sofifa.net/teams/112258/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 20, 2022\n      NaN\n      2026\n      180cm\n      73kg\n      €145K\n      23.0\n      NaN\n    \n    \n      17656\n      268279\n      22 J. Looschen\n      24\n      https://cdn.sofifa.net/players/268/279/22_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      44\n      47\n      SV Meppen\n      https://cdn.sofifa.net/teams/110597/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Mar 19, 2022\n      NaN\n      2026\n      178cm\n      78kg\n      €92K\n      42.0\n      NaN\n    \n    \n      17657\n      255283\n      20 Kim Yeong Geun\n      22\n      https://cdn.sofifa.net/players/255/283/20_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      44\n      49\n      Gyeongnam FC\n      https://cdn.sofifa.net/teams/111588/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 9, 2020\n      NaN\n      2020\n      174cm\n      71kg\n      €53K\n      43.0\n      NaN\n    \n    \n      17658\n      269038\n      22 Zhang Wenxuan\n      16\n      https://cdn.sofifa.net/players/269/038/22_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      44\n      59\n      Guangzhou FC\n      https://cdn.sofifa.net/teams/111839/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      May 1, 2022\n      NaN\n      2022\n      175cm\n      70kg\n      €239K\n      29.0\n      NaN\n    \n    \n      17659\n      168933\n      07 I. Paskov\n      33\n      https://cdn.sofifa.net/players/168/933/07_60.png\n      Bulgaria\n      https://cdn.sofifa.net/flags/bg.png\n      43\n      42\n      NaN\n      https://cdn.sofifa.net/flags/bg.png\n      ...\n      NaN\n      <span class=\"pos pos28\">SUB\n      NaN\n      NaN\n      NaN\n      184cm\n      79kg\n      NaN\n      24.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\n\n특정열을 중심으로 그룹화하여 보기(\\(\\star\\)): groupby\n\ndf.query('Nationality == \"Germany\"')['Overall'].mean()\n\n63.50481695568401\n\n\n\ndf.Nationality.unique()\n\narray(['Germany', 'Portugal', 'Argentina', 'Belgium', 'Italy', 'Austria',\n       'Brazil', 'Croatia', 'Serbia', 'Spain', 'Netherlands', 'France',\n       'Colombia', 'England', 'Uruguay', 'Morocco', 'Egypt', 'Algeria',\n       'Ukraine', 'United States', \"Côte d'Ivoire\", 'Poland', 'Chile',\n       'Senegal', 'Central African Republic', 'Denmark', 'Nigeria',\n       'Mexico', 'Turkey', 'Canada', 'Wales', 'Scotland', 'Romania',\n       'Czech Republic', 'Ghana', 'Korea Republic',\n       'Bosnia and Herzegovina', 'Mali', 'Slovakia', 'Armenia', 'Norway',\n       'Switzerland', 'Cameroon', 'Peru', 'Jamaica', 'Zambia', 'Guinea',\n       'Sweden', 'North Macedonia', 'Russia', 'Tunisia', 'Malta',\n       'Angola', 'Republic of Ireland', 'Ecuador', 'Benin', 'Paraguay',\n       'Montenegro', 'Australia', 'Comoros', 'Gabon', 'Iceland',\n       'Slovenia', 'Japan', 'Israel', 'China PR', 'Venezuela', 'Liberia',\n       'Greece', 'Bulgaria', 'Honduras', 'Saudi Arabia', 'Curacao',\n       'Northern Ireland', 'Guinea Bissau', 'Kosovo', 'Hungary',\n       'Finland', 'Costa Rica', 'Albania', 'Congo DR', 'Iran',\n       'Mozambique', 'Suriname', 'Cape Verde Islands', 'Bolivia',\n       'Madagascar', 'New Zealand', 'Burkina Faso', 'Dominican Republic',\n       'Kazakhstan', 'Syria', 'Luxembourg', 'Kenya', 'Zimbabwe', 'Haiti',\n       'Uzbekistan', 'South Africa', 'Cyprus', 'Qatar',\n       'Equatorial Guinea', 'Libya', 'Thailand', 'Togo',\n       'Trinidad and Tobago', 'Liechtenstein', 'Gambia', 'Georgia',\n       'Philippines', 'Burundi', 'United Arab Emirates', 'Grenada',\n       'Iraq', 'Panama', 'Malaysia', 'Moldova', 'Congo', 'India',\n       'Jordan', 'Kuwait', 'Antigua and Barbuda', 'Cuba', 'Vietnam',\n       'Korea DPR', 'Uganda', 'Lithuania', 'Estonia', 'Montserrat',\n       'Sierra Leone', 'Afghanistan', 'New Caledonia', 'Belarus', 'Laos',\n       'Saint Lucia', 'Bhutan', 'Guyana', 'Mauritania', 'Faroe Islands',\n       'Namibia', 'Niger', 'Palestine', 'Sudan', 'Azerbaijan',\n       'Hong Kong', 'Gibraltar', 'Tanzania', 'Latvia', 'Chinese Taipei',\n       'Singapore', 'Lebanon', 'El Salvador', 'Indonesia', 'Guatemala',\n       'Papua New Guinea', 'Puerto Rico', 'Malawi', 'South Sudan',\n       'Ethiopia', 'San Marino', 'Andorra', 'Saint Kitts and Nevis'],\n      dtype=object)\n\n\n\nlen(df.Nationality.unique())\n\n161\n\n\n\ndf.groupby(by='Nationality')[['Overall']].agg({np.mean,len}).sort_values(('Overall', 'mean'),ascending=False)\n\n\n\n\n\n  \n    \n      \n      Overall\n    \n    \n      \n      mean\n      len\n    \n    \n      Nationality\n      \n      \n    \n  \n  \n    \n      Philippines\n      74.000000\n      1\n    \n    \n      Namibia\n      72.000000\n      1\n    \n    \n      Mozambique\n      72.000000\n      2\n    \n    \n      Kuwait\n      71.000000\n      1\n    \n    \n      Brazil\n      70.556586\n      539\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      San Marino\n      53.000000\n      1\n    \n    \n      China PR\n      52.230769\n      325\n    \n    \n      South Sudan\n      52.000000\n      5\n    \n    \n      India\n      51.994681\n      188\n    \n    \n      Saint Kitts and Nevis\n      51.000000\n      1\n    \n  \n\n161 rows × 2 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#데이터-정리하기",
    "href": "posts/Data Visualization/DV_8(1024).html#데이터-정리하기",
    "title": "DV 8주차",
    "section": "데이터 정리하기",
    "text": "데이터 정리하기\n\n칼럼이름 변경\n\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\nlist(map(lambda x: x.replace(' ','_'), df.columns))\n\n['ID',\n 'Name',\n 'Age',\n 'Photo',\n 'Nationality',\n 'Flag',\n 'Overall',\n 'Potential',\n 'Club',\n 'Club_Logo',\n 'Value',\n 'Wage',\n 'Special',\n 'Preferred_Foot',\n 'International_Reputation',\n 'Weak_Foot',\n 'Skill_Moves',\n 'Work_Rate',\n 'Body_Type',\n 'Real_Face',\n 'Position',\n 'Joined',\n 'Loaned_From',\n 'Contract_Valid_Until',\n 'Height',\n 'Weight',\n 'Release_Clause',\n 'Kit_Number',\n 'Best_Overall_Rating']\n\n\n\ndf.set_axis(list(map(lambda x: x.replace(' ','_'), df.columns)), axis=1)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club_Logo\n      ...\n      Real_Face\n      Position\n      Joined\n      Loaned_From\n      Contract_Valid_Until\n      Height\n      Weight\n      Release_Clause\n      Kit_Number\n      Best_Overall_Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.set_axis(pd.Index(map(lambda x: x.replace(' ','_'), df.columns)), axis=1)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club_Logo\n      ...\n      Real_Face\n      Position\n      Joined\n      Loaned_From\n      Contract_Valid_Until\n      Height\n      Weight\n      Release_Clause\n      Kit_Number\n      Best_Overall_Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\nindex 로 쓰는게 좀 더 명확함\n\n\n\n결측치 제거\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n\ndf.drop(columns=['Loaned From', 'Best Overall Rating'])\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n    \n  \n\n17660 rows × 27 columns\n\n\n\n- Height, Weight의 자료형을 float형으로 수정하기\n\ndf[['Height', 'Weight']]\n\n\n\n\n\n  \n    \n      \n      Height\n      Weight\n    \n  \n  \n    \n      0\n      189cm\n      82kg\n    \n    \n      1\n      179cm\n      69kg\n    \n    \n      2\n      172cm\n      69kg\n    \n    \n      3\n      181cm\n      70kg\n    \n    \n      4\n      172cm\n      68kg\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      17655\n      190cm\n      78kg\n    \n    \n      17656\n      195cm\n      84kg\n    \n    \n      17657\n      190cm\n      82kg\n    \n    \n      17658\n      187cm\n      79kg\n    \n    \n      17659\n      186cm\n      78kg\n    \n  \n\n17660 rows × 2 columns\n\n\n\ncm, kg으로 되어있어서 object형인데 이걸 float형으로 바꾸자\n\ndf.assign(\n    Height= list(map(lambda x: float(x[:-2]), df.Height)),\n    Weight= list(map(lambda x: float(x[:-2]), df.Weight))\n)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189.0\n      82.0\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179.0\n      69.0\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172.0\n      69.0\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181.0\n      70.0\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172.0\n      68.0\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190.0\n      78.0\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195.0\n      84.0\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190.0\n      82.0\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187.0\n      79.0\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186.0\n      78.0\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n- Release Clause의 자료형을 float으로 수정하기\n\ndf['Release Clause']\n\n0          €157M\n1          €155M\n2         €97.7M\n3        €198.9M\n4        €154.4M\n          ...   \n17655      €218K\n17656      €188K\n17657      €142K\n17658      €214K\n17659      €131K\nName: Release Clause, Length: 17660, dtype: object\n\n\n\n_f = lambda x: float(x[1:-1])*1000 if x[-1]=='K' else float(x[1:-1])*1000000\n\n\n_f('€157M')\n\n157000000.0\n\n\n\n_f('€131K')\n\n131000.0\n\n\n(시도1) - 실패\n\nlist(map(_f, df['Release Clause']))\n\nTypeError: 'float' object is not subscriptable\n\n\n\ndf['Release Clause'].isna().sum()   # 이 column에는 1151개의 결측치가 존재\n\n1151\n\n\n(nan에 대한 예비학습)\n\ndf.loc[df['Release Clause'].isna(), 'Release Clause']\n\n18       NaN\n34       NaN\n38       NaN\n49       NaN\n50       NaN\n        ... \n17378    NaN\n17386    NaN\n17535    NaN\n17590    NaN\n17618    NaN\nName: Release Clause, Length: 1151, dtype: object\n\n\n\ndf.loc[18, 'Release Clause']\n\nnan\n\n\n\npd.isna(df.loc[18, 'Release Clause'])\n\nTrue\n\n\n\ntype(df.loc[18, 'Release Clause'])\n\nfloat\n\n\n\ndf.loc[18, 'Release Clause'][-1]\n\nTypeError: 'float' object is not subscriptable\n\n\n\n_f 함수에는 문자열이 들어가야하는데 nan이 들어가니까 에러가 뜸..\n\n(시도2) - 성공\n\ndf.rename(columns={'Release Clause':'ReleaseClause'})\\\n.assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df['Release Clause'])))\\\n.rename(columns={'ReleaseClause':'Release Clause'})\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.rename(columns={'Release Clause':'ReleaseClause'})\\\n.assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df['Release Clause'])))\\\n.rename(columns={'ReleaseClause':'Release Clause'}).info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  float64\n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(5), int64(5), object(19)\nmemory usage: 3.9+ MB\n\n\n26번 컬럼이 float64로 바뀜!\n(시도3) - 성공, 그냥 결측치를 제거하고 변경해도 무방\n\ndf2 = df.drop(columns=['Loaned From', 'Best Overall Rating']).dropna()\ndf2['Release Clause'] = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df2['Release Clause']))\ndf2\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n    \n  \n\n16364 rows × 27 columns\n\n\n\n\ndf2.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 16364 entries, 0 to 17659\nData columns (total 27 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        16364 non-null  int64  \n 1   Name                      16364 non-null  object \n 2   Age                       16364 non-null  int64  \n 3   Photo                     16364 non-null  object \n 4   Nationality               16364 non-null  object \n 5   Flag                      16364 non-null  object \n 6   Overall                   16364 non-null  int64  \n 7   Potential                 16364 non-null  int64  \n 8   Club                      16364 non-null  object \n 9   Club Logo                 16364 non-null  object \n 10  Value                     16364 non-null  object \n 11  Wage                      16364 non-null  object \n 12  Special                   16364 non-null  int64  \n 13  Preferred Foot            16364 non-null  object \n 14  International Reputation  16364 non-null  float64\n 15  Weak Foot                 16364 non-null  float64\n 16  Skill Moves               16364 non-null  float64\n 17  Work Rate                 16364 non-null  object \n 18  Body Type                 16364 non-null  object \n 19  Real Face                 16364 non-null  object \n 20  Position                  16364 non-null  object \n 21  Joined                    16364 non-null  object \n 22  Contract Valid Until      16364 non-null  object \n 23  Height                    16364 non-null  object \n 24  Weight                    16364 non-null  object \n 25  Release Clause            16364 non-null  float64\n 26  Kit Number                16364 non-null  float64\ndtypes: float64(5), int64(5), object(17)\nmemory usage: 3.5+ MB\n\n\n\n분석의 편의를 위하여 (1) colnames를 변경하고 (2) 결측치를 제거하고 (3) 몇 가지 전 처리를 추가로 진행한 뒤 df2를 만들어서 분석하는게 좋음"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#데이터-분석하기",
    "href": "posts/Data Visualization/DV_8(1024).html#데이터-분석하기",
    "title": "DV 8주차",
    "section": "데이터 분석하기",
    "text": "데이터 분석하기\n\nOverall vs Potential\n(의문)현재 능력치가 좋은 선수는 잠재력이 없는 거일까?\n\ndf.Potential # 잠재능력\n\n0        88\n1        87\n2        85\n3        91\n4        89\n         ..\n17655    61\n17656    64\n17657    56\n17658    65\n17659    61\nName: Potential, Length: 17660, dtype: int64\n\n\n\ndf.Overall  # 전반적인\n\n0        87\n1        86\n2        85\n3        91\n4        86\n         ..\n17655    48\n17656    48\n17657    51\n17658    50\n17659    50\nName: Overall, Length: 17660, dtype: int64\n\n\n\nfig = ggplot(data=df) + geom_point(aes(x='Overall',y='Potential'))\nfig\n\n\n\n\n<ggplot: (8736740509057)>\n\n\n\n뭔가 Potential > Overall 인 관계가 성립하는 듯 하다. \\(\\to\\) 우리가 생각하는 포텐셜의 의미는 사실 Potential2 = Potential - Overall 에 더 가깝다. \\(\\to\\) Potential2 = Potential - Overall 인 변수를 새로 만들고 시각화 해보자.\n\n- Potential2 = Potential - Overall 를 계산하여 새로운 열을 추가하자.\n\ndf.eval('Potential2 = Potential - Overall')\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n      1\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n      1\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n      0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n      0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n    \n  \n\n17660 rows × 30 columns\n\n\n\n- 수정된 df에 다시 시각화를 하면\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.01)\n\n\n\n\n<ggplot: (8785454643557)>\n\n\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n# position='jitter' 흩뿌려진 점\n\n\n\n\n<ggplot: (8785454337349)>\n\n\n- 해석\n\n해석1: Overall, Potential2는 음의 상관관계가 있다.\n해석2: 0근처에 데이터가 많음.. 이미 은퇴한 선수들이 아닐까?\n해석3: Overall의 값이 작을수록 Potential2의 분산이 크다.\n\n- 은퇴한 선수들을 제외하고 시각화\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n# .query('Potential2 > 1') : 은퇴선수제외, 0에 몰려있는 데이터 제외\n\n\n\n\n<ggplot: (8785454565309)>\n\n\n- Overall에 따라서 구간을 나누고 그 구간에 대응하는 boxplot을 그리자\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.Overall.describe()\n\ncount    13644.000000\nmean        61.415347\nstd          7.247821\nmin         44.000000\n25%         56.000000\n50%         61.000000\n75%         66.000000\nmax         91.000000\nName: Overall, dtype: float64\n\n\n\ndef f(x):\n    if x>66: \n        y='66<'\n    elif x>61:\n        y='61~66'\n    elif x>56:\n        y='56~61'\n    else:\n        y='<56' \n    return y\n\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall))))\\\n    + geom_boxplot(aes(x='Overall_grouped',y='Potential2',color='Overall_grouped'))\n\nNameError: name 'f' is not defined\n\n\n\nOverall_grouped = “<56” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “<56”에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “56 ~ 61” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “56~61” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “61 ~ 66” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “61 ~ 66” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “66<” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “66<” 에 대응하는 박스플랏의 x축위치로 설정\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.query(\"Overall_grouped == '66<'\").Overall.mean()\n\n71.8127687727423\n\n\n(방법1)\n\ndef g(x):\n    if x=='66<': \n        y= 71.8127687727423\n    elif x=='61~66':\n        y= 63.773918342474104\n    elif x=='56~61':\n        y= 59.155840684309005\n    else:\n        y= 52.87743190661479\n    return y\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n      Overall_grouped\n      Overall_x\n    \n  \n  \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      10\n      228251\n      L. Pellegrini\n      26\n      https://cdn.sofifa.net/players/228/251/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      84\n      87\n      Roma\n      https://cdn.sofifa.net/teams/52/30.png\n      ...\n      NaN\n      2026\n      186cm\n      77kg\n      €97.6M\n      7.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      13\n      225193\n      Merino\n      26\n      https://cdn.sofifa.net/players/225/193/23_60.png\n      Spain\n      https://cdn.sofifa.net/flags/es.png\n      83\n      86\n      Real Sociedad\n      https://cdn.sofifa.net/teams/457/30.png\n      ...\n      NaN\n      2025\n      189cm\n      83kg\n      €102.2M\n      8.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      17\n      228702\n      F. de Jong\n      25\n      https://cdn.sofifa.net/players/228/702/23_60.png\n      Netherlands\n      https://cdn.sofifa.net/flags/nl.png\n      87\n      92\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      NaN\n      2026\n      180cm\n      74kg\n      €247.6M\n      21.0\n      NaN\n      5\n      66<\n      71.812769\n    \n    \n      21\n      231281\n      T. Alexander-Arnold\n      23\n      https://cdn.sofifa.net/players/231/281/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      87\n      90\n      Liverpool\n      https://cdn.sofifa.net/teams/9/30.png\n      ...\n      NaN\n      2025\n      180cm\n      69kg\n      €193.5M\n      66.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n      <56\n      52.877432\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n      <56\n      52.877432\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n      <56\n      52.877432\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n      <56\n      52.877432\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n      <56\n      52.877432\n    \n  \n\n13644 rows × 32 columns\n\n\n\n\ndf2=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\n\n\nggplot(data=df2)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n<ggplot: (8751309238629)>\n\n\n(방법2)\n\n_df = df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\n\n\ndf3=_df.groupby(by=\"Overall_grouped\").agg({'Overall':np.mean}).reset_index()\\\n.rename(columns={'Overall':'Overall_x'}).merge(_df)\n\n\nggplot(data=df3)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n<ggplot: (8751308728441)>\n\n\n\ndf3.head()\n\n\n\n\n\n  \n    \n      \n      Overall_grouped\n      Overall_x\n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      ...\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n    \n  \n  \n    \n      0\n      56~61\n      59.155841\n      227288\n      J. Flores\n      26\n      https://cdn.sofifa.net/players/227/288/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      61\n      64\n      ...\n      <span class=\"pos pos9\">RDM\n      Jan 31, 2022\n      NaN\n      2024\n      180cm\n      75kg\n      €609K\n      21.0\n      NaN\n      3\n    \n    \n      1\n      56~61\n      59.155841\n      270916\n      A. Smrcka\n      19\n      https://cdn.sofifa.net/players/270/916/23_60.png\n      Austria\n      https://cdn.sofifa.net/flags/at.png\n      60\n      70\n      ...\n      <span class=\"pos pos29\">RES\n      Jul 1, 2022\n      NaN\n      2025\n      177cm\n      72kg\n      €866K\n      43.0\n      NaN\n      10\n    \n    \n      2\n      56~61\n      59.155841\n      246789\n      A. Smith\n      23\n      https://cdn.sofifa.net/players/246/789/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      61\n      66\n      ...\n      <span class=\"pos pos13\">RCM\n      Jul 1, 2021\n      NaN\n      2023\n      185cm\n      73kg\n      €913K\n      8.0\n      NaN\n      5\n    \n    \n      3\n      56~61\n      59.155841\n      242056\n      C. Timmins\n      22\n      https://cdn.sofifa.net/players/242/056/23_60.png\n      Australia\n      https://cdn.sofifa.net/flags/au.png\n      61\n      68\n      ...\n      <span class=\"pos pos28\">SUB\n      Aug 4, 2022\n      NaN\n      2023\n      182cm\n      72kg\n      €979K\n      15.0\n      NaN\n      7\n    \n    \n      4\n      56~61\n      59.155841\n      262363\n      22 M. Anderson\n      20\n      https://cdn.sofifa.net/players/262/363/22_60.png\n      Scotland\n      https://cdn.sofifa.net/flags/gb-sct.png\n      61\n      71\n      ...\n      <span class=\"pos pos13\">RCM\n      Nov 5, 2019\n      NaN\n      2023\n      167cm\n      70kg\n      €1.4M\n      24.0\n      NaN\n      10\n    \n  \n\n5 rows × 32 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#flights-data",
    "href": "posts/Data Visualization/DV_8(1024).html#flights-data",
    "title": "DV 8주차",
    "section": "flights data",
    "text": "flights data\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 58492 entries, 0 to 58491\nData columns (total 14 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MONTH      58492 non-null  int64  \n 1   DAY        58492 non-null  int64  \n 2   WEEKDAY    58492 non-null  int64  \n 3   AIRLINE    58492 non-null  object \n 4   ORG_AIR    58492 non-null  object \n 5   DEST_AIR   58492 non-null  object \n 6   SCHED_DEP  58492 non-null  int64  \n 7   DEP_DELAY  57659 non-null  float64\n 8   AIR_TIME   57474 non-null  float64\n 9   DIST       58492 non-null  int64  \n 10  SCHED_ARR  58492 non-null  int64  \n 11  ARR_DELAY  57474 non-null  float64\n 12  DIVERTED   58492 non-null  int64  \n 13  CANCELLED  58492 non-null  int64  \ndtypes: float64(3), int64(8), object(3)\nmemory usage: 6.2+ MB\n\n\n\ndf[['ARR_DELAY','CANCELLED']]\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n      CANCELLED\n    \n  \n  \n    \n      0\n      65.0\n      0\n    \n    \n      1\n      -13.0\n      0\n    \n    \n      2\n      35.0\n      0\n    \n    \n      3\n      -7.0\n      0\n    \n    \n      4\n      39.0\n      0\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      58487\n      -19.0\n      0\n    \n    \n      58488\n      4.0\n      0\n    \n    \n      58489\n      -5.0\n      0\n    \n    \n      58490\n      34.0\n      0\n    \n    \n      58491\n      -1.0\n      0\n    \n  \n\n58492 rows × 2 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#get_groups",
    "href": "posts/Data Visualization/DV_8(1024).html#get_groups",
    "title": "DV 8주차",
    "section": "get_groups",
    "text": "get_groups\n- groupby\n\n데이터프레임을 여러개의 서브데이터프레임으로 나누는 기준\n단독으로 쓸 이유는 별로 없다. \\(\\to\\) 그룹을 나누고 그룹을 어떠한 “변수”에 “연산”을 하기 위함이다.\n\n\ndf['AIRLINE'].unique()\n\narray(['WN', 'UA', 'MQ', 'AA', 'F9', 'EV', 'OO', 'NK', 'US', 'AS', 'DL',\n       'VX', 'B6', 'HA'], dtype=object)\n\n\n\ndf.groupby(by='AIRLINE')\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f58e3f69090>\n\n\n\n지금 이것은 항공사별로 데이터프레임이 나누어진 상태\n\n- sub dataframe으로 나누어져 있는지 확인\n\ngrouped = df.groupby(by='AIRLINE')\ngrouped.groups.keys()\n\ndict_keys(['AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US', 'VX', 'WN'])\n\n\n\ngrouped.get_group('AS')\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n#collapse_output\nfor key in grouped.groups.keys():\n    display(grouped.get_group(key))\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      3\n      1\n      1\n      4\n      AA\n      DFW\n      DCA\n      1555\n      7.0\n      126.0\n      1192\n      1935\n      -7.0\n      0\n      0\n    \n    \n      6\n      1\n      1\n      4\n      AA\n      DFW\n      MSY\n      1250\n      84.0\n      64.0\n      447\n      1410\n      83.0\n      0\n      0\n    \n    \n      8\n      1\n      1\n      4\n      AA\n      ORD\n      STL\n      1845\n      -5.0\n      44.0\n      258\n      1950\n      -5.0\n      0\n      0\n    \n    \n      15\n      1\n      1\n      4\n      AA\n      DEN\n      DFW\n      1445\n      -6.0\n      93.0\n      641\n      1745\n      4.0\n      0\n      0\n    \n    \n      26\n      1\n      1\n      4\n      AA\n      LAX\n      AUS\n      1430\n      33.0\n      157.0\n      1242\n      1925\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58470\n      12\n      31\n      4\n      AA\n      DFW\n      FAT\n      1020\n      -3.0\n      196.0\n      1313\n      1156\n      -2.0\n      0\n      0\n    \n    \n      58475\n      12\n      31\n      4\n      AA\n      IAH\n      CLT\n      710\n      1.0\n      113.0\n      912\n      1037\n      -12.0\n      0\n      0\n    \n    \n      58476\n      12\n      31\n      4\n      AA\n      DFW\n      TPA\n      1020\n      -3.0\n      121.0\n      929\n      1340\n      -6.0\n      0\n      0\n    \n    \n      58479\n      12\n      31\n      4\n      AA\n      DFW\n      ELP\n      1200\n      3.0\n      94.0\n      551\n      1250\n      13.0\n      0\n      0\n    \n    \n      58487\n      12\n      31\n      4\n      AA\n      SFO\n      DFW\n      515\n      5.0\n      166.0\n      1464\n      1045\n      -19.0\n      0\n      0\n    \n  \n\n8900 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      123\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      1230\n      0.0\n      246.0\n      2381\n      2026\n      -27.0\n      0\n      0\n    \n    \n      127\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      2359\n      68.0\n      247.0\n      2381\n      749\n      46.0\n      0\n      0\n    \n    \n      239\n      1\n      2\n      5\n      B6\n      ORD\n      BOS\n      540\n      -8.0\n      96.0\n      867\n      856\n      -22.0\n      0\n      0\n    \n    \n      333\n      1\n      3\n      6\n      B6\n      LAX\n      FLL\n      2237\n      32.0\n      270.0\n      2342\n      619\n      42.0\n      0\n      0\n    \n    \n      548\n      1\n      4\n      7\n      B6\n      SFO\n      FLL\n      2307\n      -4.0\n      298.0\n      2583\n      724\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58262\n      12\n      30\n      3\n      B6\n      SFO\n      LGB\n      1921\n      -6.0\n      57.0\n      354\n      2038\n      -14.0\n      0\n      0\n    \n    \n      58301\n      12\n      30\n      3\n      B6\n      LAX\n      JFK\n      630\n      4.0\n      285.0\n      2475\n      1445\n      -6.0\n      0\n      0\n    \n    \n      58425\n      12\n      31\n      4\n      B6\n      ORD\n      SJU\n      700\n      239.0\n      250.0\n      2072\n      1335\n      239.0\n      0\n      0\n    \n    \n      58477\n      12\n      31\n      4\n      B6\n      DFW\n      BOS\n      1145\n      12.0\n      161.0\n      1562\n      1608\n      -14.0\n      0\n      0\n    \n    \n      58483\n      12\n      31\n      4\n      B6\n      PHX\n      BOS\n      2236\n      -12.0\n      231.0\n      2300\n      515\n      -45.0\n      0\n      0\n    \n  \n\n543 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      53\n      1\n      1\n      4\n      DL\n      LAS\n      MSP\n      713\n      -5.0\n      156.0\n      1299\n      1220\n      -18.0\n      0\n      0\n    \n    \n      57\n      1\n      1\n      4\n      DL\n      MSP\n      RSW\n      700\n      -1.0\n      169.0\n      1416\n      1130\n      -20.0\n      0\n      0\n    \n    \n      77\n      1\n      1\n      4\n      DL\n      LAX\n      ATL\n      1130\n      24.0\n      217.0\n      1947\n      1840\n      16.0\n      0\n      0\n    \n    \n      79\n      1\n      1\n      4\n      DL\n      LAX\n      CMH\n      2146\n      -3.0\n      223.0\n      1995\n      459\n      -13.0\n      0\n      0\n    \n    \n      85\n      1\n      1\n      4\n      DL\n      ATL\n      OKC\n      2059\n      -4.0\n      116.0\n      761\n      2227\n      -12.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58440\n      12\n      31\n      4\n      DL\n      ATL\n      CVG\n      1611\n      -4.0\n      61.0\n      373\n      1736\n      -6.0\n      0\n      0\n    \n    \n      58448\n      12\n      31\n      4\n      DL\n      ATL\n      SRQ\n      1610\n      0.0\n      61.0\n      444\n      1740\n      -13.0\n      0\n      0\n    \n    \n      58464\n      12\n      31\n      4\n      DL\n      LAX\n      SFO\n      700\n      108.0\n      54.0\n      337\n      825\n      105.0\n      0\n      0\n    \n    \n      58467\n      12\n      31\n      4\n      DL\n      ATL\n      IND\n      1235\n      -3.0\n      63.0\n      432\n      1407\n      -13.0\n      0\n      0\n    \n    \n      58485\n      12\n      31\n      4\n      DL\n      ATL\n      CMH\n      2206\n      2.0\n      64.0\n      447\n      2338\n      -8.0\n      0\n      0\n    \n  \n\n10601 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      11\n      1\n      1\n      4\n      EV\n      ORD\n      JAN\n      1155\n      6.0\n      113.0\n      677\n      1403\n      5.0\n      0\n      0\n    \n    \n      13\n      1\n      1\n      4\n      EV\n      ORD\n      CMH\n      1010\n      -2.0\n      46.0\n      296\n      1228\n      -9.0\n      0\n      0\n    \n    \n      29\n      1\n      1\n      4\n      EV\n      ORD\n      IND\n      1025\n      -6.0\n      29.0\n      177\n      1228\n      -19.0\n      0\n      0\n    \n    \n      40\n      1\n      1\n      4\n      EV\n      IAH\n      CLE\n      1038\n      -3.0\n      126.0\n      1091\n      1425\n      -18.0\n      0\n      0\n    \n    \n      69\n      1\n      1\n      4\n      EV\n      ATL\n      RAP\n      1930\n      -5.0\n      181.0\n      1230\n      2104\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58445\n      12\n      31\n      4\n      EV\n      DFW\n      TXK\n      850\n      -5.0\n      30.0\n      181\n      948\n      -17.0\n      0\n      0\n    \n    \n      58452\n      12\n      31\n      4\n      EV\n      DFW\n      SHV\n      1650\n      -4.0\n      32.0\n      190\n      1746\n      -12.0\n      0\n      0\n    \n    \n      58459\n      12\n      31\n      4\n      EV\n      MSP\n      ORD\n      1435\n      18.0\n      61.0\n      334\n      1609\n      3.0\n      0\n      0\n    \n    \n      58463\n      12\n      31\n      4\n      EV\n      ORD\n      MSN\n      1220\n      18.0\n      32.0\n      108\n      1319\n      27.0\n      0\n      0\n    \n    \n      58486\n      12\n      31\n      4\n      EV\n      DFW\n      LFT\n      850\n      21.0\n      52.0\n      351\n      1012\n      14.0\n      0\n      0\n    \n  \n\n5858 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      7\n      1\n      1\n      4\n      F9\n      SFO\n      PHX\n      1020\n      -7.0\n      91.0\n      651\n      1315\n      -6.0\n      0\n      0\n    \n    \n      93\n      1\n      1\n      4\n      F9\n      ATL\n      DEN\n      859\n      16.0\n      181.0\n      1199\n      1026\n      10.0\n      0\n      0\n    \n    \n      209\n      1\n      2\n      5\n      F9\n      MSP\n      DEN\n      1025\n      -6.0\n      97.0\n      680\n      1134\n      -13.0\n      0\n      0\n    \n    \n      232\n      1\n      2\n      5\n      F9\n      DEN\n      PHX\n      2040\n      -7.0\n      83.0\n      602\n      2228\n      -18.0\n      0\n      0\n    \n    \n      247\n      1\n      2\n      5\n      F9\n      ORD\n      ATL\n      730\n      10.0\n      86.0\n      606\n      1020\n      23.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58288\n      12\n      30\n      3\n      F9\n      DEN\n      ORD\n      625\n      -4.0\n      136.0\n      888\n      1000\n      14.0\n      0\n      0\n    \n    \n      58331\n      12\n      30\n      3\n      F9\n      ORD\n      PHX\n      825\n      18.0\n      207.0\n      1440\n      1127\n      14.0\n      0\n      0\n    \n    \n      58447\n      12\n      31\n      4\n      F9\n      DEN\n      LAS\n      1245\n      13.0\n      94.0\n      628\n      1340\n      13.0\n      0\n      0\n    \n    \n      58449\n      12\n      31\n      4\n      F9\n      DEN\n      MCO\n      645\n      11.0\n      169.0\n      1546\n      1224\n      -11.0\n      0\n      0\n    \n    \n      58488\n      12\n      31\n      4\n      F9\n      LAS\n      SFO\n      1910\n      13.0\n      71.0\n      414\n      2050\n      4.0\n      0\n      0\n    \n  \n\n1317 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      582\n      1\n      4\n      7\n      HA\n      LAX\n      OGG\n      1115\n      -11.0\n      310.0\n      2486\n      1500\n      -27.0\n      0\n      0\n    \n    \n      712\n      1\n      5\n      1\n      HA\n      LAS\n      HNL\n      900\n      -5.0\n      357.0\n      2762\n      1315\n      5.0\n      0\n      0\n    \n    \n      878\n      1\n      6\n      2\n      HA\n      PHX\n      HNL\n      800\n      1.0\n      374.0\n      2917\n      1140\n      3.0\n      0\n      0\n    \n    \n      1053\n      1\n      7\n      3\n      HA\n      LAX\n      HNL\n      1705\n      0.0\n      332.0\n      2556\n      2055\n      -2.0\n      0\n      0\n    \n    \n      1269\n      1\n      8\n      4\n      HA\n      LAX\n      HNL\n      1000\n      -1.0\n      335.0\n      2556\n      1350\n      0.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      55883\n      12\n      16\n      3\n      HA\n      LAX\n      HNL\n      835\n      1.0\n      314.0\n      2556\n      1235\n      -18.0\n      0\n      0\n    \n    \n      56174\n      12\n      18\n      5\n      HA\n      LAX\n      HNL\n      835\n      -5.0\n      342.0\n      2556\n      1235\n      -4.0\n      0\n      0\n    \n    \n      56350\n      12\n      19\n      6\n      HA\n      PHX\n      HNL\n      800\n      -5.0\n      363.0\n      2917\n      1155\n      -34.0\n      0\n      0\n    \n    \n      56816\n      12\n      21\n      1\n      HA\n      LAX\n      LIH\n      740\n      20.0\n      303.0\n      2615\n      1145\n      -11.0\n      0\n      0\n    \n    \n      58391\n      12\n      31\n      4\n      HA\n      LAX\n      HNL\n      1000\n      0.0\n      324.0\n      2556\n      1350\n      -9.0\n      0\n      0\n    \n  \n\n112 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      2\n      1\n      1\n      4\n      MQ\n      DFW\n      VPS\n      1305\n      36.0\n      85.0\n      641\n      1453\n      35.0\n      0\n      0\n    \n    \n      10\n      1\n      1\n      4\n      MQ\n      DFW\n      DRO\n      1335\n      28.0\n      104.0\n      674\n      1438\n      28.0\n      0\n      0\n    \n    \n      18\n      1\n      1\n      4\n      MQ\n      ORD\n      DAY\n      2220\n      19.0\n      37.0\n      240\n      23\n      20.0\n      0\n      0\n    \n    \n      24\n      1\n      1\n      4\n      MQ\n      DFW\n      BTR\n      730\n      NaN\n      NaN\n      383\n      853\n      NaN\n      0\n      1\n    \n    \n      50\n      1\n      1\n      4\n      MQ\n      ORD\n      CID\n      1135\n      -7.0\n      37.0\n      196\n      1238\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58415\n      12\n      31\n      4\n      MQ\n      ORD\n      FWA\n      845\n      -2.0\n      37.0\n      157\n      1045\n      -4.0\n      0\n      0\n    \n    \n      58426\n      12\n      31\n      4\n      MQ\n      DFW\n      FAR\n      1154\n      4.0\n      124.0\n      968\n      1437\n      -13.0\n      0\n      0\n    \n    \n      58468\n      12\n      31\n      4\n      MQ\n      DFW\n      OKC\n      1720\n      -3.0\n      31.0\n      175\n      1819\n      -10.0\n      0\n      0\n    \n    \n      58474\n      12\n      31\n      4\n      MQ\n      ORD\n      FNT\n      829\n      4.0\n      40.0\n      223\n      1034\n      -4.0\n      0\n      0\n    \n    \n      58484\n      12\n      31\n      4\n      MQ\n      ORD\n      DSM\n      1333\n      1.0\n      57.0\n      299\n      1455\n      -7.0\n      0\n      0\n    \n  \n\n3471 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      17\n      1\n      1\n      4\n      NK\n      DEN\n      DTW\n      1952\n      37.0\n      124.0\n      1123\n      31\n      54.0\n      0\n      0\n    \n    \n      74\n      1\n      1\n      4\n      NK\n      PHX\n      DFW\n      159\n      -1.0\n      103.0\n      868\n      502\n      1.0\n      0\n      0\n    \n    \n      95\n      1\n      1\n      4\n      NK\n      LAS\n      OAK\n      1115\n      22.0\n      62.0\n      407\n      1246\n      10.0\n      0\n      0\n    \n    \n      109\n      1\n      1\n      4\n      NK\n      MSP\n      ORD\n      616\n      2.0\n      49.0\n      334\n      745\n      -19.0\n      0\n      0\n    \n    \n      166\n      1\n      2\n      5\n      NK\n      LAS\n      PDX\n      1535\n      -8.0\n      123.0\n      763\n      1754\n      -4.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58160\n      12\n      29\n      2\n      NK\n      MSP\n      MCO\n      740\n      0.0\n      171.0\n      1310\n      1158\n      33.0\n      0\n      0\n    \n    \n      58197\n      12\n      30\n      3\n      NK\n      IAH\n      ORD\n      755\n      -8.0\n      136.0\n      925\n      1030\n      -2.0\n      0\n      0\n    \n    \n      58437\n      12\n      31\n      4\n      NK\n      ORD\n      DFW\n      1952\n      15.0\n      135.0\n      802\n      2225\n      23.0\n      0\n      0\n    \n    \n      58461\n      12\n      31\n      4\n      NK\n      ORD\n      LGA\n      1801\n      -5.0\n      84.0\n      733\n      2109\n      -26.0\n      0\n      0\n    \n    \n      58469\n      12\n      31\n      4\n      NK\n      LAS\n      MSY\n      1950\n      124.0\n      163.0\n      1500\n      112\n      101.0\n      0\n      0\n    \n  \n\n1516 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      12\n      1\n      1\n      4\n      OO\n      ORD\n      MSP\n      1510\n      2.0\n      65.0\n      334\n      1646\n      4.0\n      0\n      0\n    \n    \n      16\n      1\n      1\n      4\n      OO\n      DEN\n      SGU\n      1105\n      21.0\n      66.0\n      517\n      1249\n      20.0\n      0\n      0\n    \n    \n      22\n      1\n      1\n      4\n      OO\n      LAS\n      LAX\n      1544\n      -4.0\n      39.0\n      236\n      1655\n      -12.0\n      0\n      0\n    \n    \n      25\n      1\n      1\n      4\n      OO\n      ORD\n      SPI\n      2110\n      -4.0\n      31.0\n      174\n      2205\n      5.0\n      0\n      0\n    \n    \n      27\n      1\n      1\n      4\n      OO\n      IAH\n      JAC\n      1104\n      -1.0\n      161.0\n      1265\n      1316\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58451\n      12\n      31\n      4\n      OO\n      ATL\n      FWA\n      1905\n      -3.0\n      72.0\n      508\n      2051\n      -14.0\n      0\n      0\n    \n    \n      58480\n      12\n      31\n      4\n      OO\n      MSP\n      BIS\n      1310\n      -2.0\n      65.0\n      386\n      1449\n      -9.0\n      0\n      0\n    \n    \n      58482\n      12\n      31\n      4\n      OO\n      DEN\n      CPR\n      1850\n      -2.0\n      38.0\n      230\n      1956\n      1.0\n      0\n      0\n    \n    \n      58489\n      12\n      31\n      4\n      OO\n      SFO\n      SBA\n      1846\n      -6.0\n      46.0\n      262\n      1956\n      -5.0\n      0\n      0\n    \n    \n      58491\n      12\n      31\n      4\n      OO\n      SFO\n      BOI\n      859\n      5.0\n      73.0\n      522\n      1146\n      -1.0\n      0\n      0\n    \n  \n\n6588 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      1\n      1\n      1\n      4\n      UA\n      DEN\n      IAD\n      823\n      7.0\n      154.0\n      1452\n      1333\n      -13.0\n      0\n      0\n    \n    \n      5\n      1\n      1\n      4\n      UA\n      IAH\n      SAN\n      1450\n      1.0\n      178.0\n      1303\n      1620\n      -14.0\n      0\n      0\n    \n    \n      9\n      1\n      1\n      4\n      UA\n      IAH\n      SJC\n      925\n      3.0\n      215.0\n      1608\n      1136\n      -14.0\n      0\n      0\n    \n    \n      14\n      1\n      1\n      4\n      UA\n      IAH\n      IND\n      1426\n      -1.0\n      102.0\n      844\n      1742\n      -20.0\n      0\n      0\n    \n    \n      21\n      1\n      1\n      4\n      UA\n      ORD\n      CLE\n      2102\n      48.0\n      47.0\n      315\n      2320\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58422\n      12\n      31\n      4\n      UA\n      DEN\n      SAN\n      1535\n      0.0\n      124.0\n      853\n      1704\n      -13.0\n      0\n      0\n    \n    \n      58432\n      12\n      31\n      4\n      UA\n      ORD\n      SAN\n      1915\n      7.0\n      238.0\n      1723\n      2143\n      -3.0\n      0\n      0\n    \n    \n      58457\n      12\n      31\n      4\n      UA\n      ORD\n      LAX\n      659\n      -1.0\n      241.0\n      1744\n      946\n      0.0\n      0\n      0\n    \n    \n      58460\n      12\n      31\n      4\n      UA\n      SFO\n      PHL\n      2235\n      -6.0\n      265.0\n      2521\n      700\n      -42.0\n      0\n      0\n    \n    \n      58481\n      12\n      31\n      4\n      UA\n      IAH\n      LAX\n      1433\n      1.0\n      197.0\n      1379\n      1625\n      -13.0\n      0\n      0\n    \n  \n\n7792 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      31\n      1\n      1\n      4\n      US\n      PHX\n      DEN\n      1810\n      29.0\n      94.0\n      602\n      1954\n      49.0\n      0\n      0\n    \n    \n      35\n      1\n      1\n      4\n      US\n      ORD\n      PHL\n      1600\n      -2.0\n      80.0\n      678\n      1857\n      -9.0\n      0\n      0\n    \n    \n      49\n      1\n      1\n      4\n      US\n      IAH\n      PHX\n      1445\n      -1.0\n      147.0\n      1009\n      1638\n      -7.0\n      0\n      0\n    \n    \n      96\n      1\n      1\n      4\n      US\n      ATL\n      PHL\n      1445\n      -4.0\n      90.0\n      666\n      1644\n      -11.0\n      0\n      0\n    \n    \n      104\n      1\n      1\n      4\n      US\n      MSP\n      PHX\n      730\n      -3.0\n      174.0\n      1276\n      1010\n      -20.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      31514\n      6\n      30\n      2\n      US\n      DEN\n      PHL\n      705\n      -4.0\n      188.0\n      1558\n      1240\n      1.0\n      0\n      0\n    \n    \n      31523\n      6\n      30\n      2\n      US\n      PHX\n      DEN\n      1451\n      6.0\n      85.0\n      602\n      1738\n      7.0\n      0\n      0\n    \n    \n      31535\n      6\n      30\n      2\n      US\n      PHX\n      AUS\n      840\n      -3.0\n      116.0\n      872\n      1304\n      -11.0\n      0\n      0\n    \n    \n      31561\n      6\n      30\n      2\n      US\n      ORD\n      PHX\n      710\n      -5.0\n      170.0\n      1440\n      901\n      -50.0\n      0\n      0\n    \n    \n      31582\n      6\n      30\n      2\n      US\n      PHX\n      OGG\n      800\n      -4.0\n      356.0\n      2845\n      1127\n      -13.0\n      0\n      0\n    \n  \n\n1615 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      56\n      1\n      1\n      4\n      VX\n      LAS\n      SFO\n      900\n      23.0\n      65.0\n      414\n      1035\n      11.0\n      0\n      0\n    \n    \n      227\n      1\n      2\n      5\n      VX\n      SFO\n      LAS\n      1220\n      -5.0\n      68.0\n      414\n      1350\n      -5.0\n      0\n      0\n    \n    \n      243\n      1\n      2\n      5\n      VX\n      SFO\n      SEA\n      700\n      -4.0\n      104.0\n      679\n      905\n      -1.0\n      0\n      0\n    \n    \n      417\n      1\n      3\n      6\n      VX\n      SFO\n      LAS\n      900\n      -2.0\n      62.0\n      414\n      1030\n      -11.0\n      0\n      0\n    \n    \n      432\n      1\n      3\n      6\n      VX\n      SFO\n      SEA\n      2035\n      -2.0\n      106.0\n      679\n      2240\n      -2.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58332\n      12\n      30\n      3\n      VX\n      SFO\n      LAS\n      1950\n      -3.0\n      58.0\n      414\n      2120\n      -4.0\n      0\n      0\n    \n    \n      58383\n      12\n      31\n      4\n      VX\n      SFO\n      PSP\n      1630\n      -7.0\n      65.0\n      421\n      1755\n      -12.0\n      0\n      0\n    \n    \n      58400\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1125\n      -4.0\n      54.0\n      337\n      1245\n      -10.0\n      0\n      0\n    \n    \n      58471\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      700\n      6.0\n      51.0\n      337\n      820\n      3.0\n      0\n      0\n    \n    \n      58478\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1530\n      29.0\n      52.0\n      337\n      1650\n      22.0\n      0\n      0\n    \n  \n\n993 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      0\n      1\n      1\n      4\n      WN\n      LAX\n      SLC\n      1625\n      58.0\n      94.0\n      590\n      1905\n      65.0\n      0\n      0\n    \n    \n      4\n      1\n      1\n      4\n      WN\n      LAX\n      MCI\n      1720\n      48.0\n      166.0\n      1363\n      2225\n      39.0\n      0\n      0\n    \n    \n      19\n      1\n      1\n      4\n      WN\n      PHX\n      LAX\n      1640\n      51.0\n      58.0\n      370\n      1700\n      59.0\n      0\n      0\n    \n    \n      20\n      1\n      1\n      4\n      WN\n      ATL\n      BWI\n      1115\n      1.0\n      76.0\n      577\n      1305\n      -15.0\n      0\n      0\n    \n    \n      23\n      1\n      1\n      4\n      WN\n      ATL\n      HOU\n      1555\n      30.0\n      113.0\n      696\n      1720\n      18.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58455\n      12\n      31\n      4\n      WN\n      LAX\n      SMF\n      1420\n      -2.0\n      64.0\n      373\n      1540\n      -7.0\n      0\n      0\n    \n    \n      58458\n      12\n      31\n      4\n      WN\n      LAS\n      SFO\n      1825\n      25.0\n      67.0\n      414\n      1955\n      17.0\n      0\n      0\n    \n    \n      58472\n      12\n      31\n      4\n      WN\n      PHX\n      HOU\n      845\n      5.0\n      119.0\n      1020\n      1210\n      7.0\n      0\n      0\n    \n    \n      58473\n      12\n      31\n      4\n      WN\n      DEN\n      PDX\n      1205\n      4.0\n      130.0\n      991\n      1400\n      -13.0\n      0\n      0\n    \n    \n      58490\n      12\n      31\n      4\n      WN\n      MSP\n      ATL\n      525\n      39.0\n      124.0\n      907\n      855\n      34.0\n      0\n      0\n    \n  \n\n8418 rows × 14 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#범주형-변수를-기준으로-groupby---agg",
    "href": "posts/Data Visualization/DV_8(1024).html#범주형-변수를-기준으로-groupby---agg",
    "title": "DV 8주차",
    "section": "범주형 변수를 기준으로 groupby -> agg",
    "text": "범주형 변수를 기준으로 groupby -> agg\n\nEX1: [AIRLINE] \\(\\to\\) {ARR_DELAY:mean}\n- 방법1: groupby() \\(\\to\\) .agg({colname: function})\n\ndf.groupby(by=\"AIRLINE\")\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5900e60850>\n\n\n\ndf.AIRLINE.unique().__len__()\n\n14\n\n\n(예시1)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':np.mean})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n(예시2)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':mean})\n\n# numpy로 하지 않고 mean만을 해도 된다\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n(실습)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':std})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      43.323160\n    \n    \n      AS\n      31.168354\n    \n    \n      B6\n      40.221718\n    \n    \n      DL\n      32.299471\n    \n    \n      EV\n      36.682336\n    \n    \n      F9\n      53.030912\n    \n    \n      HA\n      37.528283\n    \n    \n      MQ\n      36.324657\n    \n    \n      NK\n      48.727259\n    \n    \n      OO\n      35.331344\n    \n    \n      UA\n      46.405935\n    \n    \n      US\n      27.030227\n    \n    \n      VX\n      33.747675\n    \n    \n      WN\n      32.610666\n    \n  \n\n\n\n\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':max})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      858.0\n    \n    \n      AS\n      344.0\n    \n    \n      B6\n      331.0\n    \n    \n      DL\n      741.0\n    \n    \n      EV\n      669.0\n    \n    \n      F9\n      839.0\n    \n    \n      HA\n      298.0\n    \n    \n      MQ\n      357.0\n    \n    \n      NK\n      474.0\n    \n    \n      OO\n      724.0\n    \n    \n      UA\n      1185.0\n    \n    \n      US\n      431.0\n    \n    \n      VX\n      236.0\n    \n    \n      WN\n      493.0\n    \n  \n\n\n\n\n- 방법2: groupby() \\(\\to\\) key로 column 선택 \\(\\to\\) .agg(function) or .function()\n(예시1)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(np.mean)\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시2)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(mean)\n# mean에 \" \" 들어가도 된다\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시3)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].mean()\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n\n\nEX2: [AIRLINE, WEEKDAY] \\(\\to\\) {CANCELLED:mean}\n- 방법1\n(예시1)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY']).agg({'CANCELLED':np.sum})\n# 몇요일에 항공사별로 취소가 많이 되었는지 (sum)\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n(예시2)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY']).agg({'CANCELLED':sum})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].agg(np.sum)\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n(예시2)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].agg(\"sum\")\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n(예시3)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].sum()\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[[\"CANCELLED\"]].sum()\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n\n\nEX3: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean}, {DIVERTED: sum,mean}\n- 방법1\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[np.sum,np.mean],\"DIVERTED\":[np.sum,np.mean]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\nnp.sum([1,2,3])\n\n6\n\n\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[sum,np.mean],\"DIVERTED\":[sum,np.mean]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([np.sum,np.mean])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([\"sum\",\"mean\"])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시3) - 사용불가\n\n\nEX4: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean,count}, {AIR_TIME: mean,var}\n방법2 불가\n- 방법1\n(예시1)\n\ndf.groupby(['AIRLINE','WEEKDAY'])\\\n.agg({'CANCELLED':[np.sum,np.mean,len], 'AIR_TIME':[np.mean,np.var]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(예시2)\n\ndf.groupby(['AIRLINE','WEEKDAY'])\\\n.agg({'CANCELLED':[sum,mean,size], 'AIR_TIME':[mean\",\"var\"]})\n# 그 전에서는 큰 따옴표 없이도 다 됬는데, 여기서는 size 정의가 안 되어 있다고 나온다. 그래서 큰 따옴표를 해줘야 함!\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      size\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(사용자정의함수)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({'CANCELLED':[np.sum,np.mean,len],\n      'AIR_TIME':[np.mean,lambda x: np.std(x,ddof=1)**2]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      <lambda_0>\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_8(1024).html#연속형-변수를-기준으로-groupby---agg",
    "href": "posts/Data Visualization/DV_8(1024).html#연속형-변수를-기준으로-groupby---agg",
    "title": "DV 8주차",
    "section": "연속형 변수를 기준으로 groupby -> agg",
    "text": "연속형 변수를 기준으로 groupby -> agg\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      58482\n      58483\n      58484\n      58485\n      58486\n      58487\n      58488\n      58489\n      58490\n      58491\n    \n  \n  \n    \n      MONTH\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n    \n    \n      DAY\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n    \n    \n      WEEKDAY\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      ...\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n    \n    \n      AIRLINE\n      WN\n      UA\n      MQ\n      AA\n      WN\n      UA\n      AA\n      F9\n      AA\n      UA\n      ...\n      OO\n      B6\n      MQ\n      DL\n      EV\n      AA\n      F9\n      OO\n      WN\n      OO\n    \n    \n      ORG_AIR\n      LAX\n      DEN\n      DFW\n      DFW\n      LAX\n      IAH\n      DFW\n      SFO\n      ORD\n      IAH\n      ...\n      DEN\n      PHX\n      ORD\n      ATL\n      DFW\n      SFO\n      LAS\n      SFO\n      MSP\n      SFO\n    \n    \n      DEST_AIR\n      SLC\n      IAD\n      VPS\n      DCA\n      MCI\n      SAN\n      MSY\n      PHX\n      STL\n      SJC\n      ...\n      CPR\n      BOS\n      DSM\n      CMH\n      LFT\n      DFW\n      SFO\n      SBA\n      ATL\n      BOI\n    \n    \n      SCHED_DEP\n      1625\n      823\n      1305\n      1555\n      1720\n      1450\n      1250\n      1020\n      1845\n      925\n      ...\n      1850\n      2236\n      1333\n      2206\n      850\n      515\n      1910\n      1846\n      525\n      859\n    \n    \n      DEP_DELAY\n      58.0\n      7.0\n      36.0\n      7.0\n      48.0\n      1.0\n      84.0\n      -7.0\n      -5.0\n      3.0\n      ...\n      -2.0\n      -12.0\n      1.0\n      2.0\n      21.0\n      5.0\n      13.0\n      -6.0\n      39.0\n      5.0\n    \n    \n      AIR_TIME\n      94.0\n      154.0\n      85.0\n      126.0\n      166.0\n      178.0\n      64.0\n      91.0\n      44.0\n      215.0\n      ...\n      38.0\n      231.0\n      57.0\n      64.0\n      52.0\n      166.0\n      71.0\n      46.0\n      124.0\n      73.0\n    \n    \n      DIST\n      590\n      1452\n      641\n      1192\n      1363\n      1303\n      447\n      651\n      258\n      1608\n      ...\n      230\n      2300\n      299\n      447\n      351\n      1464\n      414\n      262\n      907\n      522\n    \n    \n      SCHED_ARR\n      1905\n      1333\n      1453\n      1935\n      2225\n      1620\n      1410\n      1315\n      1950\n      1136\n      ...\n      1956\n      515\n      1455\n      2338\n      1012\n      1045\n      2050\n      1956\n      855\n      1146\n    \n    \n      ARR_DELAY\n      65.0\n      -13.0\n      35.0\n      -7.0\n      39.0\n      -14.0\n      83.0\n      -6.0\n      -5.0\n      -14.0\n      ...\n      1.0\n      -45.0\n      -7.0\n      -8.0\n      14.0\n      -19.0\n      4.0\n      -5.0\n      34.0\n      -1.0\n    \n    \n      DIVERTED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      CANCELLED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n14 rows × 58492 columns\n\n\n\n\ndf.DIST.describe()\n\ncount    58492.000000\nmean       872.900072\nstd        624.996805\nmin         67.000000\n25%        391.000000\n50%        690.000000\n75%       1199.000000\nmax       4502.000000\nName: DIST, dtype: float64\n\n\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,391,690,1199,np.inf]))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      (-inf, 391.0]\n      18\n      0.015986\n      1126\n    \n    \n      (391.0, 690.0]\n      17\n      0.013589\n      1251\n    \n    \n      (690.0, 1199.0]\n      69\n      0.022066\n      3127\n    \n    \n      (1199.0, inf]\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      145\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      462\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      161\n    \n    \n      B6\n      (-inf, 391.0]\n      0\n      0.000000\n      71\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      38\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      61\n    \n    \n      (1199.0, inf]\n      1\n      0.002681\n      373\n    \n    \n      DL\n      (-inf, 391.0]\n      7\n      0.003086\n      2268\n    \n    \n      (391.0, 690.0]\n      8\n      0.002421\n      3304\n    \n    \n      (690.0, 1199.0]\n      16\n      0.006405\n      2498\n    \n    \n      (1199.0, inf]\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      (-inf, 391.0]\n      77\n      0.028785\n      2675\n    \n    \n      (391.0, 690.0]\n      47\n      0.022793\n      2062\n    \n    \n      (690.0, 1199.0]\n      22\n      0.019982\n      1101\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      20\n    \n    \n      F9\n      (-inf, 391.0]\n      0\n      0.000000\n      27\n    \n    \n      (391.0, 690.0]\n      6\n      0.013825\n      434\n    \n    \n      (690.0, 1199.0]\n      4\n      0.007105\n      563\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      293\n    \n    \n      HA\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      NaN\n      0\n    \n    \n      (690.0, 1199.0]\n      0\n      NaN\n      0\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      (-inf, 391.0]\n      90\n      0.047120\n      1910\n    \n    \n      (391.0, 690.0]\n      39\n      0.037356\n      1044\n    \n    \n      (690.0, 1199.0]\n      22\n      0.044266\n      497\n    \n    \n      (1199.0, inf]\n      1\n      0.050000\n      20\n    \n    \n      NK\n      (-inf, 391.0]\n      5\n      0.036496\n      137\n    \n    \n      (391.0, 690.0]\n      4\n      0.013201\n      303\n    \n    \n      (690.0, 1199.0]\n      6\n      0.011029\n      544\n    \n    \n      (1199.0, inf]\n      10\n      0.018797\n      532\n    \n    \n      OO\n      (-inf, 391.0]\n      75\n      0.024826\n      3021\n    \n    \n      (391.0, 690.0]\n      39\n      0.019364\n      2014\n    \n    \n      (690.0, 1199.0]\n      19\n      0.016351\n      1162\n    \n    \n      (1199.0, inf]\n      9\n      0.023018\n      391\n    \n    \n      UA\n      (-inf, 391.0]\n      5\n      0.007143\n      700\n    \n    \n      (391.0, 690.0]\n      14\n      0.011824\n      1184\n    \n    \n      (690.0, 1199.0]\n      26\n      0.010924\n      2380\n    \n    \n      (1199.0, inf]\n      48\n      0.013605\n      3528\n    \n    \n      US\n      (-inf, 391.0]\n      0\n      0.000000\n      254\n    \n    \n      (391.0, 690.0]\n      7\n      0.021944\n      319\n    \n    \n      (690.0, 1199.0]\n      2\n      0.006329\n      316\n    \n    \n      (1199.0, inf]\n      12\n      0.016529\n      726\n    \n    \n      VX\n      (-inf, 391.0]\n      2\n      0.008299\n      241\n    \n    \n      (391.0, 690.0]\n      1\n      0.003861\n      259\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      22\n    \n    \n      (1199.0, inf]\n      3\n      0.006369\n      471\n    \n    \n      WN\n      (-inf, 391.0]\n      55\n      0.023810\n      2310\n    \n    \n      (391.0, 690.0]\n      14\n      0.006487\n      2158\n    \n    \n      (690.0, 1199.0]\n      17\n      0.007896\n      2153\n    \n    \n      (1199.0, inf]\n      7\n      0.003895\n      1797\n    \n  \n\n\n\n\ncut과 관련된 설명: https://seong6496.tistory.com/247 참고\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=['~400','400~700','700~1200','1200~']))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      ~400\n      18\n      0.015986\n      1126\n    \n    \n      400~700\n      17\n      0.013589\n      1251\n    \n    \n      700~1200\n      69\n      0.022066\n      3127\n    \n    \n      1200~\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      0.000000\n      145\n    \n    \n      700~1200\n      0\n      0.000000\n      462\n    \n    \n      1200~\n      0\n      0.000000\n      161\n    \n    \n      B6\n      ~400\n      0\n      0.000000\n      71\n    \n    \n      400~700\n      0\n      0.000000\n      38\n    \n    \n      700~1200\n      0\n      0.000000\n      61\n    \n    \n      1200~\n      1\n      0.002681\n      373\n    \n    \n      DL\n      ~400\n      7\n      0.003040\n      2303\n    \n    \n      400~700\n      8\n      0.002352\n      3402\n    \n    \n      700~1200\n      16\n      0.006765\n      2365\n    \n    \n      1200~\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      ~400\n      77\n      0.027838\n      2766\n    \n    \n      400~700\n      48\n      0.023312\n      2059\n    \n    \n      700~1200\n      21\n      0.020731\n      1013\n    \n    \n      1200~\n      0\n      0.000000\n      20\n    \n    \n      F9\n      ~400\n      0\n      0.000000\n      27\n    \n    \n      400~700\n      7\n      0.015837\n      442\n    \n    \n      700~1200\n      3\n      0.005405\n      555\n    \n    \n      1200~\n      0\n      0.000000\n      293\n    \n    \n      HA\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      NaN\n      0\n    \n    \n      700~1200\n      0\n      NaN\n      0\n    \n    \n      1200~\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      ~400\n      92\n      0.047472\n      1938\n    \n    \n      400~700\n      39\n      0.035682\n      1093\n    \n    \n      700~1200\n      20\n      0.047619\n      420\n    \n    \n      1200~\n      1\n      0.050000\n      20\n    \n    \n      NK\n      ~400\n      5\n      0.036496\n      137\n    \n    \n      400~700\n      4\n      0.013201\n      303\n    \n    \n      700~1200\n      6\n      0.011029\n      544\n    \n    \n      1200~\n      10\n      0.018797\n      532\n    \n    \n      OO\n      ~400\n      76\n      0.024837\n      3060\n    \n    \n      400~700\n      38\n      0.018673\n      2035\n    \n    \n      700~1200\n      19\n      0.017241\n      1102\n    \n    \n      1200~\n      9\n      0.023018\n      391\n    \n    \n      UA\n      ~400\n      5\n      0.006993\n      715\n    \n    \n      400~700\n      14\n      0.011966\n      1170\n    \n    \n      700~1200\n      26\n      0.010929\n      2379\n    \n    \n      1200~\n      48\n      0.013605\n      3528\n    \n    \n      US\n      ~400\n      0\n      0.000000\n      254\n    \n    \n      400~700\n      7\n      0.021944\n      319\n    \n    \n      700~1200\n      2\n      0.006329\n      316\n    \n    \n      1200~\n      12\n      0.016529\n      726\n    \n    \n      VX\n      ~400\n      2\n      0.008299\n      241\n    \n    \n      400~700\n      1\n      0.003861\n      259\n    \n    \n      700~1200\n      0\n      0.000000\n      22\n    \n    \n      1200~\n      3\n      0.006369\n      471\n    \n    \n      WN\n      ~400\n      55\n      0.023022\n      2389\n    \n    \n      400~700\n      17\n      0.007795\n      2181\n    \n    \n      700~1200\n      14\n      0.006826\n      2051\n    \n    \n      1200~\n      7\n      0.003895\n      1797"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html",
    "href": "posts/Data Visualization/DV_4(0928).html",
    "title": "DV 4주차(2)",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#plt복습",
    "href": "posts/Data Visualization/DV_4(0928).html#plt복습",
    "title": "DV 4주차(2)",
    "section": "plt복습",
    "text": "plt복습\n\nplt.boxplot([y1,y2])\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f2a64e7a950>,\n  <matplotlib.lines.Line2D at 0x7f2a64e7ac90>,\n  <matplotlib.lines.Line2D at 0x7f2a64e910d0>,\n  <matplotlib.lines.Line2D at 0x7f2a64e913d0>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f2a64e83050>,\n  <matplotlib.lines.Line2D at 0x7f2a64e83350>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91710>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91a50>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f2a64e7a650>,\n  <matplotlib.lines.Line2D at 0x7f2a64e83d50>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f2a64e836d0>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91d90>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f2a64e83a10>,\n  <matplotlib.lines.Line2D at 0x7f2a64e9e110>],\n 'means': []}"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-wide-df",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-wide-df",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({1:y1,2:y2})\ndf1\n\n\n\n\n\n  \n    \n      \n      1\n      2\n    \n  \n  \n    \n      0\n      75\n      76\n    \n    \n      1\n      75\n      76\n    \n    \n      2\n      76\n      77\n    \n    \n      3\n      76\n      77\n    \n    \n      4\n      77\n      78\n    \n    \n      5\n      77\n      78\n    \n    \n      6\n      79\n      80\n    \n    \n      7\n      79\n      80\n    \n    \n      8\n      79\n      80\n    \n    \n      9\n      98\n      81\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df1)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.boxplot(np.stack([y1,y2],axis=1))   # 잘 쓰진 않는데 된다\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-long-df",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-long-df",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\nvalue 를 넣고 그 value가 어떤 category에 있는지 넣는 방법\n\ndf2 = pd.DataFrame({'score': y1+y2, 'class': ['A']*len(y1)+['B']*len(y2)})\ndf2\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df2, x='class', y='score')\n\n<AxesSubplot:xlabel='class', ylabel='score'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-array",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-array",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n- 예시1\n\nsns.boxplot(data=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시2\n\nsns.boxplot(y=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시3\n\nsns.boxplot(x=y1)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#plt-복습",
    "href": "posts/Data Visualization/DV_4(0928).html#plt-복습",
    "title": "DV 4주차(2)",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.hist(x,alpha=0.5)\nplt.hist(y,alpha=0.5)\n\n(array([2.000e+00, 1.500e+01, 1.550e+02, 7.670e+02, 2.062e+03, 3.085e+03,\n        2.479e+03, 1.117e+03, 2.790e+02, 3.900e+01]),\n array([-3.5473064 , -2.74724651, -1.94718662, -1.14712673, -0.34706684,\n         0.45299304,  1.25305293,  2.05311282,  2.85317271,  3.6532326 ,\n         4.45329248]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 예시2\n\nplt.hist([x,y]);"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-wide-df-1",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-wide-df-1",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({'x':x, 'y':y})\ndf1\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.392340\n      -0.520932\n    \n    \n      1\n      -0.027382\n      2.332888\n    \n    \n      2\n      -0.266977\n      0.973511\n    \n    \n      3\n      -0.493336\n      2.801266\n    \n    \n      4\n      0.282255\n      0.433189\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      9995\n      -0.752878\n      2.394238\n    \n    \n      9996\n      -0.212005\n      2.293700\n    \n    \n      9997\n      -1.118235\n      2.660186\n    \n    \n      9998\n      1.558492\n      0.886679\n    \n    \n      9999\n      -0.753399\n      1.977537\n    \n  \n\n10000 rows × 2 columns\n\n\n\n- 예시\n\nsns.histplot(data=df1);\n\n\n\n\n\nsns.histplot(data=df1,bins=20)  # 칸 조정\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True);    # kde : 곡선\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\");\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\",lw=5) # mpl에 대한 존경심 확인 \n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-long-df-1",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-long-df-1",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf2=pd.DataFrame({'val' : np.concatenate([x,y]), 'var': ['x']*len(x) + ['y']*len(y)})\ndf2\n\n\n\n\n\n  \n    \n      \n      val\n      var\n    \n  \n  \n    \n      0\n      0.392340\n      x\n    \n    \n      1\n      -0.027382\n      x\n    \n    \n      2\n      -0.266977\n      x\n    \n    \n      3\n      -0.493336\n      x\n    \n    \n      4\n      0.282255\n      x\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      2.394238\n      y\n    \n    \n      19996\n      2.293700\n      y\n    \n    \n      19997\n      2.660186\n      y\n    \n    \n      19998\n      0.886679\n      y\n    \n    \n      19999\n      1.977537\n      y\n    \n  \n\n20000 rows × 2 columns\n\n\n\n\nsns.histplot(data=df2, x='val', hue='var', bins=20, kde=True, lw=0)\n# hue:색깔 var로 구분하겠다! \n\n<AxesSubplot:xlabel='val', ylabel='Count'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-array-1",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-array-1",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n\nsns.histplot(data=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(x=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(x=x, color='C0', bins=20, lw=0)\nsns.histplot(x=y, color='C0', bins=20, lw=0)\n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#plt복습-1",
    "href": "posts/Data Visualization/DV_4(0928).html#plt복습-1",
    "title": "DV 4주차(2)",
    "section": "plt복습",
    "text": "plt복습\n\nplt.plot(ϵ,'--o')\n\n\n\n\n\nplt.plot(y,'--o')"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-array-2",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-array-2",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n\nsns.lineplot(data=ϵ)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.lineplot(data=y)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-wide-df-2",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-wide-df-2",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf4 = pd.DataFrame({'ϵ' : ϵ , 'y' : y})\ndf4\n\n\n\n\n\n  \n    \n      \n      ϵ\n      y\n    \n  \n  \n    \n      0\n      0.383420\n      0.383420\n    \n    \n      1\n      1.084175\n      1.467595\n    \n    \n      2\n      1.142778\n      2.610373\n    \n    \n      3\n      0.307894\n      2.918267\n    \n    \n      4\n      0.237787\n      3.156054\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      1.308688\n      -10.598788\n    \n    \n      96\n      0.405376\n      -10.193412\n    \n    \n      97\n      -0.185070\n      -10.378481\n    \n    \n      98\n      1.055388\n      -9.323094\n    \n    \n      99\n      1.187014\n      -8.136079\n    \n  \n\n100 rows × 2 columns\n\n\n\n\nsns.lineplot(data=df4)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.lineplot(data=df4, dashes=False)   # dashes : 둘다 실선\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/Data Visualization/DV_4(0928).html#sns-long-df-2",
    "href": "posts/Data Visualization/DV_4(0928).html#sns-long-df-2",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf5= pd.DataFrame({'idx':list(range(100))*2,'val':np.concatenate([ϵ,y]),'cat':['eps']*100 + ['y']*100 })\ndf5\n\n\n\n\n\n  \n    \n      \n      idx\n      val\n      cat\n    \n  \n  \n    \n      0\n      0\n      0.383420\n      eps\n    \n    \n      1\n      1\n      1.084175\n      eps\n    \n    \n      2\n      2\n      1.142778\n      eps\n    \n    \n      3\n      3\n      0.307894\n      eps\n    \n    \n      4\n      4\n      0.237787\n      eps\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      95\n      -10.598788\n      y\n    \n    \n      196\n      96\n      -10.193412\n      y\n    \n    \n      197\n      97\n      -10.378481\n      y\n    \n    \n      198\n      98\n      -9.323094\n      y\n    \n    \n      199\n      99\n      -8.136079\n      y\n    \n  \n\n200 rows × 3 columns\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',hue='cat')\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',style='cat',hue='cat',markers=True)\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',style='cat',hue='cat',dashes=[(3,1),(3,3)],markers=['o','o'])\n\n<AxesSubplot:xlabel='idx', ylabel='val'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html",
    "href": "posts/Data Visualization/DV_10(1107).html",
    "title": "DV 10주차(1)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#melt",
    "href": "posts/Data Visualization/DV_10(1107).html#melt",
    "title": "DV 10주차(1)",
    "section": "melt",
    "text": "melt\n- 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      461\n      324\n      136\n      109\n      76\n      81\n      43\n      37\n      135\n      28\n      39\n      14\n      22\n      17\n      20\n      17\n    \n    \n      1\n      2019-11\n      461\n      358\n      167\n      141\n      86\n      61\n      29\n      36\n      141\n      27\n      29\n      20\n      23\n      10\n      19\n      27\n    \n    \n      2\n      2019-12\n      426\n      383\n      143\n      105\n      53\n      45\n      51\n      48\n      129\n      30\n      20\n      26\n      28\n      18\n      18\n      19\n    \n    \n      3\n      2020-01\n      677\n      494\n      212\n      187\n      110\n      79\n      65\n      49\n      158\n      23\n      13\n      19\n      19\n      22\n      27\n      22\n    \n    \n      4\n      2020-02\n      593\n      520\n      217\n      195\n      112\n      67\n      62\n      71\n      157\n      25\n      18\n      16\n      24\n      18\n      23\n      20\n    \n    \n      5\n      2020-03\n      637\n      537\n      246\n      187\n      92\n      66\n      59\n      67\n      145\n      21\n      16\n      24\n      18\n      31\n      22\n      14\n    \n    \n      6\n      2020-04\n      647\n      583\n      222\n      154\n      98\n      59\n      48\n      64\n      113\n      20\n      23\n      25\n      19\n      19\n      23\n      21\n    \n    \n      7\n      2020-05\n      629\n      518\n      192\n      176\n      91\n      87\n      50\n      66\n      150\n      43\n      27\n      15\n      18\n      19\n      19\n      13\n    \n    \n      8\n      2020-06\n      663\n      552\n      209\n      185\n      93\n      69\n      54\n      60\n      140\n      39\n      16\n      16\n      17\n      29\n      25\n      16\n    \n    \n      9\n      2020-07\n      599\n      471\n      214\n      193\n      89\n      78\n      65\n      59\n      130\n      40\n      27\n      25\n      21\n      18\n      18\n      12\n    \n    \n      10\n      2020-08\n      615\n      567\n      204\n      182\n      105\n      82\n      62\n      42\n      129\n      47\n      16\n      23\n      21\n      27\n      23\n      20\n    \n    \n      11\n      2020-09\n      621\n      481\n      230\n      220\n      102\n      88\n      56\n      49\n      143\n      54\n      14\n      15\n      17\n      15\n      19\n      15\n    \n    \n      12\n      2020-10\n      637\n      555\n      232\n      203\n      90\n      52\n      63\n      49\n      140\n      33\n      17\n      20\n      22\n      9\n      22\n      21\n    \n  \n\n\n\n\n- 사용예시\n\ndf.melt()\n\n\n\n\n\n  \n    \n      \n      variable\n      value\n    \n  \n  \n    \n      0\n      Date\n      2019-10\n    \n    \n      1\n      Date\n      2019-11\n    \n    \n      2\n      Date\n      2019-12\n    \n    \n      3\n      Date\n      2020-01\n    \n    \n      4\n      Date\n      2020-02\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      216\n      Asus\n      16\n    \n    \n      217\n      Asus\n      12\n    \n    \n      218\n      Asus\n      20\n    \n    \n      219\n      Asus\n      15\n    \n    \n      220\n      Asus\n      21\n    \n  \n\n221 rows × 2 columns\n\n\n\n\nvariable: column name들이 들어간다.\nvalue: column name에 대응하는 값들이 들어간다.\n\n- 사용예시2: id_vars -> tidy data\n\ndf.melt(id_vars='Date')\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns\n\n\n\n- 사용예시3:\n\ndf.set_index('Date').melt()\n# 인덱스를 무시하면서 녹여버림\n\n\n\n\n\n  \n    \n      \n      variable\n      value\n    \n  \n  \n    \n      0\n      Samsung\n      461\n    \n    \n      1\n      Samsung\n      461\n    \n    \n      2\n      Samsung\n      426\n    \n    \n      3\n      Samsung\n      677\n    \n    \n      4\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      203\n      Asus\n      16\n    \n    \n      204\n      Asus\n      12\n    \n    \n      205\n      Asus\n      20\n    \n    \n      206\n      Asus\n      15\n    \n    \n      207\n      Asus\n      21\n    \n  \n\n208 rows × 2 columns\n\n\n\n- 사용예시4: ignore_index=False\n\ndf.set_index('Date').melt(ignore_index=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#stack",
    "href": "posts/Data Visualization/DV_10(1107).html#stack",
    "title": "DV 10주차(1)",
    "section": "stack",
    "text": "stack\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n\ndf.stack()\n\n\n\n\n\n  \n    \n      \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      mean\n      0.032106\n      0.004699\n    \n    \n      count\n      1277.000000\n      1277.000000\n    \n    \n      2\n      mean\n      0.007341\n      0.001631\n    \n    \n      count\n      1226.000000\n      1226.000000\n    \n    \n      3\n      mean\n      0.011949\n      0.001494\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      5\n      count\n      1201.000000\n      1201.000000\n    \n    \n      6\n      mean\n      0.010132\n      0.003040\n    \n    \n      count\n      987.000000\n      987.000000\n    \n    \n      7\n      mean\n      0.006066\n      0.002600\n    \n    \n      count\n      1154.000000\n      1154.000000\n    \n  \n\n196 rows × 2 columns\n\n\n\n- 사용에시2\n\ndf.stack().stack().reset_index().rename({0:'value'},axis=1)\n#df.stack().stack().reset_index().rename(columns={'level_2':'aggtype'})\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      level_2\n      level_3\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      mean\n      CANCELLED\n      0.032106\n    \n    \n      1\n      AA\n      1\n      mean\n      DIVERTED\n      0.004699\n    \n    \n      2\n      AA\n      1\n      count\n      CANCELLED\n      1277.000000\n    \n    \n      3\n      AA\n      1\n      count\n      DIVERTED\n      1277.000000\n    \n    \n      4\n      AA\n      2\n      mean\n      CANCELLED\n      0.007341\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      6\n      count\n      DIVERTED\n      987.000000\n    \n    \n      388\n      WN\n      7\n      mean\n      CANCELLED\n      0.006066\n    \n    \n      389\n      WN\n      7\n      mean\n      DIVERTED\n      0.002600\n    \n    \n      390\n      WN\n      7\n      count\n      CANCELLED\n      1154.000000\n    \n    \n      391\n      WN\n      7\n      count\n      DIVERTED\n      1154.000000\n    \n  \n\n392 rows × 5 columns\n\n\n\n- 사용예시3(unstack)\n\ndf.stack().unstack()\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277.0\n      0.004699\n      1277.0\n    \n    \n      2\n      0.007341\n      1226.0\n      0.001631\n      1226.0\n    \n    \n      3\n      0.011949\n      1339.0\n      0.001494\n      1339.0\n    \n    \n      4\n      0.015004\n      1333.0\n      0.003751\n      1333.0\n    \n    \n      5\n      0.014151\n      1272.0\n      0.000786\n      1272.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275.0\n      0.001569\n      1275.0\n    \n    \n      4\n      0.007911\n      1264.0\n      0.003165\n      1264.0\n    \n    \n      5\n      0.005828\n      1201.0\n      0.000000\n      1201.0\n    \n    \n      6\n      0.010132\n      987.0\n      0.003040\n      987.0\n    \n    \n      7\n      0.006066\n      1154.0\n      0.002600\n      1154.0\n    \n  \n\n98 rows × 4 columns\n\n\n\ntidy data를 만들기 위해 melt, stack를 잘 이용하자"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#tidydata의-정의",
    "href": "posts/Data Visualization/DV_10(1107).html#tidydata의-정의",
    "title": "DV 10주차(1)",
    "section": "tidydata의 정의",
    "text": "tidydata의 정의\n- 느낌: ggplot로 그림 그리기 좋은 데이터 + pandas로 query, group by 등을 쓰기 좋은 자료\n- 정의: https://r4ds.had.co.nz/tidy-data.html\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n- 예시1 (tidydata)\n\n\n\nobs\nx\ny\nshape\ncolor\n\n\n\n\n0\n0\n0\n‘star’\n‘F’\n\n\n1\n0\n1\n‘circ’\n‘F’\n\n\n2\n1\n0\n‘star’\n‘M’\n\n\n3\n1\n1\n‘circ’\n‘M’\n\n\n\n- 예시2 (tidy data x)\n\n\n\n\nshape=star\nshape=circ\n\n\n\n\ncolor=F\n(0,0)\n(0,1)\n\n\ncolor=M\n(1,0)\n(1,1)"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#예제1-wide-df",
    "href": "posts/Data Visualization/DV_10(1107).html#예제1-wide-df",
    "title": "DV 10주차(1)",
    "section": "예제1: wide df",
    "text": "예제1: wide df\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      461\n      324\n      136\n      109\n      76\n      81\n      43\n      37\n      135\n      28\n      39\n      14\n      22\n      17\n      20\n      17\n    \n    \n      1\n      2019-11\n      461\n      358\n      167\n      141\n      86\n      61\n      29\n      36\n      141\n      27\n      29\n      20\n      23\n      10\n      19\n      27\n    \n    \n      2\n      2019-12\n      426\n      383\n      143\n      105\n      53\n      45\n      51\n      48\n      129\n      30\n      20\n      26\n      28\n      18\n      18\n      19\n    \n    \n      3\n      2020-01\n      677\n      494\n      212\n      187\n      110\n      79\n      65\n      49\n      158\n      23\n      13\n      19\n      19\n      22\n      27\n      22\n    \n    \n      4\n      2020-02\n      593\n      520\n      217\n      195\n      112\n      67\n      62\n      71\n      157\n      25\n      18\n      16\n      24\n      18\n      23\n      20\n    \n    \n      5\n      2020-03\n      637\n      537\n      246\n      187\n      92\n      66\n      59\n      67\n      145\n      21\n      16\n      24\n      18\n      31\n      22\n      14\n    \n    \n      6\n      2020-04\n      647\n      583\n      222\n      154\n      98\n      59\n      48\n      64\n      113\n      20\n      23\n      25\n      19\n      19\n      23\n      21\n    \n    \n      7\n      2020-05\n      629\n      518\n      192\n      176\n      91\n      87\n      50\n      66\n      150\n      43\n      27\n      15\n      18\n      19\n      19\n      13\n    \n    \n      8\n      2020-06\n      663\n      552\n      209\n      185\n      93\n      69\n      54\n      60\n      140\n      39\n      16\n      16\n      17\n      29\n      25\n      16\n    \n    \n      9\n      2020-07\n      599\n      471\n      214\n      193\n      89\n      78\n      65\n      59\n      130\n      40\n      27\n      25\n      21\n      18\n      18\n      12\n    \n    \n      10\n      2020-08\n      615\n      567\n      204\n      182\n      105\n      82\n      62\n      42\n      129\n      47\n      16\n      23\n      21\n      27\n      23\n      20\n    \n    \n      11\n      2020-09\n      621\n      481\n      230\n      220\n      102\n      88\n      56\n      49\n      143\n      54\n      14\n      15\n      17\n      15\n      19\n      15\n    \n    \n      12\n      2020-10\n      637\n      555\n      232\n      203\n      90\n      52\n      63\n      49\n      140\n      33\n      17\n      20\n      22\n      9\n      22\n      21\n    \n  \n\n\n\n\n\ntidy data 아님\n정의에 의한 판단: 하나의 observation이 하나의 행을 차지하고 있지 않음.\n직관적인 판단: 회사별로 색을 다르게 하여 x:‘Date’, y:’판매량’을 하고 싶다면?\n\n- tidydata로 변환 (melt는 너무 쉬우니까 stack으로 해보자)\n\ndf.set_index('Date').stack().reset_index().rename({'level_1':'Company',0:'Sales'},axis=1)\n\n# axis=1 을 설정을 안해주면 index에 있는 0이 바뀌므로 컬럼에 있는 0 값을 바꿔주기 위해서 axis를 표시\n\n\n\n\n\n  \n    \n      \n      Date\n      Company\n      Sales\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-10\n      Apple\n      324\n    \n    \n      2\n      2019-10\n      Huawei\n      136\n    \n    \n      3\n      2019-10\n      Xiaomi\n      109\n    \n    \n      4\n      2019-10\n      Oppo\n      76\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-10\n      Nokia\n      20\n    \n    \n      204\n      2020-10\n      Lenovo\n      22\n    \n    \n      205\n      2020-10\n      OnePlus\n      9\n    \n    \n      206\n      2020-10\n      Sony\n      22\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns\n\n\n\n\ndf.melt('Date')\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#예제2-multi-indexed-data",
    "href": "posts/Data Visualization/DV_10(1107).html#예제2-multi-indexed-data",
    "title": "DV 10주차(1)",
    "section": "예제2: multi-indexed data",
    "text": "예제2: multi-indexed data\n- 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n\nWEEKDAY == 4 and mean(CANCELLED)> 0.001\n\n- tidydata로 변환 (stack으로 풀면 너무 쉬우니까 melt로 해보자)\n\ndf.melt(ignore_index=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      CANCELLED\n      mean\n      0.032106\n    \n    \n      1\n      AA\n      2\n      CANCELLED\n      mean\n      0.007341\n    \n    \n      2\n      AA\n      3\n      CANCELLED\n      mean\n      0.011949\n    \n    \n      3\n      AA\n      4\n      CANCELLED\n      mean\n      0.015004\n    \n    \n      4\n      AA\n      5\n      CANCELLED\n      mean\n      0.014151\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      3\n      DIVERTED\n      count\n      1275.000000\n    \n    \n      388\n      WN\n      4\n      DIVERTED\n      count\n      1264.000000\n    \n    \n      389\n      WN\n      5\n      DIVERTED\n      count\n      1201.000000\n    \n    \n      390\n      WN\n      6\n      DIVERTED\n      count\n      987.000000\n    \n    \n      391\n      WN\n      7\n      DIVERTED\n      count\n      1154.000000\n    \n  \n\n392 rows × 5 columns\n\n\n\n\ndf.stack().stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      level_2\n      level_3\n      0\n    \n  \n  \n    \n      0\n      AA\n      1\n      mean\n      CANCELLED\n      0.032106\n    \n    \n      1\n      AA\n      1\n      mean\n      DIVERTED\n      0.004699\n    \n    \n      2\n      AA\n      1\n      count\n      CANCELLED\n      1277.000000\n    \n    \n      3\n      AA\n      1\n      count\n      DIVERTED\n      1277.000000\n    \n    \n      4\n      AA\n      2\n      mean\n      CANCELLED\n      0.007341\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      6\n      count\n      DIVERTED\n      987.000000\n    \n    \n      388\n      WN\n      7\n      mean\n      CANCELLED\n      0.006066\n    \n    \n      389\n      WN\n      7\n      mean\n      DIVERTED\n      0.002600\n    \n    \n      390\n      WN\n      7\n      count\n      CANCELLED\n      1154.000000\n    \n    \n      391\n      WN\n      7\n      count\n      DIVERTED\n      1154.000000\n    \n  \n\n392 rows × 5 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_col",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_col",
    "title": "DV 10주차(1)",
    "section": "geom_col",
    "text": "geom_col\n- 예시1: 한국과 일본의 평균능력치 비교\n\ndf.groupby(\"Nationality\").agg({'Overall':np.mean})\n\n\n\n\n\n  \n    \n      \n      Overall\n    \n    \n      Nationality\n      \n    \n  \n  \n    \n      Japan\n      66.478873\n    \n    \n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\ndata=df.groupby(\"Nationality\").agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall'))\n\n\n\n\n<ggplot: (8768299681497)>\n\n\n- 예시2: 한국과 일본의 평균능력치 비교 (색상비교)\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall', color='Nationality'))\n\n\n\n\n<ggplot: (8768299537529)>\n\n\n\ncolor로 설정하니까 테두리에만 색이 변경\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall', fill='Nationality'))\n\n\n\n\n<ggplot: (8768299479765)>\n\n\n- 예시3: 한국과 일본의 평균연령 비교\n\ndata=df.groupby(\"Nationality\").agg({'Age':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Age\n    \n  \n  \n    \n      0\n      Japan\n      26.084507\n    \n    \n      1\n      Korea Republic\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Age', fill='Nationality'))\n\n\n\n\n<ggplot: (8768299452801)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_col-position-dodge",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_col-position-dodge",
    "title": "DV 10주차(1)",
    "section": "geom_col + position = ‘dodge’",
    "text": "geom_col + position = ‘dodge’\n- 예시1: 한국과 일본의 평균연령+ 평균능력치 비교\n\ndata=df.groupby('Nationality')[['Overall','Age']].mean().reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n      Age\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n      26.084507\n    \n    \n      1\n      Korea Republic\n      65.457627\n      27.158192\n    \n  \n\n\n\n\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'))\n\n\n\n\n<ggplot: (8768299401365)>\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\n\n\n\n\n<ggplot: (8768299487993)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_col-coord_flip-90도회전",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_col-coord_flip-90도회전",
    "title": "DV 10주차(1)",
    "section": "geom_col + coord_flip() 90도회전",
    "text": "geom_col + coord_flip() 90도회전\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+coord_flip() # 90도 회전\n\n\n\n\n<ggplot: (8768299486913)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_col-facet_wrapvar-면분할",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_col-facet_wrapvar-면분할",
    "title": "DV 10주차(1)",
    "section": "geom_col + facet_wrap(var) 면분할",
    "text": "geom_col + facet_wrap(var) 면분할\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('level_1')\n\n\n\n\n<ggplot: (8768299327049)>\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('level_1')\n\n\n\n\n<ggplot: (8768299261221)>\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('Nationality')\n\n\n\n\n<ggplot: (8768299202429)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_col-facet_gridvar_y-var_x",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_col-facet_gridvar_y-var_x",
    "title": "DV 10주차(1)",
    "section": "geom_col + facet_grid(‘var_y ~ var_x’)",
    "text": "geom_col + facet_grid(‘var_y ~ var_x’)\n- 예시1: 한국과 일본의 평균연령+평균능력치+최대능력치 비교(면분할)\n\ndata=df.groupby('Nationality').agg({'Overall':[np.mean,np.max],'Age':np.mean})\\\n.melt(ignore_index=False).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      mean\n      66.478873\n    \n    \n      1\n      Korea Republic\n      Overall\n      mean\n      65.457627\n    \n    \n      2\n      Japan\n      Overall\n      amax\n      79.000000\n    \n    \n      3\n      Korea Republic\n      Overall\n      amax\n      89.000000\n    \n    \n      4\n      Japan\n      Age\n      mean\n      26.084507\n    \n    \n      5\n      Korea Republic\n      Age\n      mean\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(fill='Nationality',x='Nationality',y='value'),position='dodge')\\\n+facet_grid('variable_1~variable_0')\n\n\n\n\n<ggplot: (8768299165069)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_bar-vs-geom_col",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_bar-vs-geom_col",
    "title": "DV 10주차(1)",
    "section": "geom_bar vs geom_col",
    "text": "geom_bar vs geom_col\n- 예시1: 한국과 일본의 단순 선수 숫자 비교 (with goem_col)\n\ndata=df.groupby('Nationality').agg({'Age':'count'}).reset_index().rename({'Age':'count'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      count\n    \n  \n  \n    \n      0\n      Japan\n      284\n    \n    \n      1\n      Korea Republic\n      177\n    \n  \n\n\n\n\n단순 숫자 비교이므로 Age, Overall 아무거나 변수 넣어도 상관 없음\n\nggplot(data) + geom_col(aes(x='Nationality',fill='Nationality', y='count'))\n\n\n\n\n<ggplot: (8768298937265)>\n\n\n- 예시2: 한국과 일본의 단순 선수 숫자 비교 (with goem_bar)\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'))\n\n\n\n\n<ggplot: (8768298906069)>\n\n\n\ngeom_bar : groupby + count 가 자동으로 수행된다.\n특징1: 원래 데이터프레임 그대로 하는게 아니라 뭔가 변형된 값이 출력 (정확하게는 groupby + count가 변형요소)\n특징2: y는 당연히 count이므로 y를 명시할 필요가 없음. (잘 생각해보면 명시하고 싶어도 명시할 수 없음, y는 groupby + count 에 의해서 계산된 값이고 df자체에는 존재하지 않음)\n\n- 이렇게 약속된 변형은 stat='count' 옵션 때문에 가능함\n\nstat='count'는 그룹바이이후에 count를 하라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'), stat='count')\n\n\n\n\n<ggplot: (8768298885053)>\n\n\n- stat='identity’ 로 옵션을 바꾸면 약속된 변환이 수행되지 않음\n\nstat='identity'는 아무 변환도 하지말라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'), stat='identity')\n\nKeyError: 'y'\n\n\n\n아무것도 변환하지 말라는 의미이므로 에러가 난다.\n\n- 아래 3개의 코드는 모두 같다.\n\nggplot(df)+geom_bar(aes(x='Nationality',y='..count..',fill='Nationality'),stat='count')\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'),stat='count') # y='..count..' 생략,\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality')) # y='..count..' 생략, stat='count' 생략\n\n\n\n\n<ggplot: (8768298833649)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1107).html#geom_bar의-불편한-점",
    "href": "posts/Data Visualization/DV_10(1107).html#geom_bar의-불편한-점",
    "title": "DV 10주차(1)",
    "section": "geom_bar()의 불편한 점",
    "text": "geom_bar()의 불편한 점\n- 사실 편하라고 만든것 같은데, 그닥 편하지 않음.\n\n편하라고 만든 점1: groupby를 자동으로 해줘서 groupby를 못하는 유저들이 사용하기 편리하게 함 -> 그런데 우리는 groupby 잘함\n편하라고 만든 점2: groupby이후 count연산을 알아서 해줌 -> 그런데 count연산만 알아서해주고 그 이외의 연산은 잘 지원안됨\n\n- 결론: groupby + count 조합에서만 편리하고 나머지는 편하지 않다.\n- 불편한 예시: 나라별 overall의 평균을 geom_bar()로 플랏해보라.\n\ndata= df.groupby('Nationality').agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data)+geom_bar(aes(x='Nationality',y='Overall',fill='Nationality'),stat='identity')\nggplot(data)+geom_col(aes(x='Nationality',y='Overall',fill='Nationality'))\n\n\n\n\n<ggplot: (8768298826637)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html",
    "href": "posts/Data Visualization/DV_2(0914).html",
    "title": "DV 2주차",
    "section": "",
    "text": "!pip install opencv-python\n\nCollecting opencv-python\n  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.8/61.8 MB 42.7 MB/s eta 0:00:0000:0100:01\nRequirement already satisfied: numpy>=1.17.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from opencv-python) (1.21.6)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.7.0.68\n- 히스토그램 이퀄라이제이션(https://en.wikipedia.org/wiki/Histogram_equalization)"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html#이미지-자료-다운로드",
    "href": "posts/Data Visualization/DV_2(0914).html#이미지-자료-다운로드",
    "title": "DV 2주차",
    "section": "이미지 자료 다운로드",
    "text": "이미지 자료 다운로드\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg')\n\n--2023-02-22 16:32:29--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg.1’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   519KB/s    in 0.2s    \n\n2023-02-22 16:32:29 (519 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg.1’ saved [110895/110895]\n\n\n\n\nimg.shape  # 가로, 세로 픽셀, 채널(빨,녹,파..)\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img)\n\n<matplotlib.image.AxesImage at 0x7fc8361704d0>"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html#이미지-자료의-이해",
    "href": "posts/Data Visualization/DV_2(0914).html#이미지-자료의-이해",
    "title": "DV 2주차",
    "section": "이미지 자료의 이해",
    "text": "이미지 자료의 이해\n\n비밀1: 이미지는 사실 숫자들의 집합이다.\n- 예시1\n\n_img1 = np.array([0,30,90,120,150,180,210,240,255]).reshape(3,3)\n_img1\n\narray([[  0,  30,  90],\n       [120, 150, 180],\n       [210, 240, 255]])\n\n\n\nplt.imshow(_img1, cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fc831d80090>\n\n\n\n\n\n- 예시2\n\n_img2 = np.array([0,20,40,60,80,100,120,140,160]).reshape(3,3)\n_img2\n\narray([[  0,  20,  40],\n       [ 60,  80, 100],\n       [120, 140, 160]])\n\n\n\nplt.imshow(_img2, cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fc831e82510>\n\n\n\n\n\n- 예시3\n\n_img3=np.concatenate([_img1, _img2], axis=1)\n_img3\n\narray([[  0,  30,  90,   0,  20,  40],\n       [120, 150, 180,  60,  80, 100],\n       [210, 240, 255, 120, 140, 160]])\n\n\n\nplt.imshow(_img3, cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fc830ec8d50>\n\n\n\n\n\n\n\n비밀2: 칼라이미지는 red + green + blue 의 조합으로 표현가능 (다른방식도 가능)\n- 예시1\n\nr=np.array([0]*25*3).reshape(5,5,3)\ng=np.array([0]*25*3).reshape(5,5,3)\nb=np.array([0]*25*3).reshape(5,5,3)\n\n\nr[:3,:3,0] = 255   \ng[:3,2:,1] = 255 \nb[2:,:,2] = 255\n\n\nplt.imshow(r)\n\n<matplotlib.image.AxesImage at 0x7fc830cd4f50>\n\n\n\n\n\n\nplt.imshow(g)\n\n<matplotlib.image.AxesImage at 0x7fc830e48650>\n\n\n\n\n\n\nplt.imshow(b)\n\n<matplotlib.image.AxesImage at 0x7fc830bd8950>\n\n\n\n\n\n\nplt.imshow(r+g+b)   # 빛의 3원색..색의 3원색\n\n<matplotlib.image.AxesImage at 0x7fc830be4f90>\n\n\n\n\n\n- 예시2: R,G,B를 같은 비율로 섞으면 무채색이 된다.\n\nr = np.array([0]*25*3).reshape(5,5,3) \ng = np.array([0]*25*3).reshape(5,5,3) \nb = np.array([0]*25*3).reshape(5,5,3) \nr[:3,:3,0] = 80   \ng[:3,2:,1] = 80\nb[2:,:,2] = 80 \n\n\nplt.imshow(r+g+b)\n\n<matplotlib.image.AxesImage at 0x7fc830bd8d10>\n\n\n\n\n\n- 예시3\n\nimg.shape\n\n(683, 1024, 3)\n\n\n\nimg_red = img * 0\nimg_green = img * 0\nimg_blue = img * 0\n\n\nimg_red[...,0] = img[...,0]\nimg_green[...,0] = img[...,1]\nimg_blue[...,0] = img[...,2]\n\n\nplt.imshow(img_red)\n\n<matplotlib.image.AxesImage at 0x7fc8309c6ed0>\n\n\n\n\n\n\nplt.imshow(img_red)"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html#히스토그램-이퀄라이제이션",
    "href": "posts/Data Visualization/DV_2(0914).html#히스토그램-이퀄라이제이션",
    "title": "DV 2주차",
    "section": "히스토그램 이퀄라이제이션",
    "text": "히스토그램 이퀄라이제이션\n- 이미지를 rgb로 각각 분리하고 각 색깔들의 히스토그램을 그려보자.\n\nimg_red[:,:,0].reshape(-1).shape\n\n(699392,)\n\n\n\nimg_red[:,:,0].shape  # 위 699392 = 683 * 1024\n\n(683, 1024)\n\n\n\nplt.hist(img[:,:,0].reshape(-1))\n\n(array([  3691.,  56282., 235628., 170392., 120545.,  60511.,  22052.,\n         14354.,  15246.,    691.]),\n array([114. , 123.4, 132.8, 142.2, 151.6, 161. , 170.4, 179.8, 189.2,\n        198.6, 208. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(img_red[:,:,0].reshape(-1),bins=255)\n\n(array([1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n        1.2000e+01, 0.0000e+00, 0.0000e+00, 1.9000e+01, 0.0000e+00,\n        4.9000e+01, 0.0000e+00, 0.0000e+00, 9.3000e+01, 0.0000e+00,\n        0.0000e+00, 2.2000e+02, 0.0000e+00, 4.8800e+02, 0.0000e+00,\n        0.0000e+00, 1.0610e+03, 0.0000e+00, 0.0000e+00, 1.7470e+03,\n        0.0000e+00, 0.0000e+00, 2.1600e+03, 0.0000e+00, 2.7180e+03,\n        0.0000e+00, 0.0000e+00, 3.2590e+03, 0.0000e+00, 0.0000e+00,\n        4.0390e+03, 0.0000e+00, 5.1080e+03, 0.0000e+00, 0.0000e+00,\n        6.3950e+03, 0.0000e+00, 0.0000e+00, 8.4630e+03, 0.0000e+00,\n        0.0000e+00, 1.0610e+04, 0.0000e+00, 1.3530e+04, 0.0000e+00,\n        0.0000e+00, 1.6115e+04, 0.0000e+00, 0.0000e+00, 1.9125e+04,\n        0.0000e+00, 2.2186e+04, 0.0000e+00, 0.0000e+00, 2.5696e+04,\n        0.0000e+00, 0.0000e+00, 2.8701e+04, 0.0000e+00, 0.0000e+00,\n        2.8324e+04, 0.0000e+00, 2.5759e+04, 0.0000e+00, 0.0000e+00,\n        2.4369e+04, 0.0000e+00, 0.0000e+00, 2.3578e+04, 0.0000e+00,\n        2.1775e+04, 0.0000e+00, 0.0000e+00, 2.0385e+04, 0.0000e+00,\n        0.0000e+00, 1.9839e+04, 0.0000e+00, 0.0000e+00, 1.9781e+04,\n        0.0000e+00, 1.9445e+04, 0.0000e+00, 0.0000e+00, 1.8856e+04,\n        0.0000e+00, 0.0000e+00, 1.8457e+04, 0.0000e+00, 1.7906e+04,\n        0.0000e+00, 0.0000e+00, 1.7917e+04, 0.0000e+00, 0.0000e+00,\n        1.7806e+04, 0.0000e+00, 0.0000e+00, 1.8485e+04, 0.0000e+00,\n        1.7680e+04, 0.0000e+00, 0.0000e+00, 1.5799e+04, 0.0000e+00,\n        0.0000e+00, 1.4163e+04, 0.0000e+00, 1.2812e+04, 0.0000e+00,\n        0.0000e+00, 1.1576e+04, 0.0000e+00, 0.0000e+00, 1.0751e+04,\n        0.0000e+00, 0.0000e+00, 9.8990e+03, 0.0000e+00, 9.3800e+03,\n        0.0000e+00, 0.0000e+00, 8.8630e+03, 0.0000e+00, 0.0000e+00,\n        8.3990e+03, 0.0000e+00, 7.4040e+03, 0.0000e+00, 0.0000e+00,\n        6.4030e+03, 0.0000e+00, 0.0000e+00, 5.9110e+03, 0.0000e+00,\n        0.0000e+00, 5.5910e+03, 0.0000e+00, 5.1500e+03, 0.0000e+00,\n        0.0000e+00, 4.6100e+03, 0.0000e+00, 0.0000e+00, 4.3200e+03,\n        0.0000e+00, 3.8600e+03, 0.0000e+00, 0.0000e+00, 3.6160e+03,\n        0.0000e+00, 0.0000e+00, 3.4300e+03, 0.0000e+00, 0.0000e+00,\n        3.0630e+03, 0.0000e+00, 2.6490e+03, 0.0000e+00, 0.0000e+00,\n        2.2130e+03, 0.0000e+00, 0.0000e+00, 2.0460e+03, 0.0000e+00,\n        1.8590e+03, 0.0000e+00, 0.0000e+00, 1.6920e+03, 0.0000e+00,\n        0.0000e+00, 1.4840e+03, 0.0000e+00, 0.0000e+00, 1.3620e+03,\n        0.0000e+00, 1.2900e+03, 0.0000e+00, 0.0000e+00, 1.1530e+03,\n        0.0000e+00, 0.0000e+00, 1.2320e+03, 0.0000e+00, 1.3000e+03,\n        0.0000e+00, 0.0000e+00, 1.5200e+03, 0.0000e+00, 0.0000e+00,\n        1.3840e+03, 0.0000e+00, 0.0000e+00, 1.5270e+03, 0.0000e+00,\n        1.7350e+03, 0.0000e+00, 0.0000e+00, 1.8510e+03, 0.0000e+00,\n        0.0000e+00, 1.5320e+03, 0.0000e+00, 1.3590e+03, 0.0000e+00,\n        0.0000e+00, 1.4140e+03, 0.0000e+00, 0.0000e+00, 1.4830e+03,\n        0.0000e+00, 0.0000e+00, 1.5410e+03, 0.0000e+00, 1.5950e+03,\n        0.0000e+00, 0.0000e+00, 2.3690e+03, 0.0000e+00, 0.0000e+00,\n        2.8100e+03, 0.0000e+00, 1.1430e+03, 0.0000e+00, 0.0000e+00,\n        4.2000e+02, 0.0000e+00, 0.0000e+00, 1.2800e+02, 0.0000e+00,\n        0.0000e+00, 5.6000e+01, 0.0000e+00, 4.1000e+01, 0.0000e+00,\n        0.0000e+00, 1.8000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+01,\n        0.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+00,\n        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n array([114.        , 114.36862745, 114.7372549 , 115.10588235,\n        115.4745098 , 115.84313725, 116.21176471, 116.58039216,\n        116.94901961, 117.31764706, 117.68627451, 118.05490196,\n        118.42352941, 118.79215686, 119.16078431, 119.52941176,\n        119.89803922, 120.26666667, 120.63529412, 121.00392157,\n        121.37254902, 121.74117647, 122.10980392, 122.47843137,\n        122.84705882, 123.21568627, 123.58431373, 123.95294118,\n        124.32156863, 124.69019608, 125.05882353, 125.42745098,\n        125.79607843, 126.16470588, 126.53333333, 126.90196078,\n        127.27058824, 127.63921569, 128.00784314, 128.37647059,\n        128.74509804, 129.11372549, 129.48235294, 129.85098039,\n        130.21960784, 130.58823529, 130.95686275, 131.3254902 ,\n        131.69411765, 132.0627451 , 132.43137255, 132.8       ,\n        133.16862745, 133.5372549 , 133.90588235, 134.2745098 ,\n        134.64313725, 135.01176471, 135.38039216, 135.74901961,\n        136.11764706, 136.48627451, 136.85490196, 137.22352941,\n        137.59215686, 137.96078431, 138.32941176, 138.69803922,\n        139.06666667, 139.43529412, 139.80392157, 140.17254902,\n        140.54117647, 140.90980392, 141.27843137, 141.64705882,\n        142.01568627, 142.38431373, 142.75294118, 143.12156863,\n        143.49019608, 143.85882353, 144.22745098, 144.59607843,\n        144.96470588, 145.33333333, 145.70196078, 146.07058824,\n        146.43921569, 146.80784314, 147.17647059, 147.54509804,\n        147.91372549, 148.28235294, 148.65098039, 149.01960784,\n        149.38823529, 149.75686275, 150.1254902 , 150.49411765,\n        150.8627451 , 151.23137255, 151.6       , 151.96862745,\n        152.3372549 , 152.70588235, 153.0745098 , 153.44313725,\n        153.81176471, 154.18039216, 154.54901961, 154.91764706,\n        155.28627451, 155.65490196, 156.02352941, 156.39215686,\n        156.76078431, 157.12941176, 157.49803922, 157.86666667,\n        158.23529412, 158.60392157, 158.97254902, 159.34117647,\n        159.70980392, 160.07843137, 160.44705882, 160.81568627,\n        161.18431373, 161.55294118, 161.92156863, 162.29019608,\n        162.65882353, 163.02745098, 163.39607843, 163.76470588,\n        164.13333333, 164.50196078, 164.87058824, 165.23921569,\n        165.60784314, 165.97647059, 166.34509804, 166.71372549,\n        167.08235294, 167.45098039, 167.81960784, 168.18823529,\n        168.55686275, 168.9254902 , 169.29411765, 169.6627451 ,\n        170.03137255, 170.4       , 170.76862745, 171.1372549 ,\n        171.50588235, 171.8745098 , 172.24313725, 172.61176471,\n        172.98039216, 173.34901961, 173.71764706, 174.08627451,\n        174.45490196, 174.82352941, 175.19215686, 175.56078431,\n        175.92941176, 176.29803922, 176.66666667, 177.03529412,\n        177.40392157, 177.77254902, 178.14117647, 178.50980392,\n        178.87843137, 179.24705882, 179.61568627, 179.98431373,\n        180.35294118, 180.72156863, 181.09019608, 181.45882353,\n        181.82745098, 182.19607843, 182.56470588, 182.93333333,\n        183.30196078, 183.67058824, 184.03921569, 184.40784314,\n        184.77647059, 185.14509804, 185.51372549, 185.88235294,\n        186.25098039, 186.61960784, 186.98823529, 187.35686275,\n        187.7254902 , 188.09411765, 188.4627451 , 188.83137255,\n        189.2       , 189.56862745, 189.9372549 , 190.30588235,\n        190.6745098 , 191.04313725, 191.41176471, 191.78039216,\n        192.14901961, 192.51764706, 192.88627451, 193.25490196,\n        193.62352941, 193.99215686, 194.36078431, 194.72941176,\n        195.09803922, 195.46666667, 195.83529412, 196.20392157,\n        196.57254902, 196.94117647, 197.30980392, 197.67843137,\n        198.04705882, 198.41568627, 198.78431373, 199.15294118,\n        199.52156863, 199.89019608, 200.25882353, 200.62745098,\n        200.99607843, 201.36470588, 201.73333333, 202.10196078,\n        202.47058824, 202.83921569, 203.20784314, 203.57647059,\n        203.94509804, 204.31372549, 204.68235294, 205.05098039,\n        205.41960784, 205.78823529, 206.15686275, 206.5254902 ,\n        206.89411765, 207.2627451 , 207.63137255, 208.        ]),\n <BarContainer object of 255 artists>)\n\n\n\n\n\n\n히스토그램 그림1\n\n\n_fig = plt.hist(img_red[:,:,0].reshape(-1),bins=255, range=[0,255])\n# 위의 숫자 보기 싫으니까 걍 _fig로 받으면 그림만 나온다.\n# 빨간색 말고 그린, 블루도 다 같은 모양의 그림이 나옴\n\n\n\n\n\n히스토그램 그림 2\n120~200 사이에 값이 몰려있음\n그런데 컴퓨터가 표현가능한 색은 0~244..\n만약에 120-200까지의 분포된 모양은 그대로 유지하면서 range를 0-255까지 늘린다면?\n\n- 분포의 모양은 대략적으로 유지하면서 값을 퍼트리자\n\nimg2_red = cv2.equalizeHist(img[...,0])\n\n\nplt.hist(img2_red.reshape(-1))\n\n(array([59973., 57426., 82721., 73706., 61999., 76539., 72114., 72030.,\n        72601., 70283.]),\n array([  0. ,  25.5,  51. ,  76.5, 102. , 127.5, 153. , 178.5, 204. ,\n        229.5, 255. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n히스토그램이 평평해졌네?\n\n_fig=plt.hist(img2_red.reshape(-1), bins=255, range=(0,255))\n\n\n\n\n- red말고 다른채널에도 이와 같은 변환을 정의한다면?\n\nimg2=np.stack([img2_red,img2_red,img2_red],axis=-1)   # 색깔 3개 합치기 위해서\n\n\nimg2.shape\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img2)\n\n<matplotlib.image.AxesImage at 0x7fc8300ea750>\n\n\n\n\n\n\nplt.imshow(img) #원래이미지\n\n<matplotlib.image.AxesImage at 0x7fc83010db90>\n\n\n\n\n\n\nplt.imshow(np.concatenate([img,img2],axis=1))\n\n<matplotlib.image.AxesImage at 0x7fc8301308d0>"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html#히스토그램-이퀄라이제이션-흑백버전",
    "href": "posts/Data Visualization/DV_2(0914).html#히스토그램-이퀄라이제이션-흑백버전",
    "title": "DV 2주차",
    "section": "히스토그램 이퀄라이제이션 (흑백버전)",
    "text": "히스토그램 이퀄라이제이션 (흑백버전)\n\nimg_black =  cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0)\n# 컴마하고 0하면 흑밸처리된다\n\n\nimg_black.shape\n\n(683, 1024)\n\n\n\nimg_black2 = cv2.equalizeHist(img_black)\n\n\nplt.imshow(np.concatenate([img_black,img_black2],axis=1),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fc830044090>"
  },
  {
    "objectID": "posts/Data Visualization/DV_2(0914).html#숙제",
    "href": "posts/Data Visualization/DV_2(0914).html#숙제",
    "title": "DV 2주차",
    "section": "숙제",
    "text": "숙제\nHE(Histogram Equalization)을 이용하여 아래주소에 저장된 이미지의 명암비를 보존하라\nhttps://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\n\n!wget https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\nhw = cv2.imread('hw_img.png')\n\n--2023-02-22 17:18:34--  https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 120618 (118K) [image/png]\nSaving to: ‘hw_img.png.2’\n\nhw_img.png.2        100%[===================>] 117.79K  --.-KB/s    in 0.01s   \n\n2023-02-22 17:18:34 (10.4 MB/s) - ‘hw_img.png.2’ saved [120618/120618]\n\n\n\n\nhw.shape\n\n(531, 468, 3)\n\n\n\nhw_2 = cv2.equalizeHist(hw[...,0])\n\n\nhw_2.shape\n\n(531, 468)\n\n\n\nhw2=np.stack([hw_2,hw_2,hw_2],axis=-1)\n\n\nplt.imshow(hw2)\n\n<matplotlib.image.AxesImage at 0x7fc82bd948d0>\n\n\n\n\n\n\nplt.imshow(np.concatenate([hw,hw2],axis=1))\n\n<matplotlib.image.AxesImage at 0x7fc86b573d10>"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html",
    "href": "posts/Data Visualization/DV_12(1121).html",
    "title": "DV 12주차",
    "section": "",
    "text": "!pip install folium\n\nCollecting folium\n  Downloading folium-0.14.0-py2.py3-none-any.whl (102 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.3/102.3 kB 5.6 MB/s eta 0:00:00\nRequirement already satisfied: requests in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (2.28.2)\nCollecting branca>=0.6.0\n  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: jinja2>=2.9 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (3.1.2)\nRequirement already satisfied: numpy in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (1.21.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jinja2>=2.9->folium) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (2022.12.7)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.6.0 folium-0.14.0\n\n\n\nimport numpy as np\nimport pandas as pd\nimport folium\nimport folium.plugins"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#folium.map",
    "href": "posts/Data Visualization/DV_12(1121).html#folium.map",
    "title": "DV 12주차",
    "section": "folium.Map()",
    "text": "folium.Map()\n- global view\n\nfolium.Map(scrollWheelZoom=False)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 줌스크롤을 False 시키는 방법: scrollWheelZoom=False\n- 이 옵션을 확인하려면? (1) 도움말 (2) folium 공식홈페이지 (3) Leaflet 공식홈페이지\n\nfolium.Map?\n\n\nInit signature:\nfolium.Map(\n    location=None,\n    width='100%',\n    height='100%',\n    left='0%',\n    top='0%',\n    position='relative',\n    tiles='OpenStreetMap',\n    attr=None,\n    min_zoom=0,\n    max_zoom=18,\n    zoom_start=10,\n    min_lat=-90,\n    max_lat=90,\n    min_lon=-180,\n    max_lon=180,\n    max_bounds=False,\n    crs='EPSG3857',\n    control_scale=False,\n    prefer_canvas=False,\n    no_touch=False,\n    disable_3d=False,\n    png_enabled=False,\n    zoom_control=True,\n    **kwargs,\n)\nDocstring:     \nCreate a Map with Folium and Leaflet.js\nGenerate a base map of given width and height with either default\ntilesets or a custom tileset URL. The following tilesets are built-in\nto Folium. Pass any of the following to the \"tiles\" keyword:\n    - \"OpenStreetMap\"\n    - \"Mapbox Bright\" (Limited levels of zoom for free tiles)\n    - \"Mapbox Control Room\" (Limited levels of zoom for free tiles)\n    - \"Stamen\" (Terrain, Toner, and Watercolor)\n    - \"Cloudmade\" (Must pass API key)\n    - \"Mapbox\" (Must pass API key)\n    - \"CartoDB\" (positron and dark_matter)\nYou can pass a custom tileset to Folium by passing a\n:class:`xyzservices.TileProvider` or a Leaflet-style\nURL to the tiles parameter: ``http://{s}.yourtiles.com/{z}/{x}/{y}.png``.\nYou can find a list of free tile providers here:\n``http://leaflet-extras.github.io/leaflet-providers/preview/``.\nBe sure to check their terms and conditions and to provide attribution\nwith the `attr` keyword.\nParameters\n----------\nlocation: tuple or list, default None\n    Latitude and Longitude of Map (Northing, Easting).\nwidth: pixel int or percentage string (default: '100%')\n    Width of the map.\nheight: pixel int or percentage string (default: '100%')\n    Height of the map.\ntiles: str or TileLayer or :class:`xyzservices.TileProvider`, default 'OpenStreetMap'\n    Map tileset to use. Can choose from a list of built-in tiles,\n    pass a :class:`xyzservices.TileProvider`,\n    pass a custom URL, pass a TileLayer object,\n    or pass `None` to create a map without tiles.\n    For more advanced tile layer options, use the `TileLayer` class.\nmin_zoom: int, default 0\n    Minimum allowed zoom level for the tile layer that is created.\nmax_zoom: int, default 18\n    Maximum allowed zoom level for the tile layer that is created.\nzoom_start: int, default 10\n    Initial zoom level for the map.\nattr: string, default None\n    Map tile attribution; only required if passing custom tile URL.\ncrs : str, default 'EPSG3857'\n    Defines coordinate reference systems for projecting geographical points\n    into pixel (screen) coordinates and back.\n    You can use Leaflet's values :\n    * EPSG3857 : The most common CRS for online maps, used by almost all\n    free and commercial tile providers. Uses Spherical Mercator projection.\n    Set in by default in Map's crs option.\n    * EPSG4326 : A common CRS among GIS enthusiasts.\n    Uses simple Equirectangular projection.\n    * EPSG3395 : Rarely used by some commercial tile providers.\n    Uses Elliptical Mercator projection.\n    * Simple : A simple CRS that maps longitude and latitude into\n    x and y directly. May be used for maps of flat surfaces\n    (e.g. game maps). Note that the y axis should still be inverted\n    (going from bottom to top).\ncontrol_scale : bool, default False\n    Whether to add a control scale on the map.\nprefer_canvas : bool, default False\n    Forces Leaflet to use the Canvas back-end (if available) for\n    vector layers instead of SVG. This can increase performance\n    considerably in some cases (e.g. many thousands of circle\n    markers on the map).\nno_touch : bool, default False\n    Forces Leaflet to not use touch events even if it detects them.\ndisable_3d : bool, default False\n    Forces Leaflet to not use hardware-accelerated CSS 3D\n    transforms for positioning (which may cause glitches in some\n    rare environments) even if they're supported.\nzoom_control : bool, default True\n    Display zoom controls on the map.\n**kwargs\n    Additional keyword arguments are passed to Leaflets Map class:\n    https://leafletjs.com/reference.html#map\nReturns\n-------\nFolium Map Object\nExamples\n--------\n>>> m = folium.Map(location=[45.523, -122.675], width=750, height=500)\n>>> m = folium.Map(location=[45.523, -122.675], tiles=\"cartodb positron\")\n>>> m = folium.Map(\n...     location=[45.523, -122.675],\n...     zoom_start=2,\n...     tiles=\"https://api.mapbox.com/v4/mapbox.streets/{z}/{x}/{y}.png?access_token=mytoken\",\n...     attr=\"Mapbox attribution\",\n... )\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/folium.py\nType:           type\nSubclasses:     \n\n\n\n\n- location과 scale을 조정하는 방법\n\n35.8475, 127.1305 # 전북대 자연대 본관\n35.8468, 127.1294 # 전북대 분수대\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=20)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305], #자연대본관이 센터\n          zoom_start=15)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- tiles 옵션을 주어서 지도의 외형을 변경하여 보자.\n\ntiles=“OpenStreetMap”\ntiles=“Stamen Terrain”, tiles=“Stamen Toner”, tiles=“Stamen Watercolor”\ntiles=\"CartoDB positron\", tiles=“CartoDB dark_matter”\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=15,\n          tiles=\"Stamen Terrain\")\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#folium.marker",
    "href": "posts/Data Visualization/DV_12(1121).html#folium.marker",
    "title": "DV 12주차",
    "section": "folium.Marker()",
    "text": "folium.Marker()\n- 마커생성\n\njbnu = folium.Marker(\n    location = [35.8475, 127.1305]\n)\n\nfolium.Marker 는 클래스\n\nm = folium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=14,\n          tiles=\"CartoDB positron\")\n\nfolium.Map 도 클래스\n\njbnu.add_to(m)\n\n<folium.map.Marker at 0x7f3e244f9510>\n\n\n\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nhome = folium.Marker(\n    location = [35.8368, 127.1118] # 서신동\n)\n\n\nhome.add_to(m)\n\n<folium.map.Marker at 0x7f3e244b1ed0>\n\n\n\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n마커에 팝업내용 추가\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 아이콘 변경\n- folium.Marker()에서 icon=folium.Icon(color=‘red’,icon=‘university’,prefix=‘fa’) 와 같은 식으로 옵션을 추가\n\nicon=‘university’ 대신에 `street-view’,‘tree’,‘plane’,‘bell’ 등을 추가할 수 있음.\n아이콘들은 여기 참고. ’glyphicon glyphicon-” 부분을 제외한 문자열을 넣으면 된다.\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(1)\n- “JBNU” 대신에 \"<h2> JBNU </h2><br>\"\n- “HOME” 대신에 \"<h5> HOME </h5><br>\"\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"<h2> JBNU </h2><br>\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(2)\n\n데이터프레임을 HTML로 바꾸어서 넣기\n\n\n_df=pd.DataFrame({'year':[2019,2020,2021,2022],'students':[35,30,33,26]})\n_df\n\n\n\n\n\n  \n    \n      \n      year\n      students\n    \n  \n  \n    \n      0\n      2019\n      35\n    \n    \n      1\n      2020\n      30\n    \n    \n      2\n      2021\n      33\n    \n    \n      3\n      2022\n      26\n    \n  \n\n\n\n\n\n_df.to_html()\n\n\n\n\n\n\n\n\n\n\n\n\nyear\n\n\n\nstudents\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n2019\n\n\n\n35\n\n\n\n\n\n\n\n1\n\n\n\n2020\n\n\n\n30\n\n\n\n\n\n\n\n2\n\n\n\n2021\n\n\n\n33\n\n\n\n\n\n\n\n3\n\n\n\n2022\n\n\n\n26\n\n\n\n\n\n\n\n\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _df.to_html()\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"<h5> HOME </h5><br>\" + _df.to_html(),\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(3)\n\n데이터프레임을 HTML로 바꾸어서 넣어보자.\n팝업시 크기를 조절할 수 있게 해보자. (folium.IFrame, folium.Popup 이용)\n\n\n_iframe = folium.IFrame('<h2> JBNU </h2><br>'+_df.to_html(),width=150,height=200)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(4)\n\n논리구조상 HTML 오브젝트를 아무거나 넣을 수 있음 \\(\\to\\) 그림도 넣을 수 있을까?\n그림파일을 HTML로 바꾸어서 넣어보자.\n\n\nimport matplotlib.pyplot as plt\n\n\n_df.plot.line(x='year',y='students')\nfig = plt.gcf()\n\n\n\n\n\nfig.savefig?\n\n\nSignature: fig.savefig(fname, *, transparent=None, **kwargs)\nDocstring:\nSave the current figure.\nCall signature::\n  savefig(fname, *, dpi='figure', format=None, metadata=None,\n          bbox_inches=None, pad_inches=0.1,\n          facecolor='auto', edgecolor='auto',\n          backend=None, **kwargs\n         )\nThe available output formats depend on the backend being used.\nParameters\n----------\nfname : str or path-like or binary file-like\n    A path, or a Python file-like object, or\n    possibly some backend-dependent object such as\n    `matplotlib.backends.backend_pdf.PdfPages`.\n    If *format* is set, it determines the output format, and the file\n    is saved as *fname*.  Note that *fname* is used verbatim, and there\n    is no attempt to make the extension, if any, of *fname* match\n    *format*, and no extension is appended.\n    If *format* is not set, then the format is inferred from the\n    extension of *fname*, if there is one.  If *format* is not\n    set and *fname* has no extension, then the file is saved with\n    :rc:`savefig.format` and the appropriate extension is appended to\n    *fname*.\nOther Parameters\n----------------\ndpi : float or 'figure', default: :rc:`savefig.dpi`\n    The resolution in dots per inch.  If 'figure', use the figure's\n    dpi value.\nformat : str\n    The file format, e.g. 'png', 'pdf', 'svg', ... The behavior when\n    this is unset is documented under *fname*.\nmetadata : dict, optional\n    Key/value pairs to store in the image metadata. The supported keys\n    and defaults depend on the image format and backend:\n    - 'png' with Agg backend: See the parameter ``metadata`` of\n      `~.FigureCanvasAgg.print_png`.\n    - 'pdf' with pdf backend: See the parameter ``metadata`` of\n      `~.backend_pdf.PdfPages`.\n    - 'svg' with svg backend: See the parameter ``metadata`` of\n      `~.FigureCanvasSVG.print_svg`.\n    - 'eps' and 'ps' with PS backend: Only 'Creator' is supported.\nbbox_inches : str or `.Bbox`, default: :rc:`savefig.bbox`\n    Bounding box in inches: only the given portion of the figure is\n    saved.  If 'tight', try to figure out the tight bbox of the figure.\npad_inches : float, default: :rc:`savefig.pad_inches`\n    Amount of padding around the figure when bbox_inches is 'tight'.\nfacecolor : color or 'auto', default: :rc:`savefig.facecolor`\n    The facecolor of the figure.  If 'auto', use the current figure\n    facecolor.\nedgecolor : color or 'auto', default: :rc:`savefig.edgecolor`\n    The edgecolor of the figure.  If 'auto', use the current figure\n    edgecolor.\nbackend : str, optional\n    Use a non-default backend to render the file, e.g. to render a\n    png file with the \"cairo\" backend rather than the default \"agg\",\n    or a pdf file with the \"pgf\" backend rather than the default\n    \"pdf\".  Note that the default backend is normally sufficient.  See\n    :ref:`the-builtin-backends` for a list of valid backends for each\n    file format.  Custom backends can be referenced as \"module://...\".\norientation : {'landscape', 'portrait'}\n    Currently only supported by the postscript backend.\npapertype : str\n    One of 'letter', 'legal', 'executive', 'ledger', 'a0' through\n    'a10', 'b0' through 'b10'. Only supported for postscript\n    output.\ntransparent : bool\n    If *True*, the Axes patches will all be transparent; the\n    Figure patch will also be transparent unless *facecolor*\n    and/or *edgecolor* are specified via kwargs.\n    If *False* has no effect and the color of the Axes and\n    Figure patches are unchanged (unless the Figure patch\n    is specified via the *facecolor* and/or *edgecolor* keyword\n    arguments in which case those colors are used).\n    The transparency of these patches will be restored to their\n    original values upon exit of this function.\n    This is useful, for example, for displaying\n    a plot on top of a colored background on a web page.\nbbox_extra_artists : list of `~matplotlib.artist.Artist`, optional\n    A list of extra artists that will be considered when the\n    tight bbox is calculated.\npil_kwargs : dict, optional\n    Additional keyword arguments that are passed to\n    `PIL.Image.Image.save` when saving the figure.\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/figure.py\nType:      method\n\n\n\n\n\nfig.savefig('test.png')\n\n\n저장한 그림파일을 HTML로 바꾸기 위해서 base64 가져오기\n\n\nimport base64\n\n\n_encoded = base64.b64encode(open('test.png','rb').read())\n_myhtml = '<img src=\"data:image/png;base64,{}\">'.format\n_iframe = folium.IFrame(_myhtml(_encoded.decode('UTF-8')),width=400,height=300)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#folium.circlemarker",
    "href": "posts/Data Visualization/DV_12(1121).html#folium.circlemarker",
    "title": "DV 12주차",
    "section": "folium.CircleMarker()",
    "text": "folium.CircleMarker()\n- 서클마커 생성\n\nfolium.CircleMarker?\n\n\nInit signature:\nfolium.CircleMarker(\n    location=None,\n    radius=10,\n    popup=None,\n    tooltip=None,\n    **kwargs,\n)\nDocstring:     \nA circle of a fixed size with radius specified in pixels.\nSee :func:`folium.vector_layers.path_options` for the `Path` options.\nParameters\n----------\nlocation: tuple[float, float]\n    Latitude and Longitude pair (Northing, Easting)\npopup: string or folium.Popup, default None\n    Input text or visualization for object displayed when clicking.\ntooltip: str or folium.Tooltip, default None\n    Display a text when hovering over the object.\nradius: float, default 10\n    Radius of the circle marker, in pixels.\n**kwargs\n    Other valid (possibly inherited) options. See:\n    https://leafletjs.com/reference.html#circlemarker\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/vector_layers.py\nType:           type\nSubclasses:     \n\n\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\"\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n서클마커의 색상 및 크기 변경\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color='red'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n서클마커 테두리 삭제 및 fill\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color=None,\n    fill=True,\n    fill_color='blue'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#folium.plugins.heatmap",
    "href": "posts/Data Visualization/DV_12(1121).html#folium.plugins.heatmap",
    "title": "DV 12주차",
    "section": "folium.plugins.HeatMap()",
    "text": "folium.plugins.HeatMap()\n- Heatmap은 폴리움에서 데이터 시각화를 하기에 적합한 기본도구임\nhetmap : 변수가 nx3(or2)의 형태로 저장되어야함. 위치정보, 색깔\n\ndata = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=30)\ndata\n\narray([[26.90395013, 76.67048321],\n       [25.8497742 , 78.11586853],\n       [25.9457691 , 76.38304552],\n       [26.92593912, 77.28038385],\n       [25.5991387 , 73.78185956],\n       [27.3230456 , 81.43696204],\n       [29.148638  , 77.10700642],\n       [30.67602261, 77.54824301],\n       [28.54287701, 75.90813103],\n       [27.58172922, 74.17403175],\n       [30.49801026, 75.01214148],\n       [29.13382765, 79.22643318],\n       [28.01915992, 77.16029599],\n       [26.77686428, 72.68952163],\n       [26.75485743, 73.9484101 ],\n       [23.98161607, 70.57320764],\n       [28.34373122, 76.12772879],\n       [27.59842471, 79.05475651],\n       [30.44317469, 74.30593407],\n       [30.37148679, 77.59831078],\n       [30.85907885, 79.21582417],\n       [27.09252368, 78.40493264],\n       [32.42220863, 76.50265661],\n       [25.28967556, 79.93875523],\n       [25.23525815, 75.94602496],\n       [29.14062166, 76.81364822],\n       [26.4371104 , 78.74836501],\n       [24.8546951 , 76.4959588 ],\n       [29.65245395, 78.08582716],\n       [24.8009876 , 79.0652865 ]])\n\n\n\nfolium.plugins.HeatMap?\n\n\nInit signature:\nfolium.plugins.HeatMap(\n    data,\n    name=None,\n    min_opacity=0.5,\n    max_zoom=18,\n    radius=25,\n    blur=15,\n    gradient=None,\n    overlay=True,\n    control=True,\n    show=True,\n    **kwargs,\n)\nDocstring:     \nCreate a Heatmap layer\nParameters\n----------\ndata : list of points of the form [lat, lng] or [lat, lng, weight]\n    The points you want to plot.\n    You can also provide a numpy.array of shape (n,2) or (n,3).\nname : string, default None\n    The name of the Layer, as it will appear in LayerControls.\nmin_opacity  : default 1.\n    The minimum opacity the heat will start at.\nmax_zoom : default 18\n    Zoom level where the points reach maximum intensity (as intensity\n    scales with zoom), equals maxZoom of the map by default\nradius : int, default 25\n    Radius of each \"point\" of the heatmap\nblur : int, default 15\n    Amount of blur\ngradient : dict, default None\n    Color gradient config. e.g. {0.4: 'blue', 0.65: 'lime', 1: 'red'}\noverlay : bool, default True\n    Adds the layer as an optional overlay (True) or the base layer (False).\ncontrol : bool, default True\n    Whether the Layer will be included in LayerControls.\nshow: bool, default True\n    Whether the layer will be shown on opening (only for overlays).\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/plugins/heat_map.py\nType:           type\nSubclasses:     \n\n\n\n\n\nfolium.plugins.HeatMap(data)\n\n<folium.plugins.heat_map.HeatMap at 0x7f3e15a553d0>\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMap(data).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMap(data,\n    radius=11\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#folium.plugins.heatmapwithtime",
    "href": "posts/Data Visualization/DV_12(1121).html#folium.plugins.heatmapwithtime",
    "title": "DV 12주차",
    "section": "folium.plugins.HeatMapWithTime()",
    "text": "folium.plugins.HeatMapWithTime()\n\ndata1 = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=20)\ndata2 = np.random.multivariate_normal(mean=[25,80],cov=[[5,0],[0,5]],size=20)\ndata3 = np.random.multivariate_normal(mean=[31,70],cov=[[5,0],[0,5]],size=20)\ndata = np.array([data1,data2,data3])\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMapWithTime(\n    data.tolist(),\n    index=['t1','t2','t3'], # time_index \n    radius=15,\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#예제-earthquakes",
    "href": "posts/Data Visualization/DV_12(1121).html#예제-earthquakes",
    "title": "DV 12주차",
    "section": "예제: earthquakes",
    "text": "예제: earthquakes\n\nStep1: Pandas 정리\n\ndf=pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n    \n  \n\n23412 rows × 4 columns\n\n\n\n\ndf.Date\n\n0        01/02/1965\n1        01/04/1965\n2        01/05/1965\n3        01/08/1965\n4        01/09/1965\n            ...    \n23407    12/28/2016\n23408    12/28/2016\n23409    12/28/2016\n23410    12/29/2016\n23411    12/30/2016\nName: Date, Length: 23412, dtype: object\n\n\n\n' 01/02/1965'.split('/')[-1]\n\n'1965'\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows × 5 columns\n\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date))).Year.unique()\n\narray(['1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1975-02-23T02:58:41.000Z', '1976', '1977',\n       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985',\n       '1985-04-28T02:53:41.530Z', '1986', '1987', '1988', '1989', '1990',\n       '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998',\n       '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006',\n       '2007', '2008', '2009', '2010', '2011', '2011-03-13T02:23:34.520Z',\n       '2012', '2013', '2014', '2015', '2016'], dtype=object)\n\n\n\n'1975-02-23T02:58:41.000Z'.split('-')[0]\n\n'1975'\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n.assign(Year = lambda df: list(map(lambda x: x.split('-')[0], df.Year)))\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows × 5 columns\n\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n.assign(Year = lambda df: list(map(lambda x: x.split('-')[0], df.Year))).Year.unique()\n\narray(['1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980',\n       '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988',\n       '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996',\n       '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012',\n       '2013', '2014', '2015', '2016'], dtype=object)\n\n\n\nlst =[ \n    df.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n    .assign(Year = lambda df: list(map(lambda x: x.split('-')[0] ,df.Year)))\\\n    .groupby('Year')\\\n    .pipe(list)[_year][1]\\\n    .loc[:,['Latitude','Longitude']]\\\n    .pipe(np.array).tolist()\n    \n    for _year in range(2016-1965+1) \n]\n\n\n\nStep2: folium\n\nm=folium.Map(scrollWheelZoom=False)\nfolium.plugins.HeatMapWithTime(\n    lst,\n    radius=5,\n    index=list(range(1965,2017)) \n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#세계지도-그리기",
    "href": "posts/Data Visualization/DV_12(1121).html#세계지도-그리기",
    "title": "DV 12주차",
    "section": "세계지도 그리기",
    "text": "세계지도 그리기\n\npx.scatter_geo()\n\n\n                                                \n\n\n\npx.scatter_geo(projection='natural earth') #동그랗게"
  },
  {
    "objectID": "posts/Data Visualization/DV_12(1121).html#세계지도-버블",
    "href": "posts/Data Visualization/DV_12(1121).html#세계지도-버블",
    "title": "DV 12주차",
    "section": "세계지도 + 버블",
    "text": "세계지도 + 버블\n- 예시1\n\ndf = pd.DataFrame({'lat':[37,0], 'lon':[127,0], 'size':[100,5]})\ndf\n\n\n\n\n\n  \n    \n      \n      lat\n      lon\n      size\n    \n  \n  \n    \n      0\n      37\n      127\n      100\n    \n    \n      1\n      0\n      0\n      5\n    \n  \n\n\n\n\n\npx.scatter_geo(\n    data_frame=df,\n    lat = 'lat',\n    lon = 'lon',\n    size = 'size'\n)\n\n\n                                                \n\n\n- 예시2\n\ndf= pd.DataFrame({'code':['KOR','JPN'], 'size':[100,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      code\n      size\n    \n  \n  \n    \n      0\n      KOR\n      100\n    \n    \n      1\n      JPN\n      30\n    \n  \n\n\n\n\n\npx.scatter_geo(\n    data_frame = df,\n    locations = 'code',\n    size = 'size'\n)\n\n\n                                                \n\n\n\nGapminder data 시각화\n- Gapminder data: 국가별 기대수명, 1인당 GDP, 인구에 대한 데이터\n\n특징: 연도별로 정리가 되어있다.\n\n\ndf=px.data.gapminder()\ndf\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n      AFG\n      4\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n      AFG\n      4\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n      AFG\n      4\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n      AFG\n      4\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n      AFG\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1699\n      Zimbabwe\n      Africa\n      1987\n      62.351\n      9216418\n      706.157306\n      ZWE\n      716\n    \n    \n      1700\n      Zimbabwe\n      Africa\n      1992\n      60.377\n      10704340\n      693.420786\n      ZWE\n      716\n    \n    \n      1701\n      Zimbabwe\n      Africa\n      1997\n      46.809\n      11404948\n      792.449960\n      ZWE\n      716\n    \n    \n      1702\n      Zimbabwe\n      Africa\n      2002\n      39.989\n      11926563\n      672.038623\n      ZWE\n      716\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n1704 rows × 8 columns\n\n\n\n\ndf.query('year==2007')\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      11\n      Afghanistan\n      Asia\n      2007\n      43.828\n      31889923\n      974.580338\n      AFG\n      4\n    \n    \n      23\n      Albania\n      Europe\n      2007\n      76.423\n      3600523\n      5937.029526\n      ALB\n      8\n    \n    \n      35\n      Algeria\n      Africa\n      2007\n      72.301\n      33333216\n      6223.367465\n      DZA\n      12\n    \n    \n      47\n      Angola\n      Africa\n      2007\n      42.731\n      12420476\n      4797.231267\n      AGO\n      24\n    \n    \n      59\n      Argentina\n      Americas\n      2007\n      75.320\n      40301927\n      12779.379640\n      ARG\n      32\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1655\n      Vietnam\n      Asia\n      2007\n      74.249\n      85262356\n      2441.576404\n      VNM\n      704\n    \n    \n      1667\n      West Bank and Gaza\n      Asia\n      2007\n      73.422\n      4018332\n      3025.349798\n      PSE\n      275\n    \n    \n      1679\n      Yemen, Rep.\n      Asia\n      2007\n      62.698\n      22211743\n      2280.769906\n      YEM\n      887\n    \n    \n      1691\n      Zambia\n      Africa\n      2007\n      42.384\n      11746035\n      1271.211593\n      ZMB\n      894\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n142 rows × 8 columns\n\n\n\n\npx.scatter_geo(\n    data_frame = df,\n    locations = 'iso_alpha',  \n    size = 'pop'\n)\n\n\n                                                \n\n\n\npx.scatter_geo(\n    data_frame = df.query('year==2007'),\n    locations = 'iso_alpha',  \n    size = 'pop',\n    color = 'continent' # 국가\n)\n\n\n                                                \n\n\n\nx,y 좌표 잡기\n크기\ncolor\n시간\n\n….."
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0921).html",
    "href": "posts/Data Visualization/DV_3(0921).html",
    "title": "DV 3주차(2)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nfrom IPython.display import HTML"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제1---표본상관계수",
    "href": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제1---표본상관계수",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제1 - 표본상관계수",
    "text": "산점도 응용예제1 - 표본상관계수\n\n예제소개\n- 아래와 같은 자료를 수집하였다고 하자.\n\n몸무게 = [44,48,49,58,62,68,69,70,76,79]\n키 = [159,160,162,165,167,162,165,175,165,172]\n\n\nx=[44,48,49,58,62,68,69,70,76,79]\ny=[159,160,162,165,167,162,165,175,165,172]\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립)\n키와 몸무게는 관계가 있어 보인다. (정비례)\n\n- 얼만큼 정비례인가?\n\n이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다.\n상관계수는 산점도에서 가장 중요한 개념 중 하나\n\n\n\n상관계수의 정의\n- (표본) 상관계수\n\\[r=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\sum_{i=1}^{n}(y_i-\\bar{y})^2 }}=\\sum_{i=1}^{n}\\tilde{x}_i\\tilde{y}_i \\]\n\n단, \\(\\tilde{x}_i=\\frac{(x_i-\\bar{x})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\), \\(\\tilde{y}_i=\\frac{(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\)\n\n- \\(\\tilde{x}_i\\)와 \\(\\tilde{y}_i\\)를 계산하기 위해서 \\(a=\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}, b=\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)를 계산하자.\n(방법1)\n\nfig, ax = plt.subplots(1,3, figsize=(12,4))\nax[0].plot(x,y,'o')\nax[1].plot(np.array(x) - np.mean(x), np.array(y)-np.mean(y), 'o')\n\n\n\n\n\nxx= (np.array(x) - np.mean(x)) / np.sqrt(np.sum((x-np.mean(x))**2))\nyy= (np.array(y) - np.mean(y)) / np.sqrt(np.sum((y-np.mean(y))**2))\n\n\nax[2].plot(xx,yy,'o')\n\n\nfig\n\n\n\n\n첫번째 그림에서 두번쨰 그림 갈때 0근처로 감\n두번째 그림에서 세번째 그림은 퍼져있는 정도(분산)이 큰 차이가 없음(1근처로 왔다갔다..)\n(방법2)\n- 사실 \\(a,b\\)는 아래와 같이 계산할 수 있다.\n\\(a=\\sqrt{n}\\times{\\tt np.std(x)}\\)\n\\(b=\\sqrt{n}\\times{\\tt np.std(y)}\\)\n\nn=len(x)\nnp.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y)\n\n(36.58004920718397, 15.21840990379744)\n\n\n\n\\({\\tt np.std(x)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\\({\\tt np.std(y)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)\n\n\nnote: \\({\\tt np.std(x,ddof=1)}=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\n\n# xx= (x-np.mean(x))/a\n# yy= (y-np.mean(y))/b\n# ax3.plot(xx,yy,'o')\n\n\n\n상관계수의 의미\n질문: r의 값이 양수인가? 음수인가?\n양수 일 것 같다..\n- plotly 사용하여 \\((\\tilde{x}_i,\\tilde{y}_i)\\)를 그려보자.\n\nfig=px.scatter(x=xx, y=yy)\nHTML(fig.to_html(include_plotlyjs='cdn',include_mathjax=False))\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\\(\\tilde{x}_i\\), \\(\\tilde{y}_i\\) 를 곱한값이 양수인것과 음수인것을 체크해보자.\n양수인쪽이 많은지 음수인쪽이 많은지 생각해보자.\n\\(r=\\sum_{i=1}^{n}\\tilde{x}_i \\tilde{y}_i\\) 의 부호는?\n\n\n\n그림을 보고 상관계수의 부호를 알아내는 방법\n- \\((x_i,y_i)\\)의 산점도를 보고 \\((\\tilde{x}_i, \\tilde{y}_i)\\) 의 산점도를 상상 \\(\\to\\) 1,3 분면에 점들이 많으면 양수, 2,4 분면에 점들이 많으면 음수\n\n\n그림을 보고 상관계수의 절대값을 알아내는 방법\n- 예시\n\nx=np.arange(0,10,0.1)\ny1=x+np.random.normal(loc=0,scale=1.0,size=len(x)) # 평균0,분산1인 오차항 더하기\ny2=x+np.random.normal(loc=0,scale=7.0,size=len(x)) # 평균0, 분산7인 오차항 더하기\n\n\nplt.plot(x,y1,'o')\nplt.plot(x,y2,'x')\n\n\n\n\n\ndef tilde(x):\n    n=len(x)\n    return (np.array(x) - np.mean(x)) / np.sqrt(np.sum((np.array(x) - np.mean(x))**2))\n\n\nxx = tilde(x)\nyy1 = tilde(y1)\nyy2 = tilde(y2)\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(x,y1,'o');ax[0].plot(x,y2,'x')\nax[1].plot(xx,yy1,'o');ax[1].plot(xx,yy2,'x')"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제2-앤스콤의-4분할",
    "href": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제2-앤스콤의-4분할",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제2 – 앤스콤의 4분할",
    "text": "산점도 응용예제2 – 앤스콤의 4분할\n- Anscombe’s quartet: 교과서에 나오는 그림임.\n- 교훈1: 데이터를 분석하기 전에 항상 시각화를 하라.\n\nx = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n\n\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nax1.plot(x,y1,'o') \nax2.plot(x,y2,'o') \nax3.plot(x,y3,'o')  \nax4.plot(x4,y4,'o') \n\n\n\n\n\n_xx = tilde(x)\n_yy1 = tilde(y1)\n\n\nnp.sum(_xx*_yy1) # 상관계수 계싼\n\n0.8164205163448399\n\n\n\nnp.corrcoef([x,y1]) # 상관계수 계산\n\narray([[1.        , 0.81642052],\n       [0.81642052, 1.        ]])\n\n\n\nnp.corrcoef([x,y2])\n\narray([[1.        , 0.81623651],\n       [0.81623651, 1.        ]])\n\n\n\nnp.corrcoef([x,y1,y2,y3])\n\narray([[1.        , 0.81642052, 0.81623651, 0.81628674],\n       [0.81642052, 1.        , 0.7500054 , 0.46871668],\n       [0.81623651, 0.7500054 , 1.        , 0.58791933],\n       [0.81628674, 0.46871668, 0.58791933, 1.        ]])\n\n\n\nnp.corrcoef([x4,y4])\n\narray([[1.        , 0.81652144],\n       [0.81652144, 1.        ]])\n\n\n\n앤스콤의 4분할중 1,2,3 번째 그림의 상관계수는 0.81642052, 0.81623651, 0.81628674 이라는 의미\n즉 corr(x,y1)=0.81642052, corr(x,y2)=0.81623651, corr(x,y3)=0.81628674 임\n\n* 참고로 np.corrcoef([x,y1,y2,y3])의 계산결과는 정확하게\n\\[\\begin{bmatrix} corr(x,x) & corr(x,y1) & corr(x,y2) & corr(x,y3) \\\\ corr(y1,x) & corr(y1,y1) & corr(y1,y2) & corr(y1,y3) \\\\ corr(y2,x) & corr(y2,y1) & corr(y2,y2) & corr(y2,y3) \\\\ corr(y3,x) & corr(y3,y1) & corr(y3,y2) & corr(y3,y3)\\end{bmatrix}\\]\n를 의미한다.\n- 앤스콤플랏의 4개의 그림은 모두 같은 상관계수를 가진다. \\(\\to\\) 하지만 4개의 그림은 느낌이 전혀 다르다.\n- 같은 표본상관계수를 가진다고 하여 같은 관계성을 가지는 것은 아니다. 표본상관계수는 x,y의 비례정도를 측정하는데 그 값이 1에 가깝다고 하여 꼭 정비례의 관계가 있음을 의미하는게 아니다. \\((x_i,y_i)\\)의 산점도가 선형성을 보일때만 “표본상관계수가 1이므로 정비례의 관계에 있다” 라는 논리전개가 성립한다.\n\n앤스콤의 1번째 플랏: 산점도가 선형 \\(\\to\\) 표본상관계수가 0.816 = 정비례의 관계가 0.816 정도\n앤스콤의 2번째 플랏: 산점도가 선형이 아님 \\(\\to\\) 표본상관계수가 크게 의미없음\n앤스콤의 3번째 플랏: 산점도가 선형인듯 보이나 하나의 이상치가 있음 \\(\\to\\) 하나의 이상치가 표본상관계수의 값을 무너뜨릴 수 있으므로 표본상관계수값을 신뢰할 수 없음.\n앤스콤의 4번째 플랏: 산점도를 그려보니 이상한그림 \\(\\to\\) 표존상관계수를 계산할수는 있음. 그런데 그게 무슨 의미가 있을지?\n\n- 앤스콤의 3번째 플랏: 하나의 이상치가 상관계수를 무너뜨리는 경우 시각화"
  },
  {
    "objectID": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제3-무상관은-관계가-없다는-뜻",
    "href": "posts/Data Visualization/DV_3(0921).html#산점도-응용예제3-무상관은-관계가-없다는-뜻",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제3 – 무상관은 관계가 없다는 뜻?",
    "text": "산점도 응용예제3 – 무상관은 관계가 없다는 뜻?\n\nnp.random.seed(43052)\nx=np.linspace(-1,1,100,endpoint=True)\ny=x**2+np.random.normal(scale=0.1,size=100)\n\n\nplt.plot(x,y,'o')\nplt.title('y=x**2')\n\nText(0.5, 1.0, 'y=x**2')\n\n\n\n\n\n\nnp.corrcoef(x,y)\n\narray([[1.        , 0.00688718],\n       [0.00688718, 1.        ]])\n\n\n- 표본상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미한 것이지 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다."
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html",
    "href": "posts/Data Visualization/DV_5(1005).html",
    "title": "DV 5주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#sns-aray",
    "href": "posts/Data Visualization/DV_5(1005).html#sns-aray",
    "title": "DV 5주차(1)",
    "section": "sns: aray",
    "text": "sns: aray\n\nsns.scatterplot(data=None, x=x1, y=y1)\nsns.scatterplot(data=None, x=x2, y=y2)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#sns-wide-df",
    "href": "posts/Data Visualization/DV_5(1005).html#sns-wide-df",
    "title": "DV 5주차(1)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\npd.DataFrame({'x':x1,'y':y1})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.053500\n      -1.258803\n    \n    \n      1\n      -0.517300\n      -0.273907\n    \n    \n      2\n      -0.938688\n      0.582421\n    \n    \n      3\n      1.017930\n      -0.223879\n    \n    \n      4\n      0.827941\n      0.519745\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      1.317776\n      -0.898103\n    \n    \n      996\n      -0.054884\n      0.290131\n    \n    \n      997\n      -0.082623\n      0.971652\n    \n    \n      998\n      -0.796771\n      -0.140001\n    \n    \n      999\n      0.030602\n      0.435023\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n               \nsns.scatterplot(data=pd.DataFrame({'x':x1,'y':y1}),x='x',y='y')\nsns.scatterplot(data=pd.DataFrame({'x':x2,'y':y2}),x='x',y='y')\n# #sns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#sns-long-df",
    "href": "posts/Data Visualization/DV_5(1005).html#sns-long-df",
    "title": "DV 5주차(1)",
    "section": "sns: long df",
    "text": "sns: long df\n\nx=np.concatenate([x1,x2])\n# np.array(list(x1) + list(x2))\n# x1.tolist() + x2.tolist()\n# 다 같은 코드이지만 cocaternate쓰는 방식이 제일 편하다\n\ny=np.concatenate([y1,y2])\n\ncat=['x1']*len(x1) + ['x2']*len(x2)\n\n\ndf2=pd.DataFrame({'x':x, 'y':y, 'cat':cat})\ndf2\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cat\n    \n  \n  \n    \n      0\n      0.082929\n      1.218634\n      x1\n    \n    \n      1\n      -0.019451\n      -1.352701\n      x1\n    \n    \n      2\n      -1.253126\n      1.246169\n      x1\n    \n    \n      3\n      -0.343648\n      0.078081\n      x1\n    \n    \n      4\n      0.479097\n      -1.039999\n      x1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      2.503038\n      2.350603\n      x2\n    \n    \n      1996\n      1.940601\n      2.356207\n      x2\n    \n    \n      1997\n      3.213965\n      2.769489\n      x2\n    \n    \n      1998\n      1.203818\n      -0.276493\n      x2\n    \n    \n      1999\n      1.378763\n      1.914046\n      x2\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df2, x='x', y='y', hue='cat')\n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#예제1",
    "href": "posts/Data Visualization/DV_5(1005).html#예제1",
    "title": "DV 5주차(1)",
    "section": "예제1",
    "text": "예제1\n\nfig, ax = plt.subplots()\nax.plot([1,2,4,3])\n\n\n\n\n\nax\n\n<AxesSubplot:>\n\n\n\nfig, mypltax = plt.subplots()\n\n\n\n\n\nsns.scatterplot(data=df2, x='x', y='y', hue='cat', ax=mypltax)\n# ax라는 변수를 넣자\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\nfig  # 오 sns에 ax넣으니 fig에 sns가 들어옴\n\n\n\n\n\nseaborn에서 배우지 않은 내용을 matplotlib이용해서 사용가능함\n\n\nfig, mypltax = plt.subplots()\nsns.scatterplot(data=df2, x='x', y='y', hue='cat', ax=mypltax)\nmypltax.set_title('coco babo')\nfig.suptitle('coco ddong')\n\nText(0.5, 0.98, 'coco ddong')\n\n\n\n\n\n\nfig, ax = plt.subplots(1,3, figsize=(12,4))\nax[0].plot([1,2,4,3], '--o')\nsns.scatterplot(x=x1, y=y1, ax=ax[1])\nsns.scatterplot(x=x1, y=y1, ax=ax[2]) # 겹쳐그리자\nsns.scatterplot(x=x2, y=y2, ax=ax[-1]) # 겹쳐그리자\nax[2].plot([1,2,4,3], '--m', lw=5)"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#예제2",
    "href": "posts/Data Visualization/DV_5(1005).html#예제2",
    "title": "DV 5주차(1)",
    "section": "예제2",
    "text": "예제2\n\nimport cv2\n\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg \nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0) # 채널이 1개인 흑백이미지\n!rm Unequalized_Hawkes_Bay_NZ.jpg \n\n--2023-02-25 16:17:39--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   553KB/s    in 0.2s    \n\n2023-02-25 16:17:40 (553 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895]\n\n\n\n\nplt.imshow(img,vmin=0,vmax=255,cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f61e88d36d0>\n\n\n\n\n\n\nimg2 = cv2.equalizeHist(img)\n\n\nimg.shape\n\n(683, 1024)\n\n\n\nimg.reshape(683*1024,1) # 컬럼벡터\nimg.reshape(683*1024) #길이가 1\n\narray([127, 145, 149, ..., 146, 145, 144], dtype=uint8)\n\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\n#ax[0,1].hist(img.reshape(-1))\nsns.histplot(img.reshape(-1),ax=ax[0,1], bins=15, lw=0, kde=True, color='C1')\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1], bins=15, lw=0, kde=True, color='C1')\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nax[0,1]의 x축을 ax[1,1]의 x축과 맞춰서 비교해보고 싶다.\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img.reshape(-1),ax=ax[0,1], bins=15, lw=0, kde=True, color='C1')\nax[0,1].set_xlim(0,255)\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1], bins=15, lw=0, kde=True, color='C1')\n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#축-간격조정",
    "href": "posts/Data Visualization/DV_5(1005).html#축-간격조정",
    "title": "DV 5주차(1)",
    "section": "축 간격조정",
    "text": "축 간격조정\n\nimport matplotlib as mpl\n\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로\nax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#축-삭제",
    "href": "posts/Data Visualization/DV_5(1005).html#축-삭제",
    "title": "DV 5주차(1)",
    "section": "축 삭제",
    "text": "축 삭제\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제\nax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#축-범위조정",
    "href": "posts/Data Visualization/DV_5(1005).html#축-범위조정",
    "title": "DV 5주차(1)",
    "section": "축 범위조정",
    "text": "축 범위조정\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.set_ylim(-1,2) \nax.set_xlim(-5,35)\n#plt.ylim(-1,2)   위 ax와 같은 코드\n#plt.xlim(-5,35)\n\n(-5.0, 35.0)"
  },
  {
    "objectID": "posts/Data Visualization/DV_5(1005).html#gcf-gca",
    "href": "posts/Data Visualization/DV_5(1005).html#gcf-gca",
    "title": "DV 5주차(1)",
    "section": "gcf, gca",
    "text": "gcf, gca\n\nplt.plot([1,2,3,2])\nfig=plt.gcf()\n\n# gcf: get current figure\n\n\n\n\n\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\nfig\n\n\n\n\n\nax = fig.gca()\n\n# gca: get current axes\n\n\nax.set_title('title') \nfig"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html",
    "href": "posts/Data Visualization/DV_11(1114).html",
    "title": "DV 11주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#data1-야후-파이낸스",
    "href": "posts/Data Visualization/DV_11(1114).html#data1-야후-파이낸스",
    "title": "DV 11주차(1)",
    "section": "data1: 야후 파이낸스",
    "text": "data1: 야후 파이낸스\n- yahoo finance: https://finance.yahoo.com/\n\nyf.pdr_override()\n\n\nsymbols = ['AMZN','AAPL','GOOG','MSFT','NFLX','NVDA','TSLA']\nstart = '2020-01-01'\nend = '2022-10-30'\ndf = pdr.get_data_yahoo(symbols,start,end)['Adj Close']\n\n[*********************100%***********************]  7 of 7 completed\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      AAPL\n      AMZN\n      GOOG\n      MSFT\n      NFLX\n      NVDA\n      TSLA\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-02\n      73.449379\n      94.900497\n      68.368500\n      155.761826\n      329.809998\n      59.770554\n      28.684000\n    \n    \n      2020-01-03\n      72.735313\n      93.748497\n      68.032997\n      153.822311\n      325.899994\n      58.813866\n      29.534000\n    \n    \n      2020-01-06\n      73.314880\n      95.143997\n      69.710503\n      154.219925\n      335.829987\n      59.060509\n      30.102667\n    \n    \n      2020-01-07\n      72.970078\n      95.343002\n      69.667000\n      152.813766\n      330.750000\n      59.775528\n      31.270666\n    \n    \n      2020-01-08\n      74.143898\n      94.598503\n      70.216003\n      155.247818\n      339.260010\n      59.887650\n      32.809334\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-10-24\n      148.975021\n      119.820000\n      102.970001\n      245.939163\n      282.450012\n      125.957771\n      211.250000\n    \n    \n      2022-10-25\n      151.855850\n      120.599998\n      104.930000\n      249.331085\n      291.019989\n      132.576080\n      222.419998\n    \n    \n      2022-10-26\n      148.875351\n      115.660004\n      94.820000\n      230.093628\n      298.619995\n      128.927017\n      224.639999\n    \n    \n      2022-10-27\n      144.339813\n      110.959999\n      92.599998\n      225.547836\n      296.940002\n      131.726288\n      225.089996\n    \n    \n      2022-10-28\n      155.245056\n      103.410004\n      96.580002\n      234.619492\n      295.720001\n      138.304611\n      228.520004\n    \n  \n\n713 rows × 7 columns\n\n\n\n\ndf.columns\n\nIndex(['AAPL', 'AMZN', 'GOOG', 'MSFT', 'NFLX', 'NVDA', 'TSLA'], dtype='object')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-1개의-y를-그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-1개의-y를-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 1개의 y를 그리기",
    "text": "matplotlib: 1개의 y를 그리기\n- 예시1: 1개의 y를 그리기\n\ndf.reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      AAPL\n      AMZN\n      GOOG\n      MSFT\n      NFLX\n      NVDA\n      TSLA\n    \n  \n  \n    \n      0\n      2020-01-02\n      73.449379\n      94.900497\n      68.368500\n      155.761826\n      329.809998\n      59.770554\n      28.684000\n    \n    \n      1\n      2020-01-03\n      72.735313\n      93.748497\n      68.032997\n      153.822311\n      325.899994\n      58.813866\n      29.534000\n    \n    \n      2\n      2020-01-06\n      73.314880\n      95.143997\n      69.710503\n      154.219925\n      335.829987\n      59.060509\n      30.102667\n    \n    \n      3\n      2020-01-07\n      72.970078\n      95.343002\n      69.667000\n      152.813766\n      330.750000\n      59.775528\n      31.270666\n    \n    \n      4\n      2020-01-08\n      74.143898\n      94.598503\n      70.216003\n      155.247818\n      339.260010\n      59.887650\n      32.809334\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      708\n      2022-10-24\n      148.975021\n      119.820000\n      102.970001\n      245.939163\n      282.450012\n      125.957771\n      211.250000\n    \n    \n      709\n      2022-10-25\n      151.855850\n      120.599998\n      104.930000\n      249.331085\n      291.019989\n      132.576080\n      222.419998\n    \n    \n      710\n      2022-10-26\n      148.875351\n      115.660004\n      94.820000\n      230.093628\n      298.619995\n      128.927017\n      224.639999\n    \n    \n      711\n      2022-10-27\n      144.339813\n      110.959999\n      92.599998\n      225.547836\n      296.940002\n      131.726288\n      225.089996\n    \n    \n      712\n      2022-10-28\n      155.245056\n      103.410004\n      96.580002\n      234.619492\n      295.720001\n      138.304611\n      228.520004\n    \n  \n\n713 rows × 8 columns\n\n\n\n\ndf.reset_index().melt(id_vars='Date') # tidy data\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2020-01-02\n      AAPL\n      73.449379\n    \n    \n      1\n      2020-01-03\n      AAPL\n      72.735313\n    \n    \n      2\n      2020-01-06\n      AAPL\n      73.314880\n    \n    \n      3\n      2020-01-07\n      AAPL\n      72.970078\n    \n    \n      4\n      2020-01-08\n      AAPL\n      74.143898\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4986\n      2022-10-24\n      TSLA\n      211.250000\n    \n    \n      4987\n      2022-10-25\n      TSLA\n      222.419998\n    \n    \n      4988\n      2022-10-26\n      TSLA\n      224.639999\n    \n    \n      4989\n      2022-10-27\n      TSLA\n      225.089996\n    \n    \n      4990\n      2022-10-28\n      TSLA\n      228.520004\n    \n  \n\n4991 rows × 3 columns\n\n\n\n\ndf.reset_index().plot(x='Date', y='AMZN')\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시2\n\ndf.reset_index().plot(x='Date',y='AMZN', kind='line')\n# 위의 코드는 kind가 생략된 것과 같다\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시3\n\ndf.reset_index().plot.line(x='Date',y='AMZN')\n# kind=line 대신에 plot.line\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐서-그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐서 그리기",
    "text": "matplotlib: 2개의 y를 겹쳐서 그리기\n- 2개의 y를 겹쳐 그리기\n\ndf.reset_index().plot(x='Date', y=['AMZN','AAPL'])\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-모든-y를-겹쳐서-그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-모든-y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 모든 y를 겹쳐서 그리기",
    "text": "matplotlib: 모든 y를 겹쳐서 그리기\n- 모든 y를 겹쳐서 그리기\n\ndf.reset_index().plot(x='Date')\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-그림크기조정",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-그림크기조정",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 그림크기조정",
    "text": "matplotlib: 그림크기조정\n\ndf.reset_index().plot(x='Date',figsize=(8,8))\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-서브플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-서브플랏",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 서브플랏",
    "text": "matplotlib: 서브플랏\n- 예시1: 기본 서브플랏\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(10,10))\n\n# 겹처서 말구 나눠서 그려짐! 신기하군 \n\narray([<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>], dtype=object)\n\n\n\n\n\n- 예시2: 레이아웃 조정\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2))\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-폰트조정",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-폰트조정",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 폰트조정",
    "text": "matplotlib: 폰트조정\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2),fontsize=15)\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-레전드삭제",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-레전드삭제",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 레전드삭제",
    "text": "matplotlib: 레전드삭제\n\ndf.reset_index().plot.line(x='Date',subplots=True, layout=(4,2), legend=False)\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-모든y를-겹쳐서-그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-모든y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "plotly 모든y를 겹쳐서 그리기",
    "text": "plotly 모든y를 겹쳐서 그리기\n- 방법1\n\ndf.reset_index().set_index('Date').stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      level_1\n      0\n    \n  \n  \n    \n      0\n      2020-01-02\n      AAPL\n      73.449379\n    \n    \n      1\n      2020-01-02\n      AMZN\n      94.900497\n    \n    \n      2\n      2020-01-02\n      GOOG\n      68.368500\n    \n    \n      3\n      2020-01-02\n      MSFT\n      155.761826\n    \n    \n      4\n      2020-01-02\n      NFLX\n      329.809998\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4986\n      2022-10-28\n      GOOG\n      96.580002\n    \n    \n      4987\n      2022-10-28\n      MSFT\n      234.619492\n    \n    \n      4988\n      2022-10-28\n      NFLX\n      295.720001\n    \n    \n      4989\n      2022-10-28\n      NVDA\n      138.304611\n    \n    \n      4990\n      2022-10-28\n      TSLA\n      228.520004\n    \n  \n\n4991 rows × 3 columns\n\n\n\n- 방법2\n\ndf.reset_index().melt(id_vars='Date').plot.line(backend='plotly',x='Date',y='value',color='variable')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#data2-핸드폰점유율",
    "href": "posts/Data Visualization/DV_11(1114).html#data2-핸드폰점유율",
    "title": "DV 11주차(1)",
    "section": "data2: 핸드폰점유율",
    "text": "data2: 핸드폰점유율\n\ndf = pd.read_csv('https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      31.49\n      22.09\n      10.02\n      7.79\n      4.10\n      3.15\n      2.41\n      2.40\n      9.51\n      0.54\n      2.35\n      0.95\n      0.96\n      0.70\n      0.84\n      0.74\n    \n    \n      1\n      2019-11\n      31.36\n      22.90\n      10.18\n      8.16\n      4.42\n      3.41\n      2.40\n      2.40\n      9.10\n      0.78\n      0.66\n      0.97\n      0.97\n      0.73\n      0.83\n      0.75\n    \n    \n      2\n      2019-12\n      31.37\n      24.79\n      9.95\n      7.73\n      4.23\n      3.19\n      2.50\n      2.54\n      8.13\n      0.84\n      0.75\n      0.90\n      0.87\n      0.74\n      0.77\n      0.70\n    \n    \n      3\n      2020-01\n      31.29\n      24.76\n      10.61\n      8.10\n      4.25\n      3.02\n      2.42\n      2.40\n      7.55\n      0.88\n      0.69\n      0.88\n      0.86\n      0.79\n      0.80\n      0.69\n    \n    \n      4\n      2020-02\n      30.91\n      25.89\n      10.98\n      7.80\n      4.31\n      2.89\n      2.36\n      2.34\n      7.06\n      0.89\n      0.70\n      0.81\n      0.77\n      0.78\n      0.80\n      0.69\n    \n    \n      5\n      2020-03\n      30.80\n      27.03\n      10.70\n      7.70\n      4.30\n      2.87\n      2.35\n      2.28\n      6.63\n      0.93\n      0.73\n      0.72\n      0.74\n      0.78\n      0.76\n      0.66\n    \n    \n      6\n      2020-04\n      30.41\n      28.79\n      10.28\n      7.60\n      4.20\n      2.75\n      2.51\n      2.28\n      5.84\n      0.90\n      0.75\n      0.69\n      0.71\n      0.80\n      0.76\n      0.70\n    \n    \n      7\n      2020-05\n      30.18\n      26.72\n      10.39\n      8.36\n      4.70\n      3.12\n      2.46\n      2.19\n      6.31\n      1.04\n      0.70\n      0.73\n      0.77\n      0.81\n      0.78\n      0.76\n    \n    \n      8\n      2020-06\n      31.06\n      25.26\n      10.69\n      8.55\n      4.65\n      3.18\n      2.57\n      2.11\n      6.39\n      1.04\n      0.68\n      0.74\n      0.75\n      0.77\n      0.78\n      0.75\n    \n    \n      9\n      2020-07\n      30.95\n      24.82\n      10.75\n      8.94\n      4.69\n      3.46\n      2.45\n      2.03\n      6.41\n      1.13\n      0.65\n      0.76\n      0.74\n      0.76\n      0.75\n      0.72\n    \n    \n      10\n      2020-08\n      31.04\n      25.15\n      10.73\n      8.90\n      4.69\n      3.38\n      2.39\n      1.96\n      6.31\n      1.18\n      0.63\n      0.74\n      0.72\n      0.75\n      0.73\n      0.70\n    \n    \n      11\n      2020-09\n      30.57\n      24.98\n      10.58\n      9.49\n      4.94\n      3.50\n      2.27\n      1.88\n      6.12\n      1.45\n      0.63\n      0.74\n      0.67\n      0.81\n      0.69\n      0.67\n    \n    \n      12\n      2020-10\n      30.25\n      26.53\n      10.44\n      9.67\n      4.83\n      2.54\n      2.21\n      1.79\n      6.04\n      1.55\n      0.63\n      0.69\n      0.65\n      0.85\n      0.67\n      0.64"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐그리기",
    "text": "matplotlib: 2개의 y를 겹쳐그리기\n- 예시1\n\ndf.plot.bar(x='Date', y=['Samsung', 'Apple'])\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시2: width옵션으로 폭조정\n\ndf.plot.bar(x='Date', y=['Samsung', 'Apple'], width=0.8)\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "href": "posts/Data Visualization/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립",
    "text": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립\n- 예시: barh를 이용하여 플립\n\ndf.plot.barh(x='Date', y=['Samsung', 'Apple'], width=0.8)\n\n<AxesSubplot:ylabel='Date'>"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-모든y를-stacked-bar로-나타내기",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-모든y를-stacked-bar로-나타내기",
    "title": "DV 11주차(1)",
    "section": "plotly: 모든y를 stacked bar로 나타내기",
    "text": "plotly: 모든y를 stacked bar로 나타내기\n\ndf.melt(id_vars='Date').plot.bar(backend='plotly',x='Date',y='value',color='variable')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기",
    "title": "DV 11주차(1)",
    "section": "plotly: 3개의 y를 겹쳐그리기",
    "text": "plotly: 3개의 y를 겹쳐그리기\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable')\n\n\n                                                \n\n\n- barmode=‘group’\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable', barmode='group')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기-text",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기-text",
    "title": "DV 11주차(1)",
    "section": "plotly: 3개의 y를 겹쳐그리기 + text",
    "text": "plotly: 3개의 y를 겹쳐그리기 + text\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable', barmode='group', text='value', height=600)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_col",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_col",
    "title": "DV 11주차(1)",
    "section": "plotly: 면분할로 subplot그리기 (facet_col)",
    "text": "plotly: 면분할로 subplot그리기 (facet_col)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_col='variable')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_row",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_row",
    "title": "DV 11주차(1)",
    "section": "plotly: 면분할로 subplot그리기 (facet_row)",
    "text": "plotly: 면분할로 subplot그리기 (facet_row)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_row='variable')"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#data3-팁",
    "href": "posts/Data Visualization/DV_11(1114).html#data3-팁",
    "title": "DV 11주차(1)",
    "section": "data3: 팁",
    "text": "data3: 팁\n\nimport plotly.express as px \ndf = px.data.tips() \ndf\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-팁의-박스플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 팁의 박스플랏",
    "text": "plotly: 팁의 박스플랏\n\ndf.plot.box(backend='plotly',y='tip', width=500, height=500)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-시간에-따른-팁의-박스플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-시간에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간에 따른 팁의 박스플랏",
    "text": "plotly: 시간에 따른 팁의 박스플랏\n\ndf.plot.box(backend='plotly',x='time', y='tip', width=500, height=500)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간과 성별에 따른 팁의 박스플랏",
    "text": "plotly: 시간과 성별에 따른 팁의 박스플랏\n- 예시1: y=‘tip’, x=‘time’, color=‘sex’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', width=500, height=500)\n\n\n                                                \n\n\n- 예시2: y=‘tip’, x=‘time’, color=‘sex’, points=‘all’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', points='all',width=500, height=500)\n\n\n                                                \n\n\n\n저녁이 손님이 더 많다"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간,성별,요일에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일에 따른 팁의 박스플랏\n- 예시1: y=‘tip’, x=‘time’, color=‘sex’, facet_col=‘day’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', facet_col='day', width=500, height=500)\n\n\n                                                \n\n\n- 예시2: y=‘tip’, color=‘sex’, facet_col=‘time’, facet_row=‘day’\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "href": "posts/Data Visualization/DV_11(1114).html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',x='smoker',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#data4-인사자료",
    "href": "posts/Data Visualization/DV_11(1114).html#data4-인사자료",
    "title": "DV 11주차(1)",
    "section": "data4: 인사자료",
    "text": "data4: 인사자료\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/HRDataset_v14.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Employee_Name\n      EmpID\n      MarriedID\n      MaritalStatusID\n      GenderID\n      EmpStatusID\n      DeptID\n      PerfScoreID\n      FromDiversityJobFairID\n      Salary\n      ...\n      ManagerName\n      ManagerID\n      RecruitmentSource\n      PerformanceScore\n      EngagementSurvey\n      EmpSatisfaction\n      SpecialProjectsCount\n      LastPerformanceReview_Date\n      DaysLateLast30\n      Absences\n    \n  \n  \n    \n      0\n      Adinolfi, Wilson  K\n      10026\n      0\n      0\n      1\n      1\n      5\n      4\n      0\n      62506\n      ...\n      Michael Albert\n      22.0\n      LinkedIn\n      Exceeds\n      4.60\n      5\n      0\n      1/17/2019\n      0\n      1\n    \n    \n      1\n      Ait Sidi, Karthikeyan\n      10084\n      1\n      1\n      1\n      5\n      3\n      3\n      0\n      104437\n      ...\n      Simon Roup\n      4.0\n      Indeed\n      Fully Meets\n      4.96\n      3\n      6\n      2/24/2016\n      0\n      17\n    \n    \n      2\n      Akinkuolie, Sarah\n      10196\n      1\n      1\n      0\n      5\n      5\n      3\n      0\n      64955\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      3.02\n      3\n      0\n      5/15/2012\n      0\n      3\n    \n    \n      3\n      Alagbe,Trina\n      10088\n      1\n      1\n      0\n      1\n      5\n      3\n      0\n      64991\n      ...\n      Elijiah Gray\n      16.0\n      Indeed\n      Fully Meets\n      4.84\n      5\n      0\n      1/3/2019\n      0\n      15\n    \n    \n      4\n      Anderson, Carol\n      10069\n      0\n      2\n      0\n      5\n      5\n      3\n      0\n      50825\n      ...\n      Webster Butler\n      39.0\n      Google Search\n      Fully Meets\n      5.00\n      4\n      0\n      2/1/2016\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      306\n      Woodson, Jason\n      10135\n      0\n      0\n      1\n      1\n      5\n      3\n      0\n      65893\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      4.07\n      4\n      0\n      2/28/2019\n      0\n      13\n    \n    \n      307\n      Ybarra, Catherine\n      10301\n      0\n      0\n      0\n      5\n      5\n      1\n      0\n      48513\n      ...\n      Brannon Miller\n      12.0\n      Google Search\n      PIP\n      3.20\n      2\n      0\n      9/2/2015\n      5\n      4\n    \n    \n      308\n      Zamora, Jennifer\n      10010\n      0\n      0\n      0\n      1\n      3\n      4\n      0\n      220450\n      ...\n      Janet King\n      2.0\n      Employee Referral\n      Exceeds\n      4.60\n      5\n      6\n      2/21/2019\n      0\n      16\n    \n    \n      309\n      Zhou, Julia\n      10043\n      0\n      0\n      0\n      1\n      3\n      3\n      0\n      89292\n      ...\n      Simon Roup\n      4.0\n      Employee Referral\n      Fully Meets\n      5.00\n      3\n      5\n      2/1/2019\n      0\n      11\n    \n    \n      310\n      Zima, Colleen\n      10271\n      0\n      4\n      0\n      1\n      5\n      3\n      0\n      45046\n      ...\n      David Stanley\n      14.0\n      LinkedIn\n      Fully Meets\n      4.50\n      5\n      0\n      1/30/2019\n      0\n      2\n    \n  \n\n311 rows × 36 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#인종별-급여비교-단순-groupby",
    "href": "posts/Data Visualization/DV_11(1114).html#인종별-급여비교-단순-groupby",
    "title": "DV 11주차(1)",
    "section": "인종별 급여비교 (단순 groupby)",
    "text": "인종별 급여비교 (단순 groupby)\n\ndf.groupby('RaceDesc').agg({'Salary':[np.mean,\"count\"]})\n\n\n\n\n\n  \n    \n      \n      Salary\n    \n    \n      \n      mean\n      count\n    \n    \n      RaceDesc\n      \n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      65806.000000\n      3\n    \n    \n      Asian\n      68521.206897\n      29\n    \n    \n      Black or African American\n      74431.025000\n      80\n    \n    \n      Hispanic\n      83667.000000\n      1\n    \n    \n      Two or more races\n      59998.181818\n      11\n    \n    \n      White\n      67287.545455\n      187\n    \n  \n\n\n\n\n평균을 히스토그램 그려봣을때 약간 정규분포를 띄어야 의미가 있다"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1114).html#급여의-시각화",
    "href": "posts/Data Visualization/DV_11(1114).html#급여의-시각화",
    "title": "DV 11주차(1)",
    "section": "급여의 시각화",
    "text": "급여의 시각화\n- 예시1\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly', x='Salary', color='RaceDesc', facet_col='RaceDesc')\n\n\n                                                \n\n\n- 예시2: 비율로 계싼\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly',x='Salary',color='RaceDesc',facet_col='RaceDesc',histnorm='probability')"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html",
    "href": "posts/Data Visualization/DV_10(1109).html",
    "title": "DV 10주차(2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html#시각화1-전체합격률",
    "href": "posts/Data Visualization/DV_10(1109).html#시각화1-전체합격률",
    "title": "DV 10주차(2)",
    "section": "시각화1: 전체합격률",
    "text": "시각화1: 전체합격률\n- df1\n\n(df.query('gender==\"female\" and result==\"fail\"')['count']).sum()\n\n1063\n\n\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n    \n    \n      1\n      female\n      pass\n      772\n    \n    \n      2\n      male\n      fail\n      1291\n    \n    \n      3\n      male\n      pass\n      1400\n    \n  \n\n\n\n\n- df11\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      count\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n\ndf1과 df2를 합치자\n\n- merge: 두개의 데이터프레임을 합친다.\n\n_df1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n_df2=df.groupby('gender').agg({'count':np.sum}).reset_index()\npd.merge(_df1,_df2)\n\n# _df1과 _df2의 count변수명이 다르기 때문에 아래와 같이 아무것도 안나옴\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n  \n\n\n\n\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n- merge 방법 1\n\n_df1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n_df2=df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\npd.merge(_df1,_df2)\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- merge 방법2\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- 비율계산\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n      0.579292\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n      0.420708\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n      0.479747\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n      0.520253\n    \n  \n\n\n\n\n- 시각화\n\ndata1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data1.query('result == \"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\n\n\n\n\n<ggplot: (8761232133521)>\n\n\n- 결론: 남자의 합격률이 더 높다. \\(\\to\\) 성차별?"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html#시각화2-학과별-합격률",
    "href": "posts/Data Visualization/DV_10(1109).html#시각화2-학과별-합격률",
    "title": "DV 10주차(2)",
    "section": "시각화2: 학과별 합격률",
    "text": "시각화2: 학과별 합격률\n- df2\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n    \n    \n      1\n      A\n      male\n      825\n    \n    \n      2\n      B\n      female\n      25\n    \n    \n      3\n      B\n      male\n      560\n    \n    \n      4\n      C\n      female\n      593\n    \n    \n      5\n      C\n      male\n      325\n    \n    \n      6\n      D\n      female\n      375\n    \n    \n      7\n      D\n      male\n      417\n    \n    \n      8\n      E\n      female\n      393\n    \n    \n      9\n      E\n      male\n      191\n    \n    \n      10\n      F\n      female\n      341\n    \n    \n      11\n      F\n      male\n      373\n    \n  \n\n\n\n\n- merge\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\\\n.merge(df)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n      result\n      count\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n      fail\n      19\n    \n    \n      1\n      A\n      female\n      108\n      pass\n      89\n    \n    \n      2\n      A\n      male\n      825\n      fail\n      314\n    \n    \n      3\n      A\n      male\n      825\n      pass\n      511\n    \n    \n      4\n      B\n      female\n      25\n      fail\n      7\n    \n    \n      5\n      B\n      female\n      25\n      pass\n      18\n    \n    \n      6\n      B\n      male\n      560\n      fail\n      208\n    \n    \n      7\n      B\n      male\n      560\n      pass\n      352\n    \n    \n      8\n      C\n      female\n      593\n      fail\n      391\n    \n    \n      9\n      C\n      female\n      593\n      pass\n      202\n    \n    \n      10\n      C\n      male\n      325\n      fail\n      204\n    \n    \n      11\n      C\n      male\n      325\n      pass\n      121\n    \n    \n      12\n      D\n      female\n      375\n      fail\n      244\n    \n    \n      13\n      D\n      female\n      375\n      pass\n      131\n    \n    \n      14\n      D\n      male\n      417\n      fail\n      279\n    \n    \n      15\n      D\n      male\n      417\n      pass\n      138\n    \n    \n      16\n      E\n      female\n      393\n      fail\n      299\n    \n    \n      17\n      E\n      female\n      393\n      pass\n      94\n    \n    \n      18\n      E\n      male\n      191\n      fail\n      137\n    \n    \n      19\n      E\n      male\n      191\n      pass\n      54\n    \n    \n      20\n      F\n      female\n      341\n      fail\n      103\n    \n    \n      21\n      F\n      female\n      341\n      pass\n      238\n    \n    \n      22\n      F\n      male\n      373\n      fail\n      149\n    \n    \n      23\n      F\n      male\n      373\n      pass\n      224\n    \n  \n\n\n\n\n\n위와 같은 거긴 한데 count 뒤로 보내려고 아래와 같이 작성\n\n\ndata2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate=count/count2')\ndata2\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n      108\n      0.175926\n    \n    \n      1\n      A\n      pass\n      female\n      89\n      108\n      0.824074\n    \n    \n      2\n      A\n      fail\n      male\n      314\n      825\n      0.380606\n    \n    \n      3\n      A\n      pass\n      male\n      511\n      825\n      0.619394\n    \n    \n      4\n      B\n      fail\n      female\n      7\n      25\n      0.280000\n    \n    \n      5\n      B\n      pass\n      female\n      18\n      25\n      0.720000\n    \n    \n      6\n      B\n      fail\n      male\n      208\n      560\n      0.371429\n    \n    \n      7\n      B\n      pass\n      male\n      352\n      560\n      0.628571\n    \n    \n      8\n      C\n      fail\n      female\n      391\n      593\n      0.659359\n    \n    \n      9\n      C\n      pass\n      female\n      202\n      593\n      0.340641\n    \n    \n      10\n      C\n      fail\n      male\n      204\n      325\n      0.627692\n    \n    \n      11\n      C\n      pass\n      male\n      121\n      325\n      0.372308\n    \n    \n      12\n      D\n      fail\n      female\n      244\n      375\n      0.650667\n    \n    \n      13\n      D\n      pass\n      female\n      131\n      375\n      0.349333\n    \n    \n      14\n      D\n      fail\n      male\n      279\n      417\n      0.669065\n    \n    \n      15\n      D\n      pass\n      male\n      138\n      417\n      0.330935\n    \n    \n      16\n      E\n      fail\n      female\n      299\n      393\n      0.760814\n    \n    \n      17\n      E\n      pass\n      female\n      94\n      393\n      0.239186\n    \n    \n      18\n      E\n      fail\n      male\n      137\n      191\n      0.717277\n    \n    \n      19\n      E\n      pass\n      male\n      54\n      191\n      0.282723\n    \n    \n      20\n      F\n      fail\n      female\n      103\n      341\n      0.302053\n    \n    \n      21\n      F\n      pass\n      female\n      238\n      341\n      0.697947\n    \n    \n      22\n      F\n      fail\n      male\n      149\n      373\n      0.399464\n    \n    \n      23\n      F\n      pass\n      male\n      224\n      373\n      0.600536\n    \n  \n\n\n\n\n- 시각화\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230954277)>\n\n\n\n학과별로 살펴보니 A,B,D,F는 여성 합격률이 더 높다.\n\n- 교재설명: 여성의 합격률이 낮은 학과(인기있는 학과)에만 많이 지원하였기 때문\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='department',fill='gender',y='count'),\\\nposition='dodge')\n\n\n\n\n<ggplot: (8761230699317)>\n\n\n\n살펴보니 합격률이 높은 A,B학과의 경우 상대적으로 남성이 많이 지원하였음. 합격률이 낮은 C,D학과는 상대적으로 여성이 많이 지원함. D,F의 지원수는 비슷"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html#시각화1-남녀합격률-시각화",
    "href": "posts/Data Visualization/DV_10(1109).html#시각화1-남녀합격률-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화1: 남녀합격률 시각화",
    "text": "시각화1: 남녀합격률 시각화\n\ndf.groupby(['gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1001\n    \n    \n      1\n      male\n      1002\n    \n  \n\n\n\n\n\ndatahw=df.groupby(['gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\\\n.merge(df).eval('rate = count/count2')\ndatahw\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n      department\n      result\n      count\n      rate\n    \n  \n  \n    \n      0\n      female\n      1001\n      A\n      fail\n      0\n      0.000000\n    \n    \n      1\n      female\n      1001\n      A\n      pass\n      1\n      0.000999\n    \n    \n      2\n      female\n      1001\n      B\n      fail\n      400\n      0.399600\n    \n    \n      3\n      female\n      1001\n      B\n      pass\n      600\n      0.599401\n    \n    \n      4\n      male\n      1002\n      A\n      fail\n      100\n      0.099800\n    \n    \n      5\n      male\n      1002\n      A\n      pass\n      900\n      0.898204\n    \n    \n      6\n      male\n      1002\n      B\n      fail\n      1\n      0.000998\n    \n    \n      7\n      male\n      1002\n      B\n      pass\n      1\n      0.000998\n    \n  \n\n\n\n\n\nggplot(datahw.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\n\n\n\n\n<ggplot: (8761230608089)>"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html#시각화2-학과별-남녀합격률-시각화",
    "href": "posts/Data Visualization/DV_10(1109).html#시각화2-학과별-남녀합격률-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화2: 학과별 남녀합격률 시각화",
    "text": "시각화2: 학과별 남녀합격률 시각화\n\ndatahw2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(datahw2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230576213)>\n\n\n\nA학과: 쓰면 거의 붙는 학과\nB학과: 쓰면 반정도 붙는 학과"
  },
  {
    "objectID": "posts/Data Visualization/DV_10(1109).html#시각화3-학과별-지원자-수-시각화",
    "href": "posts/Data Visualization/DV_10(1109).html#시각화3-학과별-지원자-수-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화3: 학과별 지원자 수 시각화",
    "text": "시각화3: 학과별 지원자 수 시각화\n\ndatahw3=df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\nggplot(datahw3)+geom_col(aes(x='gender',fill='gender',y='count2'))+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230548765)>\n\n\n\n여학생은 쓰면 붙는 A학과에는 거의 지원안함, 대신에 쓰면 반정도 붙는 B학과에 대부분 지원함"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1130).html",
    "href": "posts/Data Visualization/DV_13(1130).html",
    "title": "DV 13주차(2)",
    "section": "",
    "text": "import pandas as pd \nimport json \nimport requests \nimport plotly.express as px"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1130).html#data",
    "href": "posts/Data Visualization/DV_13(1130).html#data",
    "title": "DV 13주차(2)",
    "section": "DATA",
    "text": "DATA\n\ndf = px.data.election()\ngeojson = px.data.election_geojson()\n\n\n두 개의 데이터\n두 데이터를 연결하는 매개체\n지역구에 대응하는 숫자가 들어있는 칼럼이름(df)\nkey가 저장된 위치(geojson, df)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      district\n      Coderre\n      Bergeron\n      Joly\n      total\n      winner\n      result\n      district_id\n    \n  \n  \n    \n      0\n      101-Bois-de-Liesse\n      2481\n      1829\n      3024\n      7334\n      Joly\n      plurality\n      101\n    \n    \n      1\n      102-Cap-Saint-Jacques\n      2525\n      1163\n      2675\n      6363\n      Joly\n      plurality\n      102\n    \n    \n      2\n      11-Sault-au-Récollet\n      3348\n      2770\n      2532\n      8650\n      Coderre\n      plurality\n      11\n    \n    \n      3\n      111-Mile-End\n      1734\n      4782\n      2514\n      9030\n      Bergeron\n      majority\n      111\n    \n    \n      4\n      112-DeLorimier\n      1770\n      5933\n      3044\n      10747\n      Bergeron\n      majority\n      112\n    \n  \n\n\n\n\n\ngeojson.keys()\n\ndict_keys(['type', 'features'])\n\n\n\ngeojson['features'][0].keys()\n\ndict_keys(['type', 'geometry', 'properties', 'id'])\n\n\n\ngeojson['features'][0]['properties']\n\n{'district': '11-Sault-au-Récollet'}"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1130).html#시각화-예시1",
    "href": "posts/Data Visualization/DV_13(1130).html#시각화-예시1",
    "title": "DV 13주차(2)",
    "section": "시각화 예시1",
    "text": "시각화 예시1\n\npx.choropleth_mapbox(\n    data_frame= df, \n    geojson=geojson, \n    color=\"Bergeron\",\n    locations=\"district\", \n    featureidkey=\"properties.district\",\n    center={\"lat\": 45.5517, \"lon\": -73.7073},\n    mapbox_style=\"carto-positron\",\n    zoom=9\n)\n\n\n                                                \n\n\n\nfig=px.choropleth_mapbox(\n    data_frame= df, \n    geojson=geojson, \n    color=\"Bergeron\",\n    locations=\"district\", \n    featureidkey=\"properties.district\",\n    center={\"lat\": 45.5517, \"lon\": -73.7073},\n    mapbox_style=\"carto-positron\",\n    zoom=9\n)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}) # 마진 없애주기"
  },
  {
    "objectID": "posts/Data Visualization/DV_13(1130).html#시각화-예시2",
    "href": "posts/Data Visualization/DV_13(1130).html#시각화-예시2",
    "title": "DV 13주차(2)",
    "section": "시각화 예시2",
    "text": "시각화 예시2\n\nfig = px.choropleth_mapbox(data_frame= df, \n                           geojson=geojson, \n                           color=\"Bergeron\",\n                           locations=\"district_id\", \n                           featureidkey=\"id\",\n                           center={\"lat\": 45.5517, \"lon\": -73.7073},\n                           mapbox_style=\"carto-positron\",\n                           zoom=9)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html",
    "href": "posts/Data Visualization/DV_07(1017).html",
    "title": "DV 7주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#정리",
    "href": "posts/Data Visualization/DV_07(1017).html#정리",
    "title": "DV 7주차(1)",
    "section": "정리",
    "text": "정리\n\n\n\n\n.\n[]\n.iloc\n.loc\ncommnets\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\n\nrow/bool,list\nX\nO\nO\nO\n\n\n\nrow/bool,ser\nX\nO\nX\nO\n\n\n\nrow/bool,map\nX\nX\nO\nO\n\n\n\ncol/bool,list\nX\nX\nO\nO\n\n\n\ncol/bool,ser\nX\nX\nX\nX\n쓸일이없음\n\n\ncol/bool,map\nX\nX\nO\nO"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#데이터",
    "href": "posts/Data Visualization/DV_07(1017).html#데이터",
    "title": "DV 7주차(1)",
    "section": "데이터",
    "text": "데이터\n\n책 : https://github.com/PacktPublishing/Pandas-Cookbook\n\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      ...\n      num_user_for_reviews\n      language\n      country\n      content_rating\n      budget\n      title_year\n      actor_2_facebook_likes\n      imdb_score\n      aspect_ratio\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      ...\n      3054.0\n      English\n      USA\n      PG-13\n      237000000.0\n      2009.0\n      936.0\n      7.9\n      1.78\n      33000\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      ...\n      1238.0\n      English\n      USA\n      PG-13\n      300000000.0\n      2007.0\n      5000.0\n      7.1\n      2.35\n      0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      ...\n      994.0\n      English\n      UK\n      PG-13\n      245000000.0\n      2015.0\n      393.0\n      6.8\n      2.35\n      85000\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      ...\n      2701.0\n      English\n      USA\n      PG-13\n      250000000.0\n      2012.0\n      23000.0\n      8.5\n      2.35\n      164000\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      7.1\n      NaN\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      ...\n      6.0\n      English\n      Canada\n      NaN\n      NaN\n      2013.0\n      470.0\n      7.7\n      NaN\n      84\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      ...\n      359.0\n      English\n      USA\n      TV-14\n      NaN\n      NaN\n      593.0\n      7.5\n      16.00\n      32000\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      ...\n      3.0\n      English\n      USA\n      NaN\n      1400.0\n      2013.0\n      0.0\n      6.3\n      NaN\n      16\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      ...\n      9.0\n      English\n      USA\n      PG-13\n      NaN\n      2012.0\n      719.0\n      6.3\n      2.35\n      660\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      ...\n      84.0\n      English\n      USA\n      PG\n      1100.0\n      2004.0\n      23.0\n      6.6\n      1.85\n      456\n    \n  \n\n4916 rows × 28 columns\n\n\n\n- columns 이름 확인\n\ndf.columns, df.keys()\n\n(Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n        'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n        'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n        'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n        'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n        'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n        'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n        'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n       dtype='object'),\n Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n        'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n        'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n        'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n        'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n        'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n        'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n        'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n       dtype='object'))"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#기본인덱싱-df인덱싱공부-1단계-내용",
    "href": "posts/Data Visualization/DV_07(1017).html#기본인덱싱-df인덱싱공부-1단계-내용",
    "title": "DV 7주차(1)",
    "section": "기본인덱싱 (df인덱싱공부 1단계 내용)",
    "text": "기본인덱싱 (df인덱싱공부 1단계 내용)\n\ndf.loc[:,['color', 'director_name', 'num_critic_for_reviews']]   # 대괄호 쳐주면 df로 나옴\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n    \n  \n\n4916 rows × 3 columns\n\n\n\n\ndf.loc[:,'color':  'title_year','aspect_ratio'] # 슬라이싱 하고 한 개의 리스트 더 봅으려고 하면 안됨\n\nIndexingError: Too many indexers\n\n\ncolor = 0\ntitle_year = 10\naspect_ratio = 16 번째 인덱스라면\n\nlist(range(11))+[16]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16]\n\n\n\n근데 저게 몇번째인지 어떻게 세 ?\npd.Series 이용\n\n\npd.Series(df.columns)\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\ndf.iloc[:,list(range(13))+[26]] \n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      Christoph Waltz\n      Spectre\n      275868\n      2.35\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      Tom Hardy\n      The Dark Knight Rises\n      1144337\n      2.35\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      Doug Walker\n      Star Wars: Episode VII - The Force Awakens\n      8\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      Eric Mabius\n      Signed Sealed Delivered\n      629\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      Natalie Zea\n      The Following\n      73839\n      16.00\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      Eva Boehnke\n      A Plague So Pleasant\n      38\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      Alan Ruck\n      Shanghai Calling\n      1255\n      2.35\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      John August\n      My Date with Drew\n      4285\n      1.85\n    \n  \n\n4916 rows × 14 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#actor라는-단어가-포함된-column-선택",
    "href": "posts/Data Visualization/DV_07(1017).html#actor라는-단어가-포함된-column-선택",
    "title": "DV 7주차(1)",
    "section": "actor라는 단어가 포함된 column 선택",
    "text": "actor라는 단어가 포함된 column 선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n- 방법1\n\n'actor' in 'actor_1_facebook_likes'\n\nTrue\n\n\n\n'ator' in 'actor_1_facebook_likes'\n\nFalse\n\n\n\n_df = pd.DataFrame({'x':[1,2,3],'y':[2,3,4], 'z':[3,4,5]})\n_df.loc[:,[True,False,True]]\n# 요론식으로 해서 찾아보자\n\n\n\n\n\n  \n    \n      \n      x\n      z\n    \n  \n  \n    \n      0\n      1\n      3\n    \n    \n      1\n      2\n      4\n    \n    \n      2\n      3\n      5\n    \n  \n\n\n\n\n\ndf.loc[:,list(map(lambda x: 'actor' in x, df.columns))]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법3\n\ndf.iloc[:,list(map(lambda x: 'actor' in x, df.columns))]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법4\n\ndf.iloc[:,map(lambda x: 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#s로-끝나는-column선택",
    "href": "posts/Data Visualization/DV_07(1017).html#s로-끝나는-column선택",
    "title": "DV 7주차(1)",
    "section": "s로 끝나는 column선택",
    "text": "s로 끝나는 column선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n_str = 'actor_1_facebook_likes'\n_str[-1] == 's'\n\nTrue\n\n\n\nlist(map(lambda x: x[-1] == 's', df.columns))\n\n[False,\n False,\n True,\n False,\n True,\n True,\n False,\n True,\n True,\n True,\n False,\n False,\n True,\n True,\n False,\n False,\n True,\n False,\n True,\n False,\n False,\n False,\n False,\n False,\n True,\n False,\n False,\n True]\n\n\n- 방법1\n\ndf.loc[:,list(map(lambda x: x[-1] == 's', df.columns))]  # list 뺴도 됨\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns\n\n\n\n- 방법2\n\ndf.iloc[:,map(lambda x: x[-1] == 's', df.columns)]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#c-혹은-d로-시작하는-column-선택",
    "href": "posts/Data Visualization/DV_07(1017).html#c-혹은-d로-시작하는-column-선택",
    "title": "DV 7주차(1)",
    "section": "c 혹은 d로 시작하는 column 선택",
    "text": "c 혹은 d로 시작하는 column 선택\n- 방법1\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\ndf.loc[:,map(lambda x: (x[0] == 'c') or (x[0] == 'd'), df.columns)]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns\n\n\n\n- 방법2\n\ndf.iloc[:,map(lambda x: (x[0] == 'c') or (x[0] == 'd'), df.columns)]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#방법1-concat-복잡..",
    "href": "posts/Data Visualization/DV_07(1017).html#방법1-concat-복잡..",
    "title": "DV 7주차(1)",
    "section": "방법1: concat (복잡..)",
    "text": "방법1: concat (복잡..)\n\n_df = pd.DataFrame({'c':[3,4,5]})\n_df\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      3\n    \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\npd.concat([df,_df],axis=1)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#방법2-4가지-컨셉에-따른-할당",
    "href": "posts/Data Visualization/DV_07(1017).html#방법2-4가지-컨셉에-따른-할당",
    "title": "DV 7주차(1)",
    "section": "방법2: 4가지 컨셉에 따른 할당",
    "text": "방법2: 4가지 컨셉에 따른 할당\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n컨셉1: 불가능\n\ndf.c = [3,4,5]\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n컨셉2: 가능\n(예시1)\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndct['c'] = [3,4,5]\ndct\n\n{'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [3, 4, 5]}\n\n\n\ndf['c'] = [3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 사용할 필요는 없음\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['a','b']]\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['c','d']] = np.array([[1,2,3],[3,4,5]]).T\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      1\n      3\n    \n    \n      1\n      2\n      3\n      2\n      4\n    \n    \n      2\n      3\n      4\n      3\n      5\n    \n  \n\n\n\n\n(예시3)\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c'] = [3,4,5]\ndf['d'] = [4,5,6]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(위와 동일하게..)\n\n(df['c'],df['d']) = ([3,4,5], [4,5,6])\ndf \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n컨셉3: 불가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.iloc[:,2] = [3,4,5] \ndf\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n컨셉4: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'] = [3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 쓰진 말자\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,['c','d']] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'],df.loc[:,'d'] = [3,4,5],[4,5,6] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#방법3-.assign으로-할당-star",
    "href": "posts/Data Visualization/DV_07(1017).html#방법3-.assign으로-할당-star",
    "title": "DV 7주차(1)",
    "section": "방법3: .assign으로 할당 (\\(\\star\\))",
    "text": "방법3: .assign으로 할당 (\\(\\star\\))\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n(예시1)\n\ndf.assign(c=[3,4,5])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2)\n\ndf.assign(c=[3,4,5],d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf.assign(c=[3,4,5]).assign(g=[4,2,2])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      g\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      2\n    \n    \n      2\n      3\n      4\n      5\n      2\n    \n  \n\n\n\n\n\ndf  # assign은 위에 할당 해도 기본 df가 남아잇누\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#방법4-.eval을-이용",
    "href": "posts/Data Visualization/DV_07(1017).html#방법4-.eval을-이용",
    "title": "DV 7주차(1)",
    "section": "방법4: .eval을 이용",
    "text": "방법4: .eval을 이용\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]').eval('d=[4,5,6]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#연습해보기",
    "href": "posts/Data Visualization/DV_07(1017).html#연습해보기",
    "title": "DV 7주차(1)",
    "section": "연습해보기",
    "text": "연습해보기\n\n데이터\n\ndf=pd.DataFrame({'x':np.random.randn(1000),'y':np.random.randn(1000)})\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n    \n    \n      1\n      -0.620359\n      -0.310537\n    \n    \n      2\n      -0.247889\n      0.133445\n    \n    \n      3\n      0.499346\n      -1.361192\n    \n    \n      4\n      0.436258\n      -0.225653\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n    \n    \n      996\n      1.279831\n      -0.435540\n    \n    \n      997\n      -0.497101\n      -0.551975\n    \n    \n      998\n      0.457574\n      -0.647124\n    \n    \n      999\n      1.284832\n      -0.149123\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n\n# 새로운열 r을 생성하고 \\(r=\\sqrt{x^2 + y^2}\\)를 계산\n- 방법1: 브로드캐스팅\n\ndf.assign(r=np.sqrt(df.x**2 + df.y**2))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법2: lambda + map을 이용한 개별원소 계산\n\ndf.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x, df.y)))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n위의 코드에서 list를 지우게 되면 에러가 난다.\n- 방법3: eval\n\ndf.eval('r=sqrt(x**2+y**2)')\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n위의 코드에서 r=np.sqrt(~) 사용하면 안된다."
  },
  {
    "objectID": "posts/Data Visualization/DV_07(1017).html#toy-exam",
    "href": "posts/Data Visualization/DV_07(1017).html#toy-exam",
    "title": "DV 7주차(1)",
    "section": "toy exam",
    "text": "toy exam\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1) \ntemp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, \n                25.4, 26.8, 28.9, 35.1, 32.2, 34.6])\neps= np.random.normal(size=12,scale=5)\nicecream= 20 + temp * 2 + eps\n\n\nplt.plot(temp,icecream,'.')\n\n\n\n\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\] - 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자.\n\nnp.random.seed(2) \neps = np.random.normal(size=12,scale=5) \ndisease = 30+ temp* 0.5 + eps\n\n\nplt.plot(temp, disease, '.')\n\n\n\n\n\nplt.plot(icecream,disease,'.')\n\n\n\n\n\n양의 상관관계에 있다.\n\n- 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. <– 여기서부터 틀렸음\n\\[{\\tt disease}_i =\\beta_0 +\\beta_1 {\\tt icecream}_i +\\epsilon_i,\\quad \\textbf{for} ~~ i=1,2,\\dots, 12\\]\n- 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. <– 틀린주장\n\n틀린 모형\n도데체 우리가 뭘 잘못했는가?\n\n- 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다.\n(ex1)\n\n온도 \\(\\to\\) 익사\n온도 \\(\\to\\) 아이스크림\n아이스크림과 익사자도 양의 상관관계에 있을것이다.\n아이스크림을 먹이면 물에 빠져 죽는다 \\(\\to\\) 틀린주장\n사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다.\n\n(ex2)\n\n인구수 \\(\\to\\) 교회\n인구수 \\(\\to\\) 범죄건수\n지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임\n교회를 지으면 범죄건수도 증가한다? \\(\\to\\) 틀린주장\n사실 인구가 숨겨진 요인임\n\n- ex2, ex1에 대하여 바른 분석을 하려면?\n\nex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임\nex1: 온도가 비슷한 그룹끼리 묶어보자.\n\n- 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. \\(\\to\\) 상관계수가 줄어들 것이다.\n\nplt.plot(icecream[:6],disease[:6],'.')\n\n\n\n\n\nplt.plot(icecream[6:],disease[6:],'.')\n\n\n\n\n\n진짜로 선형관계가 약해졌다.."
  },
  {
    "objectID": "posts/Data Visualization/DV_1(0910).html",
    "href": "posts/Data Visualization/DV_1(0910).html",
    "title": "DV 1주차",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/Data Visualization/DV_1(0910).html#boxplot",
    "href": "posts/Data Visualization/DV_1(0910).html#boxplot",
    "title": "DV 1주차",
    "section": "boxplot",
    "text": "boxplot\n\nmotivating example\n(예제1) 전북고등학교: 평균은 좋은 측정값인가?\n\n전북고등학교에서 통계학을 수업하는 A선생님과 B선생님의 있다. A선생님에게서 수업을 들을 학생들의 평균은 79.1이고 B선생님에게서 수업을 들은 학생들의 평균은 78.3이다.\n\n\ny1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들\ny2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 \n\n\nnp.mean(y1), np.mean(y2)\n\n(79.1, 78.3)\n\n\n- 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 더 좋을 것이다.\n- 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생이 A반에 포함되어서 A반이 전체평균이 높게 나온것이고 나머지 학생들은 전체적으로 B반 학생들이 더 시험을 잘 보았다고 해석할 수 있다.\n- 교훈: 단순한 평균 비교보다 학생들이 받은 점수의 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다.\n\n\nmatplotlib으로 boxplot 그리기\n- A반 학생들의 박스플랏 그리기\n\nplt.boxplot(y1)\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635fdf5f50>,\n  <matplotlib.lines.Line2D at 0x7f6360351c50>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635e60c2d0>,\n  <matplotlib.lines.Line2D at 0x7f635e60c610>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635fd87c10>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635e60c990>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635e60cc90>],\n 'means': []}\n\n\n\n\n\n- B반 학생들의 박스플랏 그리기\n\nplt.boxplot(y2)\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635e5ba410>,\n  <matplotlib.lines.Line2D at 0x7f635e5ba750>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635e5baa90>,\n  <matplotlib.lines.Line2D at 0x7f635e5badd0>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635e5ba110>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635e60f190>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635e60f4d0>],\n 'means': []}\n\n\n\n\n\n- A반 학생들의 점수와 B반 학생들의 점수를 나란히 박스플랏으로 그리자.\n\nplt.boxplot([y1,y2]) #리스트로 만들어주면 나란히 가능\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635ec47290>,\n  <matplotlib.lines.Line2D at 0x7f635ec475d0>,\n  <matplotlib.lines.Line2D at 0x7f635ec4fa10>,\n  <matplotlib.lines.Line2D at 0x7f635ec4fd10>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635ec47910>,\n  <matplotlib.lines.Line2D at 0x7f635ec47c50>,\n  <matplotlib.lines.Line2D at 0x7f635ec67090>,\n  <matplotlib.lines.Line2D at 0x7f635ec673d0>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635ec48f50>,\n  <matplotlib.lines.Line2D at 0x7f635ec4f6d0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635ec4f050>,\n  <matplotlib.lines.Line2D at 0x7f635ec67710>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635ec4f350>,\n  <matplotlib.lines.Line2D at 0x7f635ec67a50>],\n 'means': []}\n\n\n\n\n\n\n\nboxplot이란?\n- ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb\n\nnp.random.seed(916170)\n\n# connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs\nmu, sigma = 0, 1 # mean and standard deviation\ns = np.random.normal(mu, sigma, 1000)\n\nfig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5))\n\n# rectangular box plot\nbplot = axes.boxplot(s,\n                vert=False,\n                patch_artist=True, \n                showfliers=True, # This would show outliers (the remaining .7% of the data)\n                positions = [0],\n                boxprops = dict(linestyle='--', linewidth=2, color='Black', facecolor = 'red', alpha = .4),\n                medianprops = dict(linestyle='-', linewidth=2, color='Yellow'),\n                whiskerprops = dict(linestyle='-', linewidth=2, color='Blue', alpha = .4),\n                capprops = dict(linestyle='-', linewidth=2, color='Black'),\n                flierprops = dict(marker='o', markerfacecolor='green', markersize=10,\n                  linestyle='none', alpha = .4),\n                widths = .3,\n                zorder = 1)   \n\naxes.set_xlim(-4, 4)\nplt.xticks(fontsize = 14)\n\naxes.set_yticks([])\naxes.annotate(r'',\n            xy=(-.73, .205), xycoords='data',\n            xytext=(.66, .205), textcoords='data',\n            arrowprops=dict(arrowstyle=\"|-|\",\n                            connectionstyle=\"arc3\")\n            );\n\naxes.text(0, .25, \"Interquartile Range \\n(IQR)\",  horizontalalignment='center', fontsize=18)\naxes.text(0, -.21, r\"Median\", horizontalalignment='center', fontsize=16);\naxes.text(2.65, -.15, \"\\\"Maximum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.15, \"\\\"Minimum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-.68, -.24, r\"Q1\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.21, r\"(Q1 - 1.5*IQR)\", horizontalalignment='center', fontsize=16);\naxes.text(.6745, -.24, r\"Q3\", horizontalalignment='center', fontsize=18);\naxes.text(.6745, -.30, r\"(75th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(-.68, -.30, r\"(25th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(2.65, -.21, r\"(Q3 + 1.5*IQR)\", horizontalalignment='center', fontsize=16);\n\naxes.annotate('Outliers', xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');\n\naxes.annotate('Outliers', xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');\n\n\n\n\n\n\nplotly로 boxplot 그리기\n- 로컬에서 하기 위해서는 아래를 설치 (코랩은 ㄴ)\n\n!conda env list \n\n# conda environments:\n#\nbase                     /home/koinup4/anaconda3\npy37                  *  /home/koinup4/anaconda3/envs/py37\npy39                     /home/koinup4/anaconda3/envs/py39\n\n\n\n\n!pip install plotly \n!pip install ipywidgets\n!pip install jupyter-dash\n!pip install dash \n!pip install pandas \n\nCollecting plotly\n  Downloading plotly-5.13.0-py2.py3-none-any.whl (15.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.2/15.2 MB 93.1 MB/s eta 0:00:0000:0100:01\nCollecting tenacity>=6.2.0\n  Downloading tenacity-8.2.1-py3-none-any.whl (24 kB)\nInstalling collected packages: tenacity, plotly\nSuccessfully installed plotly-5.13.0 tenacity-8.2.1\nCollecting ipywidgets\n  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 kB 5.8 MB/s eta 0:00:00\nRequirement already satisfied: ipykernel>=4.5.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (5.5.5)\nCollecting jupyterlab-widgets~=3.0\n  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 384.3/384.3 kB 35.3 MB/s eta 0:00:00\nRequirement already satisfied: traitlets>=4.3.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (5.8.1)\nCollecting widgetsnbextension~=4.0\n  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 75.0 MB/s eta 0:00:00\nRequirement already satisfied: ipython>=6.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (7.33.0)\nRequirement already satisfied: jupyter-client in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\nRequirement already satisfied: tornado>=4.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\nRequirement already satisfied: backcall in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: jedi>=0.16 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\nRequirement already satisfied: matplotlib-inline in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pexpect>4.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: pickleshare in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\nRequirement already satisfied: pygments in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\nRequirement already satisfied: decorator in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: setuptools>=18.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (65.6.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: jupyter-core>=4.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (4.11.1)\nRequirement already satisfied: pyzmq>=13 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\nRequirement already satisfied: entrypoints in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: nest-asyncio>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.5.6)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\nInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\nSuccessfully installed ipywidgets-8.0.4 jupyterlab-widgets-3.0.5 widgetsnbextension-4.0.5\nCollecting jupyter-dash\n  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\nCollecting retrying\n  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\nCollecting dash\n  Downloading dash-2.8.1-py3-none-any.whl (9.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 80.9 MB/s eta 0:00:00:00:010:01\nCollecting ansi2html\n  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\nCollecting flask\n  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 19.6 MB/s eta 0:00:00\nRequirement already satisfied: ipykernel in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (5.5.5)\nRequirement already satisfied: nest-asyncio in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (1.5.6)\nRequirement already satisfied: ipython in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (7.33.0)\nRequirement already satisfied: requests in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (2.28.2)\nRequirement already satisfied: importlib-metadata in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ansi2html->jupyter-dash) (4.11.4)\nRequirement already satisfied: plotly>=5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash->jupyter-dash) (5.13.0)\nCollecting dash-table==5.0.0\n  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nCollecting dash-html-components==2.0.0\n  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nCollecting dash-core-components==2.0.0\n  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nRequirement already satisfied: Jinja2>=3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from flask->jupyter-dash) (3.1.2)\nCollecting click>=8.0\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 13.5 MB/s eta 0:00:00\nCollecting Werkzeug>=2.2.2\n  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.6/233.6 kB 44.7 MB/s eta 0:00:00\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nRequirement already satisfied: tornado>=4.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (6.1)\nRequirement already satisfied: jupyter-client in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (7.0.6)\nRequirement already satisfied: traitlets>=4.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (5.8.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (3.0.36)\nRequirement already satisfied: matplotlib-inline in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.1.6)\nRequirement already satisfied: pexpect>4.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (4.8.0)\nRequirement already satisfied: pygments in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (2.14.0)\nRequirement already satisfied: jedi>=0.16 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.18.2)\nRequirement already satisfied: decorator in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (5.1.1)\nRequirement already satisfied: pickleshare in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.7.5)\nRequirement already satisfied: setuptools>=18.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (65.6.3)\nRequirement already satisfied: backcall in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (3.4)\nRequirement already satisfied: six>=1.7.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from retrying->jupyter-dash) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->ansi2html->jupyter-dash) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->ansi2html->jupyter-dash) (4.4.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Jinja2>=3.0->flask->jupyter-dash) (2.1.1)\nRequirement already satisfied: ptyprocess>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\nRequirement already satisfied: tenacity>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.2.1)\nRequirement already satisfied: wcwidth in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.6)\nRequirement already satisfied: entrypoints in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (0.4)\nRequirement already satisfied: pyzmq>=13 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (19.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\nRequirement already satisfied: jupyter-core>=4.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (4.11.1)\nInstalling collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, itsdangerous, click, ansi2html, flask, dash, jupyter-dash\nSuccessfully installed Werkzeug-2.2.3 ansi2html-1.8.0 click-8.1.3 dash-2.8.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-2.2.3 itsdangerous-2.1.2 jupyter-dash-0.4.2 retrying-1.3.4\nRequirement already satisfied: dash in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (2.8.1)\nRequirement already satisfied: dash-table==5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (5.0.0)\nRequirement already satisfied: dash-html-components==2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.0.0)\nRequirement already satisfied: Flask>=1.0.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.2.3)\nRequirement already satisfied: plotly>=5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (5.13.0)\nRequirement already satisfied: dash-core-components==2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.0.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (2.2.3)\nRequirement already satisfied: itsdangerous>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (2.1.2)\nRequirement already satisfied: Jinja2>=3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (3.1.2)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (4.11.4)\nRequirement already satisfied: click>=8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (8.1.3)\nRequirement already satisfied: tenacity>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotly>=5.0.0->dash) (8.2.1)\nRequirement already satisfied: zipp>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (4.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash) (2.1.1)\nRequirement already satisfied: pandas in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (1.3.5)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2022.7.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy>=1.17.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (1.21.6)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n\n\n\nimport plotly.express as px\nimport pandas as pd\nfrom IPython.display import HTML\n\n\n['A']*len(y1)  # y1숫자만큼 A반복\n\n['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n\n\n\n['A']*len(y1) + ['B']*len(y2)\n\n['A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B']\n\n\n\ndf=pd.DataFrame({'score':y1+y2, 'class':['A']*len(y1) + ['B']*len(y2)})\ndf\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n\nfig=px.box(df,x='class',y='score')\nfig\n\n\n                                                \n\n\n왜 안나오누..\n\nHTML(fig.to_html(include_plotlyjs='cdn', include_mathjax=False))"
  },
  {
    "objectID": "posts/Data Visualization/DV_1(0910).html#histogram",
    "href": "posts/Data Visualization/DV_1(0910).html#histogram",
    "title": "DV 1주차",
    "section": "histogram",
    "text": "histogram\n\nmotivating example\n- 전북고예제에서의 소망: 그냥 A반 B반 중에 어떤 반이 공부를 더 잘하냐? - 보통 이러한 질문은 중심경향값 중 하나를 골라서 비교하면 되었다. - 중심경향값이란 데이터 분포의 중심을 보여준 값으로 자료 전체를 대표할 수 있는 값을 말함. 평균, 중앙값 등이 대표적인 중심경향값이다.\n- 전북고 예제에서는 “A반 B반 중에서 어떤 반이 공부를 더 잘하냐?” 라는 질문의 대답으로 단순평균비교로는 의미가 없었다. 오히려 결과론적으로 보면 중앙값이 더 타당해 보인다.\n- 그런데 사실 생각해보면 중앙값을 기준으로 B반이 공부를 더 잘했다고 주장하는 것도 애매하다. 무튼 가장 공부잘한 학생은 A반에 있으니까!? (한명뿐이니까 빼고 가도 되지않나여? 이지만 2명 3명 점점 늘어난다 생각해보면 합리적인 기준을 제시할 수 있을까?)\n- 사실 “A반 B반 중에 누가 더 공부를 잘하냐?” 라는 질문은 굉장히 대답하기 곤란한 질문이다. 왜냐하면 - 이슈1: 단순 평균비교로 이러한 질문에 답을 하기 어렵다. - 이슈2: 박스플랏으로 전체분포를 파악해도 어떠한 반이 더 공부를 잘한다는 기준을 잡는 것이 애매하다.\n그런데 특수한 경우에는 “A반 B반 중에 누가 더 공부를 잘하냐?” 라는 질문에 대한 대답을 깔끔하게 할 수 있다.\n(예제2) 정규분포 전북고등학교: 평균은 좋은 측정값인가?\n- A반과 B반의 통계학 성적이 아래와 같다고 하자.\n\nnp.random.seed(43052)\ny1 = np.random.randn(10000)         # 평균 0 분산 1\ny2 = np.random.randn(10000) + 0.5   # 평균 0.5 분산 1\n\n\nnp.mean(y1), np.mean(y2)\n\n(-0.011790879905079434, 0.4979147460611458)\n\n\n\nnp.mean(y2) - np.mean(y1)\n\n0.5097056259662253\n\n\ny2의 값이 y1의 값보다 전체적으로 0.51 정도 높다고 볼수 있다.?\n\nplt.boxplot([y1,y2])\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f638623b0d0>,\n  <matplotlib.lines.Line2D at 0x7f63861c40d0>,\n  <matplotlib.lines.Line2D at 0x7f63861cf510>,\n  <matplotlib.lines.Line2D at 0x7f63861cf810>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f63861c4410>,\n  <matplotlib.lines.Line2D at 0x7f63861c4750>,\n  <matplotlib.lines.Line2D at 0x7f63861cfb50>,\n  <matplotlib.lines.Line2D at 0x7f63861cfe90>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f638623b9d0>,\n  <matplotlib.lines.Line2D at 0x7f63861cf1d0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f63861c4ad0>,\n  <matplotlib.lines.Line2D at 0x7f63861dc210>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f63861c4e10>,\n  <matplotlib.lines.Line2D at 0x7f63861dc550>],\n 'means': []}\n\n\n\n\n\n\n분포의 모양이 거의 비슷, 왼쪽그림을 컨트롤+C 하여 오른쪽에 붙인다음 0.5정도 y축으로 올린느낌이다!\n\n- 이러한 상황에서는 “B반의 성적 \\(\\approx\\) A반의 성적 + 0.5” 라고 주장해도 큰 무리가 없어보인다. 따라서 이 경우에는 “A반 B반 중에 어떤 반이 더 공부를 잘하냐?” 라는 질문에 대다하여 “B반이 평균적으로 0.51정도 공부를 잘한다”고 말할 수 있다.\n- 결론: 정규분포 분포가정을 한다면 이슈 1, 2에 대한 무넺를 한번에 해결 가능함\n- 정규분포 가정은 어떻게 할 수 있나? (=데이터를 보고 어떻게 정규분포라고 알 수 있는가?) : 데이터의 히스토그램을 그려서 종 모양이 되는지 확인해본다. (아직 초보단계라서 이것밖에 모를 수 있다.)\n\n\nhistogram이란?\n- 히스토그램: X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림\n\n\nmatplotlib으로 histogram 그리기\n- 히스토그램의 예시1\n\ny=[10,11,12,15,16,20,21,22,23,24,25]\n\n\nplt.hist(y)\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(y,bins=10)  # bins 빈도 10개\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 히스토그램 예시2\n\nplt.hist(y,bins=2) # 빈도 2개\n# 범위 10~17.5에 5개, 17.5~25까지는 6개가 있음\n\n(array([5., 6.]),\n array([10. , 17.5, 25. ]),\n <BarContainer object of 2 artists>)\n\n\n\n\n\n- 히스토그램 예시3\n\nplt.hist(y,bins=3)\n\n(array([3., 2., 6.]),\n array([10., 15., 20., 25.]),\n <BarContainer object of 3 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 3 = 5 이므로 각 구간의 간격은 5이다.\n구간은 [10,15), [15,20), [20,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3, 2, 6이다.\n\n- 히스토그램 예시4\n\nplt.hist(y,bins=7)\n\n(array([3., 0., 2., 0., 1., 2., 3.]),\n array([10.        , 12.14285714, 14.28571429, 16.42857143, 18.57142857,\n        20.71428571, 22.85714286, 25.        ]),\n <BarContainer object of 7 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 7 = 2.142857142857143 이므로 각 구간의 간격은 2.142857142857143이다.\n구간은 [10,12.14285714), [12.14285714,14.28571429,), [22.85714286,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3,0,2,0,1,2,3 이다.\n\n\n_a = 15/7\n_a\n\n2.142857142857143\n\n\n- 히스토그램 예시5\n\n# np.random.seed(43052)\n# y1 = np.random.randn(10000)\n# y2 = np.random.randn(10000) + 0.5 \nplt.hist([y1,y2],bins=50);\n\n\n\n\n\n\nseaborn으로 histogram 그리기\n\n!pip install seaborn\nimport seaborn as sns\n\nCollecting seaborn\n  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.3/293.3 kB 13.8 MB/s eta 0:00:00\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (3.5.3)\nRequirement already satisfied: typing_extensions in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (4.4.0)\nRequirement already satisfied: pandas>=0.25 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (1.3.5)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (1.21.6)\nRequirement already satisfied: pillow>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\nInstalling collected packages: seaborn\nSuccessfully installed seaborn-0.12.2\n\n\n\ny1, y2\n\n(array([ 0.38342049,  1.0841745 ,  1.14277825, ...,  1.03232398,\n        -0.18988252, -0.03578389]),\n array([ 1.96391024,  0.31095591, -0.65422978, ..., -0.50052895,\n         1.26755071,  1.00486301]))\n\n\n\ndf=pd.DataFrame({'score': np.concatenate([y1,y2]), 'class':['A']*len(y1) + ['B']*len(y2)})\ndf\n#list(y1)+list(y2)   위의 score를 이렇게도 쓸수있다.\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      0.383420\n      A\n    \n    \n      1\n      1.084175\n      A\n    \n    \n      2\n      1.142778\n      A\n    \n    \n      3\n      0.307894\n      A\n    \n    \n      4\n      0.237787\n      A\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      0.493276\n      B\n    \n    \n      19996\n      0.619512\n      B\n    \n    \n      19997\n      -0.500529\n      B\n    \n    \n      19998\n      1.267551\n      B\n    \n    \n      19999\n      1.004863\n      B\n    \n  \n\n20000 rows × 2 columns\n\n\n\n\nsns.histplot(df, x='score', hue='class')\n\n<AxesSubplot:xlabel='score', ylabel='Count'>\n\n\n\n\n\n\n\nplotnine으로 histogram 그리기\n\n!pip install plotnine\n\nCollecting plotnine\n  Downloading plotnine-0.8.0-py3-none-any.whl (4.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 19.9 MB/s eta 0:00:0000:0100:01\nRequirement already satisfied: matplotlib>=3.1.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (3.5.3)\nRequirement already satisfied: numpy>=1.19.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (1.21.6)\nCollecting scipy>=1.5.0\n  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.1/38.1 MB 60.6 MB/s eta 0:00:0000:0100:01\nCollecting mizani>=0.7.3\n  Downloading mizani-0.7.3-py3-none-any.whl (63 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 11.2 MB/s eta 0:00:00\nCollecting descartes>=1.1.0\n  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\nCollecting patsy>=0.5.1\n  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 38.6 MB/s eta 0:00:00\nCollecting statsmodels>=0.12.1\n  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 96.2 MB/s eta 0:00:00ta 0:00:01\nRequirement already satisfied: pandas>=1.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (1.3.5)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (4.38.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (1.4.4)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\nRequirement already satisfied: pillow>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (9.4.0)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (23.0)\nCollecting palettable\n  Downloading palettable-3.3.0-py2.py3-none-any.whl (111 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.8/111.8 kB 14.4 MB/s eta 0:00:00\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=1.1.0->plotnine) (2022.7.1)\nRequirement already satisfied: six in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from patsy>=0.5.1->plotnine) (1.16.0)\nRequirement already satisfied: typing-extensions in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine) (4.4.0)\nInstalling collected packages: palettable, scipy, patsy, statsmodels, mizani, descartes, plotnine\nSuccessfully installed descartes-1.1.0 mizani-0.7.3 palettable-3.3.0 patsy-0.5.3 plotnine-0.8.0 scipy-1.7.3 statsmodels-0.13.5\n\n\n\nfrom plotnine import *\n\n\nggplot(df) + geom_histogram(aes(x='score', fill='class'), position='identity', alpha=0.5)\n# position: 겹쳐있게 보이게 함.\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8754036207793)>\n\n\n\nggplot(df) + geom_histogram(aes(x='score', fill='class'), alpha=0.5)\n# 파란색을 그리고 빨간색을 그 위에 그림\n# 비교를 위해서 관찰만 할것 이렇게 그리진 말자\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8754019989885)>\n\n\n\n\nplotly로 histogram 그리기\n\nimport plotly.figure_factory as ff\n\nhist_data = [y1, y2]\n\ngroup_labels = ['A', 'B']\n\n# Create distplot with curve_type set to 'normal'\nff.create_distplot(hist_data, group_labels,bin_size=.2, show_rug=False)"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html",
    "href": "posts/Data Visualization/DV_11(1116).html",
    "title": "DV 11주차(2)",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#데이터읽기-pd.read_html",
    "href": "posts/Data Visualization/DV_11(1116).html#데이터읽기-pd.read_html",
    "title": "DV 11주차(2)",
    "section": "데이터읽기 // pd.read_html()",
    "text": "데이터읽기 // pd.read_html()\n- 대한민국의 저출산문제\n\nref: https://ko.wikipedia.org/wiki/대한민국의_저출산\n\n- 위의 url에서 3,5번째 테이블을 읽고싶다.\n\n3번째 테이블: 시도별 출산율\n5번째 테이블: 시도별 출생아 수\n\n\n_dflst=pd.read_html('https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%A0%80%EC%B6%9C%EC%82%B0')\n_df1 = _dflst[2]\n_df2 = _dflst[4]\n\n\n_df1 # 시도별 출산율\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2005\n      2006[7]\n      2007\n      2008[8]\n      2009[9]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      0.92\n      0.97\n      1.06\n      1.01\n      0.96\n      1.02\n      1.01\n      1.06\n      0.97\n      0.98\n      1.00\n      0.94\n      0.84\n      0.76\n      0.72\n      0.64\n      0.63\n    \n    \n      1\n      부산\n      0.88\n      0.91\n      1.02\n      0.98\n      0.94\n      1.05\n      1.08\n      1.14\n      1.05\n      1.09\n      1.14\n      1.10\n      0.98\n      0.90\n      0.83\n      0.75\n      0.73\n    \n    \n      2\n      대구\n      0.99\n      1.00\n      1.13\n      1.07\n      1.03\n      1.11\n      1.15\n      1.22\n      1.13\n      1.17\n      1.22\n      1.19\n      1.07\n      0.99\n      0.93\n      0.81\n      0.78\n    \n    \n      3\n      인천\n      1.07\n      1.11\n      1.25\n      1.19\n      1.14\n      1.21\n      1.23\n      1.30\n      1.20\n      1.21\n      1.22\n      1.14\n      1.01\n      1.01\n      0.94\n      0.83\n      0.78\n    \n    \n      4\n      광주\n      1.10\n      1.14\n      1.26\n      1.20\n      1.14\n      1.22\n      1.23\n      1.30\n      1.17\n      1.20\n      1.21\n      1.17\n      1.05\n      0.97\n      0.91\n      0.81\n      0.90\n    \n    \n      5\n      대전\n      1.10\n      1.15\n      1.27\n      1.22\n      1.16\n      1.21\n      1.26\n      1.32\n      1.23\n      1.25\n      1.28\n      1.19\n      1.08\n      0.95\n      0.88\n      0.81\n      0.81\n    \n    \n      6\n      울산\n      1.18\n      1.24\n      1.40\n      1.34\n      1.31\n      1.37\n      1.39\n      1.48\n      1.39\n      1.44\n      1.49\n      1.42\n      1.26\n      1.13\n      1.08\n      0.99\n      0.94\n    \n    \n      7\n      세종\n      -\n      -\n      -\n      -\n      -\n      -\n      -\n      1.60\n      1.44\n      1.35\n      1.89\n      1.82\n      1.67\n      1.57\n      1.47\n      1.28\n      1.28\n    \n    \n      8\n      경기\n      1.17\n      1.23\n      1.35\n      1.29\n      1.23\n      1.31\n      1.31\n      1.36\n      1.23\n      1.24\n      1.27\n      1.19\n      1.07\n      1.00\n      0.94\n      0.88\n      0.85\n    \n    \n      9\n      강원\n      1.18\n      1.19\n      1.35\n      1.25\n      1.25\n      1.31\n      1.34\n      1.37\n      1.25\n      1.25\n      1.31\n      1.24\n      1.12\n      1.07\n      1.08\n      1.04\n      0.98\n    \n    \n      10\n      충북\n      1.19\n      1.22\n      1.39\n      1.32\n      1.32\n      1.40\n      1.43\n      1.49\n      1.37\n      1.36\n      1.41\n      1.36\n      1.24\n      1.17\n      1.05\n      0.98\n      0.95\n    \n    \n      11\n      충남\n      1.26\n      1.35\n      1.50\n      1.44\n      1.41\n      1.48\n      1.50\n      1.57\n      1.44\n      1.42\n      1.48\n      1.40\n      1.28\n      1.19\n      1.11\n      1.03\n      0.96\n    \n    \n      12\n      전북\n      1.17\n      1.20\n      1.37\n      1.31\n      1.28\n      1.37\n      1.41\n      1.44\n      1.32\n      1.33\n      1.35\n      1.25\n      1.15\n      1.04\n      0.97\n      0.91\n      0.85\n    \n    \n      13\n      전남\n      1.28\n      1.33\n      1.53\n      1.45\n      1.45\n      1.54\n      1.57\n      1.64\n      1.52\n      1.50\n      1.55\n      1.47\n      1.33\n      1.24\n      1.23\n      1.15\n      1.02\n    \n    \n      14\n      경북\n      1.17\n      1.20\n      1.36\n      1.31\n      1.27\n      1.38\n      1.43\n      1.49\n      1.38\n      1.41\n      1.46\n      1.40\n      1.26\n      1.17\n      1.09\n      1.00\n      0.97\n    \n    \n      15\n      경남\n      1.18\n      1.25\n      1.43\n      1.37\n      1.32\n      1.41\n      1.45\n      1.50\n      1.37\n      1.41\n      1.44\n      1.36\n      1.23\n      1.12\n      1.05\n      0.95\n      0.90\n    \n    \n      16\n      제주\n      1.30\n      1.36\n      1.48\n      1.39\n      1.38\n      1.46\n      1.49\n      1.60\n      1.43\n      1.48\n      1.48\n      1.43\n      1.31\n      1.22\n      1.15\n      1.02\n      0.95\n    \n    \n      17\n      전국\n      1.08\n      1.13\n      1.25\n      1.19\n      1.15\n      1.23\n      1.24\n      1.30\n      1.19\n      1.21\n      1.24\n      1.17\n      1.05\n      0.98\n      0.92\n      0.84\n      0.81\n    \n  \n\n\n\n\n\n_df2 # 시도별 출생아수\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      1\n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      2\n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      3\n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      4\n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      5\n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      6\n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      7\n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      8\n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      9\n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      10\n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      11\n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      12\n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      13\n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      14\n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      15\n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      16\n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      17\n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n\n데이터정리\n\n전국 행 삭제\n지역/연도[6]에 있는 2006[7] 이런 것 정리\nnan값 표시\n\n\n_df1.drop(17)\\\n.melt(id_vars='지역/연도[6]').variable.unique()\n\narray(['2005', '2006[7]', '2007', '2008[8]', '2009[9]', '2010', '2011',\n       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n       '2020', '2021'], dtype=object)\n\n\n\ndf1 = _df1.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(variable = lambda df: list(map(lambda x:x[:4], df.variable)))\ndf1\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      variable\n      value\n    \n  \n  \n    \n      0\n      서울\n      2005\n      0.92\n    \n    \n      1\n      부산\n      2005\n      0.88\n    \n    \n      2\n      대구\n      2005\n      0.99\n    \n    \n      3\n      인천\n      2005\n      1.07\n    \n    \n      4\n      광주\n      2005\n      1.10\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      284\n      전북\n      2021\n      0.85\n    \n    \n      285\n      전남\n      2021\n      1.02\n    \n    \n      286\n      경북\n      2021\n      0.97\n    \n    \n      287\n      경남\n      2021\n      0.9\n    \n    \n      288\n      제주\n      2021\n      0.95\n    \n  \n\n289 rows × 3 columns\n\n\n\n\ndf1.value.unique()\n\narray(['0.92', '0.88', '0.99', '1.07', '1.10', '1.18', '-', '1.17',\n       '1.19', '1.26', '1.28', '1.30', '0.97', '0.91', '1.00', '1.11',\n       '1.14', '1.15', '1.24', '1.23', '1.22', '1.35', '1.20', '1.33',\n       '1.25', '1.36', '1.06', '1.02', '1.13', '1.27', '1.40', '1.39',\n       '1.50', '1.37', '1.53', '1.43', '1.48', '1.01', '0.98', '1.34',\n       '1.29', '1.32', '1.44', '1.31', '1.45', '0.96', '0.94', '1.03',\n       '1.16', '1.41', '1.38', '1.05', '1.21', '1.54', '1.46', '1.08',\n       '1.57', '1.49', 1.06, 1.14, 1.22, 1.3, 1.32, 1.48, 1.6, 1.36, 1.37,\n       1.49, 1.57, 1.44, 1.64, 1.5, 0.97, 1.05, 1.13, 1.2, 1.17, 1.23,\n       1.39, 1.25, 1.52, 1.38, 1.43, 0.98, 1.09, 1.21, 1.35, 1.24, 1.42,\n       1.33, 1.41, 1.0, 1.28, 1.89, 1.27, 1.31, 1.55, 1.46, 0.94, 1.1,\n       1.19, 1.82, 1.4, 1.47, 0.84, 1.07, 1.01, 1.08, 1.26, 1.67, 1.12,\n       1.15, 0.76, 0.9, 0.99, 0.95, 1.04, 0.72, 0.83, 0.93, 0.91, 0.88,\n       1.11, 0.64, 0.75, 0.81, 1.03, 1.02, 0.63, 0.73, 0.78, 0.85, 0.96],\n      dtype=object)\n\n\n문자열, 숫자.. 다 섞여있음\n\ndf1 = df1.assign(value=lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\n\n\ndf1=df1.set_axis(['지역','연도','출산율'],axis=1)\ndf1\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출산율\n    \n  \n  \n    \n      0\n      서울\n      2005\n      0.92\n    \n    \n      1\n      부산\n      2005\n      0.88\n    \n    \n      2\n      대구\n      2005\n      0.99\n    \n    \n      3\n      인천\n      2005\n      1.07\n    \n    \n      4\n      광주\n      2005\n      1.10\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      284\n      전북\n      2021\n      0.85\n    \n    \n      285\n      전남\n      2021\n      1.02\n    \n    \n      286\n      경북\n      2021\n      0.97\n    \n    \n      287\n      경남\n      2021\n      0.90\n    \n    \n      288\n      제주\n      2021\n      0.95\n    \n  \n\n289 rows × 3 columns\n\n\n\n\ndf2 = _df2.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(value = lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#시각화i-전국-출생아수-시각화",
    "href": "posts/Data Visualization/DV_11(1116).html#시각화i-전국-출생아수-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화I: 전국 출생아수 시각화",
    "text": "시각화I: 전국 출생아수 시각화\n\ndf2.groupby(['연도']).agg({'출생아수':np.sum}).reset_index().plot(x='연도',y='출생아수',backend='plotly')\n\n\n                                                \n\n\n\n일괄적으로 감소하는 느낌은 없음"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#시각화ii-시도별-출생아수-시각화",
    "href": "posts/Data Visualization/DV_11(1116).html#시각화ii-시도별-출생아수-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화II: 시도별 출생아수 시각화",
    "text": "시각화II: 시도별 출생아수 시각화\n- 시각화예시1\n\ndf2.plot.line(backend='plotly', x='연도', y='출생아수', color='지역')\n\n\n                                                \n\n\n\n서울과 경기가 특이하네..\n\n- 시각화예시2: plot.area\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')\n\n\n                                                \n\n\n\nareaplot의 최상단의 선: 전국출생아수 시각화와 같음 (일괄적으로 감소하는 느낌은 별로 없음. 그 이유는 서울과 경기지역 때문임)\nareaplot의 장점: 전국출생아수를 연도별로 시각화 하는 느낌 + 각 연도를 도시별로 분해하여 해석하는 느낌"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#시각화iii-시도별-출산율-시각화",
    "href": "posts/Data Visualization/DV_11(1116).html#시각화iii-시도별-출산율-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화III: 시도별 출산율 시각화",
    "text": "시각화III: 시도별 출산율 시각화\n\ndf1.plot.line(backend='plotly', x='연도', y='출산율', color='지역')\n\n\n                                                \n\n\n\n상식과 일치하는 정상적인 플랏 ( 출산율이 2021 이후로 꺽이는 느낌이 든다.)\n여기서는 서울/경기가 정상인듯 보인다.\n\n\n출산율의 경우 합계 출산율이 크게 의미가 없으므로 areaplot는 생략"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#해석",
    "href": "posts/Data Visualization/DV_11(1116).html#해석",
    "title": "DV 11주차(2)",
    "section": "해석",
    "text": "해석\n- 이상한점: 서울/경기지역에서 특정연도의 출생아수가 매우 낮으나 서울/경기지역의 출산’율’은 모든 년도에서 고른값을 가짐\n- 해석: 데이터가 이상?? / 원본 데이터를 확인하니 오타가 있음.. 컴마를 온점으로 찍음 ㅠ"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#데이터의-수정-1-df2-상태에서-수정",
    "href": "posts/Data Visualization/DV_11(1116).html#데이터의-수정-1-df2-상태에서-수정",
    "title": "DV 11주차(2)",
    "section": "데이터의 수정 (1): df2 상태에서 수정",
    "text": "데이터의 수정 (1): df2 상태에서 수정\n\ndf2.sort_values(\"출생아수\")[:10]\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      62\n      충남\n      2013\n      18.628\n    \n    \n      11\n      충남\n      2010\n      20.242\n    \n    \n      28\n      충남\n      2011\n      20.398\n    \n    \n      45\n      충남\n      2012\n      20.448\n    \n    \n      153\n      서울\n      2019\n      53.673\n    \n    \n      102\n      서울\n      2016\n      75.536\n    \n    \n      161\n      경기\n      2019\n      83.198\n    \n    \n      76\n      경기\n      2014\n      112.169\n    \n    \n      41\n      세종\n      2012\n      1054.000\n    \n    \n      58\n      세종\n      2013\n      1111.000\n    \n  \n\n\n\n\n- 오타로 예상되는 서울/경기/충남 이외의 가장 작은 값은 2012년 세종시인데, 이 값이 1054로 1000보다 크다.\n\n출생아수 < 1000 이면 출생아수 * 1000을 수행하는 함수를 구현하자.\n\n\ndf2.assign(출생아수 = list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n- 수정 잘 됬는지 시각화\n\ndf2.assign(출생아수 = list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\\\n.plot.area(x='연도', y='출생아수', color='지역', backend='plotly')\n\n\n                                                \n\n\n\n전체출산율이 점점 낮아지고 있고 항목별로 살펴보아도 모든 도시의 출생아수가 점차 낮아지고 있음"
  },
  {
    "objectID": "posts/Data Visualization/DV_11(1116).html#데이터의-수정-2-_df2-상태에서-수정",
    "href": "posts/Data Visualization/DV_11(1116).html#데이터의-수정-2-_df2-상태에서-수정",
    "title": "DV 11주차(2)",
    "section": "데이터의 수정 (2): _df2 상태에서 수정",
    "text": "데이터의 수정 (2): _df2 상태에서 수정\n\napplymap\n- 예비학습\n\npd.DataFrame(np.arange(4).reshape(2,2)).applymap(lambda x:x**2+1)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      5\n      10\n    \n  \n\n\n\n\n\n모든 element에 똑같이 함수를 적용하는 함수\n\n\n_df2.set_index('지역/연도[6]') # 임의로 인덱스를 빼자. 값에 applymap을 쓰기 위해서\n\n\n\n\n\n  \n    \n      \n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n    \n      지역/연도[6]\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n- 방법1\n\n_df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x=='-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      level_1\n      0\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      서울\n      2011\n      91526.0\n    \n    \n      2\n      서울\n      2012\n      93914.0\n    \n    \n      3\n      서울\n      2013\n      84066.0\n    \n    \n      4\n      서울\n      2014\n      83711.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      197\n      제주\n      2017\n      5037.0\n    \n    \n      198\n      제주\n      2018\n      4781.0\n    \n    \n      199\n      제주\n      2019\n      4500.0\n    \n    \n      200\n      제주\n      2020\n      4000.0\n    \n    \n      201\n      제주\n      2021\n      3728.0\n    \n  \n\n202 rows × 3 columns\n\n\n\n- 방법2\n\ndf2=_df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x=='-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.reset_index()\\\n.melt(id_vars='지역/연도[6]')\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')"
  },
  {
    "objectID": "posts/Review/Practical Synthetic Data Generation.html",
    "href": "posts/Review/Practical Synthetic Data Generation.html",
    "title": "Practical Synthetic Data Generation",
    "section": "",
    "text": "부제: 머신러닝을 위한 실전 데이터셋\n출판사: 한빛미디어\n저자: 칼리드 엘 에맘, 루시 모스케라, 리처드 홉트로프\n옮긴이: 심상진 옮김\n소개글: 머신러닝 모델을 구축하고, 테스트를 진행하려면 크고 다양한 종류의 데이터가 필요하다. 그러나 대부분의 데이터셋은 개인 정보 문제로 사용이 제한적이라 광범위하게 사용할 수 없다. 이 책에서는 실제 데이터로 새로운 데이터를 만드는 실용적인 합성 데이터 기술을 소개한다. 합성 데이터는 이차 분석에 용이하여 데이터 연구, 고객 행동의 이해, 신제품 개발 등 다양한 목적으로 활용될 수 있다. 이 책은 실제 데이터를 합성해 다양한 산업에서 사용할 수 있는 방법을 제공하며, 개인 정보 문제를 해결하는 방법을 다룬다. 또한 실제 데이터셋에서 합성 데이터를 생성하기 위한 원칙과 단계를 배운다. 더 나아가 합성 데이터가 제품이나 솔루션 개발에 드는 시간을 어떻게 단축할 수 있는지를 학습한다.\n\n\n\n- 합성 데이터 정의\n\n실제 데이터가 아니라 실제 데이터에서 생성되어 통계속성이 동일한 데이터\n\n- 합성 데이터 유형\n\n실제 데이터로 합성하기\n실제 데이터 없이 합성하기\n두 가지 유형을 합친 하이브리드\n\n- 합성 데이터 이점\n\n식별 가능한 개인 데이터가 아님 \\(\\to\\) 개인 정보 보호 규정 적용x\n데이터 이차 목적 사용 가능\n수집이 어렵거나 비실용적, 비윤리적인 경우도 사용 가능\n초기 모델을 훈련 \\(\\to\\) 데이터 모델의 정합화 촉진\n\n- 합성 데이터 활용 사례\n\n제조/유통\n헬스케어\n금융 서비스\n교통수단\n\n- 공공 데이터는 통제되지 않는다.\n- 영국 공중보건국 합성 암 등록 데이터\n\n\n\n- 데이터 합성이 데이터에 접근하는 최선의 방식인가?\n\\(\\to\\) 구현 프로세스 고려\n- 결정기준\n\n프라이버시, 운영 비용, 데이터 효용성, 소비자 신뢰도\n\n\n\n\n- 데이터 합성 방법론과 기술\n\n분포 모델링(정규 분포/지수 분포 등 고전적인 분포)에 개별 변수를 적합시키거나 데이터 구조 모델링 사용\n\n- 과적합 해결법\n\n분포를 중립 지점에서 시작해 데이터에 더 가깝게 더 가까운 쪽으로 이동하여 각 단계별 분포의 단순성과 적합도 사이에서 균형을 이루게 하는 접근법\n최고의 절충점에 언제 도착했는지 측정해서 방지\n분포 적합성 접근법?\n\n\n\n\n- 일변량\n\n실제 데이터와 합성 데이터에서 각 변수 간의 분포 차이를 측정하기 위한 헬링거 거리 계산\n0: 분포간에 차이 없음 ~ 1: 분포 차이 많음\n\n- 이변량\n\n실제 데이터와 합성 데이터의 모든 변수 쌍 간의 상관관계의 절대적 차이 = 데이터 효용성의 척도\n\n- 다변량\n\n10겹 교차 검증\n데이터 셋을 10개의 동일한 크기의 서브셋으로 나눔\n서브셋1을 테스트셋으로 하고 나머지 9개 데이터셋 모델을 만든다.\n서브셋1에서 모델 테스트, AUROC 계산\n훈련 데이터로 서브셋2 테스트 사용, AUROC 계산\n… 10회 반복 \\(\\to\\) AUROC 10개 값 \\(\\to\\) 평균계산\n\n- 합성데이터와 실제 데이터에 대한 대응 모델에 대한 계산\n- 두 AUROC값의 절대적 차이 계산\n- 모든 절대값 차이에 대한 상자 그림 생성\n- 경향점수.. (어렵… 103p)\n\n\n\n- 방법\n\n정규분포로부터 샘플링\n샘플링 프로세스 중 상관관계 유도\n코퓰러 사용\n\n- 코퓰러?\n\n확률변수들 간의 상관관계 또는 종속성을 나타내는 함수\n흠.. 나중에 찾아보자..\n\n- 머신러닝 방법 - 의사결정 트리(CART) 사용\n- 딥러닝 방법 - 변이형 오토인코더(VAE) - 생성적 적대 신경망(GAN)\n- GAN - 생성기: 입력 무작위 데이터, 정규 분포 또는 균일 분포로부터 샘플링하며 합성 데이터 생성 - 판별기: 합성 데이터와 실제 데이터 비교하여 유사한 경향 점수 생성 차이 결과를 생성 기 훈련을 위해 다시 제공\n\n\n\n\n노출 유형\n신원 노출(정보 이득이 0이라면 신원 노출에 아무런 의미가 없음)\n속성 노출"
  },
  {
    "objectID": "posts/Review/Practical Synthetic Data Generation.html#data",
    "href": "posts/Review/Practical Synthetic Data Generation.html#data",
    "title": "Practical Synthetic Data Generation",
    "section": "data",
    "text": "data\n\nfrom sdmetrics import load_demo \n\nreal_data, synthetic_data, metadata = load_demo(modality='single_table')\n\n\nmetadata\n\n{'fields': {'start_date': {'type': 'datetime', 'format': '%Y-%m-%d'},\n  'end_date': {'type': 'datetime', 'format': '%Y-%m-%d'},\n  'salary': {'type': 'numerical', 'subtype': 'integer'},\n  'duration': {'type': 'numerical', 'subtype': 'integer'},\n  'student_id': {'type': 'id', 'subtype': 'integer'},\n  'high_perc': {'type': 'numerical', 'subtype': 'float'},\n  'high_spec': {'type': 'categorical'},\n  'mba_spec': {'type': 'categorical'},\n  'second_perc': {'type': 'numerical', 'subtype': 'float'},\n  'gender': {'type': 'categorical'},\n  'degree_perc': {'type': 'numerical', 'subtype': 'float'},\n  'placed': {'type': 'boolean'},\n  'experience_years': {'type': 'numerical', 'subtype': 'float'},\n  'employability_perc': {'type': 'numerical', 'subtype': 'float'},\n  'mba_perc': {'type': 'numerical', 'subtype': 'float'},\n  'work_experience': {'type': 'boolean'},\n  'degree_type': {'type': 'categorical'}},\n 'constraints': [],\n 'model_kwargs': {},\n 'name': None,\n 'primary_key': 'student_id',\n 'sequence_index': None,\n 'entity_columns': [],\n 'context_columns': []}\n\n\n\nreal_data.head()\n\n\n\n\n\n  \n    \n      \n      student_id\n      gender\n      second_perc\n      high_perc\n      high_spec\n      degree_perc\n      degree_type\n      work_experience\n      experience_years\n      employability_perc\n      mba_spec\n      mba_perc\n      salary\n      placed\n      start_date\n      end_date\n      duration\n    \n  \n  \n    \n      0\n      17264\n      M\n      67.00\n      91.00\n      Commerce\n      58.00\n      Sci&Tech\n      False\n      0\n      55.0\n      Mkt&HR\n      58.80\n      27000.0\n      True\n      2020-07-23\n      2020-10-12\n      3.0\n    \n    \n      1\n      17265\n      M\n      79.33\n      78.33\n      Science\n      77.48\n      Sci&Tech\n      True\n      1\n      86.5\n      Mkt&Fin\n      66.28\n      20000.0\n      True\n      2020-01-11\n      2020-04-09\n      3.0\n    \n    \n      2\n      17266\n      M\n      65.00\n      68.00\n      Arts\n      64.00\n      Comm&Mgmt\n      False\n      0\n      75.0\n      Mkt&Fin\n      57.80\n      25000.0\n      True\n      2020-01-26\n      2020-07-13\n      6.0\n    \n    \n      3\n      17267\n      M\n      56.00\n      52.00\n      Science\n      52.00\n      Sci&Tech\n      False\n      0\n      66.0\n      Mkt&HR\n      59.43\n      NaN\n      False\n      NaT\n      NaT\n      NaN\n    \n    \n      4\n      17268\n      M\n      85.80\n      73.60\n      Commerce\n      73.30\n      Comm&Mgmt\n      False\n      0\n      96.8\n      Mkt&Fin\n      55.50\n      42500.0\n      True\n      2020-07-04\n      2020-09-27\n      3.0\n    \n  \n\n\n\n\n\nsynthetic_data.head()\n\n\n\n\n\n  \n    \n      \n      student_id\n      gender\n      second_perc\n      high_perc\n      high_spec\n      degree_perc\n      degree_type\n      work_experience\n      experience_years\n      employability_perc\n      mba_spec\n      mba_perc\n      salary\n      placed\n      start_date\n      end_date\n      duration\n    \n  \n  \n    \n      0\n      0\n      F\n      41.361060\n      85.425072\n      Commerce\n      74.972674\n      Comm&Mgmt\n      False\n      0\n      49.986653\n      Mkt&Fin\n      57.291083\n      NaN\n      True\n      2020-02-11\n      2020-08-02\n      3.0\n    \n    \n      1\n      1\n      M\n      63.720169\n      99.059033\n      Commerce\n      62.769650\n      Others\n      False\n      0\n      78.962948\n      Mkt&HR\n      79.068319\n      NaN\n      False\n      NaT\n      NaT\n      NaN\n    \n    \n      2\n      2\n      M\n      58.473884\n      89.241528\n      Science\n      83.066328\n      Sci&Tech\n      True\n      0\n      47.980244\n      Mkt&Fin\n      77.042950\n      26727.0\n      True\n      2020-02-13\n      2020-05-27\n      3.0\n    \n    \n      3\n      3\n      F\n      77.232204\n      100.523788\n      Commerce\n      61.010445\n      Comm&Mgmt\n      True\n      0\n      61.016218\n      Mkt&HR\n      68.132991\n      22058.0\n      True\n      2020-09-24\n      2020-11-07\n      3.0\n    \n    \n      4\n      4\n      F\n      54.067830\n      109.611537\n      Commerce\n      72.846753\n      Others\n      True\n      0\n      66.949987\n      Mkt&Fin\n      66.363138\n      NaN\n      False\n      NaT\n      NaT\n      NaN\n    \n  \n\n\n\n\n\nfrom sdmetrics.reports.single_table import QualityReport\n\nreport = QualityReport()\nreport.generate(real_data, synthetic_data, metadata)\n\nCreating report: 100%|██████████| 4/4 [00:00<00:00, 12.97it/s]\n\n\n\nOverall Quality Score: 81.44%\n\nProperties:\nColumn Shapes: 81.56%\nColumn Pair Trends: 81.33%\n\n\n\nreport.get_details(property_name='Column Shapes')\n\n\n\n\n\n  \n    \n      \n      Column\n      Metric\n      Quality Score\n    \n  \n  \n    \n      0\n      second_perc\n      KSComplement\n      0.627907\n    \n    \n      1\n      high_perc\n      KSComplement\n      0.553488\n    \n    \n      2\n      degree_perc\n      KSComplement\n      0.627907\n    \n    \n      3\n      experience_years\n      KSComplement\n      0.800000\n    \n    \n      4\n      employability_perc\n      KSComplement\n      0.781395\n    \n    \n      5\n      mba_perc\n      KSComplement\n      0.841860\n    \n    \n      6\n      salary\n      KSComplement\n      0.869155\n    \n    \n      7\n      start_date\n      KSComplement\n      0.701107\n    \n    \n      8\n      end_date\n      KSComplement\n      0.768919\n    \n    \n      9\n      duration\n      KSComplement\n      0.826051\n    \n    \n      10\n      gender\n      TVComplement\n      0.939535\n    \n    \n      11\n      high_spec\n      TVComplement\n      0.902326\n    \n    \n      12\n      degree_type\n      TVComplement\n      0.925581\n    \n    \n      13\n      work_experience\n      TVComplement\n      0.972093\n    \n    \n      14\n      mba_spec\n      TVComplement\n      0.995349\n    \n    \n      15\n      placed\n      TVComplement\n      0.916279\n    \n  \n\n\n\n\n\n시각화\n\nreport.get_visualization(property_name='Column Shapes')\n\n\n                                                \n\n\n- high Quality\n\nget_column_plot?\n\n\n\nSignature: get_column_plot(real_data, synthetic_data, column_name, metadata)\nDocstring:\nReturn a plot of the real and synthetic data for a given column.\nArgs:\n    real_data (pandas.DataFrame):\n        The real table data.\n    synthetic_data (pandas.DataFrame):\n        The synthetic table data.\n    column_name (str):\n        The name of the column.\n    metadata (dict):\n        The table metadata.\nReturns:\n    plotly.graph_objects._figure.Figure\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/sdmetrics/reports/utils.py\nType:      function\n\n\n\n\n\nfrom sdmetrics.reports.utils import get_column_plot\n\nfig = get_column_plot(\n    real_data=real_data,\n    synthetic_data=synthetic_data,\n    metadata=metadata,\n    column_name='mba_spec'\n)\n\nfig.show()\n\n\n                                                \n\n\n- low Quality\n\nfrom sdmetrics.reports.utils import get_column_plot\n\nfig = get_column_plot(\n    real_data=real_data,\n    synthetic_data=synthetic_data,\n    metadata=metadata,\n    column_name='second_perc'\n)\n\nfig.show()\n\n\n                                                \n\n\n\nreport.get_visualization(property_name='Column Pair Trends')\n\n\n                                                \n\n\n\nfrom sdmetrics.reports.utils import get_column_pair_plot\n\n\nget_column_pair_plot?\n\n\n\nSignature: get_column_pair_plot(real_data, synthetic_data, column_names, metadata)\nDocstring:\nReturn a plot of the real and synthetic data for a given column pair.\nArgs:\n    real_data (pandas.DataFrame):\n        The real table data.\n    synthetic_column (pandas.Dataframe):\n        The synthetic table data.\n    column_names (list[string]):\n        The names of the two columns to plot.\n    metadata (dict):\n        The table metadata.\nReturns:\n    plotly.graph_objects._figure.Figure\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/sdmetrics/reports/utils.py\nType:      function\n\n\n\n\n\nfig = get_column_pair_plot(\n    real_data=real_data,\n    synthetic_data=synthetic_data,\n    metadata=metadata,\n    column_names=['start_date', 'second_perc']\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\n데이터 보고서 형태로 저장\nreport.save(filepath='sdmetrics_quality_demo.pkl')\n\n# load the report at a later time\nreport = QualityReport.load(filepath='sdmetrics_quality_demo.pkl')"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Boram-coco",
    "section": "",
    "text": "Everyday with Coco"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "coco",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2023\n\n\nRef\n\n\n김보람\n\n\n\n\nMar 10, 2023\n\n\nPractical Synthetic Data Generation\n\n\n김보람\n\n\n\n\nDec 21, 2022\n\n\n기계학습 (1221)\n\n\n김보람\n\n\n\n\nDec 14, 2022\n\n\n기계학습 final\n\n\n김보람\n\n\n\n\nDec 1, 2022\n\n\n기계학습 (1201)\n\n\n김보람\n\n\n\n\nNov 30, 2022\n\n\n기계학습 (1130) 12주차\n\n\n김보람\n\n\n\n\nNov 30, 2022\n\n\nDV 13주차(2)\n\n\n김보람\n\n\n\n\nNov 29, 2022\n\n\n기계학습 final(교수님)\n\n\n최규빈\n\n\n\n\nNov 28, 2022\n\n\nDV 13주차(1)\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n6: K-beauty\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n5: 건강검진 데이터로 가설검정\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n4: 서울 종합병원 분포 확인하기\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n3: 데이터 분석 준비하기\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n2: file-path-setting\n\n\n김보람\n\n\n\n\nNov 24, 2022\n\n\n1: 주피터 노트북 사용법\n\n\n김보람\n\n\n\n\nNov 21, 2022\n\n\nDV 12주차\n\n\n김보람\n\n\n\n\nNov 16, 2022\n\n\n기계학습 (1116) 11주차\n\n\n김보람\n\n\n\n\nNov 16, 2022\n\n\nDV 11주차(2)\n\n\n김보람\n\n\n\n\nNov 14, 2022\n\n\nDV 11주차(1)\n\n\n김보람\n\n\n\n\nNov 9, 2022\n\n\n기계학습 (1109) 10주차\n\n\n김보람\n\n\n\n\nNov 9, 2022\n\n\nDV 10주차(2)\n\n\n김보람\n\n\n\n\nNov 7, 2022\n\n\nDV 10주차(1)\n\n\n김보람\n\n\n\n\nNov 2, 2022\n\n\nDV 9주차\n\n\n김보람\n\n\n\n\nOct 31, 2022\n\n\n기계학습 (1031) 9주차\n\n\n김보람\n\n\n\n\nOct 26, 2022\n\n\n기계학습 midterm\n\n\n김보람\n\n\n\n\nOct 26, 2022\n\n\n기계학습 (1026) 8주차\n\n\n김보람\n\n\n\n\nOct 24, 2022\n\n\nDV 8주차\n\n\n김보람\n\n\n\n\nOct 19, 2022\n\n\n기계학습 (1019) 7주차\n\n\n김보람\n\n\n\n\nOct 19, 2022\n\n\nDV 7주차(2)\n\n\n김보람\n\n\n\n\nOct 17, 2022\n\n\nDV 7주차(1)\n\n\n김보람\n\n\n\n\nOct 12, 2022\n\n\n기계학습 (1012) 6주차\n\n\n김보람\n\n\n\n\nOct 12, 2022\n\n\nDV 6주차\n\n\n김보람\n\n\n\n\nOct 6, 2022\n\n\nDV 5주차(2)\n\n\n김보람\n\n\n\n\nOct 5, 2022\n\n\n기계학습 (1005) 5주차\n\n\n김보람\n\n\n\n\nOct 5, 2022\n\n\nDV 5주차(1)\n\n\n김보람\n\n\n\n\nSep 28, 2022\n\n\n기계학습 (0928) 4주차\n\n\n김보람\n\n\n\n\nSep 28, 2022\n\n\nDV 4주차(2)\n\n\n김보람\n\n\n\n\nSep 26, 2022\n\n\nDV 4주차(1)\n\n\n김보람\n\n\n\n\nSep 21, 2022\n\n\n기계학습 (0921) 3주차\n\n\n김보람\n\n\n\n\nSep 21, 2022\n\n\nDV 3주차(2)\n\n\n김보람\n\n\n\n\nSep 19, 2022\n\n\nDV 3주차(1)\n\n\n김보람\n\n\n\n\nSep 14, 2022\n\n\n기계학습 (0914) 2주차\n\n\n김보람\n\n\n\n\nSep 14, 2022\n\n\nDV 2주차\n\n\n김보람\n\n\n\n\nSep 7, 2022\n\n\n기계학습 (0907) 1주차\n\n\n김보람\n\n\n\n\nSep 5, 2022\n\n\nDV 1주차\n\n\n김보람\n\n\n\n\nJun 6, 2022\n\n\n파이썬 (0606) 14주차\n\n\n김보람\n\n\n\n\nMay 30, 2022\n\n\n파이썬 (0530) 13주차\n\n\n김보람\n\n\n\n\nMay 25, 2022\n\n\n파이썬 (0525) 13주차\n\n\n김보람\n\n\n\n\nMay 23, 2022\n\n\n파이썬 (0523) 12주차\n\n\n김보람\n\n\n\n\nMay 18, 2022\n\n\n파이썬 (0518) 12주차\n\n\n김보람\n\n\n\n\nMay 16, 2022\n\n\n파이썬 (0516) 11주차\n\n\n김보람\n\n\n\n\nMay 11, 2022\n\n\n파이썬 (0511) 11주차\n\n\n김보람\n\n\n\n\nMay 9, 2022\n\n\n파이썬 (0509) 10주차\n\n\n김보람\n\n\n\n\nMay 6, 2022\n\n\n파이썬 (0506) 10주차\n\n\n김보람\n\n\n\n\nApr 18, 2022\n\n\n파이썬 (0418) 7주차\n\n\n김보람\n\n\n\n\nApr 13, 2022\n\n\n파이썬 (0413) 7주차\n\n\n김보람\n\n\n\n\nApr 11, 2022\n\n\n파이썬 (0411) 6주차\n\n\n김보람\n\n\n\n\nApr 6, 2022\n\n\n파이썬 (0406) 5주차\n\n\n김보람\n\n\n\n\nApr 4, 2022\n\n\n파이썬 (0404) 5주차\n\n\n김보람\n\n\n\n\nMar 28, 2022\n\n\n파이썬 (0328) 4주차\n\n\n김보람\n\n\n\n\nMar 23, 2022\n\n\n파이썬 (0323) 4주차\n\n\n김보람\n\n\n\n\nMar 21, 2022\n\n\n파이썬 (0321) 3주차\n\n\n김보람\n\n\n\n\nMar 16, 2022\n\n\n파이썬 (0316) 3주차\n\n\n김보람\n\n\n\n\nMar 14, 2022\n\n\n파이썬 (0314) 2주차\n\n\n김보람\n\n\n\n\nMar 7, 2022\n\n\n파이썬 (0307) 1주차\n\n\n김보람\n\n\n\n\n\n\nNo matching items"
  }
]