{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CH8. 신용카드 거래 분석(로지스틱+그래프)\n",
        "\n",
        "김보람  \n",
        "2023-04-27"
      ],
      "id": "8e59d906-b03b-4636-9447-a3405ec84130"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "default_edge_color = 'gray'\n",
        "default_node_color = '#407cc9'\n",
        "enhanced_node_color = '#f5b042'\n",
        "enhanced_edge_color = '#cc2f04'"
      ],
      "id": "70217bdd-39ac-4000-b33e-8fca4d634ccd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# df"
      ],
      "id": "9f735e29-eff4-4100-b7a8-4adad4d0c517"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"fraudTrain.csv\")\n",
        "df = df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42).append(df[df[\"is_fraud\"] == 1])\n",
        "df.head()"
      ],
      "id": "684974fd-9c59-4721-a371-2bf29b0197ea"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"is_fraud\"].value_counts()"
      ],
      "id": "718e5ab6-7124-4a0b-9da9-ca7f107e42a6"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
        "    df=df_input.copy()\n",
        "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
        "                                                      df[\"merchant\"].values.tolist()))}\n",
        "    \n",
        "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
        "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
        "    \n",
        "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
        "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
        "    \n",
        "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
        "    \n",
        "    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n",
        "    \n",
        "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
        "\n",
        "    return G"
      ],
      "id": "a7526b45-9dc8-4d80-a3af-1569fe6421ad"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    6006\n",
            "0    6006\n",
            "Name: is_fraud, dtype: int64"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df.is_fraud==0]\n",
        "df_minority = df[df.is_fraud==1]\n",
        "\n",
        "df_maj_dowsampled = resample(df_majority,\n",
        "                             n_samples=len(df_minority),\n",
        "                             random_state=42)\n",
        "\n",
        "df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n",
        "\n",
        "print(df_downsampled.is_fraud.value_counts())\n",
        "G_down = build_graph_bipartite(df_downsampled)"
      ],
      "id": "deb20eec-5a09-4d01-ae88-d9e2cd5c1c6e"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
        "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
        "                                                                      test_size=0.30, \n",
        "                                                                      random_state=42)"
      ],
      "id": "9921b5c7-7d98-4ef4-ba91-254d79c7fa8a"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "edgs = list(G_down.edges)\n",
        "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
        "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))"
      ],
      "id": "50814a7e-f393-4245-a8df-1c09ce4b912c"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from node2vec import Node2Vec\n",
        "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
        "\n",
        "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
        "model_train = node2vec_train.fit(window=10)"
      ],
      "id": "284a59f2-10de-4d2e-ba7f-d56edcaa3983"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \\_df2"
      ],
      "id": "6439202a-983c-4107-a7bb-229992c1adec"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "cus_list = set(_df.query('is_fraud==1').cc_num.tolist())\n",
        "_df2 = _df.query(\"cc_num in @ cus_list\")\n",
        "_df2 = _df2.assign(time= list(map(lambda x: int(x.split(' ')[-1].split(':')[0]), _df2['trans_date_trans_time'])))"
      ],
      "id": "5c580b86-81c7-4abb-8a97-94150569615c"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "_df2[\"is_fraud\"].value_counts()"
      ],
      "id": "10d8945f-8bea-45ad-bbc1-492e303adba3"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = _df2 "
      ],
      "id": "ba76f9d7-f01a-400b-b3f5-ab9dfc903c40"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_graph_bipartite2(df_input, graph_type=nx.Graph()):\n",
        "    df=df_input.copy()\n",
        "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
        "                                                      df[\"merchant\"].values.tolist()))}\n",
        "    \n",
        "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
        "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
        "    \n",
        "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
        "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
        "    \n",
        "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
        "    \n",
        "    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n",
        "    \n",
        "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
        "\n",
        "    return G"
      ],
      "id": "a6e52adb-6ce7-44e9-ba66-e30112067e60"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    6006\n",
            "0    6006\n",
            "Name: is_fraud, dtype: int64"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df.is_fraud==0]\n",
        "df_minority = df[df.is_fraud==1]\n",
        "\n",
        "df_maj_dowsampled2 = resample(df_majority,\n",
        "                             n_samples=len(df_minority),\n",
        "                             random_state=42)\n",
        "\n",
        "df_downsampled2 = pd.concat([df_minority, df_maj_dowsampled])\n",
        "\n",
        "print(df_downsampled2.is_fraud.value_counts())\n",
        "G_down2 = build_graph_bipartite(df_downsampled2)"
      ],
      "id": "090182d4-4639-445a-a138-cfa6715995cd"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_edges2, test_edges2, train_labels2, test_labels2 = train_test_split(list(range(len(G_down2.edges))), \n",
        "                                                                      list(nx.get_edge_attributes(G_down2, \"label\").values()), \n",
        "                                                                      test_size=0.30, \n",
        "                                                                      random_state=42)"
      ],
      "id": "b6aadafc-93fa-4582-9f59-b4501daeff76"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "edgs2 = list(G_down2.edges)\n",
        "train_graph2 = G_down2.edge_subgraph([edgs[x] for x in train_edges2]).copy()\n",
        "train_graph2.add_nodes_from(list(set(G_down2.nodes) - set(train_graph2.nodes)))"
      ],
      "id": "676f09ee-6620-48d6-8a32-8f2db2a6a1dc"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "node2vec_train2 = Node2Vec(train_graph2, weight_key='weight')\n",
        "model_train2 = node2vec_train2.fit(window=10)"
      ],
      "id": "c664f518-d4cd-4c7d-9c58-c25aaabe23d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# traing(graph), test(logistic)"
      ],
      "id": "c8199747-9752-4976-a027-c04482966f3d"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'node2vec.edges.HadamardEmbedder'>\n",
            "Precision: 0.6554307116104869\n",
            "Recall: 0.09599561162918267\n",
            "F1-Score: 0.16746411483253587\n",
            "<class 'node2vec.edges.AverageEmbedder'>\n",
            "Precision: 0.7195710455764075\n",
            "Recall: 0.7361492046077893\n",
            "F1-Score: 0.7277657266811279\n",
            "<class 'node2vec.edges.WeightedL1Embedder'>\n",
            "Precision: 0.4666666666666667\n",
            "Recall: 0.01151947339550192\n",
            "F1-Score: 0.022483940042826552\n",
            "<class 'node2vec.edges.WeightedL2Embedder'>\n",
            "Precision: 0.5319148936170213\n",
            "Recall: 0.013713658804168952\n",
            "F1-Score: 0.026737967914438502"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn import metrics \n",
        "\n",
        "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
        "for cl in classes:\n",
        "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
        "\n",
        "    train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
        "    test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges2]\n",
        "    \n",
        "    rf = RandomForestClassifier(n_estimators=1000, random_state=42) \n",
        "    rf.fit(train_embeddings, train_labels); \n",
        "\n",
        "    y_pred2 = rf.predict(test_embeddings)\n",
        "    print(cl)\n",
        "    print('Precision:', metrics.precision_score(test_labels, y_pred2)) \n",
        "    print('Recall:', metrics.recall_score(test_labels, y_pred2)) \n",
        "    print('F1-Score:', metrics.f1_score(test_labels, y_pred2)) "
      ],
      "id": "6b4684f0-41cb-4b6a-b73e-8a10ddbe39ef"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  }
}