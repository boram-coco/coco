{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CH8. 신용카드 거래에 대한 그래프 분석(교수님)\n",
        "\n",
        "김보람  \n",
        "2023-04-28\n",
        "\n",
        "## imports"
      ],
      "id": "bc9bc101-edcb-431c-ab40-7c344070a813"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import sklearn\n",
        "\n",
        "# split \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# embedding \n",
        "from node2vec import Node2Vec\n",
        "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
        "\n",
        "# models \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "\n",
        "# 평가 \n",
        "from sklearn import metrics \n"
      ],
      "id": "899f5545-1e46-4d42-97a6-d4f41a1980d6"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
        "    df=df_input.copy()\n",
        "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
        "                                                      df[\"merchant\"].values.tolist()))}\n",
        "    \n",
        "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
        "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
        "    \n",
        "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
        "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
        "    \n",
        "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
        "    \n",
        "    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n",
        "    \n",
        "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
        "\n",
        "    return G\n",
        "\n",
        "def down_sample_textbook(df):\n",
        "    df = df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42).append(df[df[\"is_fraud\"] == 1])\n",
        "    df_majority = df[df.is_fraud==0]\n",
        "    df_minority = df[df.is_fraud==1]\n",
        "    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), random_state=42)\n",
        "    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n",
        "    return df_downsampled\n",
        "\n",
        "def split(Graph,test_size=0.20,random_state=42):\n",
        "    edg = list(range(len(Graph.edges))) \n",
        "    edg_att = list(nx.get_edge_attributes(Graph, \"label\").values())\n",
        "    return train_test_split(edg,edg_att,test_size=test_size,random_state=random_state) \n",
        "\n",
        "def embedding(Graph):\n",
        "    _edgs = list(Graph.edges)\n",
        "    _train_edges, _test_edges, y, yy = split(Graph)\n",
        "    _train_graph = Graph.edge_subgraph([_edgs[x] for x in _train_edges]).copy()\n",
        "    _train_graph.add_nodes_from(list(set(Graph.nodes) - set(_train_graph.nodes)))\n",
        "    _embedded = AverageEmbedder(Node2Vec(_train_graph, weight_key='weight').fit(window=10).wv)\n",
        "    X = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _train_edges]\n",
        "    XX = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _test_edges]\n",
        "    return X,XX,y,yy \n",
        "\n",
        "def evaluate(lrnr,XX,yy):\n",
        "    yyhat = lrnr.predict(XX)\n",
        "    df = pd.DataFrame({'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n",
        "                  'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n",
        "                  'f1':[sklearn.metrics.f1_score(yy,yyhat)]})\n",
        "    return df \n",
        "\n",
        "def anal(df,n_estimators=10):\n",
        "    Graph = build_graph_bipartite(df)\n",
        "    X,XX,y,yy = embedding(Graph)\n",
        "    lrnr = RandomForestClassifier(n_estimators=n_estimators, random_state=42) \n",
        "    lrnr.fit(X,y)\n",
        "    return lrnr, XX,yy, evaluate(lrnr,XX,yy)\n",
        "\n",
        "def our_sampling1(df):\n",
        "    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n",
        "    return df.query(\"cc_num in @ cus_list\")"
      ],
      "id": "ad688491-89ce-4f1e-a848-b6adcdea37bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# data1\n",
        "\n",
        "## read and define data"
      ],
      "id": "39d5888f-ff70-4c65-b49a-c729b88bbd08"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
      ],
      "id": "5ff6f459-ddcc-4e40-8aff-f274cc99620a"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_downsampled = down_sample_textbook(df)"
      ],
      "id": "0e8d498f-97da-4442-8272-7bf7637e3917"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## embedding"
      ],
      "id": "0374043a-64a4-4acb-a763-034eb525218e"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#G_down = build_graph_bipartite(df_downsampled)"
      ],
      "id": "f87e5ee8-80ae-479e-a0fd-ddcdef0f1d53"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X,XX,y,yy = embedding(G_down)"
      ],
      "id": "cb9633ac-295f-40c8-b92c-6889a5486975"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## learn"
      ],
      "id": "495c2c57-5f80-4045-8546-e366983d4f88"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lrnr = RandomForestClassifier(n_estimators=10, random_state=42) \n",
        "# lrnr.fit(X,y)"
      ],
      "id": "51b33ad3-b39f-4c08-b512-5378b3000442"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## evaluate"
      ],
      "id": "3fe3866f-548e-456a-8f44-f5e5b16a8cf1"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate(lrnr,XX,yy)"
      ],
      "id": "c0a335c8-7687-40e1-868d-b620f19f8745"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# data1 : 다른코드"
      ],
      "id": "0dc79dab-b4ea-4695-9fb1-58c6b04b9d66"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "lrnr1, XX_textbook, yy_texbook, results = anal(down_sample_textbook(df),n_estimators=100)"
      ],
      "id": "d54feaa8-cabf-418b-a4af-a3adc928f91f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# data2\n",
        "\n",
        "## read and define data"
      ],
      "id": "74889a3e-895d-4f13-b0f1-85ab3f9a485c"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]Generating walks (CPU: 1): 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")\n",
        "lrnr2, _,_,_ = anal(down_sample_textbook(our_sampling1(df)),n_estimators=100)"
      ],
      "id": "eeadbb6e-e96f-4627-aca0-d93d5ebd26d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# textbook vs proposed"
      ],
      "id": "21407468-7772-43ba-8efb-1f10b66d0f0c"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "yyhat_textbook = lrnr1.predict(XX_textbook)\n",
        "yyhat_proposed = lrnr2.predict(XX_textbook)"
      ],
      "id": "9c8800b3-c27f-4498-9ccc-0c3008556f63"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(lrnr1, XX_textbook,yy_texbook)"
      ],
      "id": "445f21ee-072f-4ab9-b8e5-268260dea419"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(lrnr2, XX_textbook,yy_texbook)"
      ],
      "id": "28d36c39-5843-4cfc-87ba-136a4c4e6223"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# appedix\n",
        "\n",
        "김보람 ref -\n",
        "https://boram-coco.github.io/coco/posts/Graph%20Machine%20Learning/graph8.html\n",
        "\n",
        "데이터: df - “~/Desktop/fraudTrain.csv” // (214520, 23) // 여기에서\n",
        "214520은 전체에서 0.2%의 비율로 sampled 된 자료임\n",
        "\n",
        "-   \n",
        "\n",
        "-   obs: 거래건수\n",
        "\n",
        "-   var: cc_num(userid), store, 사기유무, 시간, 지역, amt, …\n",
        "\n",
        "-   y: 사기유무\n",
        "\n",
        "-   x:\n",
        "\n",
        "목적: 사기거래 y==1을 찾는 것\n",
        "\n",
        "교재의 방법\n",
        "\n",
        "def build_graph_bipartite\n",
        "\n",
        "    1. df를 변형하여 from, to를 만든다. from은 출발점 / to는 도착점 \n",
        "\n",
        "    2. df에서 from,to,amt,is_fraud를 선택하여 (from,to)로 그룹핑 => is_fraud 와 amt 의 sum을 계산 \n",
        "\n",
        "    3. sum(is_fraud) > 0 일경우 is_fraud=1 로 설정 \n",
        "\n",
        "    4. 노드들의 집합= {고객1,고객2,...고객m, 상점1,상점2,...,상점k} => 1632의 노드가 있음 즉 m+k=1632 \n",
        "\n",
        "    5. 고객-상점 간의 사기가 있으면 엣지를 1로 설정, 그렇지 않으면 0으로 설정 \n",
        "\n",
        "    6. 엣지가1인 경우 amt를 weight로 설정 \n",
        "\n",
        "**main code**\n",
        "\n",
        "1.  df load\n",
        "\n",
        "2.  df -\\> df_downsampled\n",
        "\n",
        "3.  G = build_graph_bipartite(df_downsampled)\n",
        "\n",
        "4.  tr_edg, test_edg, tr_lable, test_label = split(G)\n",
        "\n",
        "5."
      ],
      "id": "c021fa02-1807-4c0f-b408-9f7ea25f6ce3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  }
}