{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \\[FRAUD\\] 데이터 (9.13_df50 edge다르게)\n",
        "\n",
        "김보람  \n",
        "2023-09-13\n",
        "\n",
        "# imports"
      ],
      "id": "2db56cfc-094a-4639-acb7-80c5dcc533c5"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import networkx as nx\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "\n",
        "# sklearn\n",
        "from sklearn import model_selection # split함수이용\n",
        "from sklearn import ensemble # RF,GBM\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# embedding \n",
        "from node2vec import Node2Vec\n",
        "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
        "\n",
        "# gnn\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "id": "c36d6b17-9b4c-4aea-b111-133e1afce57e"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
        "    df=df_input.copy()\n",
        "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
        "                                                      df[\"merchant\"].values.tolist()))}\n",
        "    \n",
        "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
        "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
        "    \n",
        "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
        "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
        "    \n",
        "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
        "    \n",
        "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n",
        "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n",
        "    df=df_input.copy()\n",
        "    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n",
        "                                                       df[\"cc_num\"].values.tolist() +\n",
        "                                                       df[\"merchant\"].values.tolist()))}\n",
        "    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n",
        "    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n",
        "    \n",
        "        \n",
        "    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n",
        "                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n",
        "    \n",
        "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n",
        "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n",
        "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n",
        "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
        "\n",
        "    return G\n",
        "    \n",
        "    \n",
        "def down_sample_textbook(df):\n",
        "    df_majority = df[df.is_fraud==0].copy()\n",
        "    df_minority = df[df.is_fraud==1].copy()\n",
        "    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n",
        "    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n",
        "    return df_downsampled\n",
        "\n",
        "def embedding(Graph):\n",
        "    # Graph -> X (feature)\n",
        "    _edgs = list(Graph.edges)\n",
        "    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n",
        "    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n",
        "    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n",
        "    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n",
        "    # Graph -> y (label)\n",
        "    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n",
        "    return X,y \n",
        "\n",
        "def anal(df):\n",
        "    Graph = build_graph_bipartite(df)\n",
        "    X,XX,y,yy = embedding(Graph)\n",
        "    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n",
        "    lrnr.fit(X,y)\n",
        "    yyhat = lrnr.predict(XX)\n",
        "    df = pd.DataFrame({\n",
        "        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n",
        "        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n",
        "        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n",
        "        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n",
        "    )    \n",
        "    return df\n",
        "\n",
        "def our_sampling1(df):\n",
        "    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n",
        "    return df.query(\"cc_num in @ cus_list\")"
      ],
      "id": "2774d96b-b24a-492b-a587-2815ff6e3ead"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "fraudTrain = pd.read_csv(\"~/Desktop/fraudTrain.csv\").iloc[:,1:]"
      ],
      "id": "7021dc07-8a06-417b-9fb6-c71b2f05e5eb"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "fraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))\n",
        "fraudTrain"
      ],
      "id": "eb7a9b2b-f984-4bb0-b14b-e523a00d8d38"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GNN시도"
      ],
      "id": "1fe3d081-5cc0-4f71-a9a3-25105dcde540"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n",
        "_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\n",
        "df02 = pd.concat([_df1,_df2])\n",
        "df02.shape"
      ],
      "id": "adec4c87-7a49-41dd-ba04-879643113486"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df50 = down_sample_textbook(df02)\n",
        "df50.shape"
      ],
      "id": "b1eab03c-9ee2-45e1-95a5-923642e8ce6f"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df50 = df50.reset_index()"
      ],
      "id": "4f3c12b1-433f-41ac-85c0-c42ae389ba60"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = len(df50)"
      ],
      "id": "7cef7094-bd9b-43d1-a1c9-d4b1c9b4241c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### tr/test"
      ],
      "id": "5a9ad4b6-d84e-4917-a24a-025a6d7ca1fe"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)"
      ],
      "id": "1746ec92-50c0-402d-8297-92cb67c718d5"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df50_tr.shape, df50_test.shape"
      ],
      "id": "ba8e5c8a-e54e-4982-b4db-4e89f5239dfa"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_mask = [i in df50_tr.index for i in range(N)]\n",
        "test_mask = [i in df50_test.index for i in range(N)]"
      ],
      "id": "96e898a3-0f22-4e14-9c7b-96aac384fbeb"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_mask = np.array(train_mask)\n",
        "test_mask = np.array(test_mask)"
      ],
      "id": "e3b4a6c0-ae78-4601-9684-2eb876661e36"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_mask.sum(), test_mask.sum()"
      ],
      "id": "d7749396-dfc0-401f-8e05-b34693fc585a"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_mask.shape, test_mask.shape"
      ],
      "id": "2c792d09-7f9b-413c-91c0-a1e6cf6ddac4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### edge_index 설정"
      ],
      "id": "c7860146-bdb7-408c-8e86-b0403a930e98"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_time_difference(group):\n",
        "    n = len(group)\n",
        "    result = []\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n",
        "            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
        "    return result"
      ],
      "id": "92d681a1-c481-4511-a240-5a3f510fa3ee"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = df50.groupby('cc_num')\n",
        "edge_index_list_plus = [compute_time_difference(group) for _, group in groups]\n",
        "edge_index_list_plus_flat = [item for sublist in edge_index_list_plus for item in sublist]\n",
        "edge_index_list_plus_nparr = np.array(edge_index_list_plus_flat)\n",
        "np.save('edge_index_list_plus50.npy', edge_index_list_plus_nparr)"
      ],
      "id": "1982a2c2-0a55-4947-baf7-879e6c82a129"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# edge_index_list_plus = []\n",
        "# for i in range(N):\n",
        "#     for j in range(N):\n",
        "#         if df50['cc_num'][i] != df50['cc_num'][j]:  # cc_num 값이 다르다면\n",
        "#             time_difference = 0\n",
        "#         else:\n",
        "#             time_difference = (df50['trans_date_trans_time'][i] - df50['trans_date_trans_time'][j]).total_seconds()\n",
        "#         edge_index_list_plus.append([i, j, time_difference])\n",
        "#         np.save('edge_index_list_plus50.npy', edge_index_list_plus)\n",
        "\n",
        "# # edge_index_list_plus = np.load('edge_index_list_plus.npy')"
      ],
      "id": "eeb4f371-48cf-400a-9284-b7907d1f4cc4"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index = np.array(edge_index_list_plus_nparr)"
      ],
      "id": "401e1bf6-6f52-4461-aac1-1e2087a28e99"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index.shape"
      ],
      "id": "dc0d3e59-8e9b-4d87-bb22-bcd5be0eb22d"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight = (np.exp(-edge_index[:,2]/theta) != 1)*(np.exp(-edge_index[:,2]/theta))\n",
        "weight"
      ],
      "id": "fa4c5374-7638-47f3-ad7b-88ab34c99b6e"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index = np.column_stack((edge_index, weight))\n",
        "edge_index = np.delete(edge_index, 2, axis=1)"
      ],
      "id": "a2c5adae-3eed-48de-9683-d5989f09326d"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index"
      ],
      "id": "e69d317a-ce92-469e-af36-76e28e6a4c8a"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index.shape"
      ],
      "id": "b1a4b7e0-0c12-4989-8a5b-ccb3aaac8266"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_index = edge_index.tolist()"
      ],
      "id": "248d5506-ae43-4585-8def-6ac33f049c8a"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_ = np.array(edge_index)[:,2].mean()"
      ],
      "id": "06449bc0-f866-4d05-900e-9ab7341d3eec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` median"
      ],
      "id": "b6ff3a82-0d52-42be-b1e2-82f63d97591c"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "medi_ = np.median(np.array(edge_index)[:,2])"
      ],
      "id": "1b497e35-6d4c-4caa-8d67-af01fc64aac8"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_edges = [(int(row[0]), int(row[1])) for row in edge_index if row[2] > medi_]\n",
        "edge_index_selected = torch.tensor(selected_edges, dtype=torch.long).t()\n",
        "edge_index_selected.shape"
      ],
      "id": "a424f87b-9c42-4b18-8122-5242b934f395"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### data설정(x, edge_index, y)"
      ],
      "id": "e43fcd27-1355-45f7-b8db-8b99843564a0"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor(df50['amt'], dtype=torch.float).reshape(-1,1)"
      ],
      "id": "88504d40-8829-4b6f-93ed-e5bebbf8e508"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = torch.tensor(df50['is_fraud'],dtype=torch.int64)"
      ],
      "id": "f2d16b59-91b5-4208-af59-6c7d017ab922"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = torch_geometric.data.Data(x=x, edge_index = edge_index_selected, y=y, train_mask = train_mask, test_mask = test_mask)"
      ],
      "id": "5e204f74-b36f-4029-b15d-124dc2d18e24"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ],
      "id": "1ba154a6-c153-498a-8d49-f8be662eb34f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### gnn"
      ],
      "id": "ff211998-0f43-404c-b95f-b9ebc2925ba8"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(1, 16)\n",
        "        self.conv2 = GCNConv(16,2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "id": "a056670c-61d7-4056-ae60-e82896654ca3"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "model.train()\n",
        "for epoch in range(400):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "id": "d02dd95d-4c9d-4baa-8e1c-ab2866bba701"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8768"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "pred = model(data).argmax(dim=1)\n",
        "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "acc = int(correct) / int(np.array(data.test_mask).sum())\n",
        "print(f'Accuracy: {acc:.4f}')"
      ],
      "id": "00c231c6-cbd8-424c-8b19-d113472a6954"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_labels = pred[data.test_mask]\n",
        "true_labels = data.y[data.test_mask]\n"
      ],
      "id": "e6b70857-b3e6-426f-ae5d-f1323465fe67"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8799\n",
            "Recall: 0.8763\n",
            "F1 Score: 0.8764"
          ]
        }
      ],
      "source": [
        "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "id": "ab4fd2e2-b160-4624-982b-156043d2bcbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# 정리\n",
        "\n",
        "| 구분  | Train   | Test      | 모형          | 설명변수 | 비고 |\n",
        "|-------|---------|-----------|---------------|----------|------|\n",
        "| 분석1 | df50_tr | df50_test | GNN           | amt      |      |\n",
        "| 분석2 | df50_tr | df50_test | 로지스틱 회귀 | amt      |      |\n",
        "| 분석3 | df50_tr | df50_test | SVM           | amt      |      |\n",
        "| 분석4 | df50_tr | df50_test | 랜덤포레스트  | amt      |      |\n",
        "\n",
        "## 분석2(로지스틱 회귀)"
      ],
      "id": "cabf0c5b-216d-4460-9fdc-07f1aaeb25b9"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(df50_tr.loc[:,['amt']])\n",
        "XX = np.array(df50_test.loc[:,['amt']])\n",
        "y = np.array(df50_tr.is_fraud)\n",
        "yy = np.array(df50_test.is_fraud)"
      ],
      "id": "ea06ac11-0cd0-4038-8994-6fcf7c80aa1f"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr = sklearn.linear_model.LogisticRegression()"
      ],
      "id": "36e3c701-9f06-450a-b9e0-dfcb45376a56"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr.fit(X,y)"
      ],
      "id": "5e5a71b3-1be7-4196-8f45-e6679297f211"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#thresh = y.mean()\n",
        "#yyhat = (lrnr.predict_proba(XX)> thresh)[:,-1]\n",
        "yyhat = lrnr.predict(XX) "
      ],
      "id": "955bd273-0f31-4584-8376-594628f08604"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [sklearn.metrics.accuracy_score,\n",
        "           sklearn.metrics.precision_score,\n",
        "           sklearn.metrics.recall_score,\n",
        "           sklearn.metrics.f1_score]"
      ],
      "id": "384db072-7191-41b8-a9da-fb3daad9343c"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "_results2= pd.DataFrame({m.__name__:[m(yy,yyhat).round(6)] for m in metrics},index=['분석2'])\n",
        "_results2"
      ],
      "id": "d7f5aeff-78dc-4229-b112-046336a63597"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 분석3(서포트 벡터 머신)"
      ],
      "id": "9d023b27-2051-44bb-bd5c-6f5e2d5364bd"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(df50_tr.loc[:, ['amt']])\n",
        "XX = np.array(df50_test.loc[:, ['amt']])\n",
        "y = np.array(df50_tr.is_fraud)\n",
        "yy = np.array(df50_test.is_fraud)"
      ],
      "id": "993f6531-37c2-4be2-8eab-cd3481e3b780"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr = SVC(kernel='linear')  \n",
        "lrnr.fit(X,y)\n",
        "yyhat = lrnr.predict(XX)\n"
      ],
      "id": "d2fb9e83-8b63-4196-9922-18a8ad450321"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [sklearn.metrics.accuracy_score,\n",
        "           sklearn.metrics.precision_score,\n",
        "           sklearn.metrics.recall_score,\n",
        "           sklearn.metrics.f1_score]"
      ],
      "id": "f4c7c3d6-23f5-44d2-84dd-045a880b81ae"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "_results3= pd.DataFrame({m.__name__:[m(yy,yyhat).round(6)] for m in metrics},index=['분석3'])\n",
        "_results3"
      ],
      "id": "2ef43bcd-4ebe-49ad-95f1-5bf64c7bf1ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 분석4(랜덤 포레스트)"
      ],
      "id": "c7867e08-1b8b-4b3e-89a9-b45842450c14"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(df50_tr.loc[:, ['amt']])\n",
        "XX = np.array(df50_test.loc[:, ['amt']])\n",
        "y = np.array(df50_tr.is_fraud)\n",
        "yy = np.array(df50_test.is_fraud)"
      ],
      "id": "618fea38-36a7-4051-a5da-a7f2b298aa84"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr = RandomForestClassifier()  \n",
        "lrnr.fit(X, y)\n",
        "yyhat = lrnr.predict(XX)"
      ],
      "id": "4eb89790-194a-46eb-bc53-d190aca58364"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [sklearn.metrics.accuracy_score,\n",
        "           sklearn.metrics.precision_score,\n",
        "           sklearn.metrics.recall_score,\n",
        "           sklearn.metrics.f1_score]"
      ],
      "id": "9406a5e4-2154-41c4-a723-f337425e812c"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "_results4= pd.DataFrame({m.__name__:[m(yy,yyhat).round(6)] for m in metrics},index=['분석4'])\n",
        "_results4"
      ],
      "id": "f9f1cd91-e6c2-4df6-a98c-188466761a5f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 분석5(부스팅)"
      ],
      "id": "7cc06b11-8956-4c24-871e-f10c147f1725"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(df50_tr.loc[:, ['amt']])\n",
        "XX = np.array(df50_test.loc[:, ['amt']])\n",
        "y = np.array(df50_tr.is_fraud)\n",
        "yy = np.array(df50_test.is_fraud)"
      ],
      "id": "3c3e6452-3437-4357-b5da-be81d42f7e32"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr = xgb.XGBClassifier()  \n",
        "lrnr.fit(X, y)\n",
        "yyhat = lrnr.predict(XX)"
      ],
      "id": "7bcc232f-a643-468c-be38-cb21a006f63f"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [sklearn.metrics.accuracy_score,\n",
        "           sklearn.metrics.precision_score,\n",
        "           sklearn.metrics.recall_score,\n",
        "           sklearn.metrics.f1_score]"
      ],
      "id": "f6872675-e0e8-4256-8ce5-ae2273e067d0"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "_results5= pd.DataFrame({m.__name__:[m(yy,yyhat).round(6)] for m in metrics},index=['분석5'])\n",
        "_results5"
      ],
      "id": "572eb435-9165-4608-8d68-fdfa793e549d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 분석6(Naive Bayes)"
      ],
      "id": "81385af5-0f09-4c28-9ad9-4533f2fd7510"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(df50_tr.loc[:, ['amt']])\n",
        "XX = np.array(df50_test.loc[:, ['amt']])\n",
        "y = np.array(df50_tr.is_fraud)\n",
        "yy = np.array(df50_test.is_fraud)"
      ],
      "id": "a36c16c8-58e1-47be-a5ac-47f6aa8cbf81"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrnr = GaussianNB() \n",
        "lrnr.fit(X, y)\n",
        "yyhat = lrnr.predict(XX)"
      ],
      "id": "1b0e9378-4ff3-4b7e-9964-90672408044e"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [sklearn.metrics.accuracy_score,\n",
        "           sklearn.metrics.precision_score,\n",
        "           sklearn.metrics.recall_score,\n",
        "           sklearn.metrics.f1_score]"
      ],
      "id": "a5c9cebf-fd9e-4c88-8483-d2120e396255"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "_results6= pd.DataFrame({m.__name__:[m(yy,yyhat).round(6)] for m in metrics},index=['분석6'])\n",
        "_results6"
      ],
      "id": "29b079f7-a07a-4f3c-93fb-d92421c0e6ba"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add ."
      ],
      "id": "4f829e03-a7b1-4d22-bead-d8a652b4fb9c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main f9769619] .\n",
            " 8 files changed, 8800 insertions(+), 2514 deletions(-)\n",
            " create mode 100644 \"posts/GNN/FRAUD/.ipynb_checkpoints/230822 \\353\\215\\260\\354\\235\\264\\355\\204\\260(6, df02)-Copy1-checkpoint.ipynb\"\n",
            " create mode 100644 \"posts/GNN/FRAUD/.ipynb_checkpoints/230822 \\353\\215\\260\\354\\235\\264\\355\\204\\260(6, df02)-checkpoint.ipynb\"\n",
            " create mode 100644 \"posts/GNN/FRAUD/.ipynb_checkpoints/230823 \\353\\215\\260\\354\\235\\264\\355\\204\\260(7, df50_com\\354\\234\\274\\353\\241\\234 93\\355\\215\\274 accuracy)_guebin-checkpoint.ipynb\"\n",
            " create mode 100644 \"posts/GNN/FRAUD/.ipynb_checkpoints/230825 \\353\\215\\260\\354\\235\\264\\355\\204\\260(8, df02)\\354\\273\\244\\353\\204\\220\\354\\243\\275\\354\\235\\214.out-checkpoint.ipynb\"\n",
            " create mode 100644 \"posts/GNN/FRAUD/.ipynb_checkpoints/230827 \\353\\215\\260\\354\\235\\264\\355\\204\\260(9, df50 mask\\353\\247\\214\\353\\223\\244\\354\\227\\210\\353\\212\\224\\353\\215\\260 \\352\\262\\260\\352\\263\\274\\352\\260\\222\\354\\235\\264 \\353\\213\\254\\353\\235\\274).out-checkpoint.ipynb\"\n",
            " delete mode 100644 \"posts/GNN/FRAUD/230823 \\353\\215\\260\\354\\235\\264\\355\\204\\260(7, df50_com\\354\\234\\274\\353\\241\\234 93\\355\\215\\274 accuracy)_guebin-Copy1.out.ipynb\"\n",
            " rewrite \"posts/GNN/FRAUD/230825 \\353\\215\\260\\354\\235\\264\\355\\204\\260(8, df02)\\354\\273\\244\\353\\204\\220\\354\\243\\275\\354\\235\\214.out.ipynb\" (99%)\n",
            " rewrite \"posts/GNN/FRAUD/230827 \\353\\215\\260\\354\\235\\264\\355\\204\\260(9, df50 mask\\353\\247\\214\\353\\223\\244\\354\\227\\210\\353\\212\\224\\353\\215\\260 \\352\\262\\260\\352\\263\\274\\352\\260\\222\\354\\235\\264 \\353\\213\\254\\353\\235\\274).out.ipynb\" (99%)"
          ]
        }
      ],
      "source": [
        "!git commit -m ."
      ],
      "id": "dff183fa-b459-47fa-a906-75be2cdeef2e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 14, done.\n",
            "Counting objects: 100% (14/14), done.\n",
            "Delta compression using up to 16 threads\n",
            "Compressing objects: 100% (9/9), done.\n",
            "Writing objects: 100% (9/9), 5.06 KiB | 5.06 MiB/s, done.\n",
            "Total 9 (delta 7), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (7/7), completed with 5 local objects.\n",
            "To https://github.com/boram-coco/coco.git\n",
            "   1bbb61bf..f9769619  main -> main"
          ]
        }
      ],
      "source": [
        "!git push"
      ],
      "id": "2a6ae305-6cc5-485f-b2a5-f8f9981dad2f"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/boram-coco/coco\n",
            " * branch              gh-pages   -> FETCH_HEAD\n",
            "Rendering for publish:\n",
            "\n",
            "[  1/182] posts/Python/Summer Program-Python Programming Day1 Quiz.ipynb\n",
            "[  2/182] posts/Python/4. Class/python 11_0511.ipynb\n",
            "[  3/182] posts/Python/4. Class/python 13_0530.ipynb\n",
            "[  4/182] posts/Python/4. Class/python 10_0509.ipynb\n",
            "[  5/182] posts/Python/4. Class/python 12_0523.ipynb\n",
            "[  6/182] posts/Python/4. Class/python 13_0525.ipynb\n",
            "[  7/182] posts/Python/4. Class/python 12_0518.ipynb\n",
            "[  8/182] posts/Python/4. Class/python 11_0516.ipynb\n",
            "[  9/182] posts/Python/4. Class/python 14_0606.ipynb\n",
            "[ 10/182] posts/Python/1. Basic/python 3_0321.ipynb\n",
            "[ 11/182] posts/Python/1. Basic/python 1_0307.ipynb\n",
            "[ 12/182] posts/Python/1. Basic/python 4_0323.ipynb\n",
            "[ 13/182] posts/Python/1. Basic/python 3_0316.ipynb\n",
            "[ 14/182] posts/Python/1. Basic/python 4_0328.ipynb\n",
            "[ 15/182] posts/Python/1. Basic/python 2_0314.ipynb\n",
            "[ 16/182] posts/Python/3. Pandas/python 10_0506 .ipynb\n",
            "[ 17/182] posts/Python/2. Numpy/python 7_0418.ipynb\n",
            "[ 18/182] posts/Python/2. Numpy/python 5_0406.ipynb\n",
            "[ 19/182] posts/Python/2. Numpy/python 5_0404.ipynb\n",
            "[ 20/182] posts/Python/2. Numpy/python 7_0413.ipynb\n",
            "[ 21/182] posts/Python/2. Numpy/python 6_0411.ipynb\n",
            "[ 22/182] posts/Python/Summer Program-Python Programming Day2 Quiz.ipynb\n",
            "[ 23/182] posts/Special Topics in Big Data Analysis/2022-05-23-(12주차) 5월23일.ipynb\n",
            "[ 24/182] posts/Special Topics in Big Data Analysis/2022_03_07_(1주차)_3월7일.ipynb\n",
            "[ 25/182] posts/Special Topics in Big Data Analysis/2022_04_11_(6주차)_4월11일.ipynb\n",
            "[ 26/182] posts/Special Topics in Big Data Analysis/2022_03_14_(2주차)_3월14일.ipynb\n",
            "[ 27/182] posts/Special Topics in Big Data Analysis/2022_05_02_(9주차)_5월2일(2).ipynb\n",
            "[ 28/182] posts/Special Topics in Big Data Analysis/2022_03_28_(4주차)_3월28일.ipynb\n",
            "[ 29/182] posts/Special Topics in Big Data Analysis/2022_05_30_(13주차)_5월30일.ipynb\n",
            "[ 30/182] posts/Special Topics in Big Data Analysis/2022_05_09_(10주차)_5월9일.ipynb\n",
            "[ 31/182] posts/Special Topics in Big Data Analysis/2022_04_04_(5주차)_4월4일.ipynb\n",
            "[ 32/182] posts/Special Topics in Big Data Analysis/2022_05_16_(11주차)_5월16일.ipynb\n",
            "[ 33/182] posts/Special Topics in Big Data Analysis/2022_03_21_(3주차)_3월21일.ipynb\n",
            "[ 34/182] posts/Special Topics in Big Data Analysis/2022-06-09-(14주차) 6월9일.ipynb\n",
            "[ 35/182] posts/Special Topics in Big Data Analysis/2022_04_18_(7주차)_4월18일.ipynb\n",
            "[ 36/182] posts/Applied statistics/AS3_3.ipynb\n",
            "[ 37/182] posts/Applied statistics/AS4.ipynb\n",
            "[ 38/182] posts/Applied statistics/AS1_3.ipynb\n",
            "[ 39/182] posts/Applied statistics/AS4_5.ipynb\n",
            "[ 40/182] posts/Applied statistics/02. CH0304.ipynb\n",
            "[ 41/182] posts/Applied statistics/01. Simple Linear Regression.ipynb\n",
            "[ 42/182] posts/Applied statistics/AS1.ipynb\n",
            "[ 43/182] posts/Applied statistics/08. 다항회귀실습.ipynb\n",
            "[ 44/182] posts/Applied statistics/10. GLS실습.ipynb\n",
            "[ 45/182] posts/Applied statistics/alpha.ipynb\n",
            "[ 46/182] posts/Applied statistics/06. 회귀진단 실습.ipynb\n",
            "[ 47/182] posts/Applied statistics/11. 편의추정 실습.ipynb\n",
            "[ 48/182] posts/Applied statistics/04. 선형회귀분석 CH0607.ipynb\n",
            "[ 49/182] posts/Applied statistics/12. 로지스틱 회귀분석.ipynb\n",
            "[ 50/182] posts/Applied statistics/03. CH0304_simulation.ipynb\n",
            "[ 51/182] posts/Applied statistics/AS3.ipynb\n",
            "[ 52/182] posts/Applied statistics/05. 가변수 실습.ipynb\n",
            "[ 53/182] posts/Applied statistics/AS4_5-Copy1.ipynb\n",
            "[ 54/182] posts/Applied statistics/09. 변수변환.ipynb\n",
            "[ 55/182] posts/Applied statistics/07. 변수선택 실습.ipynb\n",
            "[ 56/182] posts/Applied statistics/AS2.ipynb\n",
            "[ 57/182] posts/Synthetic data/synthetic data.ipynb\n",
            "[ 58/182] posts/Synthetic data/Practical Synthetic Data Generation.ipynb\n",
            "[ 59/182] posts/Synthetic data/A Comparison of Synthetic Data Approaches Using Utility and Disclosure Risk Measures.ipynb\n",
            "[ 60/182] posts/Synthetic data/2023-07-01-CTGAN.ipynb\n",
            "[ 61/182] posts/Synthetic data/[R] synthpop.ipynb\n",
            "[ 62/182] posts/Synthetic data/Modeling Tabular Data using Conditional GAN.ipynb\n",
            "[ 63/182] posts/Synthetic data/Advaced Deep Learning with TensorFlow 2 and Keras.ipynb\n",
            "[ 64/182] posts/Synthetic data/2023-07-02-CTGAN-TOY.ipynb\n",
            "[ 65/182] posts/ref/Ref.ipynb\n",
            "[ 66/182] posts/study/주성분 분석.ipynb\n",
            "[ 67/182] posts/study/콰트로 블로그 만드는 법.ipynb\n",
            "[ 68/182] posts/study/Python Data Analysis/경사하강법.ipynb\n",
            "[ 69/182] posts/study/Python Data Analysis/딥러닝 회귀분석.ipynb\n",
            "[ 70/182] posts/study/Python Data Analysis/다층 퍼셉트론과 딥러닝.ipynb\n",
            "[ 71/182] posts/study/Python Data Analysis/인공신경망과 퍼셉트론.ipynb\n",
            "[ 72/182] posts/study/KSS-DataFrame.ipynb\n",
            "[ 73/182] posts/study/선형대수와 통계학으로 배우는 머신러닝 with 파이썬/ml with python 7.ipynb\n",
            "[ 74/182] posts/study/선형대수와 통계학으로 배우는 머신러닝 with 파이썬/ml with python 9.ipynb\n",
            "[ 75/182] posts/study/tutorial_hand_on.ipynb\n",
            "[ 76/182] posts/study/imbalaced data/plot_comparison_under_sampling.ipynb\n",
            "[ 77/182] posts/study/imbalaced data/imbalaced data.ipynb\n",
            "[ 78/182] posts/study/imbalaced data/plot_comparison_over_sampling.ipynb\n",
            "[ 79/182] posts/study/boostcourse/2. 데이터 분석 준비하기.ipynb\n",
            "[ 80/182] posts/study/boostcourse/0. jupyter basic.ipynb\n",
            "[ 81/182] posts/study/boostcourse/3. 서울 종합병원 분포 확인하기.ipynb\n",
            "[ 82/182] posts/study/boostcourse/1. file-path-setting.ipynb\n",
            "[ 83/182] posts/study/boostcourse/5. K-beauty.ipynb\n",
            "[ 84/182] posts/study/boostcourse/4. 건강검진 데이터로 가설검정.ipynb\n",
            "[ 85/182] posts/study/데이터 개념 공부.ipynb\n",
            "[ 86/182] posts/study/Deep learning with pytorch/Untitled.ipynb\n",
            "[ 87/182] posts/study/Deep learning with pytorch/tensor basic.ipynb\n",
            "[ 88/182] posts/study/baseball-salary-prediction.ipynb\n",
            "[ 89/182] posts/study/sklearn.ipynb\n",
            "[ 90/182] posts/Graph Machine Learning/graph3-2.ipynb\n",
            "[ 91/182] posts/Graph Machine Learning/graph4-1.ipynb\n",
            "[ 92/182] posts/Graph Machine Learning/9999.ipynb\n",
            "[ 93/182] posts/Graph Machine Learning/graph basic.ipynb\n",
            "[ 94/182] posts/Graph Machine Learning/graph3-3.ipynb\n",
            "[ 95/182] posts/Graph Machine Learning/graph8(logistic-amt+time+citypop+lat+merchlat).ipynb\n",
            "[ 96/182] posts/Graph Machine Learning/graph8(logistic, amt+time).ipynb\n",
            "[ 97/182] posts/Graph Machine Learning/graph8(logistic-amt+time+lat+merchlat).ipynb\n",
            "[ 98/182] posts/Graph Machine Learning/graph3-1.ipynb\n",
            "[ 99/182] posts/Graph Machine Learning/graph4-2.ipynb\n",
            "[100/182] posts/Graph Machine Learning/graph5-1.ipynb\n",
            "[101/182] posts/Graph Machine Learning/graph8(frac=0.4).ipynb\n",
            "[102/182] posts/Graph Machine Learning/graph5-2.ipynb\n",
            "[103/182] posts/Graph Machine Learning/graph8.ipynb\n",
            "[104/182] posts/Graph Machine Learning/graph8(frac=0.3).ipynb\n",
            "[105/182] posts/Graph Machine Learning/graph2.ipynb\n",
            "[106/182] posts/Graph Machine Learning/graph8(logistic+graph).ipynb\n",
            "[107/182] posts/Graph Machine Learning/graph8(logistic-amt+time+citypop).ipynb\n",
            "[108/182] posts/Graph Machine Learning/graph8.사기거래=0필터.ipynb\n",
            "[109/182] posts/Graph Machine Learning/graph8.df원본에서진행.ipynb\n",
            "[110/182] posts/Machine Learning/MachineLearning_midterm(202250926).ipynb\n",
            "[111/182] posts/Machine Learning/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.ipynb\n",
            "[112/182] posts/Machine Learning/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.ipynb\n",
            "[113/182] posts/Machine Learning/2. CNN/기계학습특강2022_10_19_ipynb의_사본.ipynb\n",
            "[114/182] posts/Machine Learning/2022_12_21_Extra_1_ipynb의_사본.ipynb\n",
            "[115/182] posts/Machine Learning/2022_09_07_(1주차)_9월7일_ipynb의_사본.ipynb\n",
            "[116/182] posts/Machine Learning/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.ipynb\n",
            "[117/182] posts/Machine Learning/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.ipynb\n",
            "[118/182] posts/Machine Learning/3. RNN/2022_11_16_11wk_ipynb의_사본.ipynb\n",
            "[119/182] posts/Machine Learning/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.ipynb\n",
            "[120/182] posts/Machine Learning/3. RNN/2022_12_08_13wk_checkpoint.ipynb\n",
            "[121/182] posts/Machine Learning/2022_09_14_(2주차)_9월14일_ipynb의_사본.ipynb\n",
            "[122/182] posts/Machine Learning/(202250926)기계학습특강_final (2).ipynb\n",
            "[123/182] posts/Machine Learning/1. DNN/2022_10_12_6wk_checkpoint.ipynb\n",
            "[124/182] posts/Machine Learning/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.ipynb\n",
            "[125/182] posts/Machine Learning/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.ipynb\n",
            "[126/182] posts/Machine Learning/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.ipynb\n",
            "[127/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-05-09-10wk-checkpoint.ipynb\n",
            "[128/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-06-06-14wk.ipynb\n",
            "[129/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-05-16-11wk-checkpoint.ipynb\n",
            "[WARNING] Citeproc: citation durrett2019probability not found\n",
            "[130/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-05-23-12wk.ipynb\n",
            "[WARNING] Citeproc: citation cybenko1989approximation not found\n",
            "[WARNING] Citeproc: citation durrett2019probability not found\n",
            "[WARNING] Citeproc: citation makarov2013real not found\n",
            "[131/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-05-30-13wk.ipynb\n",
            "[WARNING] Citeproc: citation durrett2019probability not found\n",
            "[132/182] posts/Advanved Probability Theory/2. 확률론 기초/2023-05-02-9wk-checkpoint.ipynb\n",
            "[133/182] posts/Advanved Probability Theory/fin.ipynb\n",
            "[134/182] posts/Advanved Probability Theory/1. 측도론/2023-04-25-8wk.ipynb\n",
            "[135/182] posts/Advanved Probability Theory/1. 측도론/2023-04-11-6wk-checkpoint.ipynb\n",
            "[136/182] posts/Advanved Probability Theory/1. 측도론/2023_03_14_2wk_checkpoint.ipynb\n",
            "[137/182] posts/Advanved Probability Theory/1. 측도론/2023_03_07_1wk_checkpoint.ipynb\n",
            "[138/182] posts/Advanved Probability Theory/1. 측도론/2023_04_05_5wk_checkpoint.ipynb\n",
            "[139/182] posts/Advanved Probability Theory/1. 측도론/2023_03_28_4wk_checkpoint.ipynb\n",
            "[140/182] posts/Advanved Probability Theory/1. 측도론/2023-04-18-7wk-checkpoint.ipynb\n",
            "[141/182] posts/Advanved Probability Theory/1. 측도론/2023_03_21_3wk_checkpoint.ipynb\n",
            "[142/182] posts/Review/Synthetic data/synthetic data.ipynb\n",
            "[143/182] posts/Review/Synthetic data/Practical Synthetic Data Generation.ipynb\n",
            "[144/182] posts/Review/Synthetic data/A Comparison of Synthetic Data Approaches Using Utility and Disclosure Risk Measures.ipynb\n",
            "[145/182] posts/Review/Synthetic data/[R] synthpop.ipynb\n",
            "[146/182] posts/Review/Synthetic data/Modeling Tabular Data using Conditional GAN.ipynb\n",
            "[147/182] posts/Review/Synthetic data/Advaced Deep Learning with TensorFlow 2 and Keras.ipynb\n",
            "[148/182] posts/GNN/PyG/ls2.ipynb\n",
            "[149/182] posts/GNN/PyG/ls6.out.ipynb\n",
            "[150/182] posts/GNN/PyG/ls5.ipynb\n",
            "[151/182] posts/GNN/PyG/2023-07-02-lesson1.ipynb\n",
            "[152/182] posts/GNN/PyG/ls3.ipynb\n",
            "[153/182] posts/GNN/PyG/ls4.ipynb\n",
            "[154/182] posts/GNN/An Introduction to Graph Neural Network(GNN) For Analysing Structured Data.ipynb\n",
            "[155/182] posts/GNN/GNN논문.ipynb\n",
            "[156/182] posts/GNN/FRAUD/230818 데이터(4, df50_com으로 93퍼 accuracy).ipynb\n",
            "[157/182] posts/GNN/FRAUD/230827 데이터(9, df50 mask만들었는데 결과값이 달라).out.ipynb\n",
            "[158/182] posts/GNN/FRAUD/230822 데이터(5, matrix로 ls6시도해보기..실패).ipynb\n",
            "[159/182] posts/GNN/FRAUD/230825 데이터(8, df02)커널죽음.out.ipynb\n",
            "[160/182] posts/GNN/FRAUD/230814 fraud(2, tr,test_mask).ipynb\n",
            "[161/182] posts/GNN/FRAUD/230823 데이터(7, df50_com으로 93퍼 accuracy)_guebin.ipynb\n",
            "[162/182] posts/GNN/FRAUD/230816 fraud(3, df50_com, tr,test합치기).ipynb\n",
            "[163/182] posts/GNN/FRAUD/230822 데이터(6, df02).ipynb\n",
            "[164/182] posts/GNN/FRAUD/230810 fraud(1, tr로만 96퍼 accruacy).ipynb\n",
            "[165/182] posts/GNN/FRAUD/230822 데이터(6, df02)-Copy1.ipynb\n",
            "[166/182] posts/GNN/Neural Network.ipynb\n",
            "[167/182] posts/GNN/230810 데이터정리.ipynb\n",
            "[168/182] posts/GNN/0810.ipynb\n",
            "[169/182] posts/GNN/Graph basic.ipynb\n",
            "[170/182] posts/GNN/Laplacian.ipynb\n",
            "[171/182] posts/Theoretical statistics/TS5.ipynb\n",
            "[172/182] posts/Theoretical statistics/TS7.ipynb\n",
            "[173/182] posts/Theoretical statistics/TS4.ipynb\n",
            "[174/182] posts/Theoretical statistics/TS3.ipynb\n",
            "[175/182] posts/Theoretical statistics/TS1.ipynb\n",
            "[176/182] posts/Theoretical statistics/TS8.ipynb\n",
            "[177/182] posts/Theoretical statistics/TS9.ipynb\n",
            "[178/182] posts/Theoretical statistics/TS final.ipynb\n",
            "[179/182] posts/Theoretical statistics/TS2.ipynb\n",
            "[180/182] posts/Theoretical statistics/TS6.ipynb\n",
            "[181/182] about.qmd\n",
            "[182/182] index.qmd\n",
            "\n",
            "Preparing worktree (resetting branch 'gh-pages'; was at ee6ded06)\n",
            "Branch 'gh-pages' set up to track remote branch 'gh-pages' from 'origin'.\n",
            "HEAD is now at ee6ded06 Built site for gh-pages\n",
            "error: the following files have local modifications:\n",
            "    posts/Advanved Probability Theory/2023_04_05_5wk_checkpoint.html\n",
            "    posts/Applied statistics/03. CH0304_simulation_files/figure-html/cell-53-output-1.png\n",
            "    posts/Applied statistics/03. CH0304_simulation_files/figure-html/cell-6-output-1.png\n",
            "    posts/Applied statistics/05. 가변수 실습.html\n",
            "    posts/Applied statistics/06. 회귀진단 실습.html\n",
            "    posts/Applied statistics/06. 회귀진단 실습.out.ipynb\n",
            "    posts/Applied statistics/06. 회귀진단 실습_files/figure-html/cell-33-output-1.png\n",
            "    posts/Applied statistics/06. 회귀진단 실습_files/figure-html/cell-46-output-1.png\n",
            "    posts/Applied statistics/06. 회귀진단 실습_files/figure-html/cell-47-output-1.png\n",
            "    posts/Applied statistics/06. 회귀진단 실습_files/figure-html/cell-5-output-1.png\n",
            "    posts/Applied statistics/06. 회귀진단 실습_files/figure-html/cell-7-output-1.png\n",
            "    posts/Applied statistics/07. 변수선택 실습.html\n",
            "    posts/Applied statistics/07. 변수선택 실습.out.ipynb\n",
            "(use --cached to keep the file, or -f to force removal)\n",
            "[gh-pages db1a3b4d] Built site for gh-pages\n",
            " 186 files changed, 5197 insertions(+), 6147 deletions(-)\n",
            "origin  https://github.com/boram-coco/coco.git (fetch)\n",
            "origin  https://github.com/boram-coco/coco.git (push)\n",
            "To https://github.com/boram-coco/coco.git\n",
            "   ee6ded06..db1a3b4d  HEAD -> gh-pages\n",
            "\n",
            "NOTE: GitHub Pages sites use caching so you might need to click the refresh\n",
            "button within your web browser to see changes after deployment.\n",
            "\n",
            "[✓] Published to https://boram-coco.github.io/coco/\n",
            "\n",
            "NOTE: GitHub Pages deployments normally take a few minutes (your site updates\n",
            "will be visible once the deploy completes)\n"
          ]
        }
      ],
      "source": [
        "!quarto publish gh-pages --no-prompt --no-browser"
      ],
      "id": "5e95d422-39bb-4f50-845c-12f40aff1610"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  }
}