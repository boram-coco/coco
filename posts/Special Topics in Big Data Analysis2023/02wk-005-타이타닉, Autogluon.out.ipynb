{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17831079-6a91-4941-8b53-1f0d22b3f572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "2857aa5b-d3ba-4d3d-8ecc-3fb353f66107",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[STBDA2023] 02wk-005: 타이타닉, Autogluon\"\n",
    "author: \"김보람\"\n",
    "date: \"09/17/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c52257-29d5-45ce-8e54-52e2e985fb2e",
   "metadata": {},
   "source": [
    "> 해당 자료는 전북대학교 최규빈 교수님 2023학년도 2학기 [빅데이터분석특강](https://guebin.github.io/STBDA2023/) 자료임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345a35f-b860-4ed7-94ae-6d9035b031da",
   "metadata": {},
   "source": [
    "# 02wk-005: 타이타닉, Autogluon\n",
    "\n",
    "최규빈  \n",
    "2023-09-12\n",
    "\n",
    "# 1. 강의영상\n",
    "\n",
    "<https://youtu.be/playlist?list=PLQqh36zP38-zZrOGpLc8spPa9L39RiNhR&si=TFl5m9-VohYT_47L>\n",
    "\n",
    "# 2. Import\n",
    "\n",
    "``` python\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "```\n",
    "\n",
    "    /kaggle/input/titanic/train.csv\n",
    "    /kaggle/input/titanic/test.csv\n",
    "    /kaggle/input/titanic/gender_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438db173-0810-4140-98cd-65314c5695af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a36c4a-ac65-4270-bb1e-bca688db2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919a505-77e3-4951-9bd4-82f23b02add4",
   "metadata": {},
   "source": [
    "# 3. 분석의 절차\n",
    "\n",
    "## A. 데이터\n",
    "\n",
    "`-` 비유: 문제를 받아오는 과정으로 비유할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c66df28-7fe6-47de-ba1f-4d1c74976f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ~/Desktop/titanic/train.csv | Columns = 12 / 12 | Rows = 891 -> 891\n",
      "Loaded data from: ~/Desktop/titanic/test.csv | Columns = 11 / 11 | Rows = 418 -> 418\n"
     ]
    }
   ],
   "source": [
    "tr = TabularDataset(\"~/Desktop/titanic/train.csv\")\n",
    "tst = TabularDataset(\"~/Desktop/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6404db58-2df4-4640-940d-a7f3618d5f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autogluon.core.dataset.TabularDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89558f59-a69d-47a7-9e84-92a00e90363f",
   "metadata": {},
   "source": [
    "## B. Predictor 생성\n",
    "\n",
    "`-` 비유: 문제를 풀 학생을 생성하는 과정으로 비유할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d50b7ce-2de0-4738-a699-49a91af03bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A dataset in tabular format (with rows = samples, columns = features/variables).\u001b[0m\n",
       "\u001b[0;34m    This object is essentially a pandas DataFrame (with some extra attributes) and all existing pandas methods can be applied to it.\u001b[0m\n",
       "\u001b[0;34m    For full list of methods/attributes, see pandas Dataframe documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    data : :class:`pd.DataFrame` or str\u001b[0m\n",
       "\u001b[0;34m        If str, path to data file (CSV or Parquet format).\u001b[0m\n",
       "\u001b[0;34m        If you already have your data in a :class:`pd.DataFrame`, you can specify it here.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    file_path: (str)\u001b[0m\n",
       "\u001b[0;34m        Path to data file from which this `TabularDataset` was created.\u001b[0m\n",
       "\u001b[0;34m        None if `data` was a :class:`pd.DataFrame`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Note: In addition to these attributes, `TabularDataset` also shares all the same attributes and methods of a pandas Dataframe.\u001b[0m\n",
       "\u001b[0;34m    For a detailed list, see:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from autogluon.core.dataset import TabularDataset\u001b[0m\n",
       "\u001b[0;34m    >>> train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\u001b[0m\n",
       "\u001b[0;34m    >>> train_data.head(30)\u001b[0m\n",
       "\u001b[0;34m    >>> train_data.columns\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"file_path\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# preserved properties that will be copied to a new instance of TabularDataset\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/py38/lib/python3.8/site-packages/autogluon/core/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TabularDataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267159d2-3f3a-4533-8521-28bd807f66a2",
   "metadata": {},
   "source": [
    "- class상속!! Dataframe의 기능을 다 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da42aee8-fe61-4ab0-a26c-9c725ec2ce8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mproblem_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_to_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "AutoGluon TabularPredictor predicts values in a column of a tabular dataset (classification or regression).\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "label : str\n",
       "    Name of the column that contains the target variable to predict.\n",
       "problem_type : str, default = None\n",
       "    Type of prediction problem, i.e. is this a binary/multiclass classification or regression problem (options: 'binary', 'multiclass', 'regression', 'quantile').\n",
       "    If `problem_type = None`, the prediction problem type is inferred based on the label-values in provided dataset.\n",
       "eval_metric : function or str, default = None\n",
       "    Metric by which predictions will be ultimately evaluated on test data.\n",
       "    AutoGluon tunes factors such as hyperparameters, early-stopping, ensemble-weights, etc. in order to improve this metric on validation data.\n",
       "\n",
       "    If `eval_metric = None`, it is automatically chosen based on `problem_type`.\n",
       "    Defaults to 'accuracy' for binary and multiclass classification, 'root_mean_squared_error' for regression, and 'pinball_loss' for quantile.\n",
       "\n",
       "    Otherwise, options for classification:\n",
       "        ['accuracy', 'balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'f1_weighted',\n",
       "        'roc_auc', 'roc_auc_ovo_macro', 'average_precision', 'precision', 'precision_macro', 'precision_micro',\n",
       "        'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_weighted', 'log_loss', 'pac_score']\n",
       "    Options for regression:\n",
       "        ['root_mean_squared_error', 'mean_squared_error', 'mean_absolute_error', 'median_absolute_error', 'mean_absolute_percentage_error', 'r2']\n",
       "    For more information on these options, see `sklearn.metrics`: https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics\n",
       "    For metric source code, see `autogluon.core.metrics`.\n",
       "\n",
       "    You can also pass your own evaluation function here as long as it follows formatting of the functions defined in folder `autogluon.core.metrics`.\n",
       "    For detailed instructions on creating and using a custom metric, refer to https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-custom-metric.html\n",
       "path : Union[str, pathlib.Path], default = None\n",
       "    Path to directory where models and intermediate outputs should be saved.\n",
       "    If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
       "    Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
       "    Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
       "verbosity : int, default = 2\n",
       "    Verbosity levels range from 0 to 4 and control how much information is printed.\n",
       "    Higher levels correspond to more detailed print statements (you can set verbosity = 0 to suppress warnings).\n",
       "    If using logging, you can alternatively control amount of information printed via `logger.setLevel(L)`,\n",
       "    where `L` ranges from 0 to 50 (Note: higher values of `L` correspond to fewer print statements, opposite of verbosity levels).\n",
       "    Verbosity levels:\n",
       "        0: Only log exceptions\n",
       "        1: Only log warnings + exceptions\n",
       "        2: Standard logging\n",
       "        3: Verbose logging (ex: log validation score every 50 iterations)\n",
       "        4: Maximally verbose logging (ex: log validation score every iteration)\n",
       "log_to_file: bool, default = True\n",
       "    Whether to save the logs into a file for later reference\n",
       "log_file_path: str, default = \"auto\"\n",
       "    File path to save the logs.\n",
       "    If auto, logs will be saved under `predictor_path/logs/predictor_log.txt`.\n",
       "    Will be ignored if `log_to_file` is set to False\n",
       "sample_weight : str, default = None\n",
       "    If specified, this column-name indicates which column of the data should be treated as sample weights. This column will NOT be considered as a predictive feature.\n",
       "    Sample weights should be non-negative (and cannot be nan), with larger values indicating which rows are more important than others.\n",
       "    If you want your usage of sample weights to match results obtained outside of this Predictor, then ensure sample weights for your training (or tuning) data sum to the number of rows in the training (or tuning) data.\n",
       "    You may also specify two special strings: 'auto_weight' (automatically choose a weighting strategy based on the data) or 'balance_weight' (equally weight classes in classification, no effect in regression). If specifying your own sample_weight column, make sure its name does not match these special strings.\n",
       "weight_evaluation : bool, default = False\n",
       "    Only considered when `sample_weight` column is not None. Determines whether sample weights should be taken into account when computing evaluation metrics on validation/test data.\n",
       "    If True, then weighted metrics will be reported based on the sample weights provided in the specified `sample_weight` (in which case `sample_weight` column must also be present in test data).\n",
       "    In this case, the 'best' model used by default for prediction will also be decided based on a weighted version of evaluation metric.\n",
       "    Note: we do not recommend specifying `weight_evaluation` when `sample_weight` is 'auto_weight' or 'balance_weight', instead specify appropriate `eval_metric`.\n",
       "groups : str, default = None\n",
       "    [Experimental] If specified, AutoGluon will use the column named the value of groups in `train_data` during `.fit` as the data splitting indices for the purposes of bagging.\n",
       "    This column will not be used as a feature during model training.\n",
       "    This parameter is ignored if bagging is not enabled. To instead specify a custom validation set with bagging disabled, specify `tuning_data` in `.fit`.\n",
       "    The data will be split via `sklearn.model_selection.LeaveOneGroupOut`.\n",
       "    Use this option to control the exact split indices AutoGluon uses.\n",
       "    It is not recommended to use this option unless it is required for very specific situations.\n",
       "    Bugs may arise from edge cases if the provided groups are not valid to properly train models, such as if not all classes are present during training in multiclass classification. It is up to the user to sanitize their groups.\n",
       "\n",
       "    As an example, if you want your data folds to preserve adjacent rows in the table without shuffling, then for 3 fold bagging with 6 rows of data, the groups column values should be [0, 0, 1, 1, 2, 2].\n",
       "**kwargs :\n",
       "    learner_type : AbstractLearner, default = DefaultLearner\n",
       "        A class which inherits from `AbstractLearner`. This dictates the inner logic of predictor.\n",
       "        If you don't know what this is, keep it as the default.\n",
       "    learner_kwargs : dict, default = None\n",
       "        Kwargs to send to the learner. Options include:\n",
       "\n",
       "        positive_class : str or int, default = None\n",
       "            Used to determine the positive class in binary classification.\n",
       "            This is used for certain metrics such as 'f1' which produce different scores depending on which class is considered the positive class.\n",
       "            If not set, will be inferred as the second element of the existing unique classes after sorting them.\n",
       "                If classes are [0, 1], then 1 will be selected as the positive class.\n",
       "                If classes are ['def', 'abc'], then 'def' will be selected as the positive class.\n",
       "                If classes are [True, False], then True will be selected as the positive class.\n",
       "        ignored_columns : list, default = None\n",
       "            Banned subset of column names that predictor may not use as predictive features (e.g. unique identifier to a row or user-ID).\n",
       "            These columns are ignored during `fit()`.\n",
       "        label_count_threshold : int, default = 10\n",
       "            For multi-class classification problems, this is the minimum number of times a label must appear in dataset in order to be considered an output class.\n",
       "            AutoGluon will ignore any classes whose labels do not appear at least this many times in the dataset (i.e. will never predict them).\n",
       "        cache_data : bool, default = True\n",
       "            When enabled, the training and validation data are saved to disk for future reuse.\n",
       "            Enables advanced functionality in predictor such as `fit_extra()` and feature importance calculation on the original data.\n",
       "        trainer_type : AbstractTrainer, default = AutoTrainer\n",
       "            A class inheriting from `AbstractTrainer` that controls training/ensembling of many models.\n",
       "            If you don't know what this is, keep it as the default.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "path : str\n",
       "    Path to directory where all models used by this Predictor are stored.\n",
       "problem_type : str\n",
       "    What type of prediction problem this Predictor has been trained for.\n",
       "eval_metric : function or str\n",
       "    What metric is used to evaluate predictive performance.\n",
       "label : str\n",
       "    Name of table column that contains data from the variable to predict (often referred to as: labels, response variable, target variable, dependent variable, Y, etc).\n",
       "feature_metadata : :class:`autogluon.common.features.feature_metadata.FeatureMetadata`\n",
       "    Inferred data type of each predictive variable after preprocessing transformation (i.e. column of training data table used to predict `label`).\n",
       "    Contains both raw dtype and special dtype information. Each feature has exactly 1 raw dtype (such as 'int', 'float', 'category') and zero to many special dtypes (such as 'datetime_as_int', 'text', 'text_ngram').\n",
       "    Special dtypes are AutoGluon specific feature types that are used to identify features with meaning beyond what the raw dtype can convey.\n",
       "        `feature_metadata.type_map_raw`: Dictionary of feature name -> raw dtype mappings.\n",
       "        `feature_metadata.type_group_map_special`: Dictionary of lists of special feature names, grouped by special feature dtype.\n",
       "positive_class : str or int\n",
       "    Returns the positive class name in binary classification. Useful for computing metrics such as F1 which require a positive and negative class.\n",
       "    In binary classification, :meth:`TabularPredictor.predict_proba` returns the estimated probability that each row belongs to the positive class.\n",
       "    Will print a warning and return None if called when `predictor.problem_type != 'binary'`.\n",
       "class_labels : list\n",
       "    For multiclass problems, this list contains the class labels in sorted order of `predict_proba()` output.\n",
       "    For binary problems, this list contains the class labels in sorted order of `predict_proba(as_multiclass=True)` output.\n",
       "        `class_labels[0]` corresponds to internal label = 0 (negative class), `class_labels[1]` corresponds to internal label = 1 (positive class).\n",
       "        This is relevant for certain metrics such as F1 where True and False labels impact the metric score differently.\n",
       "    For other problem types, will equal None.\n",
       "    For example if `pred = predict_proba(x, as_multiclass=True)`, then ith index of `pred` provides predicted probability that `x` belongs to class given by `class_labels[i]`.\n",
       "class_labels_internal : list\n",
       "    For multiclass problems, this list contains the internal class labels in sorted order of internal `predict_proba()` output.\n",
       "    For binary problems, this list contains the internal class labels in sorted order of internal `predict_proba(as_multiclass=True)` output.\n",
       "        The value will always be `class_labels_internal=[0, 1]` for binary problems, with 0 as the negative class, and 1 as the positive class.\n",
       "    For other problem types, will equal None.\n",
       "class_labels_internal_map : dict\n",
       "    For binary and multiclass classification problems, this dictionary contains the mapping of the original labels to the internal labels.\n",
       "    For example, in binary classification, label values of 'True' and 'False' will be mapped to the internal representation `1` and `0`.\n",
       "        Therefore, class_labels_internal_map would equal {'True': 1, 'False': 0}\n",
       "    For other problem types, will equal None.\n",
       "    For multiclass, it is possible for not all of the label values to have a mapping.\n",
       "        This indicates that the internal models will never predict those missing labels, and training rows associated with the missing labels were dropped.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/py38/lib/python3.8/site-packages/autogluon/tabular/predictor/predictor.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     _TabularPredictorExperimental, InterpretableTabularPredictor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TabularPredictor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0735ca6-fdce-4164-9a5f-2b08812f2f2b",
   "metadata": {},
   "source": [
    "- \"label\":target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba98784-7f27-48dd-9b7f-6c0a738eb56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230917_135346/\"\n"
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d7e11-b93e-4441-a123-72cbc53cc692",
   "metadata": {},
   "source": [
    "## C. 적합(fit)\n",
    "\n",
    "`-` 비유: 학생이 공부를 하는 과정으로 비유할 수 있다.\n",
    "\n",
    "`-` 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671326f7-f5a5-4601-9ac2-3832e4b5fb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff440a6-2707-4849-8c16-efb51eb4f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230917_135346/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #26~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jul 13 16:27:29 UTC 2\n",
      "Disk Space Avail:   775.59 GB / 982.82 GB (78.9%)\n",
      "Train Data Rows:    891\n",
      "Train Data Columns: 11\n",
      "Label Column: Survived\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    39350.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 8\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 28 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f291690c3a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.6536\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f291690c3a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.6536\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8101\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 9: early stopping\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8101\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.87s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230917_135346/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f2899b57f70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(tr) \n",
    "# 학생(predictr)에게 문제(tr)를 줘서 학습을 시킴(predictr.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13fce6-c66f-47de-b10f-7a7278a74994",
   "metadata": {},
   "source": [
    "`-` 리더보드확인 (모의고사 채점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e513eca-aed5-420d-afca-aca5ce499dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMLarge   0.832402       0.002893  0.406132                0.002893           0.406132            1       True         13\n",
      "1       NeuralNetFastAI   0.832402       0.006791  0.452260                0.006791           0.452260            1       True         10\n",
      "2   WeightedEnsemble_L2   0.832402       0.007321  0.783443                0.000530           0.331183            2       True         14\n",
      "3              CatBoost   0.826816       0.003689  0.362406                0.003689           0.362406            1       True          7\n",
      "4              LightGBM   0.821229       0.003210  0.207445                0.003210           0.207445            1       True          4\n",
      "5        NeuralNetTorch   0.821229       0.007692  1.186131                0.007692           1.186131            1       True         12\n",
      "6            LightGBMXT   0.815642       0.003147  0.195812                0.003147           0.195812            1       True          3\n",
      "7      RandomForestEntr   0.815642       0.024688  0.289305                0.024688           0.289305            1       True          6\n",
      "8      RandomForestGini   0.815642       0.024689  0.285907                0.024689           0.285907            1       True          5\n",
      "9        ExtraTreesGini   0.815642       0.024699  0.280003                0.024699           0.280003            1       True          8\n",
      "10              XGBoost   0.810056       0.004088  0.119255                0.004088           0.119255            1       True         11\n",
      "11       ExtraTreesEntr   0.810056       0.024130  0.290494                0.024130           0.290494            1       True          9\n",
      "12       KNeighborsUnif   0.653631       0.006800  0.025122                0.006800           0.025122            1       True          1\n",
      "13       KNeighborsDist   0.653631       0.009379  0.023463                0.009379           0.023463            1       True          2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.406132</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.406132</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.452260</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.452260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.783443</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.362406</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.362406</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>1.186131</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>1.186131</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.195812</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.195812</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.289305</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.289305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.285907</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.285907</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.280003</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.280003</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.290494</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.290494</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val  fit_time  \\\n",
       "0         LightGBMLarge   0.832402       0.002893  0.406132   \n",
       "1       NeuralNetFastAI   0.832402       0.006791  0.452260   \n",
       "2   WeightedEnsemble_L2   0.832402       0.007321  0.783443   \n",
       "3              CatBoost   0.826816       0.003689  0.362406   \n",
       "4              LightGBM   0.821229       0.003210  0.207445   \n",
       "5        NeuralNetTorch   0.821229       0.007692  1.186131   \n",
       "6            LightGBMXT   0.815642       0.003147  0.195812   \n",
       "7      RandomForestEntr   0.815642       0.024688  0.289305   \n",
       "8      RandomForestGini   0.815642       0.024689  0.285907   \n",
       "9        ExtraTreesGini   0.815642       0.024699  0.280003   \n",
       "10              XGBoost   0.810056       0.004088  0.119255   \n",
       "11       ExtraTreesEntr   0.810056       0.024130  0.290494   \n",
       "12       KNeighborsUnif   0.653631       0.006800  0.025122   \n",
       "13       KNeighborsDist   0.653631       0.009379  0.023463   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.002893           0.406132            1       True   \n",
       "1                 0.006791           0.452260            1       True   \n",
       "2                 0.000530           0.331183            2       True   \n",
       "3                 0.003689           0.362406            1       True   \n",
       "4                 0.003210           0.207445            1       True   \n",
       "5                 0.007692           1.186131            1       True   \n",
       "6                 0.003147           0.195812            1       True   \n",
       "7                 0.024688           0.289305            1       True   \n",
       "8                 0.024689           0.285907            1       True   \n",
       "9                 0.024699           0.280003            1       True   \n",
       "10                0.004088           0.119255            1       True   \n",
       "11                0.024130           0.290494            1       True   \n",
       "12                0.006800           0.025122            1       True   \n",
       "13                0.009379           0.023463            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          13  \n",
       "1          10  \n",
       "2          14  \n",
       "3           7  \n",
       "4           4  \n",
       "5          12  \n",
       "6           3  \n",
       "7           6  \n",
       "8           5  \n",
       "9           8  \n",
       "10         11  \n",
       "11          9  \n",
       "12          1  \n",
       "13          2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954a97b-9f1d-460f-8f27-9fd82f03f705",
   "metadata": {},
   "source": [
    "## D. 예측 (predict)\n",
    "\n",
    "`-` 비유: 학습이후에 문제를 푸는 과정으로 비유할 수 있다.\n",
    "\n",
    "`-` training set 을 풀어봄 (predict) $\\to$ 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91daef3c-7a51-48b6-9692-3b68b04df6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8810325476992144"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tr.Survived == predictr.predict(tr)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e521d63e-3e90-413b-8b3b-89e27bf38b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867564534231201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tr.Survived == (tr.Sex == \"female\")).mean() # 예전점수와 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1818dba-5d55-4120-8c0d-baf1dd6387c3",
   "metadata": {},
   "source": [
    "`-` test set 을 풀어봄 (predict) $\\to$ 점수 확인 하러 캐글에 결과제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b17e6-2738-4e8f-a792-e02cfb025ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.assign(Survived = predictr.predict(tst)).loc[:,['PassengerId','Survived']]\\\n",
    ".to_csv(\"autogluon_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
