{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d04db7-79e3-40cd-a3a0-87c0c09e6517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "926d31ce-3be7-43a4-a119-6c218d9c100d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Tensor Basic\"\n",
    "author: \"김보람\"\n",
    "date: \"07/14/2023\"\n",
    "categories:\n",
    "  - Tensor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce2cc9-9c45-415a-8393-edca9a912ec3",
   "metadata": {},
   "source": [
    "## Ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708e552-8108-48bb-a2e3-c1488e25ef1c",
   "metadata": {},
   "source": [
    "- Book: 딥러닝 파이토치 교과서(서지영 지음, 길벗 출판사)\n",
    "\n",
    "- github: https://github.com/gilbutITbook/080289/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998170ae-f015-478d-8580-53cf18aa8513",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a3f1cec-0102-41c4-b255-2312f23f369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110e6efe-0554-47ec-bdb3-dd750b117d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b9aca3-6716-43e1-92f0-e46ab9b46c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
       "\n",
       "Args:\n",
       "    root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
       "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
       "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
       "        otherwise from ``t10k-images-idx3-ubyte``.\n",
       "    download (bool, optional): If True, downloads the dataset from the internet and\n",
       "        puts it in root directory. If dataset is already downloaded, it is not\n",
       "        downloaded again.\n",
       "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
       "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
       "    target_transform (callable, optional): A function/transform that takes in the\n",
       "        target and transforms it.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/datasets/mnist.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torchvision.datasets.FashionMNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b0390b-f84a-497c-b3d8-81cd83f15e41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_six'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFashionMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mFashionMNIST(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()]))\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/datasets/mnist.py:91\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     85\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     download: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_legacy_exist():\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/datasets/vision.py:39\u001b[0m, in \u001b[0;36mVisionDataset.__init__\u001b[0;34m(self, root, transforms, transform, target_transform)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     33\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     target_transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_six\u001b[49m\u001b[38;5;241m.\u001b[39mstring_classes):\n\u001b[1;32m     40\u001b[0m         root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(root)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m root\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '_six'"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(\"../data\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\"../data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768791d1-fcdb-4c33-aa48-a00f1277eb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
