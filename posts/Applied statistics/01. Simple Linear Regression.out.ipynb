{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. SLR(Simple Linear Regression)\n",
        "\n",
        "김보람  \n",
        "2023-03-30\n",
        "\n",
        "> 해당 자료는 전북대학교 이영미 교수님 2023응용통계학 자료임\n",
        "\n",
        "# 회귀모형 적합\n",
        "\n",
        "## 1. 산점도(시각화), 상관 계수 (두 변수 사이 관계 요약)\n",
        "\n",
        "## 2. 회귀모형 적합: $\\widehat E(y|x) = \\widehat \\beta_0 + \\widehat \\beta_1 x, \\epsilon \\sim N(0, \\widehat \\sigma^2)$\n",
        "\n",
        "`-` 모수추정\n",
        "\n",
        "-   $\\widehat\\beta_0, \\widehat\\beta_1$ : 최소제곱추정량(LSE)\n",
        "\n",
        "-   $\\widehat\\sigma^2$ : MSE\n",
        "\n",
        "## 3. 통계적 유의성 검정\n",
        "\n",
        "`-` 회귀직선의 유의성 검정\n",
        "\n",
        "-   F검정\n",
        "\n",
        "-   $H_0 : \\beta_1 = 0 \\ vs \\  H_1 : \\beta_1 \\neq 0$\n",
        "\n",
        "`-` 개별 회귀 계수의 유의성 검정\n",
        "\n",
        "-   t검정\n",
        "\n",
        "-   $H_0 : \\beta_0 = 0 \\ vs \\  H_1 : \\beta _{0}=\\begin{cases} >0\\\\ \\neq 0\\\\ <0\\end{cases}$\n",
        "\n",
        "-   $H_0 : \\beta_1 = 0 \\ vs \\  H_1 : \\beta _{1}=\\begin{cases} >0\\\\ \\neq 0\\\\ <0\\end{cases}$\n",
        "\n",
        "> NOTE: 단순회귀모형에서는 회귀직선이 유의성검정, 개별회귀 계수의 유의성\n",
        "> 검정이 같다. 중회귀모형에서는 다르다.\n",
        "\n",
        "## 4. 모형의 적합도\n",
        "\n",
        "-   $\\mathbb{R} ^{2}$, MSE, $\\dots$\n",
        "\n",
        "## 5. 회귀진단\n",
        "\n",
        "-   잔차분석(오차항에 대한 가정 검토)\n",
        "\n",
        "-   이상점(leverage point)\n",
        "\n",
        "-   변수선택, 다중곤산성\n",
        "\n",
        "# 단순선형회귀 모형\n",
        "\n",
        "$y=\\beta_0+\\beta_1x+\\epsilon, \\epsilon \\sim_{i.i.d} N(0,\\sigma^2)$\n",
        "\n",
        "$E(y_i|x_i) = \\widehat\\beta_0 + \\widehat \\beta_1 x_i$\n",
        "\n",
        "`-` Linearity(선형성)\n",
        "\n",
        "$E(y|x)= \\mu_{yx} = \\beta_0 + \\beta_1x$\n",
        "\n",
        "i.e $E(\\epsilon_i)=0$\n",
        "\n",
        "`-` Homoscedastic(등분산성)\n",
        "\n",
        "$Var(y|x)=\\sigma^2$\n",
        "\n",
        "i.e $Var(\\epsilon_i)=\\sigma^2$\n",
        "\n",
        "`-` Normality(정규성)\n",
        "\n",
        "$y|x \\sim N(E(y|x),\\sigma^2)$\n",
        "\n",
        "i.e $\\epsilon \\sim N(0,\\sigma^2)$\n",
        "\n",
        "`-` Independency(독립성)\n",
        "\n",
        "$\\epsilon$s are mutually independent\n",
        "\n",
        "i.e $y_i$도 독립\n",
        "\n",
        "# LSE\n",
        "\n",
        "-   Least Square Estimation\n",
        "\n",
        "`-` 오차제곱합\n",
        "\n",
        "$S=\\sum_{i=1}^n \\epsilon_i^2 = \\sum_{i=1}^n [{y_i-(\\beta_0+\\beta_1 x_i)}]^2$\n",
        "\n",
        "`-` 최소제곱추정량(LSE)\n",
        "\n",
        "$(\\widehat \\beta_0, \\widehat \\beta_1) = argmin_{\\beta_0,\\beta_1 \\in \\mathbb{R}} \\sum_{i=1}^n [y_i-(\\beta_0+\\beta_1 x_i)]^2$\n",
        "\n",
        "$\\widehat \\beta_1 = \\dfrac{\\sum_{i=1}^n (x_i- \\bar x)(y_i - \\bar y)}{\\sum_{i=1}^n (x_i - \\bar x)^2} = \\dfrac{S_{(xy)}}{S_{(xx)}}$\n",
        "\n",
        "$\\widehat \\beta_0 = \\bar y - \\widehat \\beta_1 \\bar x$\n",
        "\n",
        "$\\bar y = \\dfrac{1}{n} \\sum_{i=1}^n y_i, \\bar x = \\dfrac{1}{n} \\sum_{i=1}^n x_i$\n",
        "\n",
        "# 오차분산($\\sigma^2$)\n",
        "\n",
        "`-` 잔차(오차)제곱합 (residual (or error) sum of squares)\n",
        "\n",
        "$$SSE = \\sum_{i=1}^n(y_i-\\widehat y_i)^2 = \\sum_{i=1}^n e_i^2$$\n",
        "\n",
        "`-` 평균제곱오차(MSE: Mean Squared Error)\n",
        "\n",
        "$$MSE=\\dfrac{SSE}{n-2}$$\n",
        "\n",
        "-   분모 $n-2$의 의미: $\\widehat \\beta_0, \\widehat \\beta_1$을 구하기\n",
        "    위해서 제약조건 2개($\\sum e_i=0, \\sum x_i e_i=0$) 제거\n",
        "\n",
        "`-` 오차분산의 추정값\n",
        "\n",
        "$$\\widehat \\sigma^2 = MSE$$\n",
        "\n",
        "-   오차가 작아지면 SSE가 낮아진다..\n",
        "\n",
        "# 제곱합의 분해\n",
        "\n",
        "$$SST(총제곱합)=SSE(잔차제곱합)+SSR(회귀제곱합)$$\n",
        "\n",
        "$$\\sum_{i=1}^n(y_i- \\bar y)^2 = \\sum_{i=1}^n(y_i- \\widehat y_i)^2 + \\sum_{i=1}^n(\\widehat y_i- \\bar y)^2$$\n",
        "\n",
        "# 결정계수\n",
        "\n",
        "`-` Coefficien of determination\n",
        "\n",
        "$$\\mathbb{R^2}=\\dfrac{SSR}{SST}=1-\\dfrac{SSE}{SST}$$\n",
        "\n",
        "-   회귀직선의 기여율(총변동 가운데 회귀직선으로 설명되는 변동의 비율)\n",
        "\n",
        "-   $0 \\leq \\mathbb{R^2} \\leq 1$\n",
        "\n",
        "-   1에 가까울수록 설명이 잘됨\n",
        "\n",
        "-   $\\mathbb{R^2}=r^2$(r:sample correlation) : 단순선형회귀모형에서만\n",
        "    성립\n",
        "\n",
        "# 분산분석(ANOVA)\n",
        "\n",
        "`-` 분산분석표\n",
        "\n",
        "| 요인 | 제곱합(SS) | 자유도(df) |      평균제곱(MS)      |       $F_0$        |    유의확률     |\n",
        "|:----:|:--------:|:--------:|:-----------------:|:--------------:|:------------:|\n",
        "| 회귀 |   $SSR$    |     1      |  $MSR=\\dfrac{SSR}{1}$  | $\\dfrac{MSR}{MSE}$ | $P(F \\geq F_0)$ |\n",
        "| 잔차 |   $SSE$    |   $n-2$    | $MSE=\\dfrac{SSE}{n-2}$ |                    |                 |\n",
        "|  계  |   $SST$    |   $n-1$    |                        |                    |                 |\n",
        "\n",
        "-   $F \\sim F(1,n-2)$\n",
        "\n",
        "-   $F_0 > F(1,n-2;\\alpha) \\to$ 유의수준 $\\alpha$하에서 회귀직선이 유의\n",
        "\n",
        "-   qf$(100(1-\\alpha),1,n-2)$\n",
        "\n",
        "# 회귀직선의 유의성 검정\n",
        "\n",
        "`-` F-test\n",
        "\n",
        "-   가설: $H_0: \\beta_1 = 0 \\ vs \\ H_1:\\beta_1 \\neq 0$\n",
        "\n",
        "-   검정통계량\n",
        "    $F=\\dfrac{MSR}{MSE}=\\dfrac{SSR/1}{SSE/(n-2)} \\sim_{H_0} F(1,n-2)$\n",
        "\n",
        "-   유의수준 $\\alpha$에서 기각역: $F_0 \\geq F_\\alpha(1,n-2)$\n",
        "\n",
        "-   유의확률 = $P(F \\geq F_0)$\n",
        "\n",
        "# 회귀계수에 대한 추론\n",
        "\n",
        "## $\\beta_1$에 대한 추론\n",
        "\n",
        "$$\\widehat \\beta_1 = \\dfrac{S_{(xy)}}{S_{(xx)}}$$\n",
        "\n",
        "분자\n",
        "$S_{(xy)}= \\sum(x_i - \\bar x)(y_i - \\bar y) = \\sum(x_i - \\bar x)y_i - \\sum(x_i- \\bar x)\\bar y= \\sum(x_i - \\bar x)y_i$\n",
        "\n",
        "$\\widehat \\beta_1 = \\dfrac{S_{(xy)}}{S_{(xx)}}=\\dfrac{\\sum(x_i-\\bar x)y_i}{S_{(xx)}}=\\sum \\dfrac{x_i- \\bar x}{S_{(xx)}} y_i= \\sum a_i y_i$\n",
        "\n",
        "$$\\widehat \\beta_1 \\sim N(\\beta_1, \\dfrac{\\sigma^2}{S_{(xx)}})$$\n",
        "\n",
        "`-` $E(\\widehat \\beta_1)=\\beta_1$ : 불편추정량(unbiase-)\n",
        "\n",
        "-   $E(\\widehat \\beta_1)$\n",
        "\n",
        "= $\\sum a_i E(y_i)$\n",
        "\n",
        "= $\\sum \\dfrac{(x_i - \\bar x)}{S_{xx}}(\\beta_0 + \\beta_1 x_i)$\n",
        "\n",
        "=\n",
        "$\\dfrac{1}{S_{xx}}[\\beta_0 \\sum(x_i - \\bar x) + \\beta_1 \\sum(x_i - \\bar x) x_i]$\n",
        "\n",
        "$\\because \\sum(x_i - \\bar x)=0$\n",
        "\n",
        "$\\because \\sum(x_i - \\bar x)(x_i -\\bar x + \\bar x) = \\sum(x_i- \\bar x)^2 + \\bar x \\sum(x_i - \\bar x) =\\sum(x_i- \\bar x)^2= S_{(xx)}$\n",
        "\n",
        "= $\\dfrac{\\beta_1 S_{xx}}{S_{xx}} = \\beta_1$\n",
        "\n",
        "`-` $Var(\\widehat \\beta_1)$\n",
        "\n",
        "-   $Var(\\widehat \\beta_1)$\n",
        "\n",
        "= $Var(\\sum a_i y_i)$\n",
        "\n",
        "= $\\sum a_i^2 Var(y_i)$\n",
        "\n",
        "$\\because Var(y_i)=\\sigma^2$\n",
        "\n",
        "= $\\sigma^2 \\sum a_i^2$\n",
        "\n",
        "= $\\sigma^2 \\sum \\dfrac{(x_i- \\bar x)^2}{S_{xx}^2}$\n",
        "\n",
        "= $\\sigma^2 \\dfrac{S_{xx}}{S_{xx}^2}$\n",
        "\n",
        "= $\\dfrac{\\sigma^2}{S_{xx}}$\n",
        "\n",
        "`-` BLUE\n",
        "\n",
        "-   Best Linear Unbiased Estimation\n",
        "\n",
        "$$\\widehat{Var}(\\widehat \\beta_1) = \\dfrac{MSE}{S_{xx}}$$\n",
        "\n",
        "$$\\widehat \\sigma_{\\widehat \\beta_1} = \\sqrt{\\dfrac{MSE}{S_{xx}}}$$\n",
        "\n",
        "`-` stuendtized $\\widehat \\beta_1$의 분포\n",
        "\n",
        "$$\\dfrac{\\widehat \\beta_1 - \\beta_1}{\\widehat \\sigma / \\sqrt{S_{xx}}} \\sim t(n-2), \\widehat \\sigma = \\sqrt{MSE}$$\n",
        "\n",
        "`-` $\\widehat \\beta_1$의 $100(1-\\alpha)$% 신뢰구간\n",
        "\n",
        "$$\\widehat \\beta_1 \\pm t_{\\alpha/2}(n-2) \\dfrac{\\widehat \\sigma}{\\sqrt{S_{xx}}}$$\n",
        "\n",
        "-   $\\sigma$를 몰라 추정하므로 t분포로 바뀌고 분산이 더 커진다.\n",
        "\n",
        "`-` 모회귀계수(기울기) $\\beta_1$에 대한 추론\n",
        "\n",
        "-   t검정\n",
        "\n",
        "-   $H_0 : \\beta_1 = 0 \\ vs \\  H_1 : \\beta _{1}=\\begin{cases} >0\\\\ \\neq 0\\\\ <0\\end{cases}$\n",
        "\n",
        "-   검정통계량\n",
        "\n",
        "$$\\dfrac{\\widehat \\beta_1 - \\beta_1}{\\widehat \\sigma / \\sqrt{S_{xx}}} \\sim t(n-2)$$\n",
        "\n",
        "## $\\beta_0$에 대한 추론\n",
        "\n",
        "`-` $\\beta_0$의 최소제곱추정량\n",
        "\n",
        "$$\\widehat \\beta_0 = \\bar y - \\widehat \\beta_1 \\bar x$$\n",
        "\n",
        "$$\\widehat \\beta_0 \\sim N(\\beta_0, \\sigma^2(\\dfrac{1}{n} + \\dfrac{\\bar x^2}{S_{xx}}))$$\n",
        "\n",
        "`-` stuendtized $\\widehat \\beta_0$의 분포\n",
        "\n",
        "$$\\dfrac{\\widehat \\beta_0 - \\beta_0}{\\widehat \\sigma_{\\widehat \\beta_0}} \\sim t(n-2)   ,  \\widehat \\sigma_{\\widehat \\beta_0} = \\widehat \\sigma \\sqrt{\\dfrac{1}{n}+\\dfrac{\\bar x^2}{S_{xx}}}$$\n",
        "\n",
        "`-` $\\widehat \\beta_1$의 $100(1-\\alpha)$% 신뢰구간\n",
        "\n",
        "$$\\widehat \\beta_0 \\pm t_{\\alpha/2}(n-2) \\widehat \\sigma \\sqrt{\\dfrac{1}{n}+\\dfrac{\\bar x^2}{S_{xx}}}$$\n",
        "\n",
        "# 평균반응예측\n",
        "\n",
        "`-` $x=x_0$가 주어졌을 때 평균 반응 예측(prediction)\n",
        "\n",
        "`-` 평균반응\n",
        "\n",
        "$$\\mu_0 = E(Y|x_0)=\\beta_0+\\beta_1x_0$$\n",
        "\n",
        "`-` 평균반응 추정량\n",
        "\n",
        "$$\\widehat \\mu_0 = \\widehat \\beta_0 + \\widehat \\beta_1 x_0$$\n",
        "\n",
        "$$\\widehat \\mu_0 \\sim N(\\mu_0, \\sigma^2(\\dfrac{1}{n} + \\dfrac{(x_0 - \\bar x)^2}{S_{xx}}))$$\n",
        "\n",
        "`-` stuendtized $\\widehat \\mu_0$의 분포\n",
        "\n",
        "$$\\dfrac{\\widehat \\mu_0 - \\mu_0}{\\widehat \\sigma_{\\widehat \\mu_0}} \\sim t(n-2) \\ , \\ \\widehat \\sigma_{\\widehat \\mu_0} = \\widehat \\sigma \\sqrt{\\dfrac{1}{n}+\\dfrac{(x_0 - \\bar x)^2}{S_{xx}}}$$\n",
        "\n",
        "`-` $\\widehat \\mu_0$의 $100(1-\\alpha)$% 신뢰구간\n",
        "\n",
        "$$\\widehat \\mu_0 \\pm t_{\\alpha/2}(n-2) \\widehat \\sigma \\sqrt{\\dfrac{1}{n}+\\dfrac{(x_0 - \\bar x)^2}{S_{xx}}}$$\n",
        "\n",
        "# 개별적인 $y$값 예측\n",
        "\n",
        "$y_0 = \\beta_0 + \\beta_1 x_0 + \\epsilon_0$\n",
        "\n",
        "-   예측값: $\\widehat y_0 = \\widehat \\beta_0 + \\widehat \\beta_1 x_0$\n",
        "\n",
        "$$\\widehat y_0 \\sim N(\\mu_0, (1+\\dfrac{1}{n}+\\dfrac{(x_0 - \\bar x)^2}{S_{xx}})\\sigma^2)$$\n",
        "\n",
        "-   분산에 있는 1+~ 의 1은 $\\widehat e$ 때문에 생김.ㅡ\n",
        "\n",
        "`-` stuendtized $\\widehat y_0$의 분포\n",
        "\n",
        "$$\\dfrac{\\widehat y_0 - y_0}{\\widehat \\sigma_{\\widehat y_0}} \\sim t(n-2) \\ , \\ \\widehat \\sigma_{\\widehat y_0} = \\widehat \\sigma \\sqrt{1+\\dfrac{1}{n}+\\dfrac{(x_0 - \\bar x)^2}{S_{xx}}}$$\n",
        "\n",
        "`-` $\\widehat y_0$의 $100(1-\\alpha)$% 신뢰구간\n",
        "\n",
        "$$\\widehat y_0 \\pm t_{\\alpha/2}(n-2) \\widehat \\sigma_{\\widehat y_0}$$\n",
        "\n",
        "# 잔차\n",
        "\n",
        "-   residual\n",
        "\n",
        "-   $e_i = \\widehat \\epsilon_i = y_i - \\widehat y_i, i=1,\\dots,n$\n",
        "\n",
        "`-` 잔차의 성질\n",
        "\n",
        "-   잔차의 합은 0이다 ($\\sum_{i=1}^n e_i = 0$)\n",
        "\n",
        "-   $\\sum_{i=1}^n e_i^2$은 최소값을 갖는다.\n",
        "    ($\\widehat \\beta_0,\\widehat \\beta_1$:minimize LSE)\n",
        "\n",
        "-   잔차의 $x_i$에 의한 가중합은 0이다. ($\\sum_{i=1}^n x_i e_i = 0$)\n",
        "\n",
        "-   잔차의 $\\widehat y_i$에 의한 가중합은 0이다.\n",
        "    ($\\sum_{i=1}^n \\widehat y_i e_i = 0$)\n",
        "\n",
        "-   ($\\bar x, \\bar y$)는 적합된 휘귀직선 위에 있다.\n",
        "\n",
        "1.  선형성(0을 대칭으로 잘 펴져있는지)\n",
        "\n",
        "2.  등분산성\n",
        "\n",
        "3.  정규성(표준화)\n",
        "\n",
        "$e \\to \\dfrac{e- \\bar e}{s.e(e)} \\sim N(0,1)$\n",
        "\n",
        "1.  독립성\n",
        "\n",
        "# Durbin-Waston Test\n",
        "\n",
        "`-` 가정\n",
        "\n",
        "$H_0$:오차항들은 독립이다.\n",
        "\n",
        "vs\n",
        "\n",
        "$H_1$: 오차항들은 독립이 아니다.\n",
        "\n",
        "$H_1$: 오차항들은 양의 상관관계를 갖는다.\n",
        "\n",
        "$H_1$: 오차항들은 음의 상관관계를 갖는다.\n",
        "\n",
        "`-` 검정통계량\n",
        "\n",
        "$$d= \\dfrac{\\sum_{t=2}^n(e_t - e_{t-1})^2}{\\sum_{t=1}^n e_t^2}$$\n",
        "\n",
        "-   0~4의 값\n",
        "\n",
        "-   4에 가까울수록 음의상관관계가 큼\n",
        "\n",
        "-   2에 가까울수록 양의상관관계가 큼\n",
        "\n",
        "-   2는 기준으로 2에 가까우면 결정 보류"
      ],
      "id": "89a512af-1d35-4639-8bd6-da1923f6cf01"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  }
}